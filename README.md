# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-08 05:55:13 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [SQ-format: A Unified Sparse-Quantized Hardware-friendly Data Format for LLMs](https://arxiv.org/abs/2512.05409)

**Authors**: Ruixuan Huang, Hao Zeng, Hantao Huang, Jinyuan Shi, Minghui Yu, Ian En-Hsu Yen, Shuai Wang  
**Category**: cs.CL  
**Published**: 2025-12-08  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.05409v1  

#### Abstract
Post-training quantization (PTQ) plays a crucial role in the democratization of large language models (LLMs). However, existing low-bit quantization and sparsification techniques are difficult to balance accuracy and efficiency due to the limited hardware support. For example, W4A8 can only achieve ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSQ-format: A Unified Sparse-Quantized Hardware-friendly Data Format for LLMs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨éƒ¨ç½²æ—¶é¢ä¸´**ç²¾åº¦ä¸æ•ˆç‡éš¾ä»¥å…¼é¡¾**çš„é—®é¢˜ã€‚å°½ç®¡ Post-Training Quantization (PTQ) å’Œ sparsification æŠ€æœ¯å¯ä»¥å‹ç¼©æ¨¡å‹ï¼Œä½†å­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š

- **ç¡¬ä»¶æ”¯æŒä¸è¶³**ï¼šç°æœ‰çš„ä½æ¯”ç‰¹é‡åŒ–ï¼ˆå¦‚ W4A8ï¼‰åœ¨ç°ä»£ GPU ä¸Šæ— æ³•å‘æŒ¥ç†è®ºååä¼˜åŠ¿ï¼Œå› ä¸ºç¼ºä¹å¯¹æ··åˆç²¾åº¦æ“ä½œï¼ˆå¦‚ INT4 Ã— INT8ï¼‰çš„åŸç”Ÿæ”¯æŒï¼Œé€šå¸¸ä¼šå›é€€åˆ°æ›´é«˜ç²¾åº¦è·¯å¾„ï¼ˆå¦‚ W8A8ï¼‰ï¼Œå¯¼è‡´æ€§èƒ½å¢ç›Šæ¶ˆå¤±ã€‚
- **é™æ€ç¨€ç–æ ¼å¼çµæ´»æ€§å·®**ï¼šä¾‹å¦‚ NVIDIA çš„ 2:4 semi-structure sparse è™½ç„¶ç¡¬ä»¶å‹å¥½ï¼Œä½†éš¾ä»¥é€‚åº” LLM ä¸­æƒé‡å’Œæ¿€æ´»å€¼ä¸­â€œéå‡åŒ€ä¿¡æ¯åˆ†å¸ƒâ€çš„ç‰¹æ€§ï¼ˆoutlier å­˜åœ¨ï¼‰ï¼Œå¯¼è‡´ç²¾åº¦æ˜¾è‘—ä¸‹é™ã€‚
- **åŠ¨æ€å‹ç¼©å¼€é”€é«˜**ï¼šåŸºäºè¿è¡Œæ—¶é€‰æ‹©é‡è¦å…ƒç´ çš„æ–¹æ³•ï¼ˆå¦‚ TopKï¼‰å¼•å…¥é¢å¤–è®¡ç®—å¼€é”€ï¼Œå½±å“å®é™…æ¨ç†é€Ÿåº¦ã€‚

è¿™äº›é—®é¢˜å…±åŒé€ æˆäº† **â€œç®—æ³•-ç¡¬ä»¶é¸¿æ²Ÿâ€ï¼ˆhardware-algorithm gapï¼‰**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„ç¨€ç–-é‡åŒ–æ•°æ®æ ¼å¼ â€”â€” **Sparse-Quantized Format (SQ-format)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> å°†ä¸€ä¸ªå¼ é‡åˆ’åˆ†ä¸º**é«˜ç²¾åº¦ç¨€ç–éƒ¨åˆ†**ï¼ˆä¿ç•™å…³é”®å€¼ï¼‰å’Œ**ä½ç²¾åº¦å¯†é›†éƒ¨åˆ†**ï¼ˆå‹ç¼©æ™®é€šå€¼ï¼‰ï¼Œå¹¶ä»¥ä¸€ç§**ç¡¬ä»¶å‹å¥½çš„æ–¹å¼ç»„ç»‡å­˜å‚¨å’Œè®¡ç®—**ã€‚

#### æ ¸å¿ƒè®¾è®¡ç‰¹ç‚¹ï¼š
- **ç»Ÿä¸€æ ¼å¼**ï¼šåŒæ—¶æ”¯æŒé‡åŒ–ï¼ˆquantizationï¼‰ä¸ç¨€ç–åŒ–ï¼ˆsparsificationï¼‰ï¼Œé€‚ç”¨äº weights æˆ– activationsã€‚
- **Bank-based ç»“æ„**ï¼šå°†çŸ©é˜µæŒ‰å›ºå®šå¤§å° `bank` åˆ†å—ï¼Œæ¯å—å†…å›ºå®šç¨€ç–åº¦ `s`ï¼Œé¿å…è´Ÿè½½ä¸å‡è¡¡å’Œå¤æ‚ç´¢å¼•ã€‚
- **åŒè·¯å¾„è®¡ç®—**ï¼šåˆ©ç”¨ tensor cores å¹¶è¡Œå¤„ç†é«˜ç²¾åº¦ï¼ˆsparseï¼‰å’Œä½ç²¾åº¦ï¼ˆdenseï¼‰éƒ¨åˆ†ï¼Œé€šè¿‡ä¸“ç”¨ç¡¬ä»¶å•å…ƒï¼ˆgather/scatterï¼‰åè°ƒã€‚
- **é™æ€æ¿€æ´»ç­–ç•¥**ï¼šä¸ºè§£å†³åŠ¨æ€ TopK å¼€é”€ï¼Œæå‡ºåŸºäºæ ¡å‡†é›†é¢„ç”Ÿæˆ mask çš„ **static SQ-format on activations**ï¼Œå®ç°é›¶è¿è¡Œæ—¶å¼€é”€ã€‚

è¯¥æ ¼å¼å¯çœ‹ä½œæ˜¯å¯¹ NVIDIA 2:4 sparse çš„æ³›åŒ–æ‰©å±•ï¼ˆå½“ `s=0.5`, `h_low=0`, `b=4` æ—¶é€€åŒ–ä¸º 2:4 sparseï¼‰ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | SQ-format ä¼˜åŠ¿ |
|------|----------------|
| **ç²¾åº¦-æ•ˆç‡æƒè¡¡** | å®ç°äº† Pareto æ”¹è¿›ï¼šåœ¨æ¥è¿‘ W4A8 ç²¾åº¦çš„åŒæ—¶ï¼Œè¾¾åˆ° W4A4 çº§åˆ«çš„ååã€‚ |
| **ç¡¬ä»¶å…¼å®¹æ€§** | å¯åœ¨ç°æœ‰ GPU ä¸Šæ¨¡æ‹Ÿè¿è¡Œï¼Œå¹¶ä¸ºä¸‹ä¸€ä»£ AI åŠ é€Ÿå™¨æä¾› co-design è“å›¾ã€‚ |
| **çµæ´»æ€§** | æ”¯æŒå¤šç§ `(h_high/h_low)` é…ç½®ï¼ˆå¦‚ INT8/INT4, INT8/INT2ï¼‰å’Œ sparsity è®¾ç½®ã€‚ |
| **ç³»ç»Ÿå¼€é”€ä½** | é™æ€ç­–ç•¥ä»…éœ€æå°é¢å¤–å­˜å‚¨ï¼ˆå¦‚ Llama-3-70B ä»… 5.94MBï¼‰ã€‚ |
| **ç¨³å®šæ€§å¼º** | åœ¨å¤§æ¨¡å‹ï¼ˆLlama-3-70B, Qwen-3-30Bï¼‰ä¸Šè¡¨ç°æ›´ä¼˜ï¼Œå°¤å…¶ç”Ÿæˆä»»åŠ¡å‡†ç¡®ç‡æå‡æ˜æ˜¾ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**

#### **æ¨¡å‹**
- **Dense LLMs**: Llama-3-8B, Llama-3-70B
- **MoE Model**: Qwen-3-30B-A3B
- **è¶…å¤§è§„æ¨¡æ¨¡å‹éªŒè¯**: DeepSeek-R1 (685B)

#### **è¯„ä¼°æ•°æ®é›†**
- **éç”Ÿæˆç±»ä»»åŠ¡ï¼ˆzero-shotï¼‰**:
  - ARC-easy/challenge, PIQA, Hellaswag, Winogrande, OpenBookQA
- **ç”Ÿæˆç±»ä»»åŠ¡**:
  - GSM8k (8-shot), AGIEval (zero-shot)
- **å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰æµ‹è¯•**:
  - Wikitext, Lambada

ä½¿ç”¨ `lm-evaluation-harness` è¿›è¡Œç»Ÿä¸€è¯„æµ‹ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **é‡åŒ–é…ç½®è¡¨ç¤ºæ³•**
- `W(SQx)Ay`: æƒé‡ä½¿ç”¨ SQ-formatï¼Œç­‰æ•ˆæ¯”ç‰¹æ•°ä¸º `x`ï¼Œæ¿€æ´»ä½¿ç”¨ INTy
- `WxA(SQy)`: æ¿€æ´»ä½¿ç”¨ SQ-formatï¼Œç­‰æ•ˆæ¯”ç‰¹æ•°ä¸º `y`
- ç¤ºä¾‹ï¼š`B-(8/4)=0.5` è¡¨ç¤º bank size=64, h_high=INT8, h_low=INT4, sparsity=0.5ï¼ˆå³ 2x sparseï¼‰

#### **æ ¡å‡†é›†ï¼ˆCalibration Setï¼‰**
- ä½¿ç”¨ Wikitext ä¸­éšæœºé‡‡æ ·çš„ 32 ä¸ªæ–‡æœ¬æ®µï¼Œæ¯æ®µ 2048 tokensã€‚

#### **æœç´¢ç©ºé—´**
- Bank size: {4, 8, 16, 32, 64, 128}
- Sparsity: {0.5, 0.75, 0.875, 0.9375}ï¼ˆå¯¹åº” 2x åˆ° 16x ç¨€ç–ï¼‰
- h_high/h_low: å¤šç§ç»„åˆï¼ˆå¦‚ 8/4, 8/3, 8/2, 4/2ï¼‰

é€‰å–æœ€ä¼˜ç»“æœæŠ¥å‘Šï¼Œå®Œæ•´ç½‘æ ¼è§é™„å½•ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| ç±»å‹ | åŸºçº¿æ–¹æ³• |
|------|--------|
| **PTQ æ–¹æ³•** | GPTQ, SmoothQuant, SpinQuant |
| **ç¨€ç–åŒ–æ–¹æ³•** | SpQR, SparseGPT |
| **åŸºå‡†é…ç½®** | W4A8, W4A4, W8A8, BF16 |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ª Table 1 & Dï¼‰**

| æ–¹æ³• | æ¨¡å‹ | Non-gen Avg (%) | Gen Avg (%) | Perplexity â†“ | Speedup vs W4A8 |
|------|------|------------------|-------------|---------------|------------------|
| **BF16** | Llama-3-70B | 75.6 | 63.36 | 2.92 / 2.58 | 1.00Ã— |
| **W4A8** | Llama-3-70B | 72.6 | 61.68 | 3.48 / 2.61 | 1.00Ã— |
| **W4A4** | Llama-3-70B | 68.9 | 55.71 | 4.58 / 2.98 | **1.92Ã—** |
| **SQ W4A(SQ6)** | Llama-3-70B | **72.8** | **61.5** | **3.31 / 2.65** | **1.71Ã—** |
| **SQ W(SQ6)A4** | Llama-3-70B | 71.5 | 59.73 | 3.79 / 2.66 | â€” |

> æ³¨ï¼šSQ W4A(SQ6) åœ¨ä¿æŒä¸ W4A8 æ¥è¿‘ç²¾åº¦çš„åŒæ—¶ï¼Œè·å¾— **1.71Ã— é€Ÿåº¦æå‡**ï¼Œæ¥è¿‘ W4A4 çš„ç†è®ºæé™ï¼ˆ1.92Ã—ï¼‰ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### âœ… **ä¼˜äºä¸»æµ PTQ æ–¹æ³•**
- åœ¨ Llama-3-70B ä¸Šï¼Œ`W4A(SQ6)` çš„å¹³å‡ non-gen å‡†ç¡®ç‡æ¯” GPTQ é«˜çº¦ 0.3%ï¼Œä¸” perplexity æ›´ä½ã€‚
- ç›¸æ¯” SmoothQuant å’Œ SpinQuantï¼ŒSQ-format æ˜¾è‘—æ›´ç¨³å®šï¼Œå°¤å…¶åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šé¿å…å´©æºƒï¼ˆå¦‚ SmoothQuant åœ¨ W4A4 ä¸‹ GSM8k ä¸º 0%ï¼‰ã€‚

#### âœ… **ä¼˜äºç¨€ç–åŒ–æ–¹æ³•**
- SpQR å’Œ SparseGPT åœ¨ W4A16 æˆ–å…¨ç²¾åº¦ä¸‹ä»æŸå¤±è¾ƒå¤§ç²¾åº¦ï¼ˆå¦‚ SparseGPT åœ¨ Llama-3-8B ä¸Š ARC-c ä» 53.41â†’31.74ï¼‰ã€‚
- SQ-format åœ¨åŒç­‰ç¨€ç–åº¦ä¸‹ç²¾åº¦è¿œè¶…è¿™äº›æ–¹æ³•ã€‚

#### âœ… **å®ç° Pareto æœ€ä¼˜**
- å¦‚ Figure 5 æ‰€ç¤ºï¼ŒSQ-format æˆåŠŸå¡«è¡¥äº† W4A8ï¼ˆé«˜ç²¾åº¦ä½é€Ÿï¼‰ä¸ W4A4ï¼ˆé«˜é€Ÿä½ç²¾åº¦ï¼‰ä¹‹é—´çš„ç©ºç™½ï¼Œåœ¨ç²¾åº¦å‡ ä¹æ— æŸçš„å‰æä¸‹å¤§å¹…æå‡ååã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰**é™æ€ vs åŠ¨æ€æ¿€æ´» SQ-formatï¼ˆTable 2ï¼‰**
- é™æ€ç­–ç•¥æ€§èƒ½ä¸åŠ¨æ€ç­–ç•¥ç›¸å·® <1%ï¼Œè¯´æ˜é¢„ç”Ÿæˆ mask å…·å¤‡è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚
- é™æ€ç­–ç•¥æ›´é€‚åˆéƒ¨ç½²ï¼Œæ— éœ€è¿è¡Œæ—¶ TopKï¼Œé€‚åˆ GPU å®ç°ã€‚

#### ï¼ˆ2ï¼‰**Bank Size ä¸ Sparsity å½±å“ï¼ˆFigures 7 & 8ï¼‰**
- **Bank size è¿‡å°ï¼ˆå¦‚ 4ï¼‰** å¯¼è‡´ç²¾åº¦åˆ†åŒºä¸çµæ´»ï¼Œä½ç²¾åº¦éƒ¨åˆ†ä»å« outlierï¼Œæ•ˆæœå·®ã€‚
- **æ¨è bank size â‰¥ 32**ï¼Œå°¤å…¶å¯¹äº weightsï¼›activations å¯¹ bank size æ•æ„Ÿåº¦è¾ƒä½ã€‚
- **Sparsity è¶Šé«˜è¶Šå¥½**ï¼Œä½†å—é™äºç¡¬ä»¶ç®—åŠ›å¹³è¡¡ï¼ˆå¦‚ W8A8 æ˜¯ W4A4 çš„ 4 å€ï¼Œåˆ™ sparsity è‡³å°‘éœ€ 0.75 æ‰èƒ½æ©ç›–é«˜ç²¾åº¦è·¯å¾„å»¶è¿Ÿï¼‰ã€‚

#### ï¼ˆ3ï¼‰**ä¸åŒ h_high/h_low é…ç½®**
- `INT8/INT4` è¡¨ç°æœ€ä½³ï¼›
- `INT8/INT3` å¯ä½œä¸ºæŠ˜ä¸­æ–¹æ¡ˆï¼›
- `INT8/INT2` ä»…åœ¨ä½ sparsity ä¸‹å¯ç”¨ï¼Œå¦åˆ™ç²¾åº¦ä¸¥é‡ä¸‹é™ã€‚

#### ï¼ˆ4ï¼‰**FP æ ¼å¼éªŒè¯ï¼ˆTable 8ï¼‰**
- åœ¨ DeepSeek-R1 ä¸Šåº”ç”¨ `W(SQ5)A8`ï¼ˆFP8/FP4ï¼‰ï¼š
  - æ€§èƒ½å‡ ä¹æ— æŸï¼ˆå¦‚ GSM8k: 95.83 â†’ 96.21ï¼‰
  - å±•ç°å‡ºå¼ºå¤§çš„å¯æ‰©å±•æ€§å’Œè·¨æ•°æ®ç±»å‹é€‚ç”¨æ€§ã€‚

#### ï¼ˆ5ï¼‰**ç¡¬ä»¶åˆæˆåˆ†æï¼ˆTable 9ï¼‰**
- ç›¸æ¯”æ ‡å‡† INT6 MAC é˜µåˆ—ï¼ŒSQ-format å•å…ƒæ€»é¢ç§¯å‡å°‘ **35.8%**ï¼Œè¯æ˜å…¶ç‰©ç†å®ç°é«˜æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **SQ-format å®ç°äº†ç²¾åº¦ä¸ååçš„ Pareto æ”¹è¿›**ï¼š
   - åœ¨ Llama-3-70B ä¸Šå®ç° **1.71Ã— é€Ÿåº¦æå‡**ï¼ŒåŒæ—¶ä¿æŒæ¥è¿‘ W4A8 çš„ç²¾åº¦ã€‚
   - ååé€¼è¿‘ W4A4 æé™ï¼ˆ~89%ï¼‰ï¼Œä½†ç²¾åº¦é«˜å‡º 3.9 ä¸ªç™¾åˆ†ç‚¹ã€‚

2. âœ… **é™æ€æ¿€æ´»ç­–ç•¥å¯è¡Œä¸”é«˜æ•ˆ**ï¼š
   - åŸºäº activation-weight product è´¡çŒ®é¢„å…ˆç”Ÿæˆ maskï¼Œæ€§èƒ½åª²ç¾åŠ¨æ€æ–¹æ³•ã€‚
   - æ¶ˆé™¤ TopK å¼€é”€ï¼Œæ›´é€‚åˆç¡¬ä»¶éƒ¨ç½²ã€‚

3. âœ… **Bank-based è®¾è®¡ä¼˜äºä¼ ç»Ÿç¨€ç–æ¨¡å¼**ï¼š
   - å›ºå®š bank å’Œ sparsity æå‡ç¡¬ä»¶è°ƒåº¦æ•ˆç‡ï¼Œé¿å… unstructured sparse çš„è´Ÿè½½ä¸å‡é—®é¢˜ã€‚
   - æ¯” 2:4 semi-structure sparse æ›´çµæ´»ï¼Œèƒ½æ›´å¥½æ•æ‰ä¿¡æ¯åˆ†å¸ƒã€‚

4. âœ… **å…·å¤‡è‰¯å¥½çš„é€šç”¨æ€§å’Œæ‰©å±•æ€§**ï¼š
   - æ”¯æŒ INT å’Œ FP æ ¼å¼ï¼ˆå·²éªŒè¯ FP8/FP4ï¼‰ã€‚
   - åœ¨ä¸åŒè§„æ¨¡æ¨¡å‹ï¼ˆ8B~685Bï¼‰ä¸Šå‡æœ‰æ•ˆã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–ä¸“ç”¨ç¡¬ä»¶æ‰èƒ½å®Œå…¨é‡Šæ”¾æ½œåŠ›**ï¼š
   - å½“å‰åœ¨ GPU ä¸Šä¸ºæ¨¡æ‹Ÿå®ç°ï¼ŒçœŸå®åŠ é€Ÿéœ€å®šåˆ¶ç¡¬ä»¶æ”¯æŒï¼ˆå¦‚ Figure 2a æ‰€ç¤ºçš„ gather unitï¼‰ã€‚
   - åŠ¨æ€ç­–ç•¥è‹¥æ— ä¸“ç”¨ pipeline å•å…ƒï¼Œä»ä¾èµ– CUDA core è®¡ç®— maskã€‚

2. **æç«¯ä½æ¯”ç‰¹ï¼ˆå¦‚ INT2ï¼‰æ”¯æŒæœ‰é™**ï¼š
   - `h_low=INT2` æ—¶å³ä½¿å¼•å…¥é«˜ç²¾åº¦è¡¥å¿ä¹Ÿéš¾ç»´æŒç²¾åº¦ï¼Œé™åˆ¶äº†æè‡´å‹ç¼©åœºæ™¯ã€‚

3. **bank size é€‰æ‹©éœ€æƒè¡¡çµæ´»æ€§ä¸é¢ç§¯æˆæœ¬**ï¼š
   - å¤§ bank sizeï¼ˆå¦‚ 128ï¼‰è™½æ›´çµæ´»ï¼Œä½†å¢åŠ  MUX å’Œæ§åˆ¶é€»è¾‘å¼€é”€ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ¨åŠ¨ SQ-format æˆä¸ºä¸‹ä¸€ä»£ AI åŠ é€Ÿå™¨çš„æ ‡å‡†æŒ‡ä»¤é›†æ‰©å±•**ã€‚
2. **æ¢ç´¢æ›´å¤š h_high/h_low ç»„åˆä¸è‡ªé€‚åº” sparsity æ§åˆ¶æœºåˆ¶**ã€‚
3. **å°† SQ-format åº”ç”¨äºè®­ç»ƒé˜¶æ®µï¼ˆQATï¼‰ä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½**ã€‚
4. **ç»“åˆ MoE æ¶æ„ä¼˜åŒ–ä¸“å®¶ç¨€ç–è·¯ç”±ä¸å‚æ•°å‹ç¼©ååŒè®¾è®¡**ã€‚

---

## æ€»ç»“

> SQ-format æå‡ºäº†ä¸€ç§**ç®—æ³•-ç¡¬ä»¶ååŒè®¾è®¡çš„æ–°èŒƒå¼**ï¼Œé€šè¿‡å°†ç¨€ç–åŒ–ä¸é‡åŒ–ç»Ÿä¸€åœ¨ä¸€ä¸ªç¡¬ä»¶å‹å¥½çš„æ ¼å¼ä¸­ï¼ŒæˆåŠŸæ‰“ç ´äº† PTQ ä¸­é•¿æœŸå­˜åœ¨çš„â€œç²¾åº¦-æ•ˆç‡æ‚–è®ºâ€ã€‚å®ƒä¸ä»…ä¸ºå½“å‰ LLM éƒ¨ç½²æä¾›äº†å®ç”¨é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œä¹Ÿä¸ºæœªæ¥ AI èŠ¯ç‰‡æ¶æ„è®¾è®¡æŒ‡æ˜äº†æ–¹å‘â€”â€”**ç»†ç²’åº¦ã€æ··åˆç²¾åº¦ã€ç»“æ„åŒ–ç¨€ç–å°†æˆä¸ºä¸»æµ**ã€‚

</details>

---

### 2. [When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation](https://arxiv.org/abs/2512.05341)

**Authors**: Yiwen Liang, Qiufeng Li, Shikai Wang, Weidong Cao  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.05341v1  

#### Abstract
Large Language Models (LLMs) have shown strong potential in accelerating digital hardware design through automated code generation. Yet, ensuring their reliability remains a critical challenge, as existing LLMs trained on massive heterogeneous datasets often exhibit problematic memorization of propr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ç”¨äºç¡¬ä»¶ä»£ç ç”Ÿæˆçš„ **Large Language Models (LLMs)** åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½è®°å¿†äº†ä»¥ä¸‹ä¸‰ç±»æœ‰å®³å†…å®¹ï¼š
- **ä¸“æœ‰çŸ¥è¯†äº§æƒ (IP)**ï¼šå¯¼è‡´æ½œåœ¨çš„æ³•å¾‹é£é™©å’Œæ³„éœ²ï¼›
- **è¢«æ±¡æŸ“çš„åŸºå‡†æµ‹è¯•æ•°æ®**ï¼šå½±å“æ¨¡å‹è¯„ä¼°çš„å…¬å¹³æ€§å’Œå¯ä¿¡åº¦ï¼›
- **ä¸å®‰å…¨çš„ç¼–ç æ¨¡å¼**ï¼šå¼•å…¥åŠŸèƒ½é”™è¯¯æˆ–å®‰å…¨éšæ‚£ã€‚

è¿™äº›é—®é¢˜ä¸¥é‡å¨èƒäº† LLM åœ¨æ•°å­—ç¡¬ä»¶è®¾è®¡ä¸­çš„**å¯é æ€§ä¸å®‰å…¨æ€§**ã€‚ä¼ ç»Ÿçš„â€œä»å¤´é‡è®­â€æ–¹æ³•æˆæœ¬è¿‡é«˜ï¼ˆå¦‚ LLaMA-3 éœ€ç™¾ä¸‡çº§ GPU å°æ—¶ï¼‰ï¼Œè€Œé€šç”¨çš„æœºå™¨é—å¿˜ï¼ˆmachine unlearningï¼‰æ–¹æ³•åœ¨åº”ç”¨äºç¡¬ä»¶æè¿°è¯­è¨€ï¼ˆHDLï¼‰æ—¶ä¼šç ´åè¯­æ³•æ­£ç¡®æ€§ï¼Œå¯¼è‡´ç”Ÿæˆä¸å¯ç»¼åˆï¼ˆnon-synthesizableï¼‰çš„ RTL ä»£ç ã€‚

å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨è§£å†³ï¼š**å¦‚ä½•é«˜æ•ˆã€å¯é åœ°è®© LLM â€œå¿˜è®°â€ç‰¹å®šæœ‰å®³çŸ¥è¯†ï¼ŒåŒæ—¶ä¿æŒå…¶é«˜è´¨é‡ç¡¬ä»¶ä»£ç ç”Ÿæˆèƒ½åŠ›ï¼Ÿ**

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡ºäº†é¦–ä¸ªé¢å‘ç¡¬ä»¶ä»£ç ç”Ÿæˆä»»åŠ¡çš„**é¢†åŸŸå®šåˆ¶åŒ– LLM é—å¿˜æ¡†æ¶**ï¼Œæ ¸å¿ƒåŒ…å«ä¸¤å¤§æŠ€æœ¯åˆ›æ–°ï¼š

#### âœ… åˆ›æ–°ç‚¹ä¸€ï¼šSyntax-Preserving Unlearningï¼ˆè¯­æ³•ä¿æŒå‹é—å¿˜ï¼‰
- **åŠ¨æœº**ï¼šRTL ä»£ç å…·æœ‰ä¸¥æ ¼çš„è¯­æ³•ç»“æ„ï¼ˆå¦‚ `always @(posedge clk)`ã€`module/endmodule` ç­‰ï¼‰ï¼Œè‹¥é—å¿˜è¿‡ç¨‹ä¸­ä¿®æ”¹è¿™äº›å…³é”®è¯æˆ–ç»“æ„ï¼Œä¼šå¯¼è‡´ç”Ÿæˆä»£ç æ— æ³•ç¼–è¯‘ã€‚
- **æ–¹æ³•**ï¼š
  - å¼•å…¥ **keyword masking**ï¼šå¯¹ Verilog å…³é”®å­—ï¼ˆå¦‚ `wire`, `reg`, `assign`ï¼‰è¿›è¡Œä¿æŠ¤ï¼Œä½¿å…¶ä¸å‚ä¸æŸå¤±è®¡ç®—ï¼›
  - è®¾è®¡ **skip-tag masking**ï¼šç”¨ `<SKIP_S>` å’Œ `<SKIP_E>` æ ‡è®°éœ€è·³è¿‡çš„ä»£ç æ®µï¼ˆå¦‚æ•æ„Ÿé€»è¾‘å—ï¼‰ï¼Œé˜²æ­¢å…¶å†…éƒ¨ token è¢«æ›´æ–°ã€‚
- **æ•ˆæœ**ï¼šç¡®ä¿é—å¿˜è¿‡ç¨‹ä¸ä¼šç ´å HDL çš„è¯­æ³•éª¨æ¶ï¼Œç»´æŒç”Ÿæˆä»£ç çš„**å¯ç»¼åˆæ€§ä¸æœ‰æ•ˆæ€§**ã€‚

#### âœ… åˆ›æ–°ç‚¹äºŒï¼šFine-grained Floor-aware Selective Loss (FiFSL)
- **åŠ¨æœº**ï¼šä¼ ç»Ÿé—å¿˜æ–¹æ³•ï¼ˆå¦‚ GAã€NPOï¼‰å¯¹æ‰€æœ‰æ ·æœ¬å‡åŒ€æ–½åŠ é—å¿˜å‹åŠ›ï¼Œå®¹æ˜“é€ æˆè¿‡åº¦é—å¿˜æˆ–æ¢¯åº¦ä¸ç¨³å®šã€‚
- **æ–¹æ³•**ï¼š
  - åœ¨ token çº§åˆ«å®šä¹‰å¸¦ margin çš„è´Ÿåå¥½æŸå¤±ï¼š  
    $$
    \phi_i = \frac{2}{\beta} \text{softplus}(-\beta(L_i - \gamma))
    $$
    å…¶ä¸­ $L_i$ æ˜¯æ ·æœ¬æŸå¤±ï¼Œ$\gamma$ ä¸ºé—å¿˜é˜ˆå€¼ï¼Œæ§åˆ¶ä½•æ—¶å¼€å§‹æ–½åŠ å¼ºé—å¿˜ä¿¡å·ï¼›
  - å¼•å…¥ **hard floor $L_{\min}$**ï¼Œä»…å¯¹æœªå……åˆ†é—å¿˜çš„æ ·æœ¬ï¼ˆ$\phi_i > L_{\min}$ï¼‰åå‘ä¼ æ’­æ¢¯åº¦ï¼›
  - å®ç° **é€‰æ‹©æ€§æ›´æ–°æœºåˆ¶**ï¼šéšç€è®­ç»ƒæ¨è¿›ï¼Œéš¾é—å¿˜æ ·æœ¬æˆä¸ºä¼˜åŒ–é‡ç‚¹ï¼Œå·²é—å¿˜æ ·æœ¬è¢«â€œå…³é—­â€ï¼Œé¿å…æ— æ•ˆæ›´æ–°ã€‚
- **ä¼˜åŠ¿**ï¼šæå‡é—å¿˜æ•ˆç‡ä¸ç¨³å®šæ€§ï¼Œå‡å°‘æ‰€éœ€è®­ç»ƒè½®æ•°ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | æœ¬æ–‡æ–¹æ³•ï¼ˆOursï¼‰ | åŸºçº¿æ–¹æ³•ï¼ˆGA / SimNPOï¼‰ |
|------|------------------|--------------------------|
| **é—å¿˜è§„æ¨¡** | æ”¯æŒé«˜è¾¾ 30% çš„ forget setï¼ˆå³ 3Ã— æ›´å¤§ï¼‰ | è¶…è¿‡ 10% å³å‡ºç°å´©æºƒ |
| **è®­ç»ƒå¼€é”€** | é€šå¸¸åªéœ€ **1 ä¸ª epoch** | éœ€è¦ 4â€“7 ä¸ª epochs |
| **æ¨¡å‹æ•ˆç”¨ä¿ç•™** | Pass@1 æœ€é«˜ä¿ç•™è‡³ 53%ï¼Œè¿œè¶…åŸºçº¿ï¼ˆ<15%ï¼‰ | åŠŸèƒ½æ€§èƒ½æ€¥å‰§ä¸‹é™ |
| **è¯­æ³•æ­£ç¡®æ€§** | æ˜¾å¼ä¿æŠ¤å…³é”®å­—ä¸ç»“æ„ï¼Œä¿è¯ç”Ÿæˆä»£ç å¯ç»¼åˆ | å¿½è§†é¢†åŸŸç‰¹æ€§ï¼Œæ˜“ç ´åè¯­æ³• |
| **å®ç”¨æ€§** | å¯æ‰©å±•è‡³ä¸»æµ LLM æ¶æ„ï¼ˆCodeLlama, DeepSeek, Qwen ç­‰ï¼‰ | ç¼ºä¹é¢†åŸŸé€‚é…ï¼Œåœ¨ç¡¬ä»¶åœºæ™¯è¡¨ç°å·® |

> ç‰¹åˆ«æŒ‡å‡ºï¼šå”¯ä¸€ç›¸å…³å·¥ä½œ SALAD [16] ä½¿ç”¨äº†é€šç”¨é—å¿˜æŠ€æœ¯ï¼Œä½†ç¼ºä¹é¢†åŸŸé€‚åº”ï¼Œå¯¼è‡´æ˜¾è‘—æ•ˆç”¨é€€åŒ–ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ä¸»è®­ç»ƒä¸å¾®è°ƒæ•°æ®é›†**ï¼šRTLCoder æ•°æ®é›†ï¼ˆå¼€æºï¼‰ï¼ŒåŒ…å«è‡ªç„¶è¯­è¨€è®¾è®¡éœ€æ±‚ä¸å¯¹åº” Verilog RTL å®ç°ä¹‹é—´çš„æŒ‡ä»¤-å“åº”å¯¹ã€‚
- **é—å¿˜é›†æ„é€ æ–¹å¼**ï¼šç”±äºæ— å…¬å¼€çš„â€œä¸“æœ‰/æ±¡æŸ“â€ RTL æ•°æ®é›†ï¼Œä½œè€…ä»¿ç…§å…ˆå‰ç ”ç©¶åšæ³•ï¼Œä»è®­ç»ƒé›†ä¸­éšæœºæŠ½å– 10%ã€20%ã€30% çš„æ ·æœ¬ä½œä¸º forget setï¼Œæ¨¡æ‹Ÿ IP æ³„éœ²ã€æ±¡æŸ“æ•°æ®ç­‰çœŸå®åœºæ™¯ã€‚
- **éªŒè¯ä¸æµ‹è¯•é›†**ï¼šRTLCoder çš„ hold-out æµ‹è¯•é›†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹ utilityã€‚

---

### å®éªŒè®¾ç½®
- **æ¨¡å‹é€‰æ‹©**ï¼š
  - CodeLlama-7B-Instruct
  - Llama-3-8B-Instructï¼ˆé€šç”¨æ¨¡å‹ï¼‰
  - DeepSeek-Coder-7B-Instruct
  - Qwen2.5-Coder-7B-Instruct
- **å¾®è°ƒé…ç½®**ï¼š
  - Adam ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ $1\times10^{-5}$ï¼Œæœ€å¤§åºåˆ—é•¿åº¦ 2048ï¼Œbatch size=2ï¼ˆ4Ã—A6000 GPUï¼‰
  - å¾®è°ƒ 6 ä¸ª epochs
- **é—å¿˜é˜¶æ®µè®¾ç½®**ï¼š
  - å­¦ä¹ ç‡ï¼š$2\times10^{-6}$
  - FiFSL å‚æ•°ï¼š$\beta=2.5$, $\gamma=0$, $L_{\min}=0.35$
  - ç›®æ ‡ï¼šä½¿ MinK++ æ¥è¿‘ 0.5ï¼ˆè¡¨ç¤ºæ¥è¿‘æ— è®°å¿†çŠ¶æ€ï¼‰

---

### è¯„ä¼°æŒ‡æ ‡

#### ğŸ”¹ å¿˜è®°è´¨é‡ï¼ˆForget Qualityï¼‰
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **PrivLeak â†“** | è¡¡é‡æ¨¡å‹æ˜¯å¦å†ç”Ÿå‡º forget set ä¸­çš„åŸå§‹ RTL ç‰‡æ®µï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| **MinK++ â†“** | æ£€æµ‹æœ€ä½ k% æ­£ç¡® token çš„å¹³å‡ log-likelihoodï¼Œåæ˜ éšæ€§è®°å¿†ï¼ˆå¦‚å‘½åä¹ æƒ¯ã€æ¨¡æ¿ï¼‰æ®‹ç•™ç¨‹åº¦ï¼›æœªè®­ç»ƒæ¨¡å‹çº¦ä¸º 0.5 |

#### ğŸ”¹ æ¨¡å‹æ•ˆç”¨ï¼ˆModel Utilityï¼‰
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Validation Loss â†“** | åœ¨ä¿ç•™é›†ä¸Šçš„äº¤å‰ç†µæŸå¤±ï¼Œè¡¡é‡é¢„æµ‹å‡†ç¡®æ€§ |
| **Pass@1 â†‘** | ç”Ÿæˆä»£ç èƒ½å¦é€šè¿‡ç¼–è¯‘å¹¶æ»¡è¶³æµ‹è¯•æ¿€åŠ±çš„åŠŸèƒ½æ­£ç¡®æ€§ï¼ˆé»„é‡‘æ ‡å‡†ï¼‰ |
| **BLEU / chrF â†‘** | è¡¡é‡ç”Ÿæˆä»£ç ä¸å‚è€ƒå®ç°çš„ n-gram å’Œå­—ç¬¦çº§ç›¸ä¼¼åº¦ï¼Œåæ˜ é£æ ¼ä¸€è‡´æ€§ |

#### ğŸ”¹ æ³›åŒ–èƒ½åŠ›
- åœ¨ç®€å•æœªè§ä»»åŠ¡ä¸Šæµ‹è¯• Pass@1ï¼ŒéªŒè¯é—å¿˜æ˜¯å¦æŸå®³é€šç”¨ç”Ÿæˆèƒ½åŠ›ï¼›
- åœ¨ **VerilogEval [4]** å’Œ **Rtllm [5]** åŸºå‡†ä¸Šè¯„ä¼°å‰åæ€§èƒ½å˜åŒ–ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Gradient Ascent (GA)** [9]ï¼šæœ€å¤§åŒ– forget set ä¸Šçš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼›
- **SimNPO** [12]ï¼šæ”¹è¿›ç‰ˆ NPOï¼Œå¼•å…¥å¹³æ»‘æƒ©ç½šé¡¹ä»¥å¢å¼ºç¨³å®šæ€§ï¼›
- ä¸¤è€…å‡ä¸ºå½“å‰æœ€å…ˆè¿›çš„é€šç”¨ LLM é—å¿˜æ–¹æ³•ï¼Œå¹¶è¢« SALAD [16] åº”ç”¨äºç¡¬ä»¶è®¾è®¡åœºæ™¯ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ª Table IIï¼‰

| Model | Forget Set | Method | Epochs | MinK++ â†“ | Pass@1 â†‘ | Val Loss â†“ |
|-------|------------|--------|--------|-----------|-----------|-------------|
| Llama-7B | 30% | Ours | **1** | **0.53** | **44%** | **0.32** |
| Llama-7B | 30% | GA | 4 | 0.54 | 3% | 1.00 |
| Llama-7B | 30% | SimNPO | 4 | 0.53 | 1% | 1.00 |
| DeepSeek-7B | 30% | Ours | **1** | **0.45** | **53%** | **0.29** |
| DeepSeek-7B | 30% | GA | 5 | 0.51 | 28% | 1.00 |
| Qwen-7B | 30% | Ours | **1** | **0.49** | **55%** | **0.27** |

> æ³¨ï¼šPass@1 ä¸‹é™ä¸è¶…è¿‡ 2â€“5 ä¸ªç™¾åˆ†ç‚¹ï¼Œè€ŒåŸºçº¿æ–¹æ³•ä¸‹é™è¶…è¿‡ 40 ä¸ªç™¾åˆ†ç‚¹ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å…³é”®å¯¹æ¯”ç»“æœ

- **é—å¿˜èƒ½åŠ›æ›´å¼º**ï¼š
  - æ‰€æœ‰æ¨¡å‹å‡èƒ½æˆåŠŸé—å¿˜ **æœ€å¤š 30% çš„è®­ç»ƒæ•°æ®**ï¼Œè€Œ GA/SimNPO åœ¨ 30% å¿˜è®°é›†ä¸‹å‡ ä¹å®Œå…¨å¤±æ•ˆï¼ˆPass@1 æ¥è¿‘ 0%ï¼‰ï¼›
  - MinK++ æ™®éé™è‡³ 0.5 å·¦å³ï¼Œè¡¨æ˜è®°å¿†å·²è¢«æœ‰æ•ˆæ¸…é™¤ã€‚

- **æ•ˆç”¨ä¿ç•™æ›´ä¼˜**ï¼š
  - åœ¨ 30% å¿˜è®°æ¯”ä¾‹ä¸‹ï¼Œæœ¬æ–‡æ–¹æ³•çš„ **Pass@1 å¹³å‡é«˜å‡ºåŸºçº¿ 14.3Ã—**ï¼›
  - BLEU å’Œ chrF æŒ‡æ ‡åŸºæœ¬ä¸å˜ï¼Œè¯´æ˜ä»£ç é£æ ¼å’Œè¯­æ³•å®Œæ•´æ€§å¾—ä»¥ç»´æŒã€‚

- **è®­ç»ƒæ•ˆç‡æ›´é«˜**ï¼š
  - æœ¬æ–‡æ–¹æ³•å¹³å‡ä»…éœ€ **1 ä¸ª epoch** è¾¾åˆ°ç†æƒ³é—å¿˜æ•ˆæœï¼›
  - GA å’Œ SimNPO éœ€è¦ **4â€“7 ä¸ª epochs**ï¼Œä¸”ä»æ— æ³•å…¼é¡¾é—å¿˜ä¸æ•ˆç”¨ã€‚

- **æ³›åŒ–èƒ½åŠ›ä¸å—æŸ**ï¼š
  - å¦‚ Table II æ‰€ç¤ºï¼Œâ€œGeneralization Abilityâ€åˆ—æ˜¾ç¤ºï¼Œé—å¿˜åæ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šçš„ Pass@1 ä»æ¥è¿‘åŸå§‹æ°´å¹³ï¼›
  - åœ¨ VerilogEval å’Œ Rtllm åŸºå‡†ä¸Šçš„æ€§èƒ½ä¸‹é™æå°ï¼ˆTable IIIï¼‰ï¼Œè¯æ˜ä¸‹æ¸¸ä»»åŠ¡èƒ½åŠ›æœªå—æŸã€‚

---

### æ¶ˆèå®éªŒä¸å‚æ•°åˆ†æï¼ˆæ–‡ä¸­æåŠï¼‰
- å¯¹ $\beta$ï¼ˆæ›²ç‡ï¼‰ã€$\gamma$ï¼ˆmarginï¼‰ã€$L_{\min}$ è¿›è¡Œæœç´¢ï¼Œå‘ç° $\beta=2.5, \gamma=0, L_{\min}=0.35$ æ•ˆæœæœ€ä½³ï¼›
- ç§»é™¤ syntax-preserving masking å¯¼è‡´ç”Ÿæˆä»£ç é¢‘ç¹å‡ºç°è¯­æ³•é”™è¯¯ï¼ˆå¦‚ç¼ºå¤± `endmodule`ï¼‰ï¼›
- ç§»é™¤ FiFSL çš„ selective gating æœºåˆ¶ä¼šå¯¼è‡´æ”¶æ•›å˜æ…¢ã€æ•ˆç”¨ä¸‹é™æ›´å¿«ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é¢†åŸŸå®šåˆ¶åŒ–é—å¿˜è‡³å…³é‡è¦**ï¼šç›´æ¥å°† NLP é—å¿˜æ–¹æ³•è¿ç§»è‡³ç¡¬ä»¶ä»£ç ç”Ÿæˆä¼šå¯¼è‡´ä¸¥é‡æ•ˆç”¨æŸå¤±ï¼›å¿…é¡»ç»“åˆ HDL çš„è¯­æ³•çº¦æŸè¿›è¡Œè®¾è®¡ã€‚
2. **è¯­æ³•ä¿æŠ¤ + ç²¾ç»†æŸå¤±æ§åˆ¶ = é«˜æ•ˆå¯é é—å¿˜**ï¼šSyntax-preserving masking ä¿éšœäº†ç”Ÿæˆä»£ç çš„å¯ç»¼åˆæ€§ï¼ŒFiFSL å®ç°äº†å¿«é€Ÿã€ç¨³å®šã€ç²¾å‡†çš„çŸ¥è¯†ç§»é™¤ã€‚
3. **å¤§è§„æ¨¡é—å¿˜æ˜¯å¯è¡Œçš„**ï¼šæœ¬æ¡†æ¶æ”¯æŒé—å¿˜é«˜è¾¾ **30% çš„è®­ç»ƒæ•°æ®**ï¼ˆçº¦ 3Ã— äºä¼ ç»Ÿæ–¹æ³•ï¼‰ï¼Œé€‚ç”¨äºå®é™…åœºæ™¯ä¸­çš„ IP æ¸…ç†æˆ–æ±¡æŸ“æ•°æ®å‰”é™¤ã€‚
4. **å•è½®è®­ç»ƒå³å¯å®Œæˆé—å¿˜**ï¼šç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•èŠ‚çœå¤§é‡è®¡ç®—èµ„æºï¼Œå…·å¤‡è‰¯å¥½çš„å·¥ç¨‹éƒ¨ç½²æ½œåŠ›ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–äººå·¥è§„åˆ™å®šä¹‰å…³é”®å­—é›†åˆ**ï¼šè™½ç„¶åŸºäº IEEE æ ‡å‡† [32]-[34]ï¼Œä½†ä»éœ€æ‰‹åŠ¨ç»´æŠ¤ keyword list å’Œ skip-tag è§„åˆ™ï¼›
- **forget set éœ€æ˜ç¡®æ ‡æ³¨**ï¼šå‡è®¾å·²çŸ¥å“ªäº›æ•°æ®éœ€è¦é—å¿˜ï¼Œå°šæœªè§£å†³è‡ªåŠ¨æ£€æµ‹â€œæœ‰å®³è®°å¿†â€çš„é—®é¢˜ï¼›
- **ç›®å‰ä»…é™äº Verilog**ï¼šæœªæ‰©å±•è‡³ VHDL æˆ– SystemVerilog é«˜çº§ç‰¹æ€§ï¼›
- **æœªè€ƒè™‘å¤šæ¨¡å—ä¾èµ–å…³ç³»**ï¼šé—å¿˜æŸä¸ªæ¨¡å—æ—¶ï¼Œæœªå¤„ç†å…¶è°ƒç”¨è€…çš„å½±å“ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘è‡ªåŠ¨åŒ–å·¥å…·è¯†åˆ«éœ€é—å¿˜çš„å†…å®¹ï¼ˆå¦‚é€šè¿‡ watermark detection æˆ–ç‰ˆæƒåŒ¹é…ï¼‰ï¼›
- å°†æœ¬æ¡†æ¶æ‰©å±•è‡³å…¶ä»–ç¡¬ä»¶è¯­è¨€ï¼ˆVHDLã€SystemVerilogï¼‰åŠ EDA å­ä»»åŠ¡ï¼ˆtestbench ç”Ÿæˆã€assertion synthesisï¼‰ï¼›
- æ¢ç´¢åœ¨çº¿é—å¿˜æœºåˆ¶ï¼Œæ”¯æŒåŠ¨æ€å¢é‡å¼çŸ¥è¯†æ“¦é™¤ï¼›
- ç»“åˆå½¢å¼éªŒè¯æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥æå‡ç”Ÿæˆä»£ç çš„åŠŸèƒ½å¯é æ€§ä¿è¯ã€‚

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘ç¡¬ä»¶ä»£ç ç”Ÿæˆçš„é¢†åŸŸä¸“ç”¨ LLM é—å¿˜æ¡†æ¶ï¼Œé€šè¿‡ **syntax-preserving masking** å’Œ **FiFSL æŸå¤±å‡½æ•°**ï¼Œå®ç°äº†åœ¨ä»… 1 è½®è®­ç»ƒå†…é—å¿˜ 3Ã— æ›´å¤§æ•°æ®é›†çš„åŒæ—¶ï¼Œä¿æŒç”Ÿæˆä»£ç çš„è¯­æ³•æ­£ç¡®æ€§ä¸åŠŸèƒ½å¯é æ€§ï¼Œä¸ºæ„å»ºå¯ä¿¡ã€åˆè§„çš„ AI è¾…åŠ©èŠ¯ç‰‡è®¾è®¡ç³»ç»Ÿæä¾›äº†å®ç”¨è·¯å¾„ã€‚

</details>

---

### 3. [Uncertainty Quantification for Scientific Machine Learning using Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KAN)](https://arxiv.org/abs/2512.05306)

**Authors**: Y. Sungtaek Ju  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.05306v1  

#### Abstract
Kolmogorov-Arnold Networks have emerged as interpretable alternatives to traditional multi-layer perceptrons. However, standard implementations lack principled uncertainty quantification capabilities essential for many scientific applications. We present a framework integrating sparse variational Ga...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ä¼ ç»ŸåŸºäºå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰çš„ç¥ç»ç½‘ç»œåœ¨ç§‘å­¦æœºå™¨å­¦ä¹ ä¸­ç¼ºä¹**åŸåˆ™æ€§çš„ä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›**ï¼Œä»…æä¾›ç‚¹ä¼°è®¡è€Œæ— æ³•åŒºåˆ†**aleatoric uncertainty**ï¼ˆç”±æµ‹é‡å™ªå£°ç­‰å›ºæœ‰éšæœºæ€§å¼•èµ·ï¼‰å’Œ**epistemic uncertainty**ï¼ˆç”±æ¨¡å‹è®¤çŸ¥ä¸è¶³å¼•èµ·ï¼‰ã€‚å°½ç®¡è´å¶æ–¯ç¥ç»ç½‘ç»œï¼ˆBNNï¼‰å’Œé«˜æ–¯è¿‡ç¨‹ï¼ˆGaussian Process, GPï¼‰å¯æä¾›ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œä½†å…¶è®¡ç®—å¤æ‚åº¦é«˜ã€éš¾ä»¥æ‰©å±•ã€‚

æ­¤å¤–ï¼Œæ ‡å‡†çš„ **Kolmogorov-Arnold Network (KAN)** è™½ç„¶å…·æœ‰è‰¯å¥½çš„å¯è§£é‡Šæ€§ï¼ˆé€šè¿‡è¾¹ä¸Šçš„å¯å­¦ä¹ ä¸€å…ƒå‡½æ•°ï¼‰ï¼Œä½†ä»æ˜¯ç¡®å®šæ€§æ¨¡å‹ï¼Œç¼ºä¹ä¸ç¡®å®šæ€§å»ºæ¨¡èƒ½åŠ›ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šSVGP-KAN**
æœ¬æ–‡æå‡ºäº† **Sparse Variational Gaussian Process Kolmogorov-Arnold Network (SVGP-KAN)**ï¼Œå°†ç¨€ç–å˜åˆ†é«˜æ–¯è¿‡ç¨‹ï¼ˆSparse Variational GPï¼‰å¼•å…¥ KAN æ¶æ„ï¼Œæ„å»ºäº†ä¸€ä¸ªå…¼å…·**å¯è§£é‡Šæ€§ã€ä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›å’Œè®¡ç®—å¯æ‰©å±•æ€§**çš„æ–°å‹æ¶æ„ã€‚

#### **æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š**
- **å‡½æ•°ç©ºé—´ä¸ç¡®å®šæ€§å»ºæ¨¡**ï¼šä¸åŒäºä»…å¯¹æƒé‡åˆ†å¸ƒå»ºæ¨¡çš„ Bayesian KANï¼ŒSVGP-KAN å°†æ¯æ¡è¾¹ä¸Šçš„ä¸€å…ƒå‡½æ•° $\phi_{j,i}$ è§†ä¸ºä»ä¸€ä¸ª **Gaussian Process å…ˆéªŒ** ä¸­é‡‡æ ·è€Œæ¥ï¼Œå®ç°å¯¹å‡½æ•°æœ¬èº«çš„æ¦‚ç‡å»ºæ¨¡ã€‚
- **ç¨€ç–å˜åˆ†æ¨æ–­ï¼ˆSparse Variational Inferenceï¼‰**ï¼šå¼•å…¥è¯±å¯¼ç‚¹ï¼ˆinducing pointsï¼‰è¿‘ä¼¼ï¼Œå°†åŸæœ¬ $O(N^3)$ çš„ç²¾ç¡® GP æ¨æ–­é™ä½è‡³ $O(NM^2)$ï¼Œå…¶ä¸­ $M \ll N$ï¼Œå®ç°**å‡†çº¿æ€§æ—¶é—´å¤æ‚åº¦**ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®ã€‚
- **è§£æçŸ©åŒ¹é…ï¼ˆAnalytic Moment Matchingï¼‰**ï¼šåˆ©ç”¨ KAN çš„åŠ æ€§ç»“æ„ï¼Œåœ¨è¾“å…¥å­˜åœ¨ä¸ç¡®å®šæ€§æ—¶ï¼Œé€šè¿‡é—­å¼è¡¨è¾¾ä¼ æ’­å‡å€¼ä¸æ–¹å·®ï¼Œé«˜æ•ˆå®ç°æ·±åº¦ä¸ç¡®å®šæ€§ä¼ æ’­ã€‚
- **å¼‚æ–¹å·®å™ªå£°å»ºæ¨¡**ï¼šé€šè¿‡é¢å¤–çš„ GP å¯¹è§‚æµ‹å™ªå£°çš„å¯¹æ•°æ–¹å·®è¿›è¡Œå»ºæ¨¡ï¼Œæ˜¾å¼åˆ†ç¦» aleatoric ä¸ epistemic ä¸ç¡®å®šæ€§ã€‚
- **çµæ´»çš„ KL æ­£åˆ™åŒ–æ§åˆ¶**ï¼šé€šè¿‡è°ƒèŠ‚ KL æ•£åº¦æƒé‡ $\lambda$ï¼Œå¯åœ¨ä¸åŒä»»åŠ¡ä¸­å¹³è¡¡æ‹Ÿåˆèƒ½åŠ›ä¸ä¸ç¡®å®šæ€§æ ¡å‡†â€”â€”ä¾‹å¦‚ï¼Œåœ¨ OOD æ£€æµ‹ä¸­è®¾ $\lambda=0$ ä»¥ä¿ç•™è‡ªç„¶æ–¹å·®æ”¾å¤§æœºåˆ¶ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | å¯è§£é‡Šæ€§ | ä¸ç¡®å®šæ€§é‡åŒ– | å¯æ‰©å±•æ€§ | åˆ†ç¦» aleatoric/epistemic |
|------|----------|----------------|------------|----------------------------|
| MLP | âŒ | âŒ | âœ… | âŒ |
| BNN | â­• | âœ… | âŒï¼ˆè®­ç»ƒéš¾ï¼‰ | â­• |
| Exact GP-KAN [12] | âœ… | âœ… | âŒ ($O(N^3)$) | âœ… |
| **SVGP-KAN (æœ¬æ–‡)** | âœ… | âœ… | âœ… ($O(NM^2)$) | âœ… |

> âœ… è¡¨ç¤ºæ”¯æŒï¼Œâ­• è¡¨ç¤ºéƒ¨åˆ†æ”¯æŒï¼ŒâŒ è¡¨ç¤ºä¸æ”¯æŒ

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„ä¸‰ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼ˆæ— å…¬å¼€çœŸå®æ•°æ®é›†ï¼Œå‡ä¸ºåˆæˆæˆ–æ ‡å‡†åŸºå‡†ï¼‰**

#### **Study A: æµä½“æµåœºé‡å»ºä¸­çš„å¼‚æ–¹å·®å™ªå£°æ ¡å‡†**
- **æ•°æ®ç”Ÿæˆ**ï¼š
  - ä½¿ç”¨æµå‡½æ•° $\psi$ ç”ŸæˆäºŒç»´ä¸å¯å‹ç¼©æµåœº $(v_x, v_y)$ã€‚
  - æ·»åŠ ç©ºé—´å˜åŒ–çš„å¼‚æ–¹å·®å™ªå£°ï¼š$\sigma^2_{\text{noise}}(x,y) = \sigma_{\text{base}} + A_{\text{noise}} \exp(-\frac{(x-x_c)^2 + (y-y_c)^2}{r^2})$
- **ç½‘ç»œç»“æ„**ï¼šä¸‰å±‚å…¨è¿æ¥ GPKANLayerï¼Œæ¯å±‚ 5 ä¸ªç¥ç»å…ƒï¼Œæ¯æ¡è¾¹ä½¿ç”¨ 20 ä¸ª inducing pointsã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - RMSEï¼ˆé¢„æµ‹ç²¾åº¦ï¼‰
  - é¢„æµ‹ä¸ç¡®å®šæ€§ vs å®é™…ç»å¯¹è¯¯å·®çš„ç›¸å…³æ€§ï¼ˆPearson $\rho$ï¼‰
  - ç½®ä¿¡åŒºé—´è¦†ç›–ç‡ï¼ˆÂ±1Ïƒ, Â±2Ïƒ, Â±3Ïƒï¼‰
  - æ ‡å‡†åŒ–é¢„æµ‹è¯¯å·® $(y - \mu)/\sigma$ æ˜¯å¦æ¥è¿‘ $N(0,1)$

#### **Study B: å¯¹æµ-æ‰©æ•£åŠ¨åŠ›å­¦çš„å¤šæ­¥é¢„æµ‹ä¸­è®¤çŸ¥ä¸ç¡®å®šæ€§çš„å¢é•¿**
- **ç‰©ç†ç³»ç»Ÿ**ï¼šæ±‚è§£ $\partial_t T = -u \cdot \nabla T + \kappa \nabla^2 T + S(x,t)$
- **è®­ç»ƒæ–¹å¼**ï¼šåªè®­ç»ƒå•æ­¥é¢„æµ‹ï¼ˆ$T_n \to T_{n+1}$ï¼‰
- **æµ‹è¯•æ–¹å¼**ï¼šä½¿ç”¨ ensemble rollout è¿›è¡Œ 15 æ­¥å‰å‘é¢„æµ‹ï¼Œåˆå§‹æ‰°åŠ¨ 1%
- **ç½‘ç»œç»“æ„**ï¼šå·ç§¯ç¼–ç å™¨-è§£ç å™¨ + GPKANLayer bottleneckï¼ˆ24 é€šé“ï¼Œ20 inducing pointsï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - Ensemble spreadï¼ˆepistemic uncertaintyï¼‰
  - æ—¶é—´ç»´åº¦ä¸Šçš„ä¸ç¡®å®šæ€§å¢é•¿å€æ•°
  - ç©ºé—´ä¸ç¡®å®šæ€§åˆ†å¸ƒæ¨¡å¼

#### **Study C: å·ç§¯è‡ªç¼–ç å™¨ä¸­çš„åˆ†å¸ƒå¤–æ£€æµ‹ï¼ˆOut-of-Distribution Detectionï¼‰**
- **æ•°æ®é›†**ï¼šMNISTï¼ˆä»…ç”¨ digit "0" è®­ç»ƒï¼‰
- **å¼‚å¸¸æ ·æœ¬**ï¼š"7"
- **ç½‘ç»œç»“æ„**ï¼šConv Encoder â†’ GPKANLayer Bottleneck (6D latent) â†’ Transposed Conv Decoder
- **å…³é”®è®¾è®¡**ï¼š$\lambda = 0$ï¼ˆæ—  KL æ­£åˆ™åŒ–ï¼‰ï¼Œä¿ç•™ GP çš„è‡ªç„¶æ–¹å·®æ”¾å¤§ç‰¹æ€§
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - Bottleneck ä¸ç¡®å®šæ€§ï¼ˆlatent dimensions æ–¹å·®ä¹‹å’Œï¼‰
  - Anomaly Score Ratioï¼ˆOOD / ID ä¸ç¡®å®šæ€§æ¯”å€¼ï¼‰
  - ROC-AUC
  - Reconstruction MSE

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
æ–‡ä¸­æœªç›´æ¥ä¸å…¶ä»–ä¸ç¡®å®šæ€§å»ºæ¨¡æ–¹æ³•ï¼ˆå¦‚ MC Dropoutã€Deep Ensemblesã€Standard GPï¼‰è¿›è¡Œå…¨é¢å¯¹æ¯”ï¼Œè€Œæ˜¯å¼ºè°ƒï¼š
- ç›¸æ¯” **exact GP-KAN**ï¼šæœ¬æ–¹æ³•æ˜¾è‘—æå‡å¯æ‰©å±•æ€§ï¼ˆ$O(N^3) \to O(NM^2)$ï¼‰
- ç›¸æ¯” **Bayesian KAN**ï¼šæœ¬æ–‡åœ¨å‡½æ•°ç©ºé—´å»ºæ¨¡æ›´å®Œæ•´ï¼Œèƒ½æ›´å¥½æ•æ‰éå‚æ•°ä¸ç¡®å®šæ€§
- å¼ºè°ƒ SVGP-KAN åœ¨**æ— éœ€ä¸“é—¨è®­ç»ƒæˆ–é˜ˆå€¼è°ƒæ•´**çš„æƒ…å†µä¸‹å³å¯å®ç° OOD æ£€æµ‹

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **Study A: å¼‚æ–¹å·®å™ªå£°æ ¡å‡†**
- **Pearson ç›¸å…³ç³»æ•°**ï¼š$\rho = 0.55$ï¼ˆé¢„æµ‹ä¸ç¡®å®šæ€§ä¸å®é™…è¯¯å·®ä¹‹é—´ï¼‰ï¼Œè¡¨æ˜æˆåŠŸè¯†åˆ«é«˜å™ªå£°åŒºåŸŸ
- **ç½®ä¿¡åŒºé—´è¦†ç›–ç‡è¯¯å·® < 1%**ï¼ˆåœ¨ Â±1Ïƒ, Â±2Ïƒ, Â±3Ïƒï¼‰ï¼Œè¯´æ˜ä¸ç¡®å®šæ€§é«˜åº¦æ ¡å‡†
- **æ ‡å‡†åŒ–é¢„æµ‹è¯¯å·®**ï¼šå‡å€¼ -0.09ï¼Œæ ‡å‡†å·® 1.01 â†’ æ¥è¿‘ç†æƒ³ $N(0,1)$
- **RMSE**ï¼š0.085ï¼Œæ˜¾ç¤ºå‡†ç¡®çš„å‡å€¼é¢„æµ‹

> âœ… æˆåŠŸå®ç°äº† aleatoric uncertainty çš„ç©ºé—´åˆ†è¾¨å»ºæ¨¡ä¸æ ¡å‡†

---

### **Study B: å¤šæ­¥é¢„æµ‹ä¸­ epistemic uncertainty å¢é•¿**
- **æ—¶é—´ç»´åº¦ä¸ç¡®å®šæ€§å¢é•¿**ï¼šensemble spread åœ¨ 15 æ­¥å†…å¢é•¿ **2.4 å€**
- **ç©ºé—´ä¸ç¡®å®šæ€§é›†ä¸­äºæ¢¯åº¦å‰§çƒˆåŒºåŸŸ**ï¼ˆå¦‚çƒ­å†·ç•Œé¢ï¼‰ï¼Œå˜å¼‚ç³»æ•°è¾¾ **12.7x**
- ç‰©ç†æ•æ„Ÿæ€§æµ‹è¯•ç¡®è®¤ç³»ç»Ÿç¨³å®šï¼ˆéæ··æ²Œï¼‰ï¼Œå› æ­¤ä¸ç¡®å®šæ€§å¢é•¿æºäº**æ¨¡å‹è¿‘ä¼¼è¯¯å·®ç´¯ç§¯**

> âœ… æˆåŠŸæ•è·äº†å› æ¨¡å‹ä¸å®Œç¾å¯¼è‡´çš„è®¤çŸ¥ä¸ç¡®å®šæ€§éšé¢„æµ‹æ­¥é•¿å¢åŠ çš„ç°è±¡

---

### **Study C: åˆ†å¸ƒå¤–æ£€æµ‹**
- **Anomaly Score Ratio**ï¼šå¹³å‡ **10~100 å€**ï¼ˆOOD è¾“å…¥çš„ç“¶é¢ˆä¸ç¡®å®šæ€§è¿œé«˜äº ID è¾“å…¥ï¼‰
- **ROC-AUC**ï¼š**0.8â€“0.9**ï¼Œè¡¨æ˜è‰¯å¥½åˆ¤åˆ«èƒ½åŠ›
- **Reconstruction MSE**ï¼šå¼‚å¸¸è¾“å…¥é«˜å‡ºæ­£å¸¸è¾“å…¥ **3â€“4 å€**
- è§†è§‰ä¸Šï¼Œâ€œ7â€çš„é‡æ„å‡ºç°æ¨¡ç³Šã€æ‰­æ›²ï¼Œè¯•å›¾æŠ•å½±åˆ°â€œ0â€çš„æµå½¢ä¸Š

> âœ… åœ¨ $\lambda=0$ è®¾è®¡ä¸‹ï¼ŒSVGP-KAN è‡ªç„¶å…·å¤‡ OOD æ£€æµ‹èƒ½åŠ›ï¼Œæ— éœ€é¢å¤–ç›‘ç£ä¿¡å·

---

### **æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰**
è™½ç„¶æ²¡æœ‰æ˜ç¡®å‘½åâ€œablation studyâ€ï¼Œä½†ä»¥ä¸‹è®¾è®¡ä½“ç°äº†å…³é”®å˜é‡çš„å½±å“ï¼š
- $\lambda = 0.01$ ç”¨äº Study A/B â†’ æ›´å¥½æ ¡å‡† in-distribution é¢„æµ‹
- $\lambda = 0$ ç”¨äº Study C â†’ ä¿ç•™ OOD æ–¹å·®æ”¾å¤§æœºåˆ¶
- ä½¿ç”¨ **RBF kernel** å’Œ **analytic moment matching** å®ç°é«˜æ•ˆä¸ç¡®å®šæ€§ä¼ æ’­
- Inducing point æ•°é‡ $M=20$ å·²è¶³å¤Ÿè·å¾—è‰¯å¥½è¿‘ä¼¼ï¼Œä¸”è®¡ç®—å¼€é”€å¯æ§

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **SVGP-KAN æˆåŠŸèåˆäº† KAN çš„å¯è§£é‡Šæ€§ä¸ GP çš„ä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›**ï¼Œæ˜¯é¦–ä¸ªæ”¯æŒ scalable Bayesian inference çš„ KAN å˜ä½“ã€‚
2. é€šè¿‡ç¨€ç–å˜åˆ†æ¨æ–­å’ŒåŠ æ€§ç»“æ„ï¼Œå®ç°äº† **$O(NM^2)$ å‡†çº¿æ€§å¤æ‚åº¦**ï¼Œé€‚åˆç§‘å­¦è®¡ç®—ä¸­å¤§è§„æ¨¡æ•°æ®åœºæ™¯ã€‚
3. èƒ½æœ‰æ•ˆ**åˆ†ç¦» aleatoric ä¸ epistemic uncertainty**ï¼š
   - Study A æ˜¾ç¤ºå¯¹å¼‚æ–¹å·®å™ªå£°çš„å­¦ä¹ ï¼›
   - Study B æ˜¾ç¤ºæ¨¡å‹è¯¯å·®éšæ—¶é—´ç§¯ç´¯ï¼›
4. åœ¨ $\lambda=0$ ä¸‹ï¼ŒSVGP-KAN çš„ bottleneck å±‚å¤©ç„¶å…·å¤‡ **OOD æ£€æµ‹èƒ½åŠ›**ï¼Œæºäº GP çš„æ–¹å·®å›å½’ç‰¹æ€§ã€‚
5. æ‰€æœ‰å®éªŒå‡æ˜¾ç¤ºé«˜åº¦æ ¡å‡†çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼ˆcoverage error <1%ï¼‰ï¼ŒéªŒè¯äº†æ¡†æ¶çš„å¯é æ€§ã€‚

---

### **å±€é™æ€§**
1. å½“å‰ä¸»è¦ä½¿ç”¨ **RBF kernel**ï¼Œå‡è®¾å‡½æ•°å…‰æ»‘ï¼›å¯¹äºä¸è¿ç»­æˆ–å°–é”è¿‡æ¸¡ç°è±¡ï¼ˆå¦‚æ¿€æ³¢ï¼‰ï¼Œå¯èƒ½éœ€æ”¹ç”¨ MatÃ©rn æˆ–åˆ†æ®µæ ¸å‡½æ•°ã€‚
2. **inducing point æ•°é‡ $M$ æ˜¯è¶…å‚**ï¼Œè¿‡å¤šå½±å“æ•ˆç‡ï¼Œè¿‡å°‘å½±å“è¿‘ä¼¼è´¨é‡ï¼Œå°šæ— è‡ªåŠ¨é€‰æ‹©æœºåˆ¶ã€‚
3. å‡è®¾ **Gaussian likelihood**ï¼Œé™åˆ¶äº†åœ¨åˆ†ç±»ã€è®¡æ•°æ•°æ®ç­‰ä»»åŠ¡çš„åº”ç”¨ã€‚
4. å½“å‰æ¡†æ¶é›†ä¸­åœ¨å‰é¦ˆç»“æ„ï¼Œå°šæœªæ‹“å±•è‡³ RNNã€GNN ç­‰åŠ¨æ€æˆ–å›¾ç»“æ„æ¨¡å‹ã€‚
5. **KL æƒé‡ $\lambda$ éœ€æ‰‹åŠ¨è®¾å®š**ï¼Œç¼ºä¹è‡ªåŠ¨åŒ–è°ƒä¼˜ç­–ç•¥ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³ **non-Gaussian likelihoods**ï¼ˆå¦‚ Poissonã€Bernoulliï¼‰
- å¼€å‘ **adaptive inducing point allocation** ç­–ç•¥ï¼ˆåŸºäºå±€éƒ¨å¤æ‚åº¦ï¼‰
- æ¢ç´¢ **recurrent SVGP-KAN** ç”¨äºæ—¶é—´åºåˆ—å»ºæ¨¡
- æ„å»º **graph-based SVGP-KAN** ç”¨äºåˆ†å­ã€ææ–™ç­‰å›¾ç»“æ„æ•°æ®
- è®¾è®¡ **automatic $\lambda$ tuning** æœºåˆ¶ï¼ŒåŸºäºéªŒè¯é›†ä¸ç¡®å®šæ€§æ ¡å‡†æŒ‡æ ‡åŠ¨æ€è°ƒæ•´
- åº”ç”¨äºæ›´å¤šç§‘å­¦é¢†åŸŸï¼šæ°”å€™å»ºæ¨¡ã€ç”Ÿç‰©æˆåƒã€é‡å­åŒ–å­¦ç­‰

---

## **æ€»ç»“**
**SVGP-KAN** æ˜¯ä¸€ç§é¢å‘ç§‘å­¦æœºå™¨å­¦ä¹ çš„æ–°å‹ä¸ç¡®å®šæ€§æ„ŸçŸ¥æ¶æ„ï¼Œå®ƒè§£å†³äº†ä¼ ç»Ÿ KAN ç¼ºä¹ä¸ç¡®å®šæ€§å»ºæ¨¡çš„é—®é¢˜ï¼ŒåŒæ—¶å…‹æœäº†æ ‡å‡† GP æ–¹æ³•ä¸å¯æ‰©å±•çš„ç“¶é¢ˆã€‚é€šè¿‡ç»“åˆ **sparse variational inference**ã€**analytic moment matching** å’Œ **additive edge functions**ï¼Œè¯¥æ¡†æ¶å®ç°äº†**å¯è§£é‡Šæ€§ã€ä¸ç¡®å®šæ€§åˆ†è§£ä¸è®¡ç®—æ•ˆç‡çš„ç»Ÿä¸€**ï¼Œåœ¨æµä½“åŠ›å­¦ã€ä¼ è¾“è¿‡ç¨‹å»ºæ¨¡å’Œå¼‚å¸¸æ£€æµ‹ç­‰å¤šä¸ªåœºæ™¯ä¸­å±•ç°å‡ºå¼ºå¤§æ½œåŠ›ã€‚

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/sungjuGit/svgp-kan](https://github.com/sungjuGit/svgp-kan)

</details>

---

### 4. [CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning](https://arxiv.org/abs/2512.05576)

**Authors**: Ting-Ting Xie, Yixin Zhang  
**Category**: cs.AI  
**Published**: 2025-12-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.05576v1  

#### Abstract
Current clinical agent built on small LLMs, such as TxAgent suffer from a \textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Fr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäºå°è§„æ¨¡ LLMï¼ˆå¦‚ TxAgentï¼‰æ„å»ºçš„ä¸´åºŠæ™ºèƒ½ä½“å­˜åœ¨ **Context Utilization Failure**ï¼ˆä¸Šä¸‹æ–‡åˆ©ç”¨å¤±è´¥ï¼‰é—®é¢˜ï¼šå°½ç®¡æ¨¡å‹èƒ½å¤Ÿé€šè¿‡ç›‘ç£å¾®è°ƒæˆåŠŸæ£€ç´¢åˆ°ç”Ÿç‰©åŒ»å­¦è¯æ®ï¼Œä½†åœ¨æœ€ç»ˆè¯Šæ–­ä¸­æœªèƒ½æœ‰æ•ˆåˆ©ç”¨è¿™äº›ä¿¡æ¯ï¼Œå¯¼è‡´æ¨ç†é”™è¯¯æˆ–å¹»è§‰ï¼ˆhallucinationï¼‰ã€‚æ­¤å¤–ï¼Œè¿˜å­˜åœ¨è¾“å‡ºæ ¼å¼é”™è¯¯ï¼ˆOutput Parsing Errorï¼‰ã€æŒ‡ä»¤éµå¾ªå¤±è´¥ï¼ˆInstruction Adherence Failureï¼‰ç­‰é—®é¢˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **Executor-Analyst Framework**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„æ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†â€œå·¥å…·æ‰§è¡Œâ€ä¸â€œä¸´åºŠæ¨ç†â€è§£è€¦ï¼š

- **Executorï¼ˆæ‰§è¡Œè€…ï¼‰**ï¼šç”±ä¸“é—¨å¾®è°ƒçš„å°æ¨¡å‹ï¼ˆå¦‚ TxAgentï¼‰æ‹…ä»»ï¼Œä¸“æ³¨äºç²¾ç¡®è°ƒç”¨ ToolUniverse ä¸­çš„ API å·¥å…·è¿›è¡Œä¿¡æ¯æ£€ç´¢ã€‚
- **Analystï¼ˆåˆ†æè€…ï¼‰**ï¼šç”±å¤§ä¸Šä¸‹æ–‡ã€å¼ºæ¨ç†èƒ½åŠ›çš„åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ Gemini 2.5ï¼‰æ‹…ä»»ï¼Œè´Ÿè´£å¯¹ Executor è¿”å›çš„åŸå§‹è¯æ®æµè¿›è¡Œç»¼åˆã€éªŒè¯ã€è¡¥å……æœç´¢ï¼Œå¹¶ç”Ÿæˆå¯é çš„ä¸´åºŠæ¨ç†é“¾ã€‚
- **Stratified Ensembleï¼ˆåˆ†å±‚é›†æˆï¼‰ç­–ç•¥**ï¼šä¸åŒäºä¼ ç»Ÿçš„å…¨å±€èšåˆï¼ˆGlobal Poolingï¼‰ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨â€œæ™šæœŸèåˆâ€ï¼ˆLate Fusionï¼‰æœºåˆ¶ï¼Œåœ¨å¤šä¸ªå¹¶è¡Œå­ç®¡é“ä¸­ä¿ç•™å¤šæ ·åŒ–çš„æ£€ç´¢è·¯å¾„ï¼Œç›´åˆ°æœ€åé˜¶æ®µæ‰è¿›è¡ŒæŠ•ç¥¨å†³ç­–ï¼Œä»è€Œé¿å…æ—©æœŸè¿‡æ»¤æ‰å…³é”®ä½†ç¨€æœ‰çš„è¯æ®ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€å¾®è°ƒï¼ˆTraining-Freeï¼‰**ï¼šå®Œå…¨ä¾èµ–æ¶æ„è®¾è®¡è€Œéæ˜‚è´µçš„ç«¯åˆ°ç«¯å¾®è°ƒï¼Œå…·å¤‡é«˜å¯æ‰©å±•æ€§å’Œæ•æ·éƒ¨ç½²èƒ½åŠ›ã€‚
- **æ›´é«˜çš„å‡†ç¡®æ€§ä¸é²æ£’æ€§**ï¼šé€šè¿‡è§’è‰²åˆ†ç¦»å’Œåˆ†å±‚é›†æˆæ˜¾è‘—æå‡åœ¨å¤æ‚ç—…ä¾‹ä¸Šçš„è¡¨ç°ã€‚
- **æ›´å¼ºçš„ä¿¡æ¯å¤šæ ·æ€§ä¿æŒèƒ½åŠ›**ï¼šè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„ä¿¡æ¯ç“¶é¢ˆé—®é¢˜ã€‚
- **å…¼å®¹æ€§å¼º**ï¼šå¯çµæ´»æ›¿æ¢ä¸åŒç‰ˆæœ¬çš„ Analyst æˆ– Executorï¼Œé€‚åº”å¿«é€Ÿæ¼”è¿›çš„ LLM ç”Ÿæ€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **CURE-Bench@NeurIPS 2025** å…¬å¼€ç«èµ›æ•°æ®é›†ï¼ŒåŒ…å«ä¸¤ä¸ªæµ‹è¯•é›†ï¼š
  - `testset_phase1`ï¼ˆå…¬å¼€æ’è¡Œæ¦œï¼‰
  - `testset_phase2`ï¼ˆç§æœ‰æ’è¡Œæ¦œï¼Œä½œä¸ºä¸»è¯„ä¼°åŸºå‡†ï¼‰

è¯¥æ•°æ®é›†è¦æ±‚æ¨¡å‹é€šè¿‡è°ƒç”¨ä¸€ä¸ªåŒ…å«è¶…è¿‡ 200 ä¸ªå·¥å…·çš„ **ToolUniverse**ï¼ˆæ¶µç›– FDA æ ‡ç­¾ã€OpenTarget æ•°æ®åº“ã€HPO ç­‰ï¼‰å®Œæˆå¤šæ­¥ä¸´åºŠæ¨ç†ä»»åŠ¡ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦è¯„ä¼°æŒ‡æ ‡ä¸º **å‡†ç¡®ç‡ï¼ˆAccuracy %ï¼‰**
- æ‰€æœ‰å®éªŒå‡åœ¨å›ºå®šè®¡ç®—é¢„ç®—ä¸‹è¿›è¡Œæ¯”è¾ƒï¼ˆæ§åˆ¶æ€» agent æ•°é‡ï¼‰
- å…³é”®å˜é‡åŒ…æ‹¬ï¼š
  - Executor æ•°é‡ $n_1$
  - Analyst æ•°é‡ $n_g$
  - æ˜¯å¦å¯ç”¨ Self-Consistencyï¼ˆSCï¼‰
  - æ¶æ„æ‹“æ‰‘ï¼šGlobal Pooling vs. Stratified Ensemble
  - æ˜¯å¦å¯ç”¨äº’è”ç½‘æœç´¢ï¼ˆSearchï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| TxAgent [8] | ç«èµ›å®˜æ–¹åŸºçº¿ï¼ŒLlama-3.1-8B å¾®è°ƒæ¨¡å‹ï¼Œä¸“ç”¨äºæ²»ç–—æ¨ç† |
| Gemini-2.5-flash / pro | å¼ºå¤§çš„é—­æºåŸºç¡€æ¨¡å‹ï¼Œç”¨äºé›¶æ ·æœ¬æ¨ç† |
| å•ä¸€ Agent + Self-Consistency | å¤šæ¬¡é‡‡æ ·æ¨ç†è·¯å¾„åèšåˆç»“æœ |
| Global Poolingï¼ˆConfig Aï¼‰ | æ‰€æœ‰ Executor è¾“å‡ºç»Ÿä¸€èšåˆåå†é€å…¥ Analyst |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆPhase2 å‡†ç¡®ç‡ï¼‰

| æ–¹æ³• | å‡†ç¡®ç‡ (%) |
|------|-----------|
| TxAgentï¼ˆå•æ¨¡å‹ï¼‰ | 69.325 |
| Gemini-2.5-flashï¼ˆæ— å·¥å…·ï¼‰ | 63.104 |
| TxAgent + Self-Consistency ($n=30$) | 73.508 |
| **Executor-Analystï¼ˆConfig A, $n_1=30, n_g=3$)** | **80.510** |
| **Executor-Analystï¼ˆConfig B, Stratified Ensemble, $n_1=10, n_g=3$)** | **81.367** |
| **+ Gemini with search** | **83.803** âœ…ï¼ˆæœ€ç»ˆæäº¤æˆç»©ï¼‰ |

> ğŸ’¡ **State-of-the-art æ€§èƒ½è¾¾æˆï¼š83.803%**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- ç›¸æ¯”åŸå§‹ TxAgentï¼ˆ69.3%ï¼‰ï¼Œæœ¬æ¡†æ¶æå‡ **+14.5 ä¸ªç™¾åˆ†ç‚¹**
- ç›¸æ¯”æœ€å¼ºå•ä¸€æ¨¡å‹ Gemini-3-Pro + searchï¼ˆ81.283%ï¼‰ï¼Œä»é«˜å‡º **2.5 ä¸ªç™¾åˆ†ç‚¹**
- æ˜¾è‘—ä¼˜äºæ‰€æœ‰å¼€æºæ¨¡å‹ï¼ˆè§ Table 1ï¼‰ï¼Œå³ä½¿å‚æ•°æ›´å¤§çš„ gpt-oss-120b ä¹Ÿä»…å¾— 39.896%

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰æ¸©åº¦è°ƒä¼˜ï¼ˆExecutor Calibrationï¼‰
| æ¸©åº¦ | Phase1 å‡†ç¡®ç‡ |
|-----|--------------|
| 0.6 | 58.950 |
| 0.7 | 59.248 |
| **0.8** | **65.214** âœ… |
| 0.9 | 56.747 |

â†’ æœ€ä½³æ¸©åº¦ä¸º 0.8ï¼Œè¿‡é«˜ä¼šå¯¼è‡´ä¸ç¨³å®šè¾“å‡ºã€‚

#### ï¼ˆ2ï¼‰Self-Consistency å¯¹ Executor çš„å½±å“
- éšç€é‡‡æ ·è·¯å¾„æ•°å¢åŠ ï¼ˆ$n$ ä» 1 åˆ° 60ï¼‰ï¼Œå‡†ç¡®ç‡ä» 69.3% æå‡è‡³ 74.2%
- æ”¶ç›Šåœ¨ $n > 20$ åè¶‹äºé¥±å’Œ

#### ï¼ˆ3ï¼‰æ¶æ„æ‹“æ‰‘å¯¹æ¯”ï¼ˆConfig A vs Bï¼‰
- åœ¨ç›¸åŒè®¡ç®—èµ„æºä¸‹ï¼ˆ$N_{total} = 30$ Execs, 3 Analysistsï¼‰ï¼š
  - Global Poolingï¼ˆæ—©èåˆï¼‰ï¼š79.311% â†’ 80.510%
  - **Stratified Ensembleï¼ˆæ™šèåˆï¼‰**ï¼š**81.367%**
- ç»“è®ºï¼š**Late Fusion æ›´èƒ½ä¿ç•™è¯æ®å¤šæ ·æ€§ï¼Œå‡å°‘é›†ä½“å¹»è§‰**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Decoupling æ˜¯å…³é”®**ï¼šå°†â€œå·¥å…·æ‰§è¡Œâ€ä¸â€œè¯­ä¹‰æ¨ç†â€è§£è€¦å¯æ˜¾è‘—ç¼“è§£ Context Utilization Failureï¼Œå……åˆ†å‘æŒ¥å„ç±»æ¨¡å‹ä¼˜åŠ¿ã€‚
2. **Topology matters**ï¼šStratified Ensemble æ¯” Global Pooling æ›´é€‚åˆå¤æ‚åŒ»ç–—æ¨ç†ä»»åŠ¡ï¼Œå› åè€…æ˜“é€ æˆä¿¡æ¯ç“¶é¢ˆã€‚
3. **Training-free æ¶æ„å·¥ç¨‹æ½œåŠ›å·¨å¤§**ï¼šæ— éœ€å¾®è°ƒå³å¯å®ç° SOTA è¡¨ç°ï¼Œæä¾›äº†ä¸€ç§ä½æˆæœ¬ã€é«˜é€‚åº”æ€§çš„ AI åŒ»ç–—ç³»ç»Ÿæ„å»ºèŒƒå¼ã€‚
4. **Scaling Laws å­˜åœ¨åå¸¸ç°è±¡**ï¼š
   - **Context-Performance Paradox**ï¼šå½“æ¨ç†ä¸Šä¸‹æ–‡è¶…è¿‡ 12k tokens æ—¶ï¼Œæ€§èƒ½åè€Œä¸‹é™ï¼ˆä» 94% â†’ 87.93%ï¼‰ï¼Œè¯´æ˜å™ªå£°ç§¯ç´¯ä¼šå‹å€’æ³¨æ„åŠ›æœºåˆ¶ã€‚
   - **Curse of Dimensionality in Action Spaces**ï¼šToolUniverse ä» 200+ æ‰©å±•åˆ° 600+ å·¥å…·åï¼ŒTxAgent å‡†ç¡®ç‡ä» 92.0% ä¸‹é™åˆ° 87.5%ï¼Œè¡¨æ˜æ‰å¹³åŒ–å·¥å…·æ£€ç´¢éš¾ä»¥æ‰©å±•ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶ä¾èµ–äºé«˜è´¨é‡çš„å¤–éƒ¨å·¥å…·æ¥å£ï¼ˆToolUniverseï¼‰ï¼Œè‹¥å·¥å…·ä¸å¯é æˆ–å“åº”å»¶è¿Ÿï¼Œä¼šå½±å“æ•´ä½“æ€§èƒ½ã€‚
- åˆ†å±‚æ¶æ„å¸¦æ¥æ›´é«˜æ¨ç†å»¶è¿Ÿå’Œèµ„æºæ¶ˆè€—ï¼ˆéœ€å¹¶è¡Œè¿è¡Œå¤šä¸ª agentsï¼‰ã€‚
- å¯¹ Analyst çš„ä¾èµ–è¾ƒå¼ºï¼Œè‹¥ Analyst æœ¬èº«ä¸å…·å¤‡è‰¯å¥½äº‹å®æ ¸æŸ¥èƒ½åŠ›ï¼Œåˆ™ä»å¯èƒ½äº§ç”Ÿå¹»è§‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¤§è§„æ¨¡åŠ¨ä½œç©ºé—´ä¼˜åŒ–**ï¼š
   - æ¢ç´¢ **Hierarchical Tool Indexing**ï¼ˆåˆ†å±‚å·¥å…·ç´¢å¼•ï¼‰
   - åˆ©ç”¨ **In-Context Learning (ICL)** æˆ– **RAG-based documentation retrieval** å®ç°å…è®­ç»ƒé€‚é…æ–°å·¥å…·
   - å¼•å…¥ **Curriculum Learning** é€æ­¥æš´éœ²æ›´å¤šå·¥å…·ä»¥å¢å¼ºæŠ—å¹²æ‰°èƒ½åŠ›

2. **ä¸Šä¸‹æ–‡æ•ˆç‡æ”¹è¿›**ï¼š
   - è®¾è®¡ **confidence-based filtering** æœºåˆ¶ï¼ˆå¦‚ DeepConfï¼‰ï¼Œæå‰æ‹’ç»æ— å…³è¯æ®ï¼Œæé«˜ä¿¡å™ªæ¯”
   - å¼€å‘åŠ¨æ€å‹ç¼©ç®—æ³•å‡å°‘é•¿ä¸Šä¸‹æ–‡å¸¦æ¥çš„å™ªå£°è´Ÿæ‹…

3. **æ¨ç†å¼•æ“æ¼”åŒ–**ï¼š
   - éšç€ Foundation Model è‡ªèº«å·¥å…·ä½¿ç”¨èƒ½åŠ›å¢å¼ºï¼ˆå¦‚ Gemini 3 Proï¼‰ï¼ŒExecutor å¯èƒ½é€€åŒ–ä¸ºè½»é‡çº§ Prompt Engineering æ¨¡å—
   - ä½†â€œæ‰§è¡Œ-æ¨ç†â€è§£è€¦çš„æ ¸å¿ƒç†å¿µä»å°†é•¿æœŸé€‚ç”¨

---

> ğŸ“Œ **æ€»ç»“**ï¼š  
> CureAgent å±•ç¤ºäº†é€šè¿‡**è®­ç»ƒå…è´¹çš„æ¶æ„åˆ›æ–°**è§£å†³å¤æ‚ä¸´åºŠæ¨ç†ä»»åŠ¡çš„å·¨å¤§æ½œåŠ›ã€‚å®ƒä¸ä»…åœ¨ CURE-Bench ä¸Šå–å¾—é¢†å…ˆæˆç»©ï¼Œæ›´é‡è¦çš„æ˜¯æ­ç¤ºäº†ä¸‹ä¸€ä»£å¯ä¿¡ AI åŒ»ç–—ç³»ç»Ÿçš„æ„å»ºåŸåˆ™ï¼š**æ¨¡å—åŒ–ã€å¤šæ ·æ€§ä¿æŒã€å…å¾®è°ƒé€‚åº”æ€§ã€ä»¥åŠäººæœºååŒå¼ä¿¡æ¯å¤„ç†è®¾è®¡**ã€‚

</details>

---

### 5. [Learning from Self Critique and Refinement for Faithful LLM Summarization](https://arxiv.org/abs/2512.05387)

**Authors**: Ting-Yao Hu, Hema Swetha Koppula, Hadi Pouransari, Cem Koc, Oncel Tuzel, Raviteja Vemulapalli  
**Category**: cs.CL  
**Published**: 2025-12-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.05387v1  

#### Abstract
Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced by iteratively critiquing and refining previously ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLearning from Self Critique and Refinement for Faithful LLM Summarization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ‰§è¡Œé•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚æ‘˜è¦ç”Ÿæˆï¼‰æ—¶æ™®éå­˜åœ¨**å¹»è§‰ï¼ˆhallucinationsï¼‰**é—®é¢˜ï¼Œå³ç”Ÿæˆçš„å†…å®¹æ— æ³•åœ¨è¾“å…¥ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ°ä¾æ®ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶é€šè¿‡æµ‹è¯•æ—¶ï¼ˆtest-timeï¼‰çš„è¿­ä»£æ‰¹åˆ¤ä¸ç²¾ç‚¼ï¼ˆcritique and refinementï¼‰æ¥ç¼“è§£è¯¥é—®é¢˜ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–æ›´å¼ºçš„æ•™å¸ˆæ¨¡å‹æˆ–å¤šæ¨¡å‹åä½œï¼Œå¯¼è‡´æ¨ç†æˆæœ¬é«˜ã€å®ç”¨æ€§å·®ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSCRPO
æœ¬æ–‡æå‡º **Self Critique and Refinement-based Preference Optimization (SCRPO)**ï¼Œä¸€ç§**è‡ªç›‘ç£è®­ç»ƒæ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨åŒä¸€ä¸ªLLMè‡ªèº«çš„**è‡ªæˆ‘æ‰¹åˆ¤ï¼ˆself-critiqueï¼‰** å’Œ **è‡ªæˆ‘ç²¾ç‚¼ï¼ˆself-refinementï¼‰** èƒ½åŠ›ï¼Œåœ¨è®­ç»ƒé˜¶æ®µæ„å»ºåå¥½æ•°æ®é›†ï¼›
- å°†åˆå§‹æ‘˜è¦ä¸ç»è‡ªèº«æ‰¹åˆ¤åç²¾ç‚¼çš„æ‘˜è¦æ„å»ºæˆ `(chosen, rejected)` åå¥½å¯¹ï¼›
- ä½¿ç”¨ **Preference Learning**ï¼ˆå¦‚ DPOï¼‰å¯¹è¯¥LLMè¿›è¡Œå¾®è°ƒï¼Œä»è€Œæå‡å…¶ç”Ÿæˆå¿ å®æ‘˜è¦çš„èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆTest-Time Refinementï¼‰ | SCRPOï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰ |
|------|-------------------------------|------------------|
| æ¨ç†å¼€é”€ | é«˜ï¼ˆæ¯æ¬¡æ¨ç†éœ€å¤šæ¬¡è°ƒç”¨æ¨¡å‹ï¼‰ | **æ— é¢å¤–å¼€é”€**ï¼ˆè®­ç»ƒåç›´æ¥æ¨ç†ï¼‰ |
| æ˜¯å¦éœ€è¦æ•™å¸ˆæ¨¡å‹ | æ˜¯ï¼ˆæˆ–å¤šä¸ªä¸“ç”¨æ¨¡å‹ï¼‰ | å¦ï¼ˆä»…ç”¨å•ä¸€LLMï¼‰ |
| å¯æ‰©å±•æ€§ | å·®ï¼ˆä¾èµ–å¤–éƒ¨èµ„æºï¼‰ | å¼ºï¼ˆå®Œå…¨è‡ªç›‘ç£ï¼‰ |
| æ€§èƒ½è¡¨ç° | ä¸€èˆ¬ | **æ›´ä¼˜çš„å¿ å®æ€§å’Œæ•´ä½“è´¨é‡** |

æ­¤å¤–ï¼ŒSCRPOå®ç°äº†â€œ**è®­ç»ƒæ—¶è’¸é¦æ¨ç†æ—¶ç­–ç•¥**â€ï¼Œä½†æ•ˆæœä¼˜äºç›´æ¥åœ¨æ¨ç†æ—¶è¿›è¡Œç²¾ç‚¼ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªä¸»æµæ‘˜è¦åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- **XSum**ï¼šæ–°é—»æ–‡ç« å•å¥æ‘˜è¦ï¼Œå¼ºè°ƒç®€æ´æ€§å’Œäº‹å®æ€§ã€‚
- **CNNDM**ï¼šæ–°é—»æ–‡ç« æ‘˜è¦ï¼Œå†…å®¹è¾ƒé•¿ï¼Œå¸¸ç”¨äºè¯„ä¼°æŠ½è±¡æ‘˜è¦èƒ½åŠ›ã€‚
- **SAMSum**ï¼šæ—¥å¸¸å¯¹è¯æ‘˜è¦ï¼Œæ¨¡æ‹Ÿå®¶åº­æœ‹å‹é—´çš„èŠå¤©è®°å½•ã€‚

æ‰€æœ‰å®éªŒä»å®˜æ–¹è®­ç»ƒé›†ä¸­é‡‡æ · 10,000 ä¸ªæ–‡æ¡£ä½œä¸ºæ— æ ‡ç­¾è®­ç»ƒæ•°æ®ã€‚

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen2.5-7B-Instruct`
- **é€‚é…å™¨æŠ€æœ¯**ï¼šLoRAï¼ˆrank=16, alpha=32ï¼‰
- **ç”Ÿæˆæ–¹å¼**ï¼šBeam Searchï¼ˆbeam size=5ï¼‰
- **ä»»åŠ¡è¦æ±‚**ï¼šç”Ÿæˆå•å¥æ‘˜è¦

### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ | æè¿° |
|------|------|------|
| **å¿ å®æ€§ï¼ˆFaithfulnessï¼‰** | `MiniCheck` | è‡ªåŠ¨åŒ–äº‹å®æ ¸æŸ¥å·¥å…·ï¼Œè¡¡é‡æ‘˜è¦æ˜¯å¦åŸºäºåŸæ–‡ |
| | `GPT4-Likert` | ä½¿ç”¨ GPT-4 è¿›è¡Œäººå·¥é£æ ¼è¯„åˆ†ï¼Œè¯„ä¼°å¿ å®æ€§ |
| **æ•´ä½“è´¨é‡ï¼ˆQualityï¼‰** | `GEval` ç³»åˆ— | åŒ…æ‹¬ Coherenceï¼ˆè¿è´¯æ€§ï¼‰ã€Consistencyï¼ˆä¸€è‡´æ€§ï¼‰ã€Fluencyï¼ˆæµç•…æ€§ï¼‰ã€Relevanceï¼ˆç›¸å…³æ€§ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Pretrained LLM**ï¼šåŸå§‹é¢„è®­ç»ƒæ¨¡å‹
- **MPO (Choi et al., 2024)**ï¼šåŸºäºä¸åŒè§£ç ç­–ç•¥æ„å»ºåå¥½çš„è‡ªç›‘ç£æ–¹æ³•
- **SCOPE (Duong et al., 2025)**ï¼šåˆ©ç”¨æ— ä¸Šä¸‹æ–‡æ¨¡å‹ç”Ÿæˆä¸å¿ å®ç°è±¡ä»¥æ„é€ åå¥½æ•°æ®
- **SCRPO-Inference Time**ï¼šåœ¨æ¨ç†é˜¶æ®µåº”ç”¨ç›¸åŒæ‰¹åˆ¤ä¸ç²¾ç‚¼æµç¨‹ï¼ˆéè®­ç»ƒï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰

| æ–¹æ³• | XSum MiniCheck | XSum GPT4-Likert | CNNDM MiniCheck | CNNDM GPT4-Likert | SAMSum MiniCheck | SAMSum GPT4-Likert |
|------|---------------|------------------|------------------|--------------------|-------------------|---------------------|
| Pretrained LLM | 0.701 | 4.16 | 0.715 | 4.45 | 0.437 | 4.17 |
| MPO | 0.694 | 4.13 | 0.712 | 4.42 | 0.456 | 4.18 |
| SCOPE | 0.713 | 4.14 | 0.721 | 4.43 | 0.440 | 4.17 |
| SCRPO-Inference Time | 0.722 | 4.23 | 0.746 | 4.48 | 0.470 | 4.21 |
| **SCRPO (Ours)** | **0.761** | **4.38** | **0.806** | **4.65** | **0.523** | **4.42** |

> âœ… æ‰€æœ‰æ•°æ®é›†ä¸Šï¼ŒSCRPO åœ¨ **MiniCheck** å’Œ **GPT4-Likert** ä¸Šå‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

åŒæ—¶ï¼Œ**GEval æŒ‡æ ‡æ˜¾ç¤º**ï¼šSCRPO åœ¨ä¿æŒç”šè‡³æå‡æ‘˜è¦æ•´ä½“è´¨é‡çš„å‰æä¸‹ï¼Œå¤§å¹…æé«˜å¿ å®æ€§ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æ‰¹åˆ¤ç­–ç•¥æ¯”è¾ƒï¼ˆTable 1ï¼‰
| ç­–ç•¥ | XSum MiniCheck | CNNDM MiniCheck | SAMSum MiniCheck |
|------|----------------|------------------|-------------------|
| Binary Feedback | 0.748 | 0.803 | 0.498 |
| **Fine-grained Feedback** | **0.761** | **0.806** | **0.523** |

> âœ… ç»†ç²’åº¦åé¦ˆï¼ˆåŸå­äº‹å®æå– + NLIéªŒè¯ï¼‰ä¼˜äºäºŒå€¼åˆ¤æ–­ï¼Œè¯´æ˜ç²¾ç»†åˆ†ææ›´æœ‰æ•ˆã€‚

#### ï¼ˆ2ï¼‰åå¥½ä¸‰å…ƒç»„é€‰æ‹©ç­–ç•¥ï¼ˆTable 2ï¼‰
| ç­–ç•¥ | ç‰¹ç‚¹ | ç»“æœ |
|------|------|------|
| Single Beam Search | ä»…ç”Ÿæˆä¸€å¯¹åˆç¨¿ä¸ç²¾ç‚¼ç¨¿ | å¿ å®æ€§æœ€é«˜ä½†æ•´ä½“è´¨é‡ä¸‹é™ |
| Random Selection | éšæœºé€‰å–åˆå§‹ä¸ç²¾ç‚¼æ‘˜è¦ | è¡¨ç°ä¸­ç­‰ |
| **Extreme Selection**ï¼ˆæœ€ç»ˆé‡‡ç”¨ï¼‰ | æœ€å·®åˆç¨¿ vs æœ€ä½³ç²¾ç‚¼ç¨¿ | **å¹³è¡¡å¿ å®æ€§ä¸è´¨é‡**ï¼Œç»¼åˆæœ€ä¼˜ |

#### ï¼ˆ3ï¼‰å˜ä½“å¯¹æ¯”ï¼ˆTable 3ï¼‰
| å˜ä½“ | ç‰¹å¾ | ç»“æœ |
|------|------|------|
| SCRPO-Critique Only | ä»…æ‰¹åˆ¤æ‰“åˆ†ï¼Œä¸ç²¾ç‚¼ | å¿ å®æ€§æå‡æœ‰é™ |
| SCRPO-SFT | å¯¹ç²¾ç‚¼æ‘˜è¦åš SFT å¾®è°ƒ | æ•ˆæœæ¥è¿‘ä½†ä¸å¦‚ Preference Learning |
| **SCRPO (å®Œæ•´ç‰ˆ)** | æ‰¹åˆ¤ + ç²¾ç‚¼ + Preference Learning | **å…¨é¢é¢†å…ˆ**ï¼Œè¯æ˜å„ç»„ä»¶ååŒä½œç”¨ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **SCRPO æ˜¾è‘—æå‡äº† LLM æ‘˜è¦çš„å¿ å®æ€§**ï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¶…è¶Šå½“å‰æœ€å…ˆè¿›çš„è‡ªç›‘ç£æ–¹æ³•ã€‚
2. âœ… **ä¼˜äºæ¨ç†æ—¶ç²¾ç‚¼ï¼ˆinference-time refinementï¼‰**ï¼šå°½ç®¡åè€…è®¡ç®—æ›´å¤šï¼Œä½† SCRPO åœ¨å¿ å®æ€§å’Œæ•ˆç‡ä¹‹é—´å–å¾—æ›´å¥½å¹³è¡¡ã€‚
3. âœ… **æ— éœ€å¤–éƒ¨ç›‘ç£æˆ–æ•™å¸ˆæ¨¡å‹**ï¼šå®Œå…¨ä¾é å•ä¸€LLMçš„å†…åœ¨èƒ½åŠ›å®Œæˆè‡ªæˆ‘æ”¹è¿›ï¼Œå…·å¤‡é«˜åº¦å¯éƒ¨ç½²æ€§ã€‚
4. âœ… **å…·æœ‰è·¨åŸŸæ³›åŒ–èƒ½åŠ›**ï¼ˆè§ Table 4ï¼‰ï¼šå³ä½¿åœ¨æºåŸŸä¸ç›®æ ‡åŸŸä¸åŒï¼ˆå¦‚æ–°é—» â†’ å¯¹è¯ï¼‰ï¼ŒSCRPO ä»èƒ½å¸¦æ¥å¢ç›Šã€‚
5. âœ… **äººç±»è¯„ä¼°ä¸€è‡´æ”¯æŒè‡ªåŠ¨æŒ‡æ ‡è¶‹åŠ¿**ï¼ˆTable 5ï¼‰ï¼šåœ¨ 80 ä¸ª XSum æµ‹è¯•æ ·æœ¬ä¸­ï¼ŒSCRPO åœ¨ **24%** çš„æƒ…å†µä¸‹è¢«åˆ¤å®šä¸ºæ›´å¿ å®ï¼Œä»… **1%** è½è´¥ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ¨¡å‹å®¹é‡é—¨æ§›**ï¼ˆè§ Figure 3ï¼‰ï¼šå®éªŒè¡¨æ˜ï¼Œå°äº 3B å‚æ•°çš„æ¨¡å‹ï¼ˆå¦‚ 0.5B, 1.5Bï¼‰åœ¨ SCRPO ä¸‹å‡ºç°æ€§èƒ½é€€åŒ–ï¼Œè¯´æ˜è¯¥æ–¹æ³•å¯¹æ¨¡å‹è§„æ¨¡æœ‰ä¸€å®šè¦æ±‚ã€‚
- **ä¾èµ–é«˜è´¨é‡æç¤ºå·¥ç¨‹**ï¼šæ‰¹åˆ¤ä¸ç²¾ç‚¼çš„æ•ˆæœå— prompt è®¾è®¡å½±å“è¾ƒå¤§ï¼ˆè§ Appendix A.1ï¼‰ã€‚
- **æœªè§£å†³æ ¹æœ¬å¹»è§‰æœºåˆ¶**ï¼šä»æ˜¯åå¤„ç†å¼ä¿®æ­£ï¼Œè€Œéä»å»ºæ¨¡å±‚é¢æ ¹é™¤å¹»è§‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„æ‰¹åˆ¤-ç²¾ç‚¼è·¯å¾„ï¼ˆå¦‚å‡å°‘é‡‡æ ·æ¬¡æ•° Nï¼‰ï¼›
- å°† SCRPO æ‰©å±•åˆ°å…¶ä»–æ¡ä»¶ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚é—®ç­”ã€æ•…äº‹ç”Ÿæˆï¼‰ï¼›
- ç»“åˆè§£ç æ—¶çº¦æŸï¼ˆå¦‚ context-aware decodingï¼‰è¿›ä¸€æ­¥æŠ‘åˆ¶å¹»è§‰ï¼›
- ç ”ç©¶å¦‚ä½•é™ä½å¯¹å¤§æ¨¡å‹è§„æ¨¡çš„ä¾èµ–ï¼Œä½¿å°æ¨¡å‹ä¹Ÿèƒ½å—ç›Šäºè‡ªæˆ‘ç²¾ç‚¼ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SCRPO æˆåŠŸå°†â€œæ¨ç†æ—¶è‡ªæˆ‘ç²¾ç‚¼â€è’¸é¦è¿›æ¨¡å‹æƒé‡ä¸­ï¼Œå®ç°äº†**é«˜æ•ˆã€ä½æˆæœ¬ã€é«˜ä¿çœŸçš„æ‘˜è¦ç”Ÿæˆ**ï¼Œä¸ºæ„å»ºå¯ä¿¡ LLM åº”ç”¨æä¾›äº†å®ç”¨ä¸”å¼ºå¤§çš„è®­ç»ƒèŒƒå¼ã€‚

</details>

---

### 6. [Capturing Classic Authorial Style in Long-Form Story Generation with GRPO Fine-Tuning](https://arxiv.org/abs/2512.05747)

**Authors**: Jinlong Liu, Mohammed Bahja, Venelin Kovatchev, Mark Lee  
**Category**: cs.CL  
**Published**: 2025-12-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.05747v1  

#### Abstract
Recent advances in large language models (LLMs) show impressive performance in open-ended story generation, but fine-grained stylistic control remains limited. Existing methods often rely on shallow cues (e.g., names or topics) to simulate authorial style, without robust evaluation. In this work, we...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCapturing Classic Authorial Style in Long-Form Story Generation with GRPO Fine-Tuning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼€æ”¾æ€§æ•…äº‹ç”Ÿæˆä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨**ç»†ç²’åº¦çš„ä½œè€…é£æ ¼æ§åˆ¶**æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–æµ…å±‚çº¿ç´¢ï¼ˆå¦‚è§’è‰²åã€ä¸»é¢˜è¯ï¼‰æ¥æ¨¡æ‹Ÿâ€œé£æ ¼â€ï¼Œç¼ºä¹å¯¹çœŸæ­£æ–‡å­¦å£°éŸ³ï¼ˆliterary voiceï¼‰ã€å™äº‹èŠ‚å¥å’Œå¥æ³•ç‰¹å¾çš„å»ºæ¨¡ï¼Œä¸”ç¼ºä¹å¯é çš„è¯„ä¼°æœºåˆ¶ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æ ¸å¿ƒæŒ‘æˆ˜ï¼š
- å¦‚ä½•åœ¨ä¸ç‰ºç‰²æ•…äº‹é€»è¾‘æ€§å’Œè¿è´¯æ€§çš„å‰æä¸‹ï¼Œç²¾ç¡®å¼•å¯¼æ¨¡å‹æ¨¡ä»¿ç»å…¸ä½œå®¶çš„å†™ä½œé£æ ¼ï¼Ÿ
- å¦‚ä½•æ„å»ºä¸€ä¸ªå¯é‡åŒ–ã€å¯æ§çš„é£æ ¼ç”Ÿæˆä¸è¯„ä¼°é—­ç¯ï¼Ÿ

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

1. **åŸºäº GRPO çš„é£æ ¼æ¡ä»¶åŒ–è®­ç»ƒæ¡†æ¶**
   - é¦–æ¬¡å°† **Group Relative Policy Optimization (GRPO)** åº”ç”¨äºé•¿ç¯‡å°è¯´çš„é£æ ¼åŒ–ç”Ÿæˆä»»åŠ¡ã€‚
   - åˆ©ç”¨ GRPO åŒæ¨¡å‹æ¶æ„ï¼ˆå‚è€ƒæ¨¡å‹ + å¯è®­ç»ƒç­–ç•¥æ¨¡å‹ï¼‰ï¼Œé€šè¿‡ç»„å†…å¥–åŠ±ä¼°è®¡å®ç°æ›´ç¨³å®šã€å¤šæ ·åŒ–çš„æ¢ç´¢ã€‚

2. **å¤šå¥–åŠ±ç³»ç»Ÿè®¾è®¡**
   - æ„å»ºä¸‰é‡å¥–åŠ±å‡½æ•°ï¼š
     - **Style Reward**ï¼šåŸºäº fine-tuned Sentence Transformer æ¨¡å‹è®¡ç®—ä¸ç›®æ ‡ä½œè€…ï¼ˆMark Twainï¼‰æ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼Œæºè‡ª Authorship Verification (AV) ä¿¡å·ã€‚
     - **Content Reward**ï¼šç”±å¦ä¸€ä¸ª LLMï¼ˆopenchat-3.5-0106ï¼‰æ ¹æ®é¢„å®šä¹‰è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œè¡¡é‡å™äº‹è´¨é‡ï¼ˆè¿è´¯æ€§ã€äººç‰©å‘å±•ç­‰ï¼‰ã€‚
     - **Completeness Reward**ï¼šæ£€æŸ¥è¾“å‡ºæ˜¯å¦è¾¾åˆ°çº¦ 1500 å­—å¹¶ä»¥å®Œæ•´å¥å­ç»“å°¾ï¼Œé˜²æ­¢æˆªæ–­æˆ–æœªå®Œæˆç»“å±€ã€‚
   - æœ€ç»ˆå¥–åŠ±ä¸ºåŠ æƒç»„åˆï¼š`0.6 Ã— Style + 0.3 Ã— Content + 0.1 Ã— Completeness`

3. **åŠ¨æ€é£æ ¼ç›¸ä¼¼æ€§è¯„ä¼°æŒ‡æ ‡**
   - å°† AV-based reward model çš„è¾“å‡ºä½œä¸º**åŠ¨æ€é£æ ¼å¯¹é½åº¦é‡**ï¼Œæä¾›å¯è§£é‡Šã€è¿ç»­çš„é£æ ¼åˆ†æ•°ï¼ˆè€Œéä»…åˆ†ç±»åˆ¤æ–­ï¼‰ã€‚

4. **å—æ§çš„æ•°æ®å¢å¼ºç­–ç•¥ç”¨äºé£æ ¼æ ‡æ³¨**
   - è®¾è®¡äº†ä¸€ç§åŸºäºæ©ç -é‡å¡«ï¼ˆmasking and refillï¼‰çš„æ–¹æ³•æ„é€ å¸¦æ ‡ç­¾çš„é£æ ¼ç›¸ä¼¼æ€§æ•°æ®é›†ï¼Œä½¿ç›¸ä¼¼åº¦è¿‘ä¼¼ç­‰äº `1 - r_mask`ï¼Œä»è€Œè·å¾—å¯è§£é‡Šçš„è½¯æ ‡ç­¾ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| **é£æ ¼å»ºæ¨¡æ·±åº¦** | æµ…å±‚æç¤ºï¼ˆå¦‚â€œç”¨é©¬å…‹Â·åæ¸©çš„è¯­æ°”â€ï¼‰ | åŸºäº AV çš„æ·±å±‚è¯­ä¹‰+å¥æ³•é£æ ¼åµŒå…¥ |
| **è®­ç»ƒæ–¹å¼** | å¤šæ•°ä¸ºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æˆ– DPO | ä½¿ç”¨ GRPO è¿›è¡Œå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ï¼Œæ”¯æŒå¤šæ ·åŒ–æ¢ç´¢ |
| **è¯„ä¼°å¯é æ€§** | ç¼ºä¹å®¢è§‚æŒ‡æ ‡æˆ–ä¾èµ–äººå·¥è¯„ä»· | å¼•å…¥ AV-based reward model ä½œä¸ºè‡ªåŠ¨åŒ–ã€å¯å¤ç°çš„é£æ ¼åº¦é‡ |
| **é•¿æ–‡æœ¬æ§åˆ¶èƒ½åŠ›** | æ˜“å‡ºç°é£æ ¼æ¼‚ç§»æˆ–é€»è¾‘æ–­è£‚ | å¤šå¥–åŠ±æœºåˆ¶ååŒç»´æŒé£æ ¼ä¸€è‡´æ€§ä¸å™äº‹å®Œæ•´æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

1. **åŸºç¡€æ•…äº‹ç”Ÿæˆæ•°æ®é›†ï¼ˆSFT Datasetï¼‰**
   - æ¥æºï¼šFan et al. (2018) çš„ 300K prompt-story å¯¹ã€‚
   - è‡ªå»ºå­é›†ï¼šä»ä¸­ç²¾é€‰ 50 ä¸ªé€šç”¨æ–‡å­¦æ€§æç¤ºï¼ˆpromptï¼‰ï¼Œä½¿ç”¨ Qwen2.5-32B ç”Ÿæˆ 40,000 ä¸ªçº¦ 1500 å­—çš„æ•…äº‹ã€‚
   - ç”¨é€”ï¼šç”¨äº Supervised Fine-Tuningï¼ˆSFTï¼‰ï¼Œå»ºç«‹åŸºç¡€å™äº‹èƒ½åŠ›ã€‚

2. **é£æ ¼å¯¹é½è®­ç»ƒæ•°æ®é›†ï¼ˆGRPO Datasetï¼‰**
   - ç›®æ ‡ä½œè€…ï¼šMark Twainï¼Œä»¥ *The Adventures of Huckleberry Finn* ä¸ºä¸»è¦å‚è€ƒæ–‡æœ¬ã€‚
   - æ„é€ æ–¹å¼ï¼š
     - å°†åŸè‘—åˆ‡åˆ†ä¸º 1500 å­—çš„æ®µè½ï¼›
     - ä½¿ç”¨ 7B æ¨¡å‹ï¼ˆopenchat-3.5-0106ï¼‰ä½œä¸ºè¯„ä¼°å™¨ï¼›
     - æ¯ä¸ªåŸå§‹ prompt è¢«ä¿®æ”¹ä¸ºåŒ…å«â€œä»¥é©¬å…‹Â·åæ¸©é£æ ¼å†™ä½œâ€çš„æŒ‡ä»¤ï¼›
     - å…±ç”Ÿæˆ 4,450 ä¸ª prompt-reference å¯¹ï¼Œç”¨äº GRPO å¾®è°ƒã€‚

3. **é£æ ¼å¥–åŠ±æ¨¡å‹è®­ç»ƒæ•°æ®**
   - æ­£æ ·æœ¬ï¼ˆPositive Pairsï¼‰ï¼šåŒä¸€ä½œè€…ä¸åŒä½œå“é—´çš„åŸæ®µè½ vs æ©ç åé‡å¡«æ®µè½ï¼Œå¾—åˆ† = `1 - r_mask`
   - è´Ÿæ ·æœ¬ï¼ˆNegative Pairsï¼‰ï¼šä¸åŒä½œè€…ä¹‹é—´çš„é‡å¡«æ®µè½ï¼Œå¾—åˆ† = 0
   - ä¸­é—´æ ·æœ¬ï¼ˆRefilled-Refilled Pairsï¼‰ï¼šåŒä½œè€…ä¸åŒä¹¦ä¸­ä¸¤æ¬¡é‡å¡«çš„ç»“æœï¼Œå¾—åˆ† = `|r_mask1 - r_mask2|`
   - æ€»è§„æ¨¡ï¼š65K è®­ç»ƒæ ·æœ¬ï¼Œ7K éªŒè¯/æµ‹è¯•å„ä¸€ä»½

---

### âš™ï¸ å®éªŒè®¾ç½®

- **æ¨¡å‹è§„æ¨¡**ï¼šä¸»å®éªŒä½¿ç”¨ **8B å‚æ•°æ¨¡å‹**
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š4Ã—NVIDIA A100 GPUï¼ˆ80GBï¼‰ï¼Œ2Ã—Intel Xeon CPUï¼Œ512GB RAM
- **è®­ç»ƒæµç¨‹**ï¼š
  1. SFT åˆå§‹åŒ– â†’ 2. Reward Model Fine-tuning â†’ 3. GRPO å¾®è°ƒ
- **è¶…å‚æ•°**ï¼š
  - å­¦ä¹ ç‡ï¼šåˆå§‹ 5e-6ï¼Œæœ€ç»ˆè°ƒæ•´è‡³ 3e-6
  - Î²ï¼ˆKL æ§åˆ¶ç³»æ•°ï¼‰ï¼šé€‰æ‹© **0.035** ä»¥å¹³è¡¡ç¨³å®šæ€§ä¸æ¢ç´¢æ•ˆç‡
  - æ‰¹å¤§å°ï¼šæ¯ prompt è‡³å°‘é‡‡æ · 16 ä¸ª completion
  - DrGRPO æŸå¤±å‡½æ•°ï¼ˆLiu et al., 2025ï¼‰

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Style Score** | åŸºäº fine-tuned AV reward model è¾“å‡ºçš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0â€“1ï¼‰ |
| **Content Score** | ç”± openchat-3.5-0106 æŒ‰ç…§å››çº§è¯„åˆ†æ ‡å‡†ç»™å‡ºï¼ˆ1â€“4 åˆ†ï¼‰ï¼Œå½’ä¸€åŒ–åˆ° [0.25, 1] |
| **Completeness Score** | æ˜¯å¦è¾¾å­—æ•°è¦æ±‚ + æ˜¯å¦å®Œæ•´ç»“æŸï¼Œæœ‰æƒ©ç½šå› å­ï¼ˆç¼ºå¥åˆ™Ã—0.5ï¼‰ |
| **Weighted Average Score** | `0.6Ã—Style + 0.3Ã—Content + 0.1Ã—Completeness` |
| **Human-interpretable Analysis** | å®šæ€§åˆ†æç”Ÿæˆæ–‡æœ¬çš„è¯­è¨€ç‰¹å¾ï¼ˆå¦‚æ–¹è¨€ä½¿ç”¨ã€ç¬¬ä¸€äººç§°å™è¿°ã€å¹½é»˜è®½åˆºè¯­æ°”ï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

å‚ä¸æ¯”è¾ƒçš„ä¸»æµ LLMs åŒ…æ‹¬ï¼š
- **GPT-4o**
- **Claude Sonnet 4**
- **Gemini 2.5 Flash**
- **Gemma 3-27B**
- **Qwen 2.5-32B**

æ‰€æœ‰æ¨¡å‹å‡æ¥æ”¶ç›¸åŒ 10 ä¸ª promptï¼Œå¹¶ç”Ÿæˆä¸€ç¯‡æ•…äº‹è¿›è¡Œç»Ÿä¸€è¯„åˆ†ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 3ï¼‰

| Model | Style (â†‘) | Content (â†‘) | Completeness (â†‘) | Weighted Avg (â†‘) |
|-------|-----------|-------------|------------------|------------------|
| **FT-Agentic (8B)** | **0.628** | 0.750 | 0.744 | **0.676** |
| GPT-4o | 0.510 | **0.800** | 0.873 | 0.633 |
| Claude Sonnet 4 | 0.450 | 0.750 | 0.999 | 0.595 |
| Qwen 2.5-32B | 0.328 | 0.750 | 0.911 | 0.513 |
| Gemma 3-27B | 0.306 | 0.750 | 0.450 | 0.453 |

> âœ… **æ ¸å¿ƒå‘ç°**ï¼šå°½ç®¡æˆ‘ä»¬çš„ 8B æ¨¡å‹åœ¨å†…å®¹è´¨é‡å’Œå®Œæ•´æ€§ä¸Šç•¥é€Šäº GPT-4o å’Œ Claudeï¼Œä½†åœ¨ **Style Score ä¸Šæ˜¾è‘—é¢†å…ˆï¼ˆ0.628 vs. 0.510ï¼‰**ï¼Œä¸”æ€»åŠ æƒå¾—åˆ†æœ€é«˜ï¼ˆ0.676ï¼‰ï¼Œè¯æ˜è¯¥æ–¹æ³•åœ¨é£æ ¼æ•æ‰ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒä¸å…³é”®åˆ†æ

#### ï¼ˆ1ï¼‰é£æ ¼å¥–åŠ±æ¨¡å‹ fine-tuning æ•ˆæœï¼ˆTable 1 vs Table 2ï¼‰
- **Pretrained Models è¡¨ç°å·®**ï¼šbaseline æ¨¡å‹ï¼ˆå¦‚ all-mpnet-base-v2ï¼‰åœ¨åŒºåˆ†åŒä½œè€… vs å¼‚ä½œè€…æ—¶å‡ ä¹æ— å·®å¼‚ï¼ˆâ–³â‰ˆ0.003â€“0.015ï¼‰ï¼ŒIQR é‡å  >80%
- **Fine-tuned åå¤§å¹…æå‡**ï¼š
  - FT-all-distilroberta-v1 è¾¾åˆ° â–³=+0.628ï¼ŒIQR é‡å é™è‡³ **0%**
  - æ‰€æœ‰ fine-tuned æ¨¡å‹å®ç°å®Œå…¨åˆ†å¸ƒåˆ†ç¦»ï¼Œè¯´æ˜ä»»åŠ¡ç‰¹å®šå¾®è°ƒè‡³å…³é‡è¦

#### ï¼ˆ2ï¼‰ä¸ºä½•é€‰æ‹© FT-all-mpnet-base-v2 ä½œä¸ºæœ€ç»ˆ RMï¼Ÿ
- è™½ç„¶ FT-all-distilroberta-v1 åœ¨åˆ¤åˆ«åŠ›ä¸Šæœ€å¼ºï¼Œä½†å…¶å¥–åŠ±ç©ºé—´è¿‡äºâ€œä¿å®ˆâ€ï¼ˆreward saturationï¼‰ï¼Œå¯¼è‡´æ—©æœŸ RL æ›´æ–°éš¾ä»¥è·å¾—æ­£åé¦ˆã€‚
- FT-all-mpnet-base-v2 æä¾›æ›´å¹³æ»‘çš„æ¢¯åº¦ä¿¡å·ï¼Œåˆ©äºç¨³å®šè®­ç»ƒã€‚

#### ï¼ˆ3ï¼‰Î² å‚æ•°å½±å“ï¼ˆFigure 3ï¼‰
- Î² < 0.04 å¯¼è‡´ KL divergence æ³¢åŠ¨å‰§çƒˆï¼Œè®­ç»ƒä¸ç¨³å®šï¼›
- Î² = 0.035 ç»“åˆä½å­¦ä¹ ç‡ï¼ˆ3e-6ï¼‰å’Œæ¢¯åº¦å½’ä¸€åŒ–å¯æœ‰æ•ˆæŠ‘åˆ¶ reward hackingã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **é£æ ¼å¯ä»¥è¢«æœ‰æ•ˆå»ºæ¨¡ä¸ä¼˜åŒ–**  
   é€šè¿‡ AV-based reward model ä¸ GRPO æ¡†æ¶ç»“åˆï¼Œå³ä½¿æ˜¯ä¸­ç­‰è§„æ¨¡ï¼ˆ8Bï¼‰æ¨¡å‹ä¹Ÿèƒ½åœ¨é£æ ¼æ¨¡ä»¿ä¸Šè¶…è¶Š GPT-4o ç­‰æ›´å¤§æ¨¡å‹ã€‚

2. **é£æ ¼ä¸å™äº‹å®Œæ•´æ€§å­˜åœ¨æƒè¡¡**  
   å®éªŒè¡¨æ˜ï¼Œè¿½æ±‚é«˜é£æ ¼å¯¹é½å¯èƒ½å¯¼è‡´ completeness ä¸‹é™ï¼ˆæœ¬æ¨¡å‹ completeness=0.744ï¼Œä½äº Claude çš„ 0.999ï¼‰ï¼Œåæ˜ å…¨å±€è¿è´¯æ€§ä»æ˜¯æŒ‘æˆ˜ã€‚

3. **å¤šå¥–åŠ±æœºåˆ¶æå‡è®­ç»ƒç¨³å®šæ€§**  
   å†…å®¹ä¸å®Œæ•´æ€§å¥–åŠ±æœ‰æ•ˆé˜²æ­¢æ¨¡å‹é™·å…¥â€œåªé¡¾é£æ ¼è€Œå¿½ç•¥æƒ…èŠ‚â€çš„é™·é˜±ï¼Œç¡®ä¿ç”Ÿæˆçš„æ˜¯å®Œæ•´ã€å¯è¯»çš„æ•…äº‹ã€‚

4. **å°æ¨¡å‹ + ç‰¹å®šè®­ç»ƒ > å¤§æ¨¡å‹ + é€šç”¨èƒ½åŠ›**  
   åœ¨ç‰¹å®šä»»åŠ¡ï¼ˆç»å…¸ä½œå®¶é£æ ¼ç”Ÿæˆï¼‰ä¸Šï¼Œç»è¿‡ç²¾å¿ƒè®¾è®¡çš„ä»»åŠ¡ä¸“ç”¨è®­ç»ƒæµç¨‹ï¼Œå°å‹æ¨¡å‹å¯è¶…è¶Šé€šç”¨å¤§æ¨¡å‹ã€‚

---

### âš ï¸ å±€é™æ€§

1. **è®¡ç®—èµ„æºé™åˆ¶å¯¼è‡´å†…å®¹å¥–åŠ±æ¨¡å‹ä¸å¯é **  
   å½“å‰ content reward ä¾èµ–å•ä¸€ LLM æ‰“åˆ†ï¼Œå­˜åœ¨è¯¯åˆ¤é£é™©ï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚å™äº‹ç»“æ„æ—¶ã€‚

2. **è®­ç»ƒæ•°æ®èŒƒå›´ç‹­çª„**  
   ä»…åŸºäº Mark Twain çš„ä¸€éƒ¨ä½œå“ï¼ˆ*Huckleberry Finn*ï¼‰è¿›è¡Œè®­ç»ƒï¼Œæ³›åŒ–èƒ½åŠ›å—é™ï¼Œæ— æ³•é€‚åº”å…¶ä»–æ–‡ä½“æˆ–ä½œè€…ã€‚

3. **ç¼ºä¹äººç±»ä¸»è§‚è¯„ä¼°**  
   æ‰€æœ‰è¯„ä¼°å‡ä¸ºè‡ªåŠ¨æŒ‡æ ‡é©±åŠ¨ï¼Œç¼ºå°‘çœŸå®è¯»è€…å¯¹â€œé£æ ¼çœŸå®æ€§â€çš„æ„ŸçŸ¥éªŒè¯ã€‚

4. **å™äº‹å®Œæ•´æ€§ä»å¾…æ”¹è¿›**  
   éƒ¨åˆ†ç”Ÿæˆæ•…äº‹è™½é£æ ¼é²œæ˜ï¼Œä½†ç»“å±€ä»“ä¿ƒæˆ–é€»è¾‘æ–­è£‚ï¼Œæ˜¾ç¤ºé•¿æœŸä¾èµ–å»ºæ¨¡ä»æœ‰å›°éš¾ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•å¤šä½œè€…ã€å¤šä½“è£æ•°æ®é›†**  
   æ”¶é›†æ›´å¤šç»å…¸ä½œå®¶ä½œå“ï¼ˆå¦‚ Jane Austen, Hemingway, Dickensï¼‰ï¼Œæ„å»ºè·¨é£æ ¼è¿ç§»èƒ½åŠ›ã€‚

2. **å¼•å…¥äººç±»åé¦ˆï¼ˆRLHF æˆ– RLAIFï¼‰**  
   ç»“åˆäººå·¥æ ‡æ³¨æå‡é£æ ¼çœŸå®æ€§ä¸å™äº‹è´¨é‡çš„è¯„ä¼°å¯ä¿¡åº¦ã€‚

3. **æ”¹è¿›å†…å®¹å¥–åŠ±æ¨¡å‹**  
   ä½¿ç”¨æ›´å¼ºçš„ evaluator model æˆ–é›†æˆå¤šä¸ªæ¨¡å‹æŠ•ç¥¨æœºåˆ¶ï¼Œæé«˜ content scoring çš„é²æ£’æ€§ã€‚

4. **æ¢ç´¢å…¨å±€å™äº‹è§„åˆ’æ¨¡å—**  
   åœ¨ç”Ÿæˆå‰åŠ å…¥ plot planner æˆ– outline generatorï¼Œè¾…åŠ©ç»´æŒé•¿ç¨‹ä¸€è‡´æ€§ã€‚

5. **ä¼¦ç†é€æ˜åŒ–æœºåˆ¶**  
   æ˜ç¡®å£°æ˜ç”Ÿæˆæ–‡æœ¬éâ€œå¤æ´»â€ä½œè€…ï¼Œé¿å…è¯¯å¯¼æ€§ä½¿ç”¨ï¼Œå¼ºè°ƒæ•™è‚²ä¸åˆ›æ„è¾…åŠ©å®šä½ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€å¥—åŸºäº **GRPO + AV-style reward modeling** çš„æ–°å‹é£æ ¼åŒ–é•¿ç¯‡æ•…äº‹ç”Ÿæˆæ¡†æ¶ï¼Œåœ¨æœ‰é™æ¨¡å‹è§„æ¨¡ä¸‹å®ç°äº†ä¼˜äº GPT-4o çš„ç»å…¸ä½œå®¶é£æ ¼æ•æ‰èƒ½åŠ›ï¼ŒéªŒè¯äº†â€œagent-styleâ€åˆ›ä½œä»£ç†çš„å¯è¡Œæ€§ï¼ŒåŒæ—¶æ­ç¤ºäº†é£æ ¼ä¿çœŸä¸å™äº‹å®Œæ•´çš„å†…åœ¨å¼ åŠ›ï¼Œä¸ºæœªæ¥å¯æ§åˆ›æ„ç”Ÿæˆç ”ç©¶æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 7. [LDLT $\mathcal{L}$-Lipschitz Network: Generalized Deep End-To-End Lipschitz Network Construction](https://arxiv.org/abs/2512.05915)

**Authors**: Marius F. R. Juston, Ramavarapu S. Sreenivas, Dustin Nottage, Ahmet Soylemezoglu  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.05915v1  

#### Abstract
Deep residual networks (ResNets) have demonstrated outstanding success in computer vision tasks, attributed to their ability to maintain gradient flow through deep architectures. Simultaneously, controlling the Lipschitz constant in neural networks has emerged as an essential area of research to enh...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLDLT $\mathcal{L}$-Lipschitz Network

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡æ—¨åœ¨è§£å†³æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰åœ¨å®‰å…¨æ•æ„Ÿé¢†åŸŸä¸­çš„**å¯¹æŠ—é²æ£’æ€§**å’Œ**å¯è®¤è¯æ€§**é—®é¢˜ã€‚ä¼ ç»Ÿæ·±åº¦ç½‘ç»œå¯¹è¾“å…¥çš„å°æ‰°åŠ¨éå¸¸æ•æ„Ÿï¼Œå®¹æ˜“å—åˆ°å¯¹æŠ—æ”»å‡»ã€‚é€šè¿‡æ–½åŠ  **Lipschitz çº¦æŸ**å¯ä»¥é™åˆ¶ç½‘ç»œè¾“å‡ºå¯¹è¾“å…¥å˜åŒ–çš„æ•æ„Ÿåº¦ï¼Œä»è€Œæå‡æ¨¡å‹çš„é²æ£’æ€§å’Œå¯éªŒè¯æ€§ã€‚

ç„¶è€Œï¼Œç°æœ‰çš„ Lipschitz çº¦æŸæ–¹æ³•å­˜åœ¨ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- å¤šæ•°åŸºäº **SDPï¼ˆSemidefinite Programmingï¼‰æ¡†æ¶**çš„æ–¹æ³•éš¾ä»¥æ‰©å±•åˆ°æ·±å±‚æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰ï¼Œå› ä¸ºå…¶å½¢æˆçš„ LMIï¼ˆLinear Matrix Inequalityï¼‰å…·æœ‰å¤æ‚çš„å¾ªç¯ä¸‰å¯¹è§’ç»“æ„ï¼Œå¯¼è‡´é—­å¼è§£éš¾ä»¥æ¨å¯¼ã€‚
- ç°æœ‰æ–¹æ³•å¤šä¸ºé€å±‚çº¦æŸï¼ˆå¦‚å †å  1-Lipschitz å±‚ï¼‰ï¼Œç¼ºä¹ç«¯åˆ°ç«¯çš„å…¨å±€ Lipschitz æ§åˆ¶ï¼Œå¯èƒ½å¯¼è‡´è¡¨è¾¾èƒ½åŠ›ä¸‹é™æˆ–ä¼˜åŒ–å›°éš¾ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **LDLT $\mathcal{L}$-Lipschitz Network** çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ **LDLT åˆ†è§£** æ¥é«˜æ•ˆæ±‚è§£å¹¶å‚æ•°åŒ–æ»¡è¶³ Lipschitz çº¦æŸçš„æ·±å±‚ç½‘ç»œã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. **å°† ResNet æ„å»ºä¸ºå¾ªç¯å—ä¸‰å¯¹è§’ LMI**  
   å°†æ•´ä¸ªæ®‹å·®ç½‘ç»œçš„ Lipschitz çº¦æŸå½¢å¼åŒ–ä¸ºä¸€ä¸ªå¤§å‹çº¿æ€§çŸ©é˜µä¸ç­‰å¼ç³»ç»Ÿï¼Œå¹¶è¯†åˆ«å‡ºå…¶ç‰¹æœ‰çš„â€œä¼ªä¸‰å¯¹è§’â€ç»“æ„ã€‚

2. **å¼•å…¥ LDLT åˆ†è§£è¿›è¡Œå¯è¡Œæ€§è®¤è¯ä¸å‚æ•°åŒ–**  
   åˆ©ç”¨ **LDLT åˆ†è§£**ï¼ˆå®æ•°å¹³æ–¹æ ¹è‡ªç”± Cholesky åˆ†è§£ï¼‰å°†åŸå§‹ LMI è½¬æ¢ä¸ºæ›´æ˜“å¤„ç†çš„å½¢å¼ã€‚è¯¥åˆ†è§£å…è®¸ç›´æ¥çº¦æŸå¯¹è§’çŸ©é˜µ $D$ çš„æ­£å®šæ€§æ¥ä¿è¯æ•´ä½“ LMI çš„åŠè´Ÿå®šæ€§ï¼Œé¿å…æ˜‚è´µçš„ç‰¹å¾å€¼è®¡ç®—ã€‚

3. **æå‡ºç«¯åˆ°ç«¯çš„ C-Lipschitz å‚æ•°åŒ–æ–¹æ³•**  
   æ¨å¯¼å‡ºç½‘ç»œæƒé‡ï¼ˆ$A, B, \{C_i\}$ï¼‰çš„æ˜¾å¼å‚æ•°åŒ–å…¬å¼ï¼Œç¡®ä¿æ•´ä¸ªç½‘ç»œæ»¡è¶³å…¨å±€ C-Lipschitz æ¡ä»¶ï¼Œè€Œä¸ä»…ä»…æ˜¯æ¯å±‚ç‹¬ç«‹æ»¡è¶³ã€‚è¿™å®ç°äº†çœŸæ­£çš„ **end-to-end Lipschitz æ„é€ **ã€‚

4. **ç»“åˆ Cholesky åˆ†è§£å®ç°é«˜æ•ˆè®¡ç®—**  
   è¿›ä¸€æ­¥ä½¿ç”¨ **Cholesky åˆ†è§£** æ›¿ä»£çŸ©é˜µå¹³æ–¹æ ¹è¿ç®—ï¼Œåœ¨ä¿æŒç›¸åŒè¡¨è¾¾èƒ½åŠ›çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¤æ‚åº¦ï¼ˆä» $O(n^3)$ åˆ° $O(n)$ï¼‰ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡ç½‘ç»œã€‚

5. **é€šç”¨æ¶æ„æ‰©å±•èƒ½åŠ›**  
   æ‰€ææ–¹æ³•ä¸ä»…é€‚ç”¨äº ResNetï¼Œè¿˜å¯æ¨å¹¿è‡³å…¶ä»–åˆ†å±‚éçº¿æ€§ç³»ç»Ÿï¼Œå¦‚å…¨è¿æ¥ç½‘ç»œï¼ˆFNNï¼‰ã€U-Net ç­‰ï¼Œæä¾›ç»Ÿä¸€çš„ Lipschitz æ„é€ èŒƒå¼ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | LDLT æ–¹æ³• | å…¶ä»–ä¸»æµæ–¹æ³•ï¼ˆå¦‚ SLL, AOL, Orthogonalï¼‰ |
|------|----------|----------------------------------------|
| **ç†è®ºä¿éšœ** | âœ… ä¸¥æ ¼çš„å…¨å±€ C-Lipschitz ä¿è¯ | âš ï¸ å¤šä¸ºé€å±‚è¿‘ä¼¼æˆ–æ¾å¼› |
| **è¡¨è¾¾èƒ½åŠ›** | âœ… é«˜ï¼ˆæ”¯æŒæ·±å±‚æ¨¡å—åŒ–ç»“æ„ï¼‰ | âŒ å—é™äºæ­£äº¤/å•ä½è°±å½’ä¸€åŒ– |
| **è®¡ç®—æ•ˆç‡** | âœ… ä½¿ç”¨ Cholesky åŠ é€Ÿï¼Œé¿å…ç‰¹å¾å€¼åˆ†è§£ | âš ï¸ æˆ–éœ€è¿­ä»£æŠ•å½±ã€å¹‚è¿­ä»£ç­‰è€—æ—¶æ“ä½œ |
| **çµæ´»æ€§** | âœ… æ”¯æŒå¤šç§æ¿€æ´»å‡½æ•°ï¼ˆReLU, GELU, SiLU ç­‰ï¼‰ | âš ï¸ æŸäº›æ–¹æ³•å¯¹æ¿€æ´»å‡½æ•°æœ‰é™åˆ¶ |
| **å¯æ‰©å±•æ€§** | âœ… å¯æ‰©å±•è‡³ ConvNetã€U-Net ç­‰å¤æ‚ç»“æ„ | âš ï¸ å¤šé›†ä¸­äºç®€å•å‰é¦ˆç»“æ„ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒåœ¨ **121 ä¸ª UCI æœºå™¨å­¦ä¹ æ•°æ®é›†** ä¸Šè¿›è¡Œï¼Œæ¶µç›–ç‰©ç†ã€åœ°è´¨ã€ç”Ÿç‰©ç­‰å¤šä¸ªé¢†åŸŸã€‚è¿™äº›æ•°æ®é›†å¤§å°ä» 10 åˆ° 6300 ä¸‡æ ·æœ¬ä¸ç­‰ï¼Œç‰¹å¾ç»´åº¦ä» 1 åˆ° 320 ä¸‡ï¼Œå…·æœ‰å¹¿æ³›çš„ä»£è¡¨æ€§ã€‚

å­é›†é€‰æ‹©å‚è€ƒäº†å…ˆå‰å…³äº SeLU çš„ç ”ç©¶å·¥ä½œï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

### å®éªŒè®¾ç½®
- **ç½‘ç»œç»“æ„**ï¼šæ‰€æœ‰æ¨¡å‹å‡ä¸º **4 å±‚éšè—å±‚** çš„ MLPã€‚
- **å®½åº¦å¯å‘å¼**ï¼šæ ¹æ®è¾“å…¥è§„æ¨¡åŠ¨æ€è®¾å®šå®½åº¦ $w = \min(\max(4N, 32), 512)$ï¼Œå¹¶å–æœ€æ¥è¿‘çš„ 2 çš„å¹‚æ¬¡ã€‚
- **ä¼˜åŒ–å™¨**ï¼šä½¿ç”¨ **AdamW**ï¼Œåˆå§‹å­¦ä¹ ç‡ $1e^{-3}$ï¼Œweight decay $1e^{-4}$ã€‚
- **å­¦ä¹ ç‡è°ƒåº¦**ï¼šå½“éªŒè¯å‡†ç¡®ç‡åœæ»è¶…è¿‡ 8 ä¸ª epoch æ—¶å‡åŠã€‚
- **è®­ç»ƒè½®æ•°**ï¼šæœ€å¤š 100 ä¸ª epochï¼Œæ—©åœæ¡ä»¶ä¸º 30 ä¸ª epoch æ— æ”¹è¿›ã€‚
- **æŸå¤±å‡½æ•°**ï¼šäº¤å‰ç†µæŸå¤±ï¼Œä½¿ç”¨ç±»åˆ«æƒé‡å¹³è¡¡ä¸å¹³è¡¡æ•°æ®ã€‚
- **æœ€åä¸€å±‚**ï¼šæ·»åŠ  **çº¿æ€§å½’ä¸€åŒ–å¤´ï¼ˆlinear normalization headï¼‰** ä»¥æ–¹ä¾¿è®¤è¯å‡†ç¡®ç‡è®¡ç®—ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
1. **Clean Accuracy**ï¼šæ ‡å‡†æµ‹è¯•é›†ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡ã€‚
2. **Certified Robust Accuracy**ï¼šåœ¨ä¸åŒ $l_2$ æ‰°åŠ¨åŠå¾„ä¸‹çš„**å¯è¯æ˜é²æ£’å‡†ç¡®ç‡**ï¼Œå³é¢„æµ‹æ ‡ç­¾åœ¨æ‰°åŠ¨çƒå†…ä¸å˜çš„æ¯”ä¾‹ã€‚
   - æµ‹è¯•åŠå¾„ï¼š$\epsilon = 36/255, 72/255, 108/255, 255/255$
3. **ç»Ÿè®¡æ£€éªŒ**ï¼š
   - **å¹³å‡æ’åï¼ˆAverage Rankï¼‰**
   - **Wilcoxon ç¬¦å·ç§©æ£€éªŒ**ï¼ˆé…å¯¹æ¯”è¾ƒï¼‰
   - **Nemenyi æ£€éªŒ**ï¼ˆå¤šé‡æ¯”è¾ƒæ ¡æ­£ï¼‰

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±å¯¹æ¯”å…­ç§æ–¹æ³•ï¼š
| æ–¹æ³• | ç±»å‹ |
|------|------|
| **AOL** | Almost-Orthogonal Layers |
| **Orthogonal** | æ­£äº¤å‚æ•°åŒ–ç½‘ç»œ |
| **Sandwich** | Sandwich Layers (Wang & Manchester, 2023) |
| **SLL** | SDP-based Lipschitz Layers (Araujo et al., 2023) |
| **LDLT-L** | LDLT æ„é€ çš„çº¿æ€§ç½‘ç»œå˜ä½“ |
| **LDLT-R** | LDLT æ„é€ çš„æ®‹å·®ç½‘ç»œå˜ä½“ï¼ˆæœ¬æ–‡ä¸»æ¨ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰

| Algorithm | Clean Acc (%) | Certified @ 36/255 | @ 72/255 | @ 108/255 | @ 255/255 |
|----------|---------------|---------------------|-----------|------------|------------|
| **AOL** | 62.95 Â± 0.2278 | 36.69 | 26.60 | 20.76 | 9.99 |
| **Orthogonal** | 69.69 Â± 0.1938 | 59.73 | 50.73 | 43.00 | 19.70 |
| **Sandwich** | **72.15 Â± 0.1871** | **63.75** | **55.93** | **48.36** | **24.96** |
| **SLL** | 69.78 Â± 0.1998 | 58.85 | 49.75 | 41.46 | 19.18 |
| **LDLT-L** | 72.23 Â± 0.1868 | 53.01 | 42.93 | 35.35 | 16.52 |
| **LDLT-R** | 70.22 Â± 0.1944 | 61.07 | 52.92 | 44.92 | 21.72 |

> æ³¨ï¼šæ•°å€¼ä¸º 121 ä¸ªæ•°æ®é›†ä¸Šçš„å‡å€¼ Â± æ ‡å‡†å·®ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰æ€»ä½“æ’åè¡¨ç°ï¼ˆTable 3â€“4ï¼‰
- åœ¨ **Clean Accuracy** ä¸Šï¼š
  - **LDLT-L** è¡¨ç°æœ€ä½³ï¼ˆå¹³å‡æ’å 2.434ï¼‰ï¼Œç•¥ä¼˜äº **Sandwich**ï¼ˆ2.566ï¼‰ã€‚
  - **LDLT-R** æ’åç¬¬ä¸‰ï¼ˆ3.438ï¼‰ï¼Œä¼˜äº SLL å’Œ Orthogonalã€‚
- åœ¨ **Certified Accuracy**ï¼ˆå„æ‰°åŠ¨çº§åˆ«ï¼‰ä¸Šï¼š
  - **Sandwich** å§‹ç»ˆæ’åç¬¬ä¸€ã€‚
  - **LDLT-R** ç¨³å®šç¬¬äºŒï¼Œæ˜¾è‘—ä¼˜äº SLLã€Orthogonal å’Œ AOLã€‚
  - **LDLT-L** åœ¨é«˜æ‰°åŠ¨ä¸‹è¡¨ç°è¾ƒå·®ï¼Œè¯´æ˜å…¶ç»“æ„å¯¹å™ªå£°å®¹å¿åº¦è¾ƒä½ã€‚

#### ï¼ˆ2ï¼‰ç›¸å¯¹äº SLL çš„ä¼˜åŠ¿
- LDLT-R åœ¨æ‰€æœ‰æ‰°åŠ¨çº§åˆ«çš„è®¤è¯å‡†ç¡®ç‡ä¸Šå‡ **æ˜¾è‘—é«˜äº SLL**ã€‚
- å¹³å‡æå‡å¹…åº¦è¾¾ **3%â€“13%**ï¼Œå°¤å…¶åœ¨ä¸­ç­‰æ‰°åŠ¨ï¼ˆ72/255 ~ 108/255ï¼‰åŒºé—´ä¼˜åŠ¿æ˜æ˜¾ã€‚
- Wilcoxon æ£€éªŒæ˜¾ç¤º LDLT-R å¯¹ SLL çš„èƒœç‡é«˜è¾¾ 66/121ï¼ˆTable 10ï¼‰ï¼Œä¸” p-value < 0.001ã€‚

#### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒåˆ†æï¼ˆéšå«åœ¨è®¾è®¡ä¸­ï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»æ–¹æ³•è®¾è®¡å¯ä»¥çœ‹å‡ºï¼š
- ä½¿ç”¨ **LDLT åˆ†è§£** è€Œéä¼ ç»Ÿ Cholesky æˆ– SDP æ±‚è§£ï¼Œä½¿æ·±å±‚ ResNet çš„ Lipschitz æ„é€ æˆä¸ºå¯èƒ½ã€‚
- å¼•å…¥ **Cholesky åŠ é€Ÿ** æ˜¾è‘—é™ä½äº†è®­ç»ƒå¼€é”€ï¼Œä½¿å¾—å¤§æ¨¡å‹å¯è¡Œã€‚
- **æ®‹å·®ç»“æ„ï¼ˆLDLT-Rï¼‰** æ¯”çº¿æ€§ç»“æ„ï¼ˆLDLT-Lï¼‰åœ¨è®¤è¯é²æ£’æ€§ä¸Šæ›´å…·ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨ä¸­ç­‰æ‰°åŠ¨æ°´å¹³ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LDLT åˆ†è§£æ˜¯ä¸€ç§æœ‰æ•ˆçš„ LMI æ±‚è§£å·¥å…·**ï¼Œç‰¹åˆ«é€‚åˆå¤„ç†å…·æœ‰ç¨€ç–å—ç»“æ„çš„æ·±å±‚ç½‘ç»œ LMIï¼Œèƒ½å¤Ÿå®ç°ç²¾ç¡®ä¸”é«˜æ•ˆçš„ Lipschitz çº¦æŸå‚æ•°åŒ–ã€‚
2. **LDLT-R æ„é€ çš„æ®‹å·®ç½‘ç»œåœ¨è®¤è¯é²æ£’æ€§æ–¹é¢æ˜¾è‘—ä¼˜äº SLL å±‚**ï¼Œè¯æ˜äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚
3. å°½ç®¡ **Sandwich Layer** æ•´ä½“æ€§èƒ½æœ€ä¼˜ï¼Œä½† LDLT-R æ˜¯å”¯ä¸€èƒ½ä¸ä¹‹æŠ—è¡¡çš„åŸºäºä¸¥æ ¼ LMI çš„æ„é€ æ–¹æ³•ï¼Œä¸”å…·å¤‡æ›´å¼ºçš„ç†è®ºå¯è§£é‡Šæ€§ã€‚
4. **Cholesky åŠ é€Ÿç­–ç•¥ä¸ä¼šæŸå¤±è¡¨è¾¾èƒ½åŠ›**ï¼ˆLemma 26ï¼‰ï¼Œå¯åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å¤§å¹…æå‡è®¡ç®—æ•ˆç‡ã€‚
5. è¯¥æ¡†æ¶å…·æœ‰è‰¯å¥½çš„**é€šç”¨æ€§**ï¼Œå¯è‡ªç„¶æ‰©å±•åˆ° FNNã€ConvNetã€U-Net ç­‰å¤šç§æ¶æ„ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **æ•°å€¼ç¨³å®šæ€§é—®é¢˜**ï¼šåœ¨ææ·±ç½‘ç»œä¸­ï¼ŒResNet ç»“æ„å¯èƒ½å‡ºç°æ•°å€¼ä¸ç¨³å®šï¼Œéœ€è¦æ›´é²æ£’çš„ Cholesky æ›´æ–°æœºåˆ¶ã€‚
2. **å·ç§¯å®ç°æˆæœ¬é«˜**ï¼šå½“å‰å·ç§¯ç‰ˆæœ¬ä¾èµ–é¢‘åŸŸå˜æ¢å’Œå¤æ•°è¿ç®—ï¼Œè®¡ç®—å¼€é”€è¾ƒå¤§ï¼Œå°¤å…¶åœ¨ CIFARã€TinyImageNet ç­‰å›¾åƒä»»åŠ¡ä¸Šéš¾ä»¥æ‰©å±•ã€‚
3. **PyTorch æ”¯æŒä¸è¶³**ï¼šç¼ºå°‘é’ˆå¯¹ä¸‰è§’çŸ©é˜µä¹˜æ³•çš„åŸç”Ÿä¼˜åŒ–å†…æ ¸ï¼Œéœ€è‡ªå®šä¹‰ CUDA å®ç°æ‰èƒ½å……åˆ†å‘æŒ¥æ€§èƒ½æ½œåŠ›ã€‚
4. **è¶…å‚è°ƒä¼˜å¤æ‚**ï¼šå‚æ•°åŒ–æ¶‰åŠå¤šä¸ªç¼©æ”¾å› å­ï¼ˆå¦‚ $\alpha, \gamma$ï¼‰ï¼Œéœ€ careful tuning æ‰èƒ½è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é›†æˆ Sandwich Layer æ€æƒ³**ï¼šå°† Sandwich çš„é«˜æ€§èƒ½å‚æ•°åŒ–æ–¹å¼èå…¥ LDLT æ¡†æ¶ï¼Œè¿›ä¸€æ­¥æå‡ç²¾åº¦ã€‚
2. **å¼€å‘ U-Net ç‰ˆæœ¬**ï¼šæ¢ç´¢ 1-Lipschitz U-Net åœ¨ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚ Diffusion Modelï¼‰ä¸­çš„åº”ç”¨ï¼Œæ„å»º Lipschitz ç¼–ç ç©ºé—´ã€‚
3. **è®¾è®¡æ–°å‹å½’ä¸€åŒ–æ–¹æ¡ˆ**ï¼šåŸºäº LDLT åˆ†è§£å¼€å‘æ›´é«˜æ•ˆçš„è®­ç»ƒåŠ é€Ÿç­–ç•¥ã€‚
4. **æ‹“å±•è‡³å›¾åƒåŸºå‡†**ï¼šåœ¨ CIFAR-10/100ã€TinyImageNet ä¸ŠéªŒè¯æ–¹æ³•çš„å¤§è§„æ¨¡é€‚ç”¨æ€§ã€‚
5. **å¼€æºæ”¯æŒå¢å¼º**ï¼šå‘å¸ƒå®Œæ•´ä»£ç ä¸é¢„è®­ç»ƒæƒé‡ï¼ˆå·²éƒ¨åˆ†å…¬å¼€äº GitHub å’Œ HuggingFaceï¼‰ã€‚

---

> **ä»£ç ä»“åº“**ï¼šhttps://github.com/Marius-Juston/DeepLipschitzResNet  
> **æ¨¡å‹æƒé‡**ï¼šhttps://huggingface.co/SuperComputer/LDLT

</details>

---

### 8. [BEAVER: An Efficient Deterministic LLM Verifier](https://arxiv.org/abs/2512.05439)

**Authors**: Tarun Suresh, Nalin Wadhwa, Debangshu Banerjee, Gagandeep Singh  
**Category**: cs.AI  
**Published**: 2025-12-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.05439v1  

#### Abstract
As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of model behavior, they offer no sound guarantees. We pr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# BEAVER: An Efficient Deterministic LLM Verifier è®ºæ–‡æ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»ç ”ç©¶åŸå‹è½¬å‘ç”Ÿäº§ç³»ç»Ÿï¼Œç¡®ä¿å…¶è¾“å‡ºæ»¡è¶³ç‰¹å®šçº¦æŸï¼ˆå¦‚æ­£ç¡®æ€§ã€éšç§ã€å®‰å…¨æ€§ï¼‰å˜å¾—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„éªŒè¯æ–¹æ³•å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼š
- **Sampling-based æ–¹æ³•**ï¼ˆå¦‚ rejection samplingï¼‰ä»…æä¾›ç»Ÿè®¡ä¼°è®¡ï¼Œæ— æ³•ç»™å‡º**sound guarantees**ï¼ˆå³ç¡®å®šæ€§çš„æ¦‚ç‡è¾¹ç•Œï¼‰ã€‚
- ä¼ ç»Ÿç¥ç»ç½‘ç»œéªŒè¯æŠ€æœ¯ï¼ˆå¦‚åŸºäºæŠ½è±¡è§£é‡Šæˆ– SMT æ±‚è§£å™¨çš„æ–¹æ³•ï¼‰éš¾ä»¥æ‰©å±•åˆ° LLM çš„è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ã€‚

å› æ­¤ï¼Œè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•ä¸º LLM è¾“å‡ºæä¾›**ç¡®å®šæ€§ã€å¯è¯æ˜æ­£ç¡®çš„æ¦‚ç‡è¾¹ç•Œ**è¿™ä¸€æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€è·¯
ä½œè€…æå‡ºäº† **BEAVER**ï¼Œè¿™æ˜¯é¦–ä¸ªå®ç”¨çš„ã€ç”¨äºè®¡ç®— LLM çº¦æŸæ»¡è¶³æ¦‚ç‡çš„**ç¡®å®šæ€§ã€sound éªŒè¯æ¡†æ¶**ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **å½¢å¼åŒ–éªŒè¯é—®é¢˜**ï¼šå°† LLM éªŒè¯é—®é¢˜å®šä¹‰ä¸ºåœ¨ç»™å®šæç¤ºï¼ˆpromptï¼‰ä¸‹ï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½è¾“å‡ºåºåˆ—ä¸­æ»¡è¶³è¯­ä¹‰çº¦æŸï¼ˆsemantic constraintï¼‰çš„æ€»æ¦‚ç‡ï¼Œå¹¶æ±‚å…¶ sound çš„ä¸Šä¸‹ç•Œ `[PLB, PUB]`ã€‚
- **åˆ©ç”¨ Prefix-closed è¯­ä¹‰çº¦æŸ**ï¼šé’ˆå¯¹ä¸€ç±»é‡è¦çš„â€œå‰ç¼€å°é—­â€ï¼ˆprefix-closedï¼‰è¯­ä¹‰çº¦æŸï¼ˆå³ä¸€æ—¦æŸä¸ªå‰ç¼€è¿åçº¦æŸï¼Œåˆ™å…¶æ‰€æœ‰åç»­æ‰©å±•ä¹Ÿå¿…ç„¶è¿åï¼‰ï¼ŒBEAVER èƒ½å¤Ÿåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­**å°½æ—©æ£€æµ‹å¹¶å‰ªæ**ï¼ˆpruneï¼‰è¿åçº¦æŸçš„è·¯å¾„ï¼Œä»è€Œå¤§å¹…å‡å°‘æœç´¢ç©ºé—´ã€‚
- **æ–°é¢–çš„æ•°æ®ç»“æ„**ï¼š
  - **Token Trie**ï¼šæ˜¾å¼åœ°è·Ÿè¸ªæ‰€æœ‰å·²æ¢ç´¢çš„ã€æ»¡è¶³çº¦æŸçš„å‰ç¼€åºåˆ—åŠå…¶æ¦‚ç‡ã€‚
  - **Frontier**ï¼šç»´æŠ¤å½“å‰å¾…æ‰©å±•çš„ä¸å®Œæ•´åºåˆ—é›†åˆï¼Œç”¨äºé«˜æ•ˆæ›´æ–°æ¦‚ç‡è¾¹ç•Œã€‚
- **åˆ†æ”¯å®šç•Œï¼ˆBranch-and-Boundï¼‰ç®—æ³•**ï¼šé€šè¿‡è¿­ä»£é€‰æ‹© Frontier ä¸­çš„åºåˆ—è¿›è¡Œæ‰©å±•ï¼Œé€æ­¥æ”¶ç´§æ¦‚ç‡è¾¹ç•Œï¼Œæä¾›â€œanytime guaranteesâ€ï¼ˆå³åœ¨ä»»æ„æ—¶åˆ»ç»ˆæ­¢éƒ½èƒ½å¾—åˆ° sound çš„åŒºé—´ï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **Soundness**ï¼šç›¸æ¯”é‡‡æ ·æ–¹æ³•ï¼ŒBEAVER æä¾›çš„æ˜¯**å¯è¯æ˜æ­£ç¡®çš„æ¦‚ç‡è¾¹ç•Œ**ï¼Œè€Œéç»Ÿè®¡ä¼°è®¡ã€‚
- **æ•ˆç‡ä¸ç²¾åº¦**ï¼šç›¸æ¯” baselineï¼ˆrejection samplingï¼‰ï¼ŒBEAVER èƒ½å¤Ÿå®ç°**6-8å€æ›´ç´§çš„æ¦‚ç‡è¾¹ç•Œ**ï¼Œå¹¶è¯†åˆ«å‡º**3-4å€æ›´å¤šçš„é«˜é£é™©å®ä¾‹**ã€‚
- **å®ç”¨æ€§**ï¼šåœ¨ç›¸åŒçš„è®¡ç®—é¢„ç®—ä¸‹ï¼Œèƒ½å¤Ÿå¯¹ LLM è¡Œä¸ºè¿›è¡Œæ›´ç²¾ç¡®çš„é£é™©è¯„ä¼°å’Œç‰¹å¾æè¿°ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡
å®éªŒåœ¨ä¸‰ä¸ªå…³é”®çš„éªŒè¯ä»»åŠ¡ä¸Šè¿›è¡Œï¼Œè¦†ç›–äº†ä¸åŒç±»å‹çš„è¯­ä¹‰çº¦æŸï¼š

1. **GSM-Symbolic**ï¼šæ•°å­¦æ¨ç†ä»»åŠ¡ï¼ŒéªŒè¯ç”Ÿæˆçš„ç¬¦å·è¡¨è¾¾å¼æ˜¯å¦è¯­æ³•æ­£ç¡®ä¸”åŠŸèƒ½ç­‰ä»·äºæ ‡å‡†ç­”æ¡ˆã€‚è¯­ä¹‰çº¦æŸ `Î¦_GSM` æ˜¯å‰ç¼€å°é—­çš„ï¼ˆè¯­æ³•éƒ¨åˆ†ï¼‰ã€‚
2. **Enron Email Leakage**ï¼šéšç§æ³„éœ²ä»»åŠ¡ï¼Œè¯„ä¼°æ¨¡å‹æ˜¯å¦ä¼šæ³„éœ²è®­ç»ƒæ•°æ®ä¸­çš„ä¸ªäººé‚®ç®±åœ°å€ã€‚è¯­ä¹‰çº¦æŸ `Î¦_p` å®šä¹‰ä¸ºä¸ç”ŸæˆæœªçŸ¥çš„é‚®ç®±åœ°å€ã€‚
3. **Secure Code Generation**ï¼šå®‰å…¨ä»£ç ç”Ÿæˆä»»åŠ¡ï¼Œä½¿ç”¨ CyberSecEval åŸºå‡†æµ‹è¯• Rust ä»£ç è¡¥å…¨çš„å®‰å…¨æ€§ã€‚è¯­ä¹‰çº¦æŸ `Î¦_safe` æ£€æµ‹æ˜¯å¦å­˜åœ¨ä¸å®‰å…¨ç¼–ç æ¨¡å¼ï¼ˆå¦‚ç¡¬ç¼–ç å¯†é’¥ã€è·³è¿‡è¯ä¹¦éªŒè¯ï¼‰ï¼Œè¯¥çº¦æŸæ˜¯å‰ç¼€å°é—­çš„ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šè¯„ä¼°äº†å››ç§ state-of-the-art çš„æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ï¼šQwen3-4B, Qwen2.5-14B, Qwen3-30B-A3B, Llama3.3-70Bã€‚
- **è®¡ç®—é¢„ç®—**ï¼šæ¯ä¸ªä»»åŠ¡å®ä¾‹åˆ†é… **100 æ¬¡ forward passes**ï¼Œç¡®ä¿ä¸åŸºçº¿æ–¹æ³•å…¬å¹³æ¯”è¾ƒã€‚
- **æ—©æœŸç»ˆæ­¢**ï¼šå¦‚æœä¸Šä¸‹ç•Œå·®è· `< Îµ = 0.01`ï¼Œåˆ™æå‰ç»ˆæ­¢ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Bound Tightness (Gap)**ï¼š`PUB - PLB`ï¼Œè¡¡é‡æ¦‚ç‡è¾¹ç•Œçš„ç´§å¯†ç¨‹åº¦ã€‚
  - **Risky Distribution Ratio (RDR)**ï¼šæ»¡è¶³ `PUB < 0.9` çš„ä»»åŠ¡æ¯”ä¾‹ï¼Œè¡¨ç¤ºæ¨¡å‹æœ‰éå¹³å‡¡æ¦‚ç‡ï¼ˆ>0.1ï¼‰è¿åçº¦æŸã€‚æ›´é«˜çš„ RDR æ„å‘³ç€èƒ½æ­ç¤ºæ›´å¤šæ½œåœ¨é£é™©ã€‚
  - **æ”¶æ•›é€Ÿåº¦**ï¼šè¾¾åˆ° `Gap < 0.01` æ‰€éœ€çš„å¹³å‡ forward passes æ•°é‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼š**Rejection Sampling (RS)**ã€‚è¿™æ˜¯ä½œè€…é‡‡ç”¨çš„åŸºçº¿ï¼Œå› ä¸ºæ­¤å‰æ²¡æœ‰é’ˆå¯¹æ­¤è®¾å®šçš„ç›´æ¥å¯æ¯”å·¥ä½œã€‚
- **å¯¹æ¯”æ–¹å¼**ï¼šåœ¨å®Œå…¨ç›¸åŒçš„è®¡ç®—é¢„ç®—ï¼ˆ100æ¬¡ forward passesï¼‰ä¸‹ï¼Œæ¯”è¾ƒ BEAVER ä¸ RS çš„ Gapã€RDR å’Œæ”¶æ•›é€Ÿåº¦ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰GSM-Symbolic ä»»åŠ¡ï¼ˆæ­£ç¡®æ€§éªŒè¯ï¼‰
- **ç»“æœè§ Table 2**ï¼š
  - BEAVER å°†æ¦‚ç‡ Gap æ˜¾è‘—ç¼©å°ã€‚ä¾‹å¦‚ï¼Œå¯¹äº Qwen3-4Bï¼ŒRS çš„ Gap ä¸º 0.092ï¼Œè€Œ BEAVER ç¼©å°è‡³ **0.013**ï¼ˆçº¦ **7 å€æ›´ç´§**ï¼‰ã€‚
  - BEAVER æ”¶æ•›æ›´å¿«ã€‚ä¾‹å¦‚ï¼ŒQwen3-4B è¾¾åˆ° tight bounds çš„å¹³å‡ forward passes ä» RS çš„ 49.02 é™è‡³ BEAVER çš„ 24.95ã€‚
- **æ„ä¹‰**ï¼šç´§è‡´çš„è¾¹ç•Œä½¿å¾—æ¨¡å‹èƒ½åŠ›çš„æ¯”è¾ƒæˆä¸ºå¯èƒ½ï¼ˆå¦‚ Llama3.3-70B â‰¥43.5% æ­£ç¡®ç‡ï¼‰ï¼Œè€Œ RS çš„å®½æ¾è¾¹ç•Œï¼ˆå¦‚ Qwen2.5-14B çš„ [0.356, 0.704]ï¼‰æ— æ³•æä¾›æœ‰æ„ä¹‰çš„ä¿¡æ¯ã€‚

#### ï¼ˆ2ï¼‰Enron Email Leakage ä»»åŠ¡ï¼ˆéšç§éªŒè¯ï¼‰
- **ç»“æœè§ Table 3**ï¼š
  - BEAVER çš„ RDR è¿œé«˜äº RSã€‚ä¾‹å¦‚ï¼Œå¯¹äº Qwen3-4Bï¼ŒRS çš„ RDR ä¸º 15/100 (0.15)ï¼Œè€Œ BEAVER ä¸º **67/100 (0.67)**ã€‚
- **æ„ä¹‰**ï¼šRS çš„å®½æ¾ä¸Šç•Œä¼šç»™äººé”™è¯¯çš„å®‰å…¨æ„Ÿï¼Œè€Œ BEAVER æ­ç¤ºäº†æ¨¡å‹å­˜åœ¨ä¸¥é‡çš„éšç§æ³„éœ²é£é™©ã€‚

#### ï¼ˆ3ï¼‰Secure Code Generation ä»»åŠ¡ï¼ˆå®‰å…¨ä»£ç ç”Ÿæˆï¼‰
- **ç»“æœè§ Table 4**ï¼š
  - BEAVER è¯†åˆ«å‡ºçš„é£é™©å®ä¾‹æ•°é‡è¿œè¶… RSã€‚ä¾‹å¦‚ï¼Œå¯¹äº Qwen3-4Bï¼ŒRS ä»…è¯†åˆ«å‡º 9/204 ä¸ªé£é™©å®ä¾‹ï¼Œè€Œ BEAVER è¯†åˆ«å‡º **68/204** ä¸ªã€‚
  - å¯¹äº Qwen3-30B-A3Bï¼ŒRS ä»…è¯†åˆ«å‡º 2/204 ä¸ªï¼Œè€Œ BEAVER è¯†åˆ«å‡º **86/204** ä¸ªã€‚
- **æ„ä¹‰**ï¼šåœ¨å¯¹æŠ—æ€§æç¤ºä¸‹ï¼ŒBEAVER èƒ½æœ‰æ•ˆæ­ç¤ºæ¨¡å‹ç”Ÿæˆä¸å®‰å…¨ä»£ç çš„é‡å¤§é£é™©ï¼Œè€Œ RS ä¼šäº§ç”Ÿâ€œè™šå‡çš„å®‰å…¨æ„Ÿâ€ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **åºåˆ—é€‰æ‹©ç­–ç•¥å¯¹æ¯”**ï¼ˆTable 5ï¼‰ï¼š
  - æ¯”è¾ƒäº†è´ªå¿ƒç­–ç•¥ **Max-p**ï¼ˆæ€»æ˜¯æ‰©å±•æ¦‚ç‡æœ€é«˜çš„åºåˆ—ï¼‰å’Œéšæœºç­–ç•¥ **Sample-u**ã€‚
  - ç»“æœæ˜¾ç¤ºä¸¤è€…æœ€ç»ˆçš„è¾¹ç•Œç´§å¯†åº¦ç›¸è¿‘ï¼Œä½† Max-p åœ¨æ”¶æ•›é€Ÿåº¦ä¸Šç•¥ä¼˜ã€‚
- **æ¸©åº¦å‚æ•°çš„å½±å“**ï¼ˆTable 6ï¼‰ï¼š
  - é™ä½ **temperature**ï¼ˆå¦‚ T=0.33ï¼‰ä¼šä½¿æ¦‚ç‡åˆ†å¸ƒæ›´é›†ä¸­ï¼Œä»è€Œä½¿ BEAVER æ›´å¿«åœ°æ”¶æ•›ï¼ˆGap æ›´å°ï¼Œæ‰€éœ€ forward passes æ›´å°‘ï¼‰ã€‚
  - åŒæ—¶ï¼Œåœ¨å®‰å…¨éªŒè¯ä»»åŠ¡ä¸­ï¼Œè¾ƒä½çš„æ¸©åº¦ä¼šæé«˜ RDRï¼Œå› ä¸ºæ›´å®¹æ˜“ç¡®å®šé«˜æ¦‚ç‡è¡¥å…¨æ˜¯ä¸å®‰å…¨çš„ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç¡®å®šæ€§éªŒè¯æ˜¯å¯è¡Œä¸”å®ç”¨çš„**ï¼šBEAVER æˆåŠŸè¯æ˜äº†ä¸º LLM æä¾› sound çš„æ¦‚ç‡è¾¹ç•Œæ˜¯å¯èƒ½çš„ï¼Œå¹¶ä¸”åœ¨å®é™…è®¡ç®—é¢„ç®—å†…æ˜¯é«˜æ•ˆçš„ã€‚
2. **å‰ç¼€å°é—­æ€§æ˜¯å…³é”®**ï¼šåˆ©ç”¨ `prefix-closed` è¯­ä¹‰çº¦æŸè¿›è¡Œæ—©æœŸå‰ªææ˜¯ BEAVER é«˜æ•ˆæ€§çš„æ ¸å¿ƒã€‚
3. **ç´§è‡´è¾¹ç•Œè‡³å…³é‡è¦**ï¼šå®½æ¾çš„è¾¹ç•Œï¼ˆå¦‚æ¥è‡ª rejection samplingï¼‰ä¼šæ©ç›–çœŸå®é£é™©ï¼Œå¯¼è‡´é”™è¯¯çš„éƒ¨ç½²å†³ç­–ã€‚BEAVER æä¾›çš„ç´§è‡´è¾¹ç•Œèƒ½å®ç°ç²¾ç¡®çš„é£é™©è¯„ä¼°ã€‚
4. **BEAVER æ˜¾è‘—ä¼˜äºåŸºçº¿**ï¼šåœ¨ç›¸åŒé¢„ç®—ä¸‹ï¼ŒBEAVER å®ç°äº† 6-8 å€æ›´ç´§çš„è¾¹ç•Œï¼Œå¹¶å‘ç°äº† 3-4 å€æ›´å¤šçš„é«˜é£é™©å®ä¾‹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä»…é™äº Prefix-closed çº¦æŸ**ï¼šæ— æ³•å¤„ç†éå‰ç¼€å°é—­çš„çº¦æŸï¼ˆå¦‚å¿…é¡»ä»¥ç‰¹å®šæ ¼å¼ç»“å°¾çš„æ—¥æœŸï¼‰ã€‚å°½ç®¡æ–‡ä¸­æåˆ°å¯ä»¥è½¬æ¢ä¸ºå‰ç¼€å°é—­å˜ä½“ï¼Œä½†è¿™å¹¶éå¯¹æ‰€æœ‰çº¦æŸéƒ½é€‚ç”¨ã€‚
2. **éœ€è¦ç™½ç›’è®¿é—®**ï¼šè¦æ±‚è®¿é—®æ¨¡å‹æ¯ä¸€æ­¥çš„å®Œæ•´æ¦‚ç‡åˆ†å¸ƒï¼Œæ— æ³•åº”ç”¨äºé»‘ç›’ API æ¨¡å‹ã€‚
3. **çº¦æŸæ£€æŸ¥å¼€é”€**ï¼šå¯¹äºå¤æ‚çš„è¯­ä¹‰çº¦æŸï¼ˆå¦‚è°ƒç”¨å¤–éƒ¨ SMT æ±‚è§£å™¨ï¼‰ï¼Œæ¯æ¬¡æ‰©å±•æ—¶çš„çº¦æŸæ£€æŸ¥æˆæœ¬å¯èƒ½å¾ˆé«˜ï¼Œæˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„ **frontier expansion ç­–ç•¥**ã€‚
- å°†éªŒè¯æ‰©å±•åˆ° **prompt åˆ†å¸ƒ** ä¸Šï¼Œè€Œä¸ä»…ä»…æ˜¯å•ä¸ª promptã€‚
- å¼€å‘é€‚ç”¨äº **æœ‰é™æ¨¡å‹è®¿é—®**ï¼ˆå¦‚é»‘ç›’ï¼‰åœºæ™¯çš„éªŒè¯æŠ€æœ¯ã€‚
- æ¢ç´¢åœ¨ **å…¬å¹³æ€§éªŒè¯ã€å¹»è§‰é‡åŒ–ã€å¤šè½®å¯¹è¯å®‰å…¨** ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚

</details>

---

### 9. [Bridging quantum and classical computing for partial differential equations through multifidelity machine learning](https://arxiv.org/abs/2512.05241)

**Authors**: Bruno Jacob, Amanda A. Howard, Panos Stinis  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.05241v1  

#### Abstract
Quantum algorithms for partial differential equations (PDEs) face severe practical constraints on near-term hardware: limited qubit counts restrict spatial resolution to coarse grids, while circuit depth limitations prevent accurate long-time integration. These hardware bottlenecks confine quantum P...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Bridging Quantum and Classical Computing for Partial Differential Equations through Multifidelity Machine Learning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰é‡å­ç®—æ³•åœ¨æ±‚è§£åå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEsï¼‰æ—¶é¢ä¸´ä¸¥é‡çš„ç¡¬ä»¶é™åˆ¶ï¼š
- **æœ‰é™çš„ qubit æ•°é‡** å¯¼è‡´ç©ºé—´åˆ†è¾¨ç‡æä½ï¼ˆç²—ç½‘æ ¼ï¼‰ï¼›
- **ç”µè·¯æ·±åº¦å—é™** é˜»ç¢é•¿æ—¶é—´ç§¯åˆ†çš„ç²¾åº¦ï¼›
- å› æ­¤ï¼Œé‡å­ PDE æ±‚è§£å™¨åªèƒ½äº§ç”Ÿ**ä½ä¿çœŸåº¦ï¼ˆlow-fidelityï¼‰** çš„è¿‘ä¼¼è§£ï¼Œéš¾ä»¥æ»¡è¶³å®é™…ç§‘å­¦è®¡ç®—éœ€æ±‚ã€‚

å°½ç®¡é‡å­ç®—æ³•ç†è®ºä¸Šå…·æœ‰åŠ é€Ÿæ½œåŠ›ï¼Œä½†åœ¨è¿‘æœŸç¡¬ä»¶ä¸Šæ— æ³•ç›´æ¥è¾¾åˆ°é«˜ç²¾åº¦ï¼Œé™åˆ¶äº†å…¶â€œé‡å­ä¼˜åŠ¿â€çš„å®ç°ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**æ··åˆé‡å­-ç»å…¸å¤šä¿çœŸåº¦æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ˆhybrid quantum-classical multifidelity learning frameworkï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨**é‡å­æ±‚è§£å™¨**ï¼ˆå¦‚ QLBMï¼‰ç”Ÿæˆå¤§é‡**ä½ä¿çœŸæ•°æ®**ï¼ˆcoarse grid, short timeï¼‰ï¼›
- åˆ©ç”¨**ç»å…¸æ±‚è§£å™¨**ç”Ÿæˆå°‘é‡**é«˜ä¿çœŸå‚è€ƒæ•°æ®**ï¼ˆfine grid, long timeï¼‰ï¼›
- æ„å»ºä¸€ä¸ªåŸºäº **Kolmogorov-Arnold Networks (KANs)** çš„å¤šä¿çœŸåº¦ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå­¦ä¹ ä»ä½ä¿çœŸåˆ°é«˜ä¿çœŸçš„æ˜ å°„å…³ç³»ï¼Œä»è€Œâ€œçº æ­£â€é‡å­è§£ä¸ºé«˜ç²¾åº¦é¢„æµ‹ã€‚

è¯¥æ¡†æ¶çš„å…³é”®ç»„ä»¶åŒ…æ‹¬ï¼š
- **ä½é˜¶ç½‘ç»œ $K_{LF}$**ï¼šä»…è®­ç»ƒäºé‡å­è¾“å‡ºï¼Œç”¨äºå»ºæ¨¡ä½ä¿çœŸåŠ¨æ€ï¼›
- **çº¿æ€§æ ¡æ­£ç½‘ç»œ $K_{lin}$** å’Œ **éçº¿æ€§æ ¡æ­£ç½‘ç»œ $K_{nl}$**ï¼šåˆ†åˆ«æ•æ‰çº¿æ€§å’Œéçº¿æ€§ç›¸å…³æ€§ï¼›
- **å¯å­¦ä¹ æ··åˆå‚æ•° $\alpha$**ï¼šè‡ªåŠ¨å¹³è¡¡çº¿æ€§ä¸éçº¿æ€§æ ¡æ­£æƒé‡ï¼Œå½¢å¼ä¸ºï¼š
  $$
  q_{MF} = \alpha \cdot K_{nl}(x,t,q_{LF}) + (1-\alpha) \cdot K_{lin}(x,t,q_{LF})
  $$

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **èµ„æºæ•ˆç‡** | æ˜¾è‘—å‡å°‘å¯¹æ˜‚è´µé«˜ä¿çœŸæ¨¡æ‹Ÿçš„éœ€æ±‚ï¼ˆåªéœ€ç¨€ç–é‡‡æ ·ï¼‰ï¼Œé™ä½æ€»ä½“è®¡ç®—æˆæœ¬ |
| **æ³›åŒ–èƒ½åŠ›** | èƒ½å¤Ÿè¿›è¡Œ**æ—¶é—´å¤–æ¨ï¼ˆtemporal extrapolationï¼‰**ï¼Œå³åœ¨æ— é«˜ä¿çœŸè®­ç»ƒæ•°æ®çš„æ—¶é—´æ®µä»èƒ½å‡†ç¡®é¢„æµ‹ |
| **ç¡¬ä»¶å…¼å®¹æ€§** | å……åˆ†åˆ©ç”¨å½“å‰å«å™ªå£°ã€å°è§„æ¨¡é‡å­è®¾å¤‡çš„èƒ½åŠ›ï¼Œæ— éœ€ç­‰å¾…å®¹é”™é‡å­è®¡ç®—æœº |
| **æ¨¡å‹å¯è§£é‡Šæ€§** | KAN ç»“æ„é€šè¿‡è¾¹ä¸Šçš„å¯å­¦ä¹ æ ·æ¡å‡½æ•°æä¾›æ›´å¼ºçš„å‚æ•°æ•ˆç‡å’Œè§£é‡Šæ€§ |
| **ç³»ç»Ÿæ€§è¯¯å·®ä¿®æ­£** | æˆåŠŸè¡¥å¿é‡å­æ±‚è§£å™¨å› ç²—ç½‘æ ¼å¯¼è‡´çš„ç©ºé—´å¹³æ»‘å’Œæ•°å€¼è€—æ•£ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸ç‰©ç†é—®é¢˜
ç ”ç©¶åœ¨ä¸¤ä¸ªå…¸å‹éçº¿æ€§ PDE ä¸ŠéªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ï¼š

1. **1D é»æ€§ Burgers æ–¹ç¨‹**  
   - åˆå§‹æ¡ä»¶ï¼šé«˜æ–¯è„‰å†² $ u(x,0) = \exp(-40(x-0.35)^2) $
   - è¾¹ç•Œæ¡ä»¶ï¼šå‘¨æœŸè¾¹ç•Œ
   - ç‰©ç†ç‰¹æ€§ï¼šéçº¿æ€§å¯¹æµä¸æ‰©æ•£ç«äº‰ï¼Œå½¢æˆé™¡å³­æ¢¯åº¦

2. **2D é¡¶ç›–é©±åŠ¨ç©ºè…”æµï¼ˆlid-driven cavity flowï¼‰**
   - åŸŸï¼š$[0,1]^2$ï¼Œé¡¶éƒ¨è¾¹ç•Œé€Ÿåº¦ $u=1$ï¼Œå…¶ä½™å£é¢é™æ­¢
   - Reynolds æ•°ï¼šRe = 100
   - ä½¿ç”¨**æµå‡½æ•°-æ¶¡é‡å…¬å¼**é¿å…å‹åŠ›æ±‚è§£

---

### å®éªŒè®¾ç½®
| ç»„ä»¶ | è®¾ç½®è¯´æ˜ |
|------|----------|
| **é‡å­æ±‚è§£å™¨** | é‡‡ç”¨ **QLBM-frugal** æ–¹æ³•ï¼š<br>- Burgers: D1Q3 lattice, 16-grid points<br>- Navier-Stokes: D2Q5 lattice, 16Ã—16 grid<br>- ä½¿ç”¨ block encoding + LCU å®ç°éé…‰ç¢°æ’ç®—å­ |
| **ç»å…¸æ±‚è§£å™¨** | <br>- Burgers: FD, upwind advection, central diffusion, 256-grid<br>- NS: streamfunction-vorticity FDM, 64Ã—64 grid |
| **è®­ç»ƒç­–ç•¥** | åˆ†ä¸¤é˜¶æ®µï¼š<br>1. ç”¨å…¨éƒ¨é‡å­æ•°æ®è®­ç»ƒ $K_{LF}$<br>2. å†»ç»“ $K_{LF}$ åï¼Œç”¨ç¨€ç–ç»å…¸æ•°æ®è®­ç»ƒ $K_{lin}, K_{nl}, \alpha$ |
| **å¤–æ¨è®¾ç½®** | é«˜ä¿çœŸè®­ç»ƒæ•°æ®ä»…è¦†ç›–éƒ¨åˆ†æ—¶é—´åŒºé—´ï¼š<br>- Burgers: $t \leq 0.25$ï¼ˆæ€»è‡³ 0.5ï¼‰<br>- Cavity: $t \leq 2.0$ï¼ˆæ€»è‡³ 3.0ï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡** | ç›¸å¯¹ $L^2$ è¯¯å·®ï¼š<br>$L_2 = \|q_{pred} - q_{HF}\| / \|q_{HF}\|$<br>åˆ†ä¸ºè®­ç»ƒåŒºã€å¤–æ¨åŒºã€å…¨åŸŸè¯¯å·® |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **çº¯é‡å­ä½ä¿çœŸè§£ï¼ˆLFï¼‰**ï¼šåŸå§‹ QLBM è¾“å‡º
- **çº¯éçº¿æ€§æ ¡æ­£ï¼ˆ$\alpha=1$ å›ºå®šï¼‰**
- ä¸åŒæ­£åˆ™åŒ–å¼ºåº¦ï¼ˆ$\lambda_\alpha$ï¼‰å’Œæ ·æ¡åˆ†è¾¨ç‡ï¼ˆ$G$ï¼‰çš„æ¶ˆèå®éªŒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… **Burgers æ–¹ç¨‹ï¼ˆå®éªŒ B4 æœ€ä¼˜ï¼‰**
| æ–¹æ³• | å…¨åŸŸ $L_2$ è¯¯å·® | å¤–æ¨åŒºè¯¯å·® | æå‡å¹…åº¦ |
|------|------------------|------------|-----------|
| åŸå§‹é‡å­ LF | 0.335 | â€” | â€” |
| MF-KAN (B4) | **0.0615** | 0.0914 | â†“ **82%** |

> åœ¨å¤–æ¨åŒºåŸŸè¯¯å·®ç›¸æ¯”æœªæ­£åˆ™åŒ–æ¨¡å‹ä¸‹é™ **21%**

#### âœ… **2D ç©ºè…”æµï¼ˆå®éªŒ C3 æœ€ä¼˜ï¼‰**
| æ–¹æ³• | æ°´å¹³é€Ÿåº¦ $L_2$ | å‚ç›´é€Ÿåº¦ $L_2$ | æå‡å¹…åº¦ |
|------|------------------|------------------|-----------|
| åŸå§‹é‡å­ LF | 0.285 | 0.412 | â€” |
| MF-KAN (C3) | **0.079** | **0.167** | â†“ **72% (u), 60% (v)** |

> å¤–æ¨è‡³ $t=3.0$ æ—¶ä»ä¿æŒé«˜ç²¾åº¦ï¼Œå°¤å…¶åœ¨è¾¹ç•Œå±‚é™„è¿‘æ”¹è¿›æ˜¾è‘—

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å›ºå®š $\alpha=1$ï¼ˆçº¯éçº¿æ€§ï¼‰**ï¼š
  - Burgers ä¸Šå¤–æ¨å¤±è´¥ï¼ˆ$L_2^{extrap}=0.7173 > LF$ï¼‰
  - è¡¨æ˜**è¿‡åº¦ä¾èµ–éçº¿æ€§æ ¡æ­£ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆ**
- **å¼ºæ­£åˆ™åŒ–ï¼ˆ$\lambda_\alpha=10^{-4}$ï¼‰**ï¼š
  - å­¦å¾—è¾ƒå° $\alpha$ï¼ˆ0.53ï¼‰ï¼Œæ›´ä¾èµ–çº¿æ€§è·¯å¾„
  - å¤–æ¨æ€§èƒ½æœ€ä½³ â†’ **çº¿æ€§å…ˆéªŒæœ‰åŠ©äºæ³›åŒ–**

---

### æ¶ˆèå®éªŒå…³é”®å‘ç°

#### ğŸ”¹ æ­£åˆ™åŒ–å¼ºåº¦ $\lambda_\alpha$ å½±å“
- $\lambda_\alpha = 0$ï¼šè®­ç»ƒè¯¯å·®ä½ä½†å¤–æ¨å·®ï¼ˆè¿‡æ‹Ÿåˆï¼‰
- $\lambda_\alpha = 10^{-4}$ï¼ˆBurgersï¼‰ã€$10^{-5}$ï¼ˆNSï¼‰ï¼šæœ€ä¼˜æƒè¡¡
- æ­£åˆ™é¡¹ $\lambda_\alpha \alpha^n$ï¼ˆ$n=4$ï¼‰æœ‰æ•ˆé˜²æ­¢å¤æ‚æ¨¡å‹æ»¥ç”¨

#### ğŸ”¹ B-spline ç½‘æ ¼åˆ†è¾¨ç‡ $G$
- $G=3$ï¼šæ¬ è¡¨è¾¾ï¼Œè®­ç»ƒè¯¯å·®é«˜
- $G=7$ï¼šè¿‡è¡¨è¾¾ï¼Œå¤–æ¨æ€§èƒ½æ¶åŒ–ï¼ˆè¿‡æ‹Ÿåˆï¼‰
- $G=5$ï¼šæœ€ä½³å¹³è¡¡ç‚¹ â†’ **é€‚åº¦è¡¨è¾¾åŠ›ä¼˜äºæœ€å¤§å®¹é‡**

#### ğŸ”¹ ç½‘ç»œå®½åº¦å½±å“ï¼ˆCavity æµ‹è¯•ï¼‰
- å®½åº¦è¿‡å°ï¼ˆ5ï¼‰â†’ æ¬ æ‹Ÿåˆ
- è¿‡å®½ï¼ˆ15ï¼‰â†’ è®­ç»ƒæ—¶é—´å¢åŠ ä¸”æœªæå‡æ€§èƒ½
- ä¸­ç­‰å®½åº¦ï¼ˆ10ï¼‰ç»“åˆæ­£åˆ™åŒ–è¡¨ç°æœ€å¥½

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å¤šä¿çœŸåº¦å­¦ä¹ å¯æœ‰æ•ˆæ¡¥æ¥é‡å­ä¸ç»å…¸è®¡ç®—**ï¼šå³ä½¿é‡å­è§£éå¸¸ç²—ç³™ï¼ˆ16 vs 256 ç‚¹ï¼‰ï¼Œä¹Ÿèƒ½é€šè¿‡ç¨€ç–ç»å…¸æ•°æ®çº æ­£è‡³æ¥è¿‘é«˜ä¿çœŸç²¾åº¦ã€‚
2. âœ… **æˆåŠŸå®ç°æ—¶é—´å¤–æ¨**ï¼šæ¨¡å‹èƒ½åœ¨æ²¡æœ‰é«˜ä¿çœŸè®­ç»ƒæ•°æ®çš„æ—¶é—´æ®µåšå‡ºå‡†ç¡®é¢„æµ‹ï¼Œæ‹“å±•äº†å®ç”¨åœºæ™¯ã€‚
3. âœ… **çº¿æ€§-éçº¿æ€§æ··åˆç»“æ„è‡³å…³é‡è¦**ï¼šè‡ªåŠ¨å­¦ä¹ çš„ $\alpha$ å‚æ•°è¡¨æ˜ï¼Œ**çº¿æ€§ç›¸å…³æ€§ä¸»å¯¼æ³›åŒ–è¡Œä¸º**ï¼Œè€Œæ­£åˆ™åŒ–é¼“åŠ±ç®€çº¦æ¨¡å‹ã€‚
4. âœ… **KAN æ¶æ„é€‚åˆæ­¤ç±»ä»»åŠ¡**ï¼šè¾¹ç¼˜å¯å­¦ä¹ æ ·æ¡æä¾›äº†è‰¯å¥½çš„å‡½æ•°é€¼è¿‘èƒ½åŠ›å’Œç¨³å®šæ€§ï¼Œå°¤å…¶é€‚ç”¨äºæ—¶ç©ºè¿ç»­åœºçš„å»ºæ¨¡ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–é«˜è´¨é‡é‡å­æ¨¡æ‹Ÿè¾“å‡º** | å½“å‰å®éªŒåŸºäº statevector æ¨¡æ‹Ÿï¼›çœŸå®ç¡¬ä»¶å™ªå£°å¯èƒ½ç ´åä½é˜¶è§£è´¨é‡ |
| **éœ€ç»å…¸é«˜ä¿çœŸæ•°æ®åˆå§‹åŒ–** | å°½ç®¡ç¨€ç–ï¼Œä½†ä»éœ€è¦ä¸€å®šæ•°é‡çš„ç»å…¸ä»¿çœŸä½œä¸ºé”šç‚¹ |
| **ç‰¹å®šäºQLBMç»“æ„** | å½“å‰æ¡†æ¶é’ˆå¯¹ QLBM è®¾è®¡ï¼Œæ‰©å±•åˆ°å…¶ä»–é‡å­ç®—æ³•éœ€é‡æ–°é€‚é… |
| **å°šæœªåœ¨çœŸå®é‡å­ç¡¬ä»¶è¿è¡Œ** | æ‰€æœ‰é‡å­ç”µè·¯å‡é€šè¿‡ Qiskit æ¨¡æ‹Ÿæ‰§è¡Œ |

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥ Physics-Informed Learning**ï¼šåŠ å…¥æ®‹å·®çº¦æŸæˆ–å®ˆæ’å¾‹ï¼Œè¿›ä¸€æ­¥å‡å°‘å¯¹é«˜ä¿çœŸæ•°æ®çš„ä¾èµ–ã€‚
2. **ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰æ‰©å±•**ï¼šæ„å»ºæ¦‚ç‡æ€§å¤šä¿çœŸæ¨¡å‹ï¼ˆå¦‚ Bayesian KANï¼‰ï¼Œä¼°è®¡é¢„æµ‹ç½®ä¿¡åŒºé—´ã€‚
3. **çœŸå®ç¡¬ä»¶éƒ¨ç½²**ï¼šåœ¨è¶…å¯¼æˆ–ç¦»å­é˜±è®¾å¤‡ä¸Šæµ‹è¯•æ¡†æ¶é²æ£’æ€§ã€‚
4. **æ‰©å±•è‡³æ›´å¤š PDE ç±»å‹**ï¼šå¦‚ååº”-æ‰©æ•£ç³»ç»Ÿã€å¯å‹ç¼©æµã€å¤šç›¸æµç­‰ã€‚
5. **ç»“åˆ Variational Quantum Algorithms**ï¼šå°† VQA ä¸æœ¬æ¡†æ¶èåˆï¼Œå¤„ç†æ›´å¼ºéçº¿æ€§é—®é¢˜ã€‚

---

## æ€»ç»“
æœ¬æ–‡å¼€åˆ›æ€§åœ°æå‡ºäº†ä¸€æ¡**é€šå¾€è¿‘æœŸé‡å­å®ç”¨æ€§ï¼ˆNISQ utilityï¼‰çš„å¯è¡Œè·¯å¾„**ï¼šä¸è¿½æ±‚å•ä¸€é‡å­æ±‚è§£å™¨çš„å®Œç¾ç²¾åº¦ï¼Œè€Œæ˜¯å°†å…¶è§†ä¸º**å¿«é€Ÿä½ä¿çœŸå¼•æ“**ï¼Œå†é€šè¿‡**å¤šä¿çœŸæœºå™¨å­¦ä¹ **å‡çº§ä¸ºé«˜ç²¾åº¦é¢„æµ‹å·¥å…·ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æå‡äº†é‡å­è®¡ç®—çš„å®é™…ä»·å€¼ï¼Œä¹Ÿä¸ºæœªæ¥é‡å­-ç»å…¸ååŒç®—æ³•çš„è®¾è®¡æä¾›äº†èŒƒå¼å‚è€ƒã€‚

</details>

---

### 10. [Utility Boundary of Dataset Distillation: Scaling and Configuration-Coverage Laws](https://arxiv.org/abs/2512.05817)

**Authors**: Zhengquan Luo, Zhiqiang Xu  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.05817v1  

#### Abstract
Dataset distillation (DD) aims to construct compact synthetic datasets that allow models to achieve comparable performance to full-data training while substantially reducing storage and computation. Despite rapid empirical progress, its theoretical foundations remain limited: existing methods (gradi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Utility Boundary of Dataset Distillation: Scaling and Configuration-Coverage Laws è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

æœ¬æ–‡é’ˆå¯¹ **Dataset Distillation (DD)** é¢†åŸŸå­˜åœ¨çš„ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š

1. **ç†è®ºç¢ç‰‡åŒ–**ï¼šç°æœ‰çš„ DD æ–¹æ³•ï¼ˆå¦‚ Gradient Matching, Distribution Matching, Trajectory Matchingï¼‰åŸºäºå¼‚æ„çš„ä»£ç†ç›®æ ‡ï¼ˆsurrogate objectivesï¼‰å’Œä¼˜åŒ–å‡è®¾ï¼Œç¼ºä¹ç»Ÿä¸€çš„ç†è®ºæ¡†æ¶æ¥è§£é‡Šå…¶å…±æ€§åŸç†æˆ–æä¾›é€šç”¨ä¿è¯ã€‚
2. **é…ç½®é²æ£’æ€§ç¼ºå¤±**ï¼šå½“å‰æ–¹æ³•åœ¨è®­ç»ƒé…ç½®ï¼ˆå¦‚ optimizerã€architectureã€augmentationï¼‰å‘ç”Ÿå˜åŒ–æ—¶ï¼Œè’¸é¦æ•°æ®çš„æœ‰æ•ˆæ€§å¾€å¾€æ˜¾è‘—ä¸‹é™ï¼Œå°šä¸æ¸…æ¥šåœ¨ä½•ç§æ¡ä»¶ä¸‹è’¸é¦æ•°æ®èƒ½ä¿æŒä¸å…¨é‡æ•°æ®ç›¸å½“çš„æ€§èƒ½ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Configuration-Dynamics-Error Analysis** çš„ç»Ÿä¸€ç†è®ºæ¡†æ¶ï¼Œå°†ä¸»æµ DD æ–¹æ³•ç½®äºä¸€ä¸ªå…±åŒçš„æ³›åŒ–è¯¯å·®è§†è§’ä¸‹è¿›è¡Œåˆ†æï¼Œå¹¶ç”±æ­¤å¾—å‡ºä¸¤ä¸ªæ ¸å¿ƒå®šå¾‹ï¼š

#### ï¼ˆ1ï¼‰**Scaling Lawï¼ˆç¼©æ”¾å¾‹ï¼‰**

- **å†…å®¹**ï¼šå½“è’¸é¦æ ·æœ¬æ•° $k$ å¢åŠ æ—¶ï¼Œæ³›åŒ–è¯¯å·®ä»¥ $\Delta \leq O(1/\sqrt{k}) + \epsilon_{\text{bound}}$ çš„é€Ÿç‡ä¸‹é™ã€‚
- **æ„ä¹‰**ï¼šè§£é‡Šäº†å®è·µä¸­å¹¿æ³›è§‚å¯Ÿåˆ°çš„ **IPCï¼ˆImages Per Classï¼‰é¥±å’Œç°è±¡**â€”â€”å½“ $k$ è¶³å¤Ÿå¤§æ—¶ï¼Œè¯¯å·®è¢«ä¸å¯çº¦çš„ $\epsilon_{\text{bound}}$ æ‰€é™åˆ¶ï¼Œç»§ç»­å¢åŠ  $k$ æ— æ³•æå‡æ€§èƒ½ã€‚æ­¤æ—¶ï¼Œé™ä½ $\epsilon_{\text{bound}}$ æ¯”ç›²ç›®å¢åŠ  $k$ æ›´æœ‰æ•ˆã€‚

#### ï¼ˆ2ï¼‰**Coverage Lawï¼ˆè¦†ç›–å¾‹ï¼‰**

- **å†…å®¹**ï¼šä¸ºäº†åœ¨å¤šæ ·åŒ–çš„é…ç½®æ— $\mathcal{A}$ ä¸Šä¿æŒæ³›åŒ–èƒ½åŠ›ï¼Œæ‰€éœ€çš„è’¸é¦æ ·æœ¬æ•° $k$ å¿…é¡»ä¸é…ç½®å¤šæ ·æ€§ $H_{\text{cov}}(\mathcal{A}, r)$ æˆ**çº¿æ€§å…³ç³»**ï¼Œå³ $k = \Omega(H_{\text{cov}}(\mathcal{A}, r))$ã€‚
- **æ„ä¹‰**ï¼šé¦–æ¬¡å½¢å¼åŒ–å®šä¹‰äº† **Dataset Distillation çš„æ•ˆç”¨è¾¹ç•Œï¼ˆutility boundaryï¼‰**ï¼Œæ­ç¤ºäº†æ ·æœ¬æ•ˆç‡ä¸é…ç½®é²æ£’æ€§ä¹‹é—´çš„æ ¹æœ¬æƒè¡¡ã€‚

æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜æ­ç¤ºäº† GMã€DMã€TM ä¸‰ç§çœ‹ä¼¼ä¸åŒçš„åŒ¹é…æ–¹æ³•æœ¬è´¨ä¸Šæ˜¯åŒä¸€ç›®æ ‡ï¼ˆæœ€å°åŒ–è®­ç»ƒåŠ¨æ€å·®å¼‚ï¼‰çš„ä¸åŒä»£ç†é€‰æ‹©ï¼Œå®ƒä»¬é€šè¿‡ç›¸åŒçš„åŒå±‚æœºåˆ¶å‡å°‘ç›¸åŒçš„æ³›åŒ–è¯¯å·®ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

- **ç†è®ºç»Ÿä¸€æ€§**ï¼šé¦–æ¬¡å°† GMã€DMã€TM ç»Ÿä¸€åœ¨ä¸€ä¸ªç†è®ºæ¡†æ¶ä¸‹ï¼Œè§£é‡Šäº†ä¸ºä½•ä¸åŒæ–¹æ³•éƒ½èƒ½å®ç°æ•°æ®è’¸é¦ã€‚
- **å¯è§£é‡Šæ€§å¼º**ï¼šæå‡ºçš„ä¸¤ä¸ªå®šå¾‹ä¸º DD çš„è®¾è®¡æä¾›äº†æ˜ç¡®çš„æŒ‡å¯¼åŸåˆ™ï¼Œä¾‹å¦‚å¦‚ä½•å¹³è¡¡æ ·æœ¬å¤§å°ä¸é…ç½®å¤šæ ·æ€§ã€‚
- **æŒ‡å¯¼å®è·µ**ï¼šä¸ºæ„å»ºæ›´é«˜æ•ˆã€æ›´å…·é…ç½®é²æ£’æ€§çš„è’¸é¦æ–¹æ³•æä¾›äº†ç†è®ºä¾æ®ï¼Œæ¨åŠ¨äº†ä»ç»éªŒé©±åŠ¨å‘ç†è®ºé©±åŠ¨çš„è®¾è®¡èŒƒå¼è½¬å˜ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†

å®éªŒåœ¨ä»¥ä¸‹å››ä¸ªæ ‡å‡†æ•°æ®é›†ä¸Šè¿›è¡Œï¼š
- **MNIST**
- **CIFAR-10**
- **CIFAR-100**
- **ImageNette**ï¼ˆImageNet çš„ 10 ç±»å­é›†ï¼‰

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### å®éªŒè®¾ç½®
- **è’¸é¦æ–¹æ³•**ï¼šé€‰å–å››ç±»ä»£è¡¨æ€§æ–¹æ³•ï¼š
  - **Gradient Matching (GM)**ï¼šDCã€DSA
  - **Distribution Matching (DM)**ï¼šDM
  - **Trajectory Matching (TM)**ï¼šMTT
  - **Diffusion-based**ï¼šMGD3ï¼ˆç”¨äº ImageNetteï¼‰
- **æºé…ç½®ï¼ˆSource Configurationï¼‰**ï¼šæ‰€æœ‰è’¸é¦å‡åœ¨ `ConvNet + SGD` ä¸‹å®Œæˆï¼ˆå¯ç”¨ DSA æ—¶ä¹Ÿä¸€è‡´ï¼‰ã€‚
- **ç›®æ ‡é…ç½®ï¼ˆTarget Configurationï¼‰**ï¼šè¯„ä¼°æ—¶ä½¿ç”¨å¤šç§ç»„åˆï¼ŒåŒ…æ‹¬ä¸åŒæ¶æ„ï¼ˆConvNet, LeNet, ResNet-18, AlexNetï¼‰ã€ä¼˜åŒ–å™¨ï¼ˆSGD, Adamï¼‰å’Œå¢å¼ºç­–ç•¥ï¼ˆå¯ç”¨/ç¦ç”¨ DSAï¼‰ã€‚
- **è’¸é¦é¢„ç®—**ï¼šç³»ç»Ÿæ€§åœ°æ”¹å˜æ¯ç±»å›¾åƒæ•°ï¼ˆIPCï¼‰ï¼ŒèŒƒå›´ä¸º `{2, 4, 6, 8, 12, 18, 28, 51, 100, 200}`ã€‚

#### è¯„ä¼°æŒ‡æ ‡
- **ä¸»è¦æŒ‡æ ‡**ï¼š**æ³›åŒ–è¯¯å·®ï¼ˆGeneralization Errorï¼‰**
  $$
  \Delta_a = |R(\theta_s^{(a)}) - R(\theta_T^{(a)})|
  $$
  å³åœ¨ç›¸åŒç›®æ ‡é…ç½® $a$ ä¸‹ï¼Œä½¿ç”¨è’¸é¦æ•°æ®è®­ç»ƒæ¨¡å‹ä¸ä½¿ç”¨çœŸå®æ•°æ®è®­ç»ƒæ¨¡å‹çš„æµ‹è¯•é£é™©å·®ã€‚
- **éªŒè¯ Scaling Law**ï¼šå›ºå®šå•ä¸€é…ç½®ï¼ˆå¦‚ `ConvNet+SGD`ï¼‰ï¼Œç»˜åˆ¶ $\Delta_a$ å¯¹ $1/\sqrt{k}$ çš„æ›²çº¿ï¼Œæ£€éªŒæ˜¯å¦å‘ˆçº¿æ€§å…³ç³»ã€‚
- **éªŒè¯ Coverage Law**ï¼šå¯¹é…ç½®å­é›†å¤§å° $m$ï¼Œè®¡ç®—å¹³å‡è¯¯å·® $\Delta(k, m)$ï¼Œå¹¶ç»˜åˆ¶ $\Delta(k, m)$ å¯¹ $\sqrt{\log m}/\sqrt{k}$ çš„æ›²çº¿ï¼Œæ£€éªŒçº¿æ€§è¶‹åŠ¿ã€‚
- **é…ç½®å¤šæ ·æ€§ä¼°è®¡**ï¼šä½¿ç”¨ $\log M$ï¼ˆå€™é€‰é…ç½®æ•°é‡çš„å¯¹æ•°ï¼‰ä½œä¸º $H_{\text{cov}}(\mathcal{A}, r)$ çš„ä»£ç†ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰Scaling Law éªŒè¯ï¼ˆå•é…ç½®åœºæ™¯ï¼‰

- åœ¨ **MNISTã€CIFAR-10ã€CIFAR-100 å’Œ ImageNette** ä¸Šï¼Œæ‰€æœ‰æ–¹æ³•çš„ $\Delta_a$ å‡éš $1/\sqrt{k}$ è¿‘ä¼¼çº¿æ€§ä¸‹é™ã€‚
- **æ‹Ÿåˆä¼˜åº¦ $R^2$ å¤šæ•°é«˜äº 0.85**ï¼Œå¼ºçƒˆæ”¯æŒç†è®ºé¢„æµ‹ã€‚
  - **MNIST**ï¼šDCã€DSAã€DM çš„ $R^2$ è¾¾ 0.90â€“0.99ï¼ŒMTT æ–œç‡æ›´é™¡ä¸”æ–¹å·®å¤§ï¼Œåæ˜ å…¶ä¸ç¨³å®šæ€§ã€‚
  - **CIFAR-10**ï¼šæ‰€æœ‰æ–¹æ³• $R^2 = 0.86â€“0.96$ï¼ŒDC å’Œ DSA æœ€ç¨³å®šã€‚
  - **CIFAR-100**ï¼šDC å’Œ DSA ä»ä¿æŒé«˜çº¿æ€§ï¼ˆ$R^2 = 0.92â€“0.97$ï¼‰ï¼Œè€Œ DM ($R^2=0.84$) å’Œ MTT ($R^2=0.73$) åç¦»æ›´å¤šï¼Œè¡¨æ˜è½¨è¿¹å¤±é…åœ¨å¤æ‚æ•°æ®é›†ä¸Šè¢«æ”¾å¤§ã€‚
- **ç»“è®º**ï¼š$1/\sqrt{k}$ ç¼©æ”¾å¾‹å…·æœ‰æ™®é€‚æ€§ï¼Œä½†ä¸åŒæ–¹æ³•çš„æ ·æœ¬æ•ˆç‡å’Œç¨³å®šæ€§å­˜åœ¨å·®å¼‚ã€‚

#### ï¼ˆ2ï¼‰Coverage Law éªŒè¯ï¼ˆè·¨é…ç½®åœºæ™¯ï¼‰

- ç»˜åˆ¶ $\Delta(k, m)$ å¯¹ $\sqrt{\log m}/\sqrt{k}$ çš„æ›²çº¿ï¼Œè§‚å¯Ÿåˆ°è¿‘ä¼¼çš„çº¿æ€§è¶‹åŠ¿ï¼Œæ”¯æŒ Coverage Lawã€‚
- **æ–œç‡åæ˜ æ–¹æ³•å¯¹é…ç½®å¤šæ ·æ€§çš„æ•æ„Ÿåº¦**ï¼š
  - **MNIST**ï¼šMTT æ•æ„Ÿåº¦æœ€é«˜ï¼ˆ$\beta_1=0.91$ï¼‰ï¼ŒDC/DSA è¾ƒä½ï¼ˆ$\beta_1 \sim 0.20$ï¼‰ï¼ŒDM å±…ä¸­ï¼ˆ$\beta_1=0.14$ï¼‰ã€‚
  - **CIFAR-10**ï¼šæ•æ„Ÿåº¦æ’åºä¸º MTT < DC < DSA < DMï¼Œè¡¨æ˜ DM å¯¹å¤šæ ·æ€§æœ€ç¨³å¥ä½†ä¾èµ–æ›´å¤§çš„ $k$ã€‚
  - **CIFAR-100**ï¼šè§„å¾‹ä¾ç„¶å¯è§ä½†æ‹Ÿåˆåº¦é™ä½ï¼ˆ$R^2 < 0.74$ï¼‰ï¼Œå› ç±»åˆ«å¢å¤šå¯¼è‡´ä¼°è®¡å™ªå£°å¢å¤§ã€‚
- **ç»“è®º**ï¼šCoverage Law å¾—åˆ°å®è¯æ”¯æŒï¼Œä¸åŒæ–¹æ³•åœ¨é…ç½®é²æ£’æ€§ä¸Šè¡¨ç°ä¸åŒã€‚

#### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒä¸å‘ç°

- **MTT ä¸ç¨³å®šæ€§**ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒMTT è¡¨ç°å‡ºæ›´é«˜çš„æ–¹å·®å’Œæ›´é™¡çš„æ–œç‡ï¼ŒéªŒè¯äº†å…¶å¯¹é…ç½®å˜åŒ–çš„è„†å¼±æ€§ã€‚
- **GM æ–¹æ³•ï¼ˆDC/DSAï¼‰**ï¼šåœ¨å•ä¸€é…ç½®ä¸‹æ ·æœ¬æ•ˆç‡é«˜ï¼Œä½†åœ¨è·¨é…ç½®æ—¶é€€åŒ–è¾ƒå¿«ã€‚
- **DM æ–¹æ³•**ï¼šç›¸å¯¹æ›´é²æ£’äºé…ç½®å¤šæ ·æ€§ï¼Œä½†éœ€è¦æ›´å¤šæ ·æœ¬æ‰èƒ½è¾¾åˆ°ä½è¯¯å·®ã€‚
- **æ‰©æ•£æ–¹æ³• MGD3**ï¼šåœ¨ ImageNette ä¸Šä¹Ÿè¡¨ç°å‡º $1/\sqrt{k}$ ç¼©æ”¾ï¼Œè¯´æ˜è¯¥å®šå¾‹å¯èƒ½è¶…è¶Šä¼ ç»ŸåŒ¹é…èŒƒå¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°

1. **ç»Ÿä¸€æ¡†æ¶æˆç«‹**ï¼šGMã€DMã€TM å¹¶éç‹¬ç«‹å¯å‘å¼æ–¹æ³•ï¼Œè€Œæ˜¯é€šè¿‡åŒå±‚ä¼˜åŒ–æœºåˆ¶å‡å°‘ç›¸åŒæ³›åŒ–è¯¯å·®çš„ä¸åŒä»£ç†é€‰æ‹©ã€‚
2. **Scaling Law å­˜åœ¨**ï¼šæ³›åŒ–è¯¯å·®éš $1/\sqrt{k}$ ä¸‹é™ï¼Œæœ€ç»ˆå—é™äºä¸å¯çº¦è¯¯å·® $\epsilon_{\text{bound}}$ï¼Œè§£é‡Šäº† IPC é¥±å’Œç°è±¡ã€‚
3. **Coverage Law å­˜åœ¨**ï¼šè’¸é¦æ ·æœ¬æ•° $k$ å¿…é¡»ä¸é…ç½®å¤šæ ·æ€§ $H_{\text{cov}}$ çº¿æ€§å¢é•¿ï¼Œæ‰èƒ½ç»´æŒè·¨é…ç½®çš„æ€§èƒ½ï¼Œè¿™å®šä¹‰äº† DD çš„â€œæ•ˆç”¨è¾¹ç•Œâ€ã€‚
4. **æ–¹æ³•ç‰¹æ€§å·®å¼‚**ï¼šGM é«˜æ•ˆä½†ä¸é²æ£’ï¼ŒDM é²æ£’ä½†éœ€æ›´å¤šæ ·æœ¬ï¼ŒTM æ˜“å—é…ç½®å˜åŒ–å½±å“ã€‚

### æ–¹æ³•çš„å±€é™æ€§

1. **ä¼˜åŒ–åŠ¨åŠ›å­¦å‡è®¾**ï¼šç†è®ºä¾èµ– PL æ¡ä»¶å’Œ Lipschitz è¿ç»­æ€§ï¼Œåœ¨å¤§è§„æ¨¡è‡ªé€‚åº”ä¼˜åŒ–å™¨ï¼ˆå¦‚ AdamWï¼‰æˆ–éå…‰æ»‘ç›®æ ‡ä¸‹å¯èƒ½å¤±æ•ˆã€‚
2. **è¦†ç›–å¤æ‚åº¦ä¼°è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨ $\log M$ ä½œä¸º $H_{\text{cov}}$ çš„ä»£ç†ï¼Œå¯èƒ½ä½ä¼°å®é™…å¼‚è´¨æ€§ï¼Œå°¤å…¶å½“é…ç½®é—´å·®å¼‚æ˜¾è‘—æ—¶ã€‚
3. **ç”Ÿæ€èŒƒå›´æœ‰é™**ï¼šå½“å‰æ¡†æ¶ä»…è€ƒè™‘ç®—æ³•çº§å˜åŒ–ï¼ˆoptimizer, architectureï¼‰ï¼Œæœªæ¶µç›–æ•°æ®åˆ†å¸ƒåç§»ï¼ˆå¦‚è·¨åŸŸè¿ç§»ï¼‰ã€ç±»åˆ«ä¸å¹³è¡¡ç­‰è¯­ä¹‰å±‚é¢çš„å¤šæ ·æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ”¾å®½ä¼˜åŒ–å‡è®¾**ï¼šå°†ç†è®ºæ‰©å±•åˆ°æ›´å¼±çš„æ¡ä»¶ï¼Œå¦‚ one-point convexity æˆ– uniform stabilityã€‚
2. **æ”¹è¿›è¦†ç›–ä¼°è®¡**ï¼šå¼€å‘åŸºäº $d_A$ åº¦é‡ç©ºé—´çš„èšç±»æ–¹æ³•ï¼Œè‡ªé€‚åº”åˆ†é…è’¸é¦åŸå‹ã€‚
3. **æ‰©å±•é…ç½®å®šä¹‰**ï¼šå°†æ•°æ®åˆ†å¸ƒè·ç¦»ï¼ˆå¦‚ Wasserstein æˆ– MMDï¼‰çº³å…¥ $d_A$ï¼Œç ”ç©¶è·¨åŸŸåœºæ™¯ä¸‹çš„ç¼©æ”¾å¾‹ã€‚
4. **ç†è®ºé©±åŠ¨è®¾è®¡**ï¼šåˆ©ç”¨ Coverage Law è®¾è®¡æ›´é«˜æ•ˆçš„è’¸é¦ç­–ç•¥ï¼Œä¾‹å¦‚æ ¹æ®é…ç½®å¤šæ ·æ€§åŠ¨æ€è°ƒæ•´ $k$ã€‚

--- 

> **æ€»ç»“**ï¼šæœ¬æ–‡é€šè¿‡æå‡º **Configuration-Dynamics-Error** æ¡†æ¶ï¼Œé¦–æ¬¡ä¸º Dataset Distillation å»ºç«‹äº†åšå®çš„ç†è®ºåŸºç¡€ï¼Œæ­ç¤ºäº† **Scaling Law** å’Œ **Coverage Law** ä¸¤å¤§æ ¸å¿ƒè§„å¾‹ï¼Œä¸ä»…ç»Ÿä¸€äº†è§£é‡Šç°æœ‰æ–¹æ³•ï¼Œä¹Ÿä¸ºæœªæ¥æ„å»ºæ›´é«˜æ•ˆã€æ›´é²æ£’çš„è’¸é¦æŠ€æœ¯æä¾›äº†æ˜ç¡®çš„è®¾è®¡è“å›¾ã€‚

</details>

---

### 11. [A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning](https://arxiv.org/abs/2512.05753)

**Authors**: Wencheng Cai, Xuchao Gao, Congying Han, Mingqiang Li, Tiande Guo  
**Category**: cs.AI  
**Published**: 2025-12-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.05753v1  

#### Abstract
The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local o...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**è®¤çŸ¥é›·è¾¾åœ¨ç”µå­å¹²æ‰°ç¯å¢ƒä¸‹çš„å¿«é€Ÿéƒ¨ç½²é—®é¢˜**ï¼ˆAnti-Jamming Cognitive Radar Deploymentï¼‰ï¼Œè¯¥é—®é¢˜æ˜¯ç°ä»£æˆ˜äº‰ä¸­æå‡ç›®æ ‡æ¢æµ‹æ•ˆç‡çš„å…³é”®æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äº**è¿›åŒ–ç®—æ³•**ï¼ˆå¦‚ GAã€PSOï¼‰ï¼Œå­˜åœ¨ä»¥ä¸‹ç¼ºé™·ï¼š
- **è®¡ç®—è€—æ—¶é•¿**ï¼šéœ€è¦å¤šè½®è¿­ä»£å’Œç§ç¾¤é€‚åº”åº¦è¯„ä¼°ï¼›
- **æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜**ï¼šæœç´¢ç­–ç•¥å—é™ï¼Œéš¾ä»¥å……åˆ†æ¢ç´¢è§£ç©ºé—´ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„åŸºäº**æ·±åº¦å¼ºåŒ–å­¦ä¹ **ï¼ˆDeep Reinforcement Learning, DRLï¼‰çš„æ¡†æ¶â€”â€”**Fast Anti-Jamming Radar Deployment Algorithm (FARDA)**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **é¦–æ¬¡å°† DRL åº”ç”¨äºæŠ—å¹²æ‰°é›·è¾¾éƒ¨ç½²é—®é¢˜**  
   è¿„ä»Šä¸ºæ­¢ï¼Œå°šæ— ç ”ç©¶ä½¿ç”¨ DRL è§£å†³æ­¤ç±»ç»„åˆä¼˜åŒ–é—®é¢˜ã€‚

2. **ç«¯åˆ°ç«¯å»ºæ¨¡ä¸ºåºåˆ—å†³ç­–é—®é¢˜**  
   å°†é›·è¾¾éƒ¨ç½²å»ºæ¨¡ä¸ºä¸€ä¸ª**é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹**ï¼ˆMDPï¼‰ï¼Œé€šè¿‡æ™ºèƒ½ä½“é€æ­¥é€‰æ‹©é›·è¾¾ä½ç½®ã€‚

3. **è®¾è®¡ä¸“ç”¨ç¥ç»ç½‘ç»œæ¶æ„**
   - æ„å»ºäº†ä¸€ä¸ªèåˆ **DCNN** å’Œ **LSTM** çš„**ç¼–ç å™¨æ¨¡å—**ï¼ˆEncoder Networkï¼‰ï¼š
     - DCNN ç”¨äºæå–æ£€æµ‹æ¦‚ç‡çƒ­åŠ›å›¾ï¼ˆheatmapï¼‰çš„ç©ºé—´ç‰¹å¾ï¼›
     - LSTM ç”¨äºè®°å¿†å†å²éƒ¨ç½²çŠ¶æ€çš„æ—¶é—´åŠ¨æ€å˜åŒ–ã€‚

4. **æå‡ºæ–°å‹å¥–åŠ±æ•´å½¢æœºåˆ¶ CVDP-EXPR**
   - **Constraint Violation Degree Penalty (CVDP)**ï¼šå¯¹åç¦»å‡åŒ€éƒ¨ç½²çº¦æŸçš„è¡Œä¸ºæ–½åŠ æƒ©ç½šï¼Œé˜²æ­¢è®­ç»ƒå´©æºƒï¼›
   - **EXPonential Function Reward (EXPR)**ï¼šç¼“è§£åæœŸå¢ç›Šé€’å‡å¯¼è‡´çš„å­¦ä¹ åœæ»é—®é¢˜ã€‚

5. **é—®é¢˜ç®€åŒ–ç­–ç•¥æå‡æ±‚è§£æ•ˆç‡**
   - **ç»´åº¦é™ä½**ï¼šä»…åœ¨éƒ¨ç½²åŒºåŸŸè¾¹ç•Œ BR ä¸Šéƒ¨ç½²é›·è¾¾ï¼›
   - **æ¾å¼›å¤„ç†**ï¼šå°†ç¦»æ•£åŠ¨ä½œç©ºé—´æ¾å¼›ä¸ºè¿ç»­è¾¹ç•Œï¼›
   - **ç¯å¢ƒç®€åŒ–**ï¼šç¼©å°é‡‡æ ·å¯†åº¦å¹¶è£å‰ªä½ä¿¡æ¯é‡åŒºåŸŸï¼Œå‡å°‘è®¡ç®—å¼€é”€ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é€Ÿåº¦æå¿«**ï¼šéƒ¨ç½²é€Ÿåº¦çº¦ä¸ºè¿›åŒ–ç®—æ³•çš„ **7,000 å€**ï¼›
- **è¦†ç›–æ€§èƒ½æ›´ä¼˜æˆ–ç›¸å½“**ï¼šå¹³å‡è¦†ç›–ç‡ç•¥é«˜äºåŸºçº¿ï¼›
- **è®­ç»ƒç¨³å®šé«˜æ•ˆ**ï¼šé€šè¿‡ CVDP-EXPR é¿å…ç­–ç•¥é€€åŒ–ï¼›
- **é€‚ç”¨äºå®æ—¶æˆ˜åœºå“åº”åœºæ™¯**ï¼šæ»¡è¶³â€œå¿«é€Ÿéƒ¨ç½²å³æˆ˜æ–—åŠ›â€çš„å†›äº‹éœ€æ±‚ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ç¯å¢ƒè®¾ç½®
- **ä»¿çœŸåŒºåŸŸ S**ï¼š$20\text{km} \times 120\text{km}$ï¼Œåæ ‡èŒƒå›´ $[3\times10^4, 5\times10^4] \times [0, 1.2\times10^5]$ï¼›
- **å¹²æ‰°èŠ‚ç‚¹åŒºåŸŸ $D_j$**ï¼šå³ä¸Šè§’çŸ©å½¢åŒºåŸŸï¼›
- **é›·è¾¾å¯éƒ¨ç½²åŒºåŸŸ $D_R$**ï¼šå·¦ä¸‹è§’çŸ©å½¢åŒºåŸŸï¼›
- **ç¦»æ•£åŒ–ç²’åº¦**ï¼šåŸå§‹ä¸ºæ¯ 100 ç±³é‡‡æ ·ä¸€ç‚¹ï¼ˆå…±çº¦ $2.4\times10^5$ ç‚¹ï¼‰ï¼Œè®­ç»ƒæ—¶ç®€åŒ–ä¸ºæ¯ 500 ç±³é‡‡æ ·ï¼Œå¹¶å»é™¤ä¸‹åŠéƒ¨åˆ†ï¼Œå‡å°‘è‡³çº¦ 1/50 çš„è®¡ç®—é‡ï¼›
- **å¹²æ‰°æºæ•°é‡**ï¼šå›ºå®š 3 ä¸ªï¼›
- **éœ€éƒ¨ç½²é›·è¾¾æ•°**ï¼š4 ä¸ªã€‚

### å®éªŒè®¾ç½®
- **æµ‹è¯•æ•°æ®é›†**ï¼šéšæœºç”Ÿæˆ 500 ç»„ä¸åŒçš„å¹²æ‰°èŠ‚ç‚¹ç»„åˆï¼›
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ **Nvidia GeForce RTX 3090 GPU** è®­ç»ƒ FARDAï¼›
  - è¿›åŒ–ç®—æ³•è¿è¡Œäº **Intel i9-12900 CPU**ï¼›
  - æ€»è®­ç»ƒå›åˆæ•° $E = 2\times10^5$ï¼Œæ¯è½®æœ€å¤š 4 æ­¥ï¼ˆå¯¹åº” 4 ä¸ªé›·è¾¾ï¼‰ï¼›
  - ä½¿ç”¨ **PPO** ç®—æ³•è®­ç»ƒï¼Œ**Adam** ä¼˜åŒ–å™¨ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Coverage (%)** | è¢«æˆåŠŸæ¢æµ‹çš„åŒºåŸŸå æ¯”ï¼ˆä»¥é˜ˆå€¼ $T=0.5$ åˆ¤å®šï¼‰ |
| **Time** | å•æ¬¡éƒ¨ç½²æ‰€éœ€æ—¶é—´ï¼ˆç§’æˆ–åˆ†é’Ÿï¼‰ |
| **Efficiency** | è‡ªå®šä¹‰æ•ˆç‡æŒ‡æ ‡ï¼š<br>$\frac{\text{coverage}}{\log(1+\text{time})}$ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **PSO1D**ï¼šç²’å­ç¾¤ä¼˜åŒ–ï¼Œåœ¨è¾¹ç•Œ BR ä¸Šéƒ¨ç½²ï¼›
- **GA1D**ï¼šé—ä¼ ç®—æ³•ï¼Œåœ¨è¾¹ç•Œ BR ä¸Šéƒ¨ç½²ï¼›
> æ³¨ï¼šæ–‡ä¸­å·²éªŒè¯åœ¨è¾¹ç•Œéƒ¨ç½²ä¼˜äºå…¨åŒºåŸŸéƒ¨ç½²ï¼Œå› æ­¤æ‰€æœ‰æ¯”è¾ƒå‡åŸºäºè¾¹ç•Œç­–ç•¥ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 3ï¼‰
| æ–¹æ³• | Coverage (%) | Time | Efficiency |
|------|---------------|--------|------------|
| PSO1D | 93.75 | 24.9 min | 0.13 |
| GA1D | 93.79 | 30.7 min | 0.12 |
| **FARDA** | **93.94** | **0.25s** | **4.21** |

#### å¯¹æ¯”åˆ†æ
- **é€Ÿåº¦ä¼˜åŠ¿**ï¼šFARDA æ¯”æœ€æ…¢çš„ GA1D å¿«çº¦ **7,368 å€**ï¼ˆ30.7 min vs 0.25 sï¼‰ï¼›
- **æ•ˆç‡æå‡**ï¼šæ•ˆç‡æŒ‡æ ‡ä» ~0.12 æå‡è‡³ **4.21**ï¼Œæé«˜è¶…è¿‡ **35 å€**ï¼›
- **è¦†ç›–æ€§èƒ½**ï¼šFARDA åœ¨æ‰€æœ‰ç±»åˆ«æ•°æ®ä¸Šå‡ä¼˜äºåŸºçº¿ã€‚

### ä¸åŒéš¾åº¦æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼ˆTable 4ï¼‰
| æ•°æ®ç±»å‹ | æ•°é‡ | FARDA (%) | GA1D (%) | æå‡å¹…åº¦ |
|---------|-------|-------------|-----------|----------|
| Badï¼ˆ<90%ï¼‰ | 56 | **89.70** | 89.44 | +0.29% |
| Normalï¼ˆ90~95%ï¼‰ | 288 | **93.10** | 92.94 | +0.17% |
| Goodï¼ˆ>95%ï¼‰ | 156 | **97.00** | 96.92 | +0.08% |

> ç»“æœæ˜¾ç¤ºï¼šFARDA åœ¨æ›´éš¾çš„â€œBadâ€å’Œâ€œNormalâ€æ¡ˆä¾‹ä¸­æå‡æ›´ä¸ºæ˜¾è‘—ï¼Œè¯´æ˜å…¶åœ¨å¤æ‚å¹²æ‰°ç¯å¢ƒä¸‹æ›´å…·å®ç”¨æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ç½‘ç»œç»“æ„æ¶ˆèï¼ˆTable 5ï¼‰
| æ–¹æ³• | Coverage (%) |
|------|----------------|
| FARDAï¼ˆå®Œæ•´ï¼‰ | **93.94** |
| w/o CNN | 93.89 |
| w/o LSTM | 93.90 |
| w/o Encoder | 91.44 |

> **ç»“è®º**ï¼šEncoder è‡³å…³é‡è¦ï¼›ç§»é™¤ä»»ä¸€ç»„ä»¶éƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶æ˜¯å®Œå…¨ç§»é™¤ Encoder å¯¼è‡´ **-2.5%** çš„å¤§å¹…å›è½ã€‚

#### ï¼ˆ2ï¼‰å¥–åŠ±æœºåˆ¶æ¶ˆèï¼ˆTable 6ï¼‰
| æ–¹æ³• | Coverage (%) |
|------|----------------|
| FARDAï¼ˆå®Œæ•´ï¼‰ | **93.94** |
| w/o CVDP | 88.80 |
| w/o EXPR | 93.90 |
| w/o CVDP-EXPR | 88.80 |

> **å…³é”®å‘ç°**ï¼š
> - ç§»é™¤ **CVDP** å¯¼è‡´ä¸¥é‡æ€§èƒ½å´©æºƒï¼ˆâ†“5.14%ï¼‰ï¼Œå¯è§†åŒ–æ˜¾ç¤ºé›·è¾¾èšé›†åœ¨åŒä¸€æ–¹å‘ï¼ˆå›¾5ï¼‰ï¼›
> - CVDP å¼•å…¥è´Ÿå¥–åŠ±æœºåˆ¶ï¼Œé˜²æ­¢ç­–ç•¥å‘æ•£ï¼›
> - EXPR å½±å“è¾ƒå°ï¼Œä½†ä»æœ‰åŠ©äºç»´æŒå­¦ä¹ åŠ¨åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º
1. **FARDA æ˜¯é¦–ä¸ªå°† DRL æˆåŠŸåº”ç”¨äºæŠ—å¹²æ‰°é›·è¾¾éƒ¨ç½²çš„æ¡†æ¶**ï¼Œå®ç°äº†ä»â€œç¼“æ…¢è¿­ä»£æœç´¢â€åˆ°â€œå¿«é€Ÿæ¨ç†å†³ç­–â€çš„èŒƒå¼è½¬å˜ã€‚
2. é€šè¿‡**é—®é¢˜é‡æ„ + ç½‘ç»œè®¾è®¡ + å¥–åŠ±æ•´å½¢**ä¸‰ä½ä¸€ä½“çš„è®¾è®¡ï¼Œè§£å†³äº†é«˜ç»´ã€éè¿ç»­ã€å¤§æœç´¢ç©ºé—´å¸¦æ¥çš„ä¼˜åŒ–éš¾é¢˜ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFARDA åœ¨ä¿æŒç”šè‡³ç•¥å¾®æå‡**è¦†ç›–æ€§èƒ½**çš„åŒæ—¶ï¼Œå®ç°é«˜è¾¾ **7,000 å€çš„é€Ÿåº¦åŠ é€Ÿ**ï¼Œå…·å¤‡æå¼ºçš„å®æˆ˜åº”ç”¨æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¨¡å‹å‡è®¾ä¸º**é™æ€å¹²æ‰°ç¯å¢ƒ**ï¼Œæœªè€ƒè™‘å¹²æ‰°æºç§»åŠ¨ç­‰åŠ¨æ€æƒ…å†µï¼›
- é›·è¾¾æ•°é‡å›ºå®šä¸º 4ï¼Œå°šæœªæ‰©å±•è‡³å¯å˜è§„æ¨¡ï¼›
- æ‰€æœ‰å‚æ•°ï¼ˆå¦‚åŠŸç‡ã€æ³¢é•¿ç­‰ï¼‰é¢„è®¾ä¸å˜ï¼Œæœªè”åˆä¼˜åŒ–ï¼›
- æ¨¡å‹æ³›åŒ–èƒ½åŠ›æœ‰å¾…åœ¨æ›´å¤šåœ°å½¢å’Œéƒ¨ç½²å½¢çŠ¶ä¸­éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‹“å±•è‡³æ›´å¤æ‚çš„é™æ€ç¯å¢ƒ**ï¼š
   - å˜åŒ–çš„é›·è¾¾/å¹²æ‰°æºæ•°é‡ï¼›
   - ä¸è§„åˆ™çš„éƒ¨ç½²åŒºåŸŸå½¢çŠ¶ï¼›
   - æ›´å¤§çš„åœ°ç†å°ºåº¦ã€‚

2. **ç ”ç©¶åŠ¨æ€ç¯å¢ƒä¸‹çš„è‡ªé€‚åº”éƒ¨ç½²**ï¼š
   - å¹²æ‰°èŠ‚ç‚¹éšæ—¶é—´ç§»åŠ¨ï¼›
   - é›·è¾¾ä½ç½®éœ€å¹³æ»‘è°ƒæ•´ï¼ˆä¸èƒ½çªå˜ï¼‰ï¼›
   - å¼•å…¥åœ¨çº¿å­¦ä¹ ä¸é‡è§„åˆ’æœºåˆ¶ã€‚

3. **æ”¹è¿›è¯„ä¼°ä½“ç³»**ï¼š
   - è®¾è®¡é¢å‘åŠ¨æ€åœºæ™¯çš„æ–°å‹è¯„ä»·æŒ‡æ ‡ï¼›
   - åŠ å…¥é€šä¿¡æˆæœ¬ã€èƒ½è€—ç­‰å› ç´ è¿›è¡Œå¤šç›®æ ‡ä¼˜åŒ–ã€‚

4. **æ¢ç´¢å¤šæ™ºèƒ½ä½“ååŒéƒ¨ç½²**ï¼ˆMulti-Agent RLï¼‰ä»¥åº”å¯¹å¤§è§„æ¨¡åˆ†å¸ƒå¼é›·è¾¾ç³»ç»Ÿã€‚

</details>

---

### 12. [Interleaved Latent Visual Reasoning with Selective Perceptual Modeling](https://arxiv.org/abs/2512.05665)

**Authors**: Shuai Dong, Siyuan Wang, Xingyu Liu, Zhongyu Wei  
**Category**: cs.CL  
**Published**: 2025-12-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.05665v1  

#### Abstract
Interleaved reasoning paradigms enhance Multimodal Large Language Models (MLLMs) with visual feedback but are hindered by the prohibitive computational cost of repeatedly re-encoding pixel-dense images. A promising alternative, latent visual reasoning, circumvents this bottleneck yet currently force...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šInterleaved Latent Visual Reasoning with Selective Perceptual Modeling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è¿›è¡Œ**äº¤é”™å›¾åƒ-æ–‡æœ¬æ¨ç†**ï¼ˆinterleaved image-text reasoningï¼‰æ—¶é¢ä¸´ä¸¤ä¸ªæ ¸å¿ƒç“¶é¢ˆï¼š
- **è®¡ç®—æˆæœ¬è¿‡é«˜**ï¼šåå¤å¯¹é«˜åˆ†è¾¨ç‡åƒç´ å›¾åƒè¿›è¡Œç¼–ç å¯¼è‡´æ¨ç†æ•ˆç‡ä½ä¸‹ã€‚
- **æ„ŸçŸ¥ä¸åŠ¨æ€å»ºæ¨¡çš„æƒè¡¡**ï¼šç°æœ‰**æ½œåœ¨è§†è§‰æ¨ç†**ï¼ˆlatent visual reasoningï¼‰æ–¹æ³•å­˜åœ¨ä¸¤éš¾ï¼š
  - è¦ä¹ˆé€šè¿‡è¿‡åº¦å‹ç¼©ç‰¹å¾ç‰ºç‰²ç»†ç²’åº¦æ„ŸçŸ¥èƒ½åŠ›ï¼ˆå¦‚ Mirageï¼‰ï¼›
  - è¦ä¹ˆé‡‡ç”¨é™æ€ã€éäº¤é”™ç»“æ„ï¼Œæ— æ³•å»ºæ¨¡åŠ¨æ€æ¼”åŒ–çš„è§†è§‰çŠ¶æ€ï¼ˆå¦‚ LVRï¼‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šInterleaved Latent Visual Reasoning (ILVR)
ILVR æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ¨¡æ€æ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åœ¨**æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹**ä¸­**äº¤é”™æ’å…¥åŠ¨æ€æ›´æ–°çš„æ½œåœ¨è§†è§‰è¡¨ç¤º**ï¼ˆlatent visual representationsï¼‰ï¼Œä½œä¸ºåç»­æ¨ç†æ­¥éª¤çš„å…·ä½“ã€æ¼”åŒ–çº¿ç´¢ã€‚
- è¿™äº›æ½œåœ¨è¡¨ç¤ºä¸æ˜¯ä¸€æ¬¡æ€§ç”Ÿæˆï¼Œè€Œæ˜¯éšç€æ¨ç†æ­¥éª¤é€æ­¥æ›´æ–°ï¼Œå®ç°**åŠ¨æ€çŠ¶æ€æ¼”åŒ–**ã€‚

### åˆ›æ–°æœºåˆ¶
1. **è‡ªç›‘ç£çš„é€‰æ‹©æ€§æ„ŸçŸ¥å»ºæ¨¡**ï¼ˆSelective Perceptual Modelingï¼‰ï¼š
   - å¼•å…¥ä¸€ä¸ª**åŠ¨é‡æ•™å¸ˆæ¨¡å‹**ï¼ˆMomentum Teacher Modelï¼‰ï¼Œä»â€œè¾…åŠ©å›¾åƒâ€ï¼ˆhelper imagesï¼‰ä¸­é€‰æ‹©æœ€å…³é”®çš„è§†è§‰ patch ç‰¹å¾ã€‚
   - æ•™å¸ˆæ¨¡å‹åŸºäºå½“å‰ä¸Šä¸‹æ–‡ï¼ˆæ–‡æœ¬å†å² + ä¸Šä¸€æ­¥æ½œåœ¨çŠ¶æ€ï¼‰ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ç­›é€‰å‡ºæœ€ç›¸å…³çš„è§†è§‰ç‰¹å¾ï¼Œå½¢æˆç¨€ç–ç›‘ç£ç›®æ ‡ã€‚
2. **ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥**ï¼š
   - **ç¬¬ä¸€é˜¶æ®µ**ï¼šè”åˆç›‘ç£ï¼Œå¼ºåˆ¶å­¦ç”Ÿæ¨¡å‹ç”Ÿæˆçš„æ½œåœ¨çŠ¶æ€ä¸æ•™å¸ˆé€‰æ‹©çš„ç‰¹å¾å¯¹é½ï¼ˆ`latent alignment loss`ï¼‰ã€‚
   - **ç¬¬äºŒé˜¶æ®µ**ï¼šä»…ä¿ç•™æ–‡æœ¬ç›‘ç£ï¼Œæ”¾æ¾æ½œåœ¨å¯¹é½çº¦æŸï¼Œä½¿æ¨¡å‹å†…åŒ–æ¨ç†è¿‡ç¨‹ï¼Œæå‡çµæ´»æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Mirage / LVRï¼‰ | ILVR |
|------|----------------------------|------|
| ç»“æ„ | é™æ€ã€éäº¤é”™ï¼ˆnon-interleavedï¼‰ | åŠ¨æ€ã€äº¤é”™ï¼ˆinterleavedï¼‰ |
| æ„ŸçŸ¥ç²¾åº¦ | è¿‡åº¦å‹ç¼©å¯¼è‡´ç»†èŠ‚ä¸¢å¤± | è‡ªé€‚åº”é€‰æ‹©å…³é”®ç‰¹å¾ï¼Œä¿ç•™ç»†ç²’åº¦ä¿¡æ¯ |
| åŠ¨æ€å»ºæ¨¡ | æ— æ³•æ¨¡æ‹ŸçŠ¶æ€å˜åŒ– | æ”¯æŒå¤šæ­¥è§†è§‰çŠ¶æ€æ¼”åŒ– |
| æ¨ç†æ•ˆç‡ | é¿å…é‡å¤åƒç´ ç¼–ç  | åŒæ ·é¿å…åƒç´ çº§å¤„ç†ï¼Œé«˜æ•ˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ä¸»è¯„ä¼°åŸºå‡†**ï¼š
  - **COMT**ï¼šåŒ…å« Creation, Deletion, Selection, Update å››ç±»ä»»åŠ¡ï¼Œå…± 400 ä¸ªæµ‹è¯•æ ·æœ¬ã€‚
  - **VSP**ï¼šç©ºé—´è§„åˆ’ä»»åŠ¡ï¼Œè¯„ä¼°æ„ŸçŸ¥ä¸æ¨ç†åŒé‡æŒ‘æˆ˜ï¼Œ400 ä¸ªæµ‹è¯•æ ·æœ¬ã€‚
- **æ³›åŒ–æ€§è¯„ä¼°**ï¼ˆOODï¼‰ï¼š
  - **Zebra-CoT**ï¼šè®­ç»ƒé›†ç”¨äºè®­ç»ƒï¼Œä¿ç•™ 2D å­é›†ï¼ˆVisual Jigsaw, Visual Searchï¼‰ç”¨äºæµ‹è¯•ã€‚
  - **EMMA BENCH**ï¼šç§‘å­¦æ¨ç†ä»»åŠ¡ï¼ˆChemistry, Coding, Math, Physicsï¼‰ï¼Œ400 é¢˜ã€‚
  - **VisualLogic**ï¼šç»†ç²’åº¦è§†è§‰é€»è¾‘æ¨ç†ï¼ˆPositional, Quantitative, Stylisticï¼‰ï¼Œ290 é¢˜ã€‚

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šQwen2.5-VL 7Bã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - AdamW ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ 1e-5ï¼Œä½™å¼¦è°ƒåº¦ã€‚
  - æ½œåœ¨ token æ•°é‡ $ K = 8 $ï¼ŒEMA è¡°å‡ç³»æ•° $ \tau = 0.999 $ã€‚
  - è®­ç»ƒè½®æ•°ï¼šCOMT/VSP ä¸º 15 è½®ï¼ŒZebra-CoT ä¸º 2 è½®ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼šå‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ï¼Œå®å¹³å‡ï¼ˆMacro-averageï¼‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| é›¶æ ·æœ¬ | Qwen2.5-VL (Zero-shot) |
| å¾®è°ƒåŸºçº¿ | Qwen2.5-VL (Direct-FT), Qwen2.5-VL (CoT-FT) |
| æ½œåœ¨æ¨ç†åŸºçº¿ | Mirageï¼ˆç›´æ¥èŒƒå¼ï¼Œé™æ€å‹ç¼©ï¼‰ |
| æœ¬æ–‡æ–¹æ³• | ILVRï¼ˆäº¤é”™èŒƒå¼ï¼‰ |

> æ³¨ï¼šLVR å› ä¾èµ–çœŸå®è¾¹ç•Œæ¡†æ ‡æ³¨ï¼Œæœªå‚ä¸é€šç”¨ä»»åŠ¡æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ä¸»è¦æ€§èƒ½å¯¹æ¯”ï¼ˆTable 1ï¼‰
| æ–¹æ³• | èŒƒå¼ | COMT (Avg.) | VSP (Acc.) |
|------|------|-------------|-----------|
| Qwen2.5-VL (Direct-FT) | Direct Ans. | 53% | 72% |
| Qwen2.5-VL (CoT-FT) | Text CoT | 55.8% | 47% |
| Mirage | Direct | 56% | 76% |
| **ILVR (Ours)** | **Interleaved** | **60.8%** | **81.5%** |

> âœ… ILVR åœ¨ä¸¤ä¸ªä¸»åŸºå‡†ä¸Šå‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œå°¤å…¶åœ¨ VSP ä¸Šè¶…è¶Šæœ€å¼ºåŸºçº¿ 5.5 ä¸ªç™¾åˆ†ç‚¹ã€‚

### æ³›åŒ–æ€§èƒ½ï¼ˆTable 2ï¼‰
| æ–¹æ³• | EMMA BENCH | VisualLogic | Zebra-CoT (OOD) | **Overall Avg.** |
|------|------------|--------------|------------------|------------------|
| CoT-FT | 27.8% | 25.9% | 45% | 33.6% |
| Mirage | 27.0% | 26.6% | 47.3% | 34.3% |
| **ILVR (Ours)** | **33.3%** | **29.3%** | **47.8%** | **37.5%** |

> âœ… ILVR åœ¨è·¨é¢†åŸŸä»»åŠ¡ä¸­è¡¨ç°æœ€ä¼˜ï¼Œå°¤å…¶åœ¨ç§‘å­¦æ¨ç†ï¼ˆEMMAï¼‰å’Œç»†ç²’åº¦é€»è¾‘ï¼ˆVisualLogicï¼‰ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3 & 4ï¼‰

#### æ ¸å¿ƒç»„ä»¶æ¶ˆèï¼ˆTable 3ï¼‰
| æ–¹æ³• | ç»“æ„ | æœºåˆ¶ | æ€»ä½“å‡†ç¡®ç‡ |
|------|------|------|------------|
| Direct (Pooling) | Ã— | å¹³å‡æ± åŒ– | 31.5% |
| Direct (Adaptive) | Ã— | è‡ªé€‚åº”é€‰æ‹© | 32.4% |
| **ILVR (Ours)** | âˆš | è‡ªé€‚åº”é€‰æ‹© | **34.8%** |

> ğŸ” ç»“è®ºï¼š**äº¤é”™ç»“æ„**ï¼ˆinterleaved structureï¼‰æ¯”è‡ªé€‚åº”é€‰æ‹©æ›´é‡è¦ï¼ŒäºŒè€…ç»“åˆæ•ˆæœæœ€ä½³ã€‚

#### è¶…å‚æ•°åˆ†æ
- **æ½œåœ¨ token æ•°é‡ $ K $**ï¼ˆFig. 4ï¼‰ï¼š
  - æœ€ä¼˜å€¼ä¸º $ K=8 $ï¼Œæ€»å‡†ç¡®ç‡è¾¾ 34.8%ã€‚
  - $ K > 8 $ åæ€§èƒ½ä¸‹é™ï¼Œè¡¨æ˜è¿‡é•¿åºåˆ—å¼•å…¥å™ªå£°ã€‚
- **å¯¹é½æŸå¤±æƒé‡ $ \lambda_{\text{sim}} $**ï¼ˆTable 4ï¼‰ï¼š
  - æœ€ä¼˜å€¼ä¸º $ \lambda_{\text{sim}} = 1.0 $ã€‚
  - æƒé‡è¿‡å¤§ï¼ˆå¦‚ 10ï¼‰ä¼šè¿‡åº¦çº¦æŸæ½œåœ¨ç©ºé—´ï¼ŒæŸå®³æ¨ç†çµæ´»æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **äº¤é”™å¼æ½œåœ¨æ¨ç†ä¼˜äºé™æ€å‹ç¼©**ï¼š
   - åŠ¨æ€æ›´æ–°çš„æ½œåœ¨è¡¨ç¤ºèƒ½æœ‰æ•ˆå»ºæ¨¡å¤æ‚ä»»åŠ¡ä¸­çš„çŠ¶æ€æ¼”åŒ–ï¼ˆå¦‚æ£‹å±€æ¨æ¼”ã€ç‰©ä½“æ“ä½œï¼‰ã€‚
2. **é€‰æ‹©æ€§æ„ŸçŸ¥å»ºæ¨¡è‡³å…³é‡è¦**ï¼š
   - åŠ¨é‡æ•™å¸ˆå¼•å¯¼çš„ç‰¹å¾é€‰æ‹©æœºåˆ¶å¯é¿å…ä¿¡æ¯ä¸¢å¤±ï¼Œä¿ç•™å…³é”®è§†è§‰ç»†èŠ‚ã€‚
3. **ä¸¤é˜¶æ®µè®­ç»ƒæå‡æ³›åŒ–èƒ½åŠ›**ï¼š
   - å…ˆä¸¥æ ¼å¯¹é½ï¼Œå†æ”¾æ¾çº¦æŸï¼Œæœ‰åŠ©äºæ¨¡å‹å†…åŒ–æ¨ç†æ¨¡å¼è€Œéæœºæ¢°æ¨¡ä»¿ã€‚
4. **ILVR å®ç°äº†æ„ŸçŸ¥ä¸æ¨ç†çš„ç»Ÿä¸€**ï¼š
   - åœ¨ä¸ç‰ºç‰²æ¨ç†èƒ½åŠ›çš„å‰æä¸‹ï¼Œå®ç°äº†ç»†ç²’åº¦è§†è§‰ç†è§£ä¸å¤šæ­¥åŠ¨æ€æ¨ç†çš„èåˆã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„ helper images**ï¼šéœ€è¦é¢„æ„å»ºåŒ…å«ä¸­é—´çŠ¶æ€çš„å›¾åƒåºåˆ—ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œåœ¨çœŸå®ä¸–ç•Œåº”ç”¨ä¸­å¯èƒ½éš¾ä»¥è·å–ã€‚
- **æ½œåœ¨è¡¨ç¤ºä»ä¸ºé»‘ç®±**ï¼šè™½ç„¶å¯è§†åŒ–æ˜¾ç¤ºæ³¨æ„åŠ›èšç„¦åˆç†åŒºåŸŸï¼Œä½†æ½œåœ¨ç©ºé—´çš„è¯­ä¹‰è§£é‡Šæ€§æœ‰å¾…åŠ å¼ºã€‚
- **æ‰©å±•åˆ°æ›´å¤§æ¨¡å‹çš„æˆæœ¬**ï¼šç›®å‰åŸºäº 7B æ¨¡å‹éªŒè¯ï¼Œæ‰©å±•è‡³æ›´å¤§è§„æ¨¡ï¼ˆå¦‚ 72Bï¼‰çš„è®­ç»ƒå¼€é”€éœ€è¿›ä¸€æ­¥è¯„ä¼°ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ„å»ºè‡ªåŠ¨åŒ–çš„ helper image ç”Ÿæˆ pipelineï¼Œå‡å°‘äººå·¥æ ‡æ³¨ä¾èµ–ã€‚
- æ¢ç´¢æ— æ•™å¸ˆçš„è‡ªè’¸é¦æ–¹å¼ï¼Œè¿›ä¸€æ­¥é™ä½ç›‘ç£éœ€æ±‚ã€‚
- å°† ILVR åº”ç”¨äºå…·èº«æ™ºèƒ½ï¼ˆembodied AIï¼‰ã€æœºå™¨äººè§„åˆ’ç­‰éœ€è¦é•¿æœŸçŠ¶æ€è¿½è¸ªçš„ä»»åŠ¡ã€‚
- ç ”ç©¶æ½œåœ¨è¡¨ç¤ºçš„å¯è§£é‡Šæ€§ä¸å¯æ§ç¼–è¾‘èƒ½åŠ›ã€‚

---

> **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/XD111ds/ILVR](https://github.com/XD111ds/ILVR)

</details>

---

### 13. [IDK-S: Incremental Distributional Kernel for Streaming Anomaly Detection](https://arxiv.org/abs/2512.05531)

**Authors**: Yang Xu, Yixiao Ma, Kaifeng Zhang, Zuliang Yang, Kai Ming Ting  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.05531v1  

#### Abstract
Anomaly detection on data streams presents significant challenges, requiring methods to maintain high detection accuracy among evolving distributions while ensuring real-time efficiency. Here we introduce $\mathcal{IDK}$-$\mathcal{S}$, a novel $\mathbf{I}$ncremental $\mathbf{D}$istributional $\mathb...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šIDK-S: Incremental Distributional Kernel for Streaming Anomaly Detection

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**æ•°æ®æµç¯å¢ƒä¸‹çš„å¼‚å¸¸æ£€æµ‹**ï¼ˆStreaming Anomaly Detectionï¼‰ä¸­å­˜åœ¨çš„ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **æ¦‚å¿µæ¼‚ç§»**ï¼ˆConcept Driftï¼‰ï¼šæ•°æ®åˆ†å¸ƒéšæ—¶é—´å˜åŒ–ï¼Œä¼ ç»Ÿé™æ€æ¨¡å‹æ— æ³•é€‚åº”ï¼›
- **è®¡ç®—æ•ˆç‡ç“¶é¢ˆ**ï¼šç°æœ‰æ–¹æ³•è‹¥é‡‡ç”¨å…¨é‡é‡è®­ç»ƒï¼ˆretraining-basedï¼‰ç­–ç•¥ï¼Œè®¡ç®—å¼€é”€å¤§ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æ€§è¦æ±‚ã€‚

è®¸å¤šç°æœ‰æµå¼å¼‚å¸¸æ£€æµ‹å™¨åŸºäºè¾ƒå¼±çš„ç¦»çº¿åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ iForestã€LOFï¼‰ï¼Œå…¶æ€§èƒ½ä¸Šé™å—é™äºè¿™äº›åŸºç¡€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå°¤å…¶åœ¨å¤„ç†å¯†åº¦å˜åŒ–å¤§æˆ–å±€éƒ¨å¼‚å¸¸çš„æ•°æ®æ—¶è¡¨ç°ä¸ä½³ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **IDK-S**ï¼ˆIncremental Distributional Kernel for Streaming anomaly detectionï¼‰ï¼Œä¸€ç§é¢å‘æ•°æ®æµçš„å¢é‡å¼åˆ†å¸ƒæ ¸æ–¹æ³•ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰ç»§æ‰¿å¹¶æ”¹è¿›å¼ºå¤§çš„ç¦»çº¿æ£€æµ‹å™¨ IDK
- åŸºäº **Isolation Distributional Kernel (IDK)** æ„å»ºï¼Œè¯¥æ–¹æ³•åˆ©ç”¨**æ•°æ®ä¾èµ–å‹æ ¸å‡½æ•°**ï¼ˆdata-dependent kernelï¼‰ï¼Œèƒ½æ›´å‡†ç¡®æ•æ‰å¤æ‚æ•°æ®åˆ†å¸ƒä¸­çš„â€œæ­£å¸¸æ€§â€ã€‚
- IDK åœ¨ç¦»çº¿åœºæ™¯ä¸‹å·²è¢«è¯æ˜æ˜¾è‘—ä¼˜äº iForestã€LOF å’Œ kNN ç­‰ç»å…¸æ–¹æ³•ã€‚

#### ï¼ˆ2ï¼‰è®¾è®¡è½»é‡çº§å¢é‡æ›´æ–°æœºåˆ¶
- é¿å…å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œæ˜‚è´µçš„å‘¨æœŸæ€§é‡è®­ç»ƒï¼›
- å¼•å…¥**å¢é‡åˆ†åŒºæ›¿æ¢æœºåˆ¶**ï¼ˆincremental partition-update mechanismï¼‰ï¼š
  - å°†æ—§çª—å£ä¸­è¿‡æ—¶æ ·æœ¬ç”Ÿæˆçš„ hypersphere åˆ†åŒºç§»é™¤ï¼›
  - ç”¨æ–°åˆ°è¾¾æ•°æ®ä¸­çš„æ ·æœ¬æ„å»ºæ–°çš„åˆ†åŒºè¿›è¡Œæ›¿æ¢ï¼›
  - ä»…æ›´æ–°å—å½±å“éƒ¨åˆ†çš„ç‰¹å¾æ˜ å°„å’Œå‡å€¼å‘é‡ã€‚

#### ï¼ˆ3ï¼‰ç†è®ºä¿éšœï¼šç»Ÿè®¡ç­‰ä»·æ€§
- æå‡º **Proposition 1 (Sampling Distribution Equivalence)**ï¼š
  > IDK-S çš„é‡‡æ ·è¿‡ç¨‹ä¸å®Œå…¨é‡è®­ç»ƒç‰ˆæœ¬çš„ IDK å…·æœ‰ç›¸åŒçš„æ ·æœ¬é›†åˆæ¦‚ç‡åˆ†å¸ƒã€‚
- è¿™æ„å‘³ç€å…¶æ•ˆç‡æå‡**ä¸æ˜¯ä»¥ç‰ºç‰²æ¨¡å‹ç»Ÿè®¡æœ‰æ•ˆæ€§ä¸ºä»£ä»·çš„è¿‘ä¼¼æ–¹æ³•**ï¼Œè€Œæ˜¯ä¿æŒäº†åŸå§‹æ¨¡å‹çš„ç»Ÿè®¡æ€§è´¨ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | IDK-S çš„ä¼˜åŠ¿ |
|------|--------------|
| **å‡†ç¡®æ€§** | åŸºäºæ›´å¼ºçš„ IDK æ¨¡å‹ï¼Œåœ¨å¤šæ•°æ•°æ®é›†ä¸Šè¾¾åˆ° SOTA AUC æ€§èƒ½ |
| **æ•ˆç‡** | æ—¶é—´å¤æ‚åº¦ä» $O(wbt)$ é™è‡³ $O(lwt)$ï¼Œå…¶ä¸­ $l \ll w$ï¼Œå®ç°æ•°é‡çº§åŠ é€Ÿ |
| **å†…å­˜å‹å¥½** | ç©ºé—´å¤æ‚åº¦ä¸çª—å£å¤§å°ç›¸å…³ï¼Œé€‚ç”¨äºæ— é™é•¿æ•°æ®æµ |
| **é€‚åº”æ€§** | èƒ½æœ‰æ•ˆåº”å¯¹æ¸è¿›å¼æ¦‚å¿µæ¼‚ç§»ï¼ˆgradual concept driftï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å…±ä½¿ç”¨ **13 ä¸ªåŸºå‡†æ•°æ®é›†**ï¼Œæ¶µç›–ä¸åŒç±»å‹ï¼š

| ç±»å‹ | æ•°æ®é›† |
|------|--------|
| **å¤§è§„æ¨¡é™æ€æ•°æ®æµ**ï¼ˆ11ä¸ªï¼‰ | `Donors`, `Http`, `ForestCover`, `Fraud`, `Mulcross`, `Smtp`, `Shuttle`, `Mammography`, `NYC_taxi_single`, `Annthyroid`, `Satellite` |
| **éå¹³ç¨³/æ¦‚å¿µæ¼‚ç§»æ•°æ®æµ**ï¼ˆ2ä¸ªï¼‰ | `INSECTS`ï¼ˆçªå˜å‹æ¼‚ç§»ï¼‰ã€`TwoCluster`ï¼ˆæ¸è¿›å‹æ¼‚ç§»ï¼‰ |

> æ‰€æœ‰é™æ€æ•°æ®é›†ç»è¿‡éšæœºæ‰“ä¹±åæ¨¡æ‹Ÿæ•°æ®æµè¾“å…¥ï¼›`INSECTS` åŒ…å«çœŸå®ç”±æ¸©åº¦å¼•èµ·çš„æ˜†è™«è¡Œä¸ºå˜åŒ–ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| è®¾ç½®é¡¹ | é…ç½®è¯´æ˜ |
|-------|----------|
| **çª—å£å¤§å°** $w$ | 2048 |
| **æ›´æ–°æ­¥é•¿** $l$ | 100 |
| **é›†æˆæ•°** $t$ | 100ï¼ˆæ‰€æœ‰ ensemble æ–¹æ³•ç»Ÿä¸€è®¾ç½®ï¼‰ |
| **IDK-S å‚æ•°æœç´¢èŒƒå›´** | $\nu \in [2^1, 2^2, ..., 2^6]$ |
| **è¿è¡Œæ¬¡æ•°** | æ¯ä¸ªæ–¹æ³•åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šæ‰§è¡Œ 20 æ¬¡å–å¹³å‡ |
| **ç¡¬ä»¶å¹³å°** | AMD 128æ ¸ CPU @ 2GHz, 1TB RAMï¼ˆé™¤ Memstream å¤–å‡è·‘åœ¨ CPU ä¸Šï¼‰ |

#### è¯„ä¼°æŒ‡æ ‡
- **æ£€æµ‹æ•ˆæœ**ï¼šROC-AUCï¼ˆArea Under Curveï¼‰
- **è¿è¡Œæ•ˆç‡**ï¼šæ€»è¿è¡Œæ—¶é—´ï¼ˆsecondsï¼‰
- **åŠ¨æ€æ€§èƒ½åˆ†æ**ï¼šæ»‘åŠ¨çª—å£å†…ç¬æ—¶ AUC æ›²çº¿ï¼ˆç”¨äºè§‚å¯Ÿå¯¹æ¦‚å¿µæ¼‚ç§»çš„å“åº”èƒ½åŠ›ï¼‰

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¯”è¾ƒäº†äº”ç±»ä¸»æµæµå¼å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼Œä»£è¡¨ä¸åŒæŠ€æœ¯è·¯çº¿ï¼š

| æ–¹æ³• | åŸºç¡€æ¨¡å‹ | ç±»å‹ |
|------|---------|------|
| **SiForest** | Isolation Forest | æµå¼æ‰©å±• |
| **oIFOR** | Isolation Forest | æµå¼æ‰©å±•ï¼ˆåŸºäºå¤šåˆ†è¾¨ç‡ç›´æ–¹å›¾ï¼‰ |
| **DILOF** | LOF | å¯†åº¦åŸºæµå¼æ–¹æ³• |
| **CPOD** | Distance-based | è·ç¦»åŸºæµå¼æ–¹æ³• |
| **Memstream** | Autoencoder + kNN | æ·±åº¦å­¦ä¹ æµå¼æ–¹æ³•ï¼ˆå”¯ä¸€ä½¿ç”¨ GPUï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 3ï¼‰

| æ–¹æ³• | å¹³å‡ AUC | å¹³å‡è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰ |
|------|----------|------------------|
| **IDK-S** | **0.876** âœ… | **27** âœ… |
| SiForest | 0.853 | 432 |
| oIFOR | 0.838 | 218 |
| DILOF | 0.730 | 781 |
| CPOD | 0.727 | 1916 |
| Memstream | 0.841 | 423 |

> âœ… è¡¨ç¤ºæœ€ä¼˜å€¼

#### æ€§èƒ½æå‡æ€»ç»“ï¼š
- **AUC æå‡**ï¼šç›¸æ¯”æ¬¡ä¼˜æ–¹æ³• SiForestï¼ŒIDK-S æé«˜ **2.2%**ï¼›
- **é€Ÿåº¦ä¼˜åŠ¿**ï¼š
  - æ¯” SiForest å¿« **16å€**ï¼›
  - æ¯” oIFOR å¿« **8å€**ï¼›
  - æ¯” CPOD å¿« **71å€**ï¼›
- åœ¨å¤šä¸ªå¤§æ•°æ®é›†ï¼ˆå¦‚ `Donors`, `Fraud`, `INSECTS`ï¼‰ä¸Šæé€Ÿè¾¾ **5x~10xä»¥ä¸Š**ï¼›
- åœ¨å°æ•°æ®é›†ï¼ˆå¦‚ `Satellite`, `Annthyroid`ï¼‰ç”šè‡³å®ç° **è¶…è¿‡ä¸€ä¸ªæ•°é‡çº§çš„é€Ÿåº¦æå‡**ã€‚

---

### åŠ¨æ€é€‚åº”æ€§è¡¨ç°ï¼ˆFigure 4ï¼‰
- åœ¨ `INSECTS`ï¼ˆçªå˜æ¼‚ç§»ï¼‰ä¸Šï¼š
  - æ‰€æœ‰æ–¹æ³•åœ¨æ¼‚ç§»ç‚¹é™„è¿‘å‡ºç° AUC ä¸‹é™ï¼›
  - **IDK-S æ¢å¤æœ€å¿«**ï¼Œè¡¨ç°å‡ºè‰¯å¥½é²æ£’æ€§ã€‚
- åœ¨ `TwoCluster`ï¼ˆæ¸è¿›æ¼‚ç§»ï¼‰ä¸Šï¼š
  - IDK-S å’Œ oIFOR è¡¨ç°ç¨³å®šï¼›
  - **SiForest å‡ºç°æ˜æ˜¾æ€§èƒ½é€€åŒ–**ï¼Œå› å…¶ reservoir sampling æ›´æ–°æœºåˆ¶å¯¼è‡´æ—§æ•°æ®æ»ç•™è¿‡ä¹…ã€‚

---

### å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 5ï¼‰
- IDK-S æœ€ä¼˜å‚æ•° $\nu$ï¼ˆæ¯è½®é‡‡æ ·æ•°ï¼‰é›†ä¸­åœ¨ **[2, 8]**ï¼›
- å¯¹æ¯”ï¼š
  - oIFORï¼šæœ€ä¼˜ `max_leaf_samples` âˆˆ [32, 128]
  - SiForestï¼šæœ€ä¼˜ `reservoir_samples` âˆˆ [256, 512]
- ç»“è®ºï¼š**IDK-S æ›´åŠ æ ·æœ¬é«˜æ•ˆ**ï¼Œå°‘é‡æ ·æœ¬å³å¯æ•è·æ•°æ®åˆ†å¸ƒï¼Œæ˜¯å…¶é«˜æ•ˆæ€§çš„å…³é”®åŸå› ä¹‹ä¸€ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰â€”â€”IDK å˜ä½“å¯¹æ¯”

| æ–¹æ³• | ç±»å‹ | å¹³å‡ AUC | å¹³å‡æ—¶é—´ï¼ˆç§’ï¼‰ |
|------|------|----------|----------------|
| **IDK-S** | Online | 0.877 | 14 |
| Retraining-based IDK | Online | 0.879 | 352 |
| IDKï¼ˆofflineï¼‰ | Offline | 0.898 | 8 |

> æ³¨ï¼šæ­¤å¤„ IDK-S æ—¶é—´æ›´ä½æ˜¯å› ä¸ºæœªè®¡å…¥åˆå§‹åŒ–æˆæœ¬ï¼Œä½“ç°é•¿æœŸè¿è¡Œä¼˜åŠ¿ã€‚

#### å‘ç°ï¼š
- IDK-S ä¸ retraining-based IDK çš„ AUC å·®è·æå°ï¼ˆä»…å·® 0.002ï¼‰ï¼›
- ä½†è¿è¡Œæ—¶é—´å‡å°‘ **è¶…è¿‡ 20å€**ï¼›
- éªŒè¯äº†å¢é‡æ›´æ–°æœºåˆ¶åœ¨ä¸æŸå¤±ç²¾åº¦çš„å‰æä¸‹æå¤§æå‡äº†æ•ˆç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ€§èƒ½å¤©èŠ±æ¿æºäºåŸºç¡€æ¨¡å‹**ï¼š
   - å½“å‰æµå¼æ–¹æ³•æ€§èƒ½å—é™äºå…¶åº•å±‚ç¦»çº¿æ¨¡å‹ï¼ˆå¦‚ iForestã€LOFï¼‰ï¼›
   - è‹¥æƒ³çªç ´æ€§èƒ½ç“¶é¢ˆï¼Œå¿…é¡»é‡‡ç”¨æ›´å¼ºçš„åŸºç¡€æ£€æµ‹å™¨ â€”â€” IDK æ­£æ˜¯è¿™æ ·ä¸€ä¸ªæ›´ä¼˜é€‰æ‹©ã€‚

2. **IDK-S å®ç°ç²¾åº¦ä¸æ•ˆç‡åŒèµ¢**ï¼š
   - åˆ©ç”¨ IDK çš„æ•°æ®ä¾èµ–æ ¸ç‰¹æ€§ï¼Œè·å¾—æ›´é«˜æ£€æµ‹ç²¾åº¦ï¼›
   - è®¾è®¡å¢é‡æ›´æ–°æœºåˆ¶ï¼Œåœ¨ä¿æŒç»Ÿè®¡ç­‰ä»·æ€§çš„å‰æä¸‹å¤§å¹…é™ä½è®¡ç®—è´Ÿæ‹…ã€‚

3. **IDK-S æ˜¯ç›®å‰æœ€é«˜æ•ˆçš„æµå¼å¼‚å¸¸æ£€æµ‹å™¨ä¹‹ä¸€**ï¼š
   - åœ¨ 13 ä¸ªåŸºå‡†ä»»åŠ¡ä¸­ï¼Œç»¼åˆæ€§èƒ½é¢†å…ˆï¼›
   - ç‰¹åˆ«é€‚åˆé«˜ååã€ä½å»¶è¿Ÿçš„çœŸå®å·¥ä¸šåœºæ™¯åº”ç”¨ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **å¯¹çªå˜å‹æ¦‚å¿µæ¼‚ç§»ä»æœ‰ä¸€å®šæ»å**ï¼š
  - è™½ç„¶æ¢å¤è¾ƒå¿«ï¼Œä½†åœ¨ `INSECTS` ä¸Šä»æœ‰çŸ­æš‚æ€§èƒ½ä¸‹é™ï¼›
  - å½“å‰æœºåˆ¶ä¾èµ–æ»‘åŠ¨çª—å£é€æ­¥æ›¿æ¢ï¼Œç¼ºä¹ä¸»åŠ¨æ¼‚ç§»æ£€æµ‹ä¸å¿«é€Ÿé‡ç½®æœºåˆ¶ã€‚
- **å‚æ•°é€‰æ‹©å½±å“æ€§èƒ½**ï¼š
  - å°½ç®¡ $\nu$ è¾ƒå°ä¸”æ˜“è°ƒï¼Œä½†ä»éœ€é€šè¿‡äº¤å‰éªŒè¯ç¡®å®šæœ€ä¼˜å€¼ï¼›
  - è‡ªåŠ¨åŒ–è¶…å‚ä¼˜åŒ–å°šæœªæ¢ç´¢ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å¢å¼ºå¯¹**çªå‘å¼æ¦‚å¿µæ¼‚ç§»**çš„é²æ£’æ€§ï¼›
- å¼•å…¥**åœ¨çº¿æ¼‚ç§»æ£€æµ‹æ¨¡å—**ï¼Œè§¦å‘æ›´æ¿€è¿›çš„æ¨¡å‹è°ƒæ•´ï¼›
- æ‰©å±•è‡³**å¤šæ¨¡æ€æˆ–å›¾æ•°æ®æµ**ä¸Šçš„å¼‚å¸¸æ£€æµ‹ï¼›
- ç»“åˆè½»é‡åŒ–æ·±åº¦è¡¨ç¤ºå­¦ä¹ ï¼Œè¿›ä¸€æ­¥æå‡é«˜ç»´ç¨€ç–æ•°æ®çš„è¡¨ç°ã€‚

---

## æ€»ç»“
**IDK-S** æ˜¯ä¸€é¡¹å°†å¼ºå¤§ç¦»çº¿æ£€æµ‹å™¨ IDK æˆåŠŸè¿ç§»åˆ°æµå¼åœºæ™¯çš„é‡è¦å·¥ä½œã€‚å®ƒä¸ä»…æå‡ºäº†ä¸€ä¸ªé«˜æ•ˆã€å¯è¯æ˜ç­‰ä»·äºå…¨é‡é‡è®­ç»ƒçš„å¢é‡æ¡†æ¶ï¼Œè€Œä¸”åœ¨å®éªŒä¸­å±•ç°å‡º**å‰æ‰€æœªæœ‰çš„ç²¾åº¦-æ•ˆç‡å¹³è¡¡**ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ€§èƒ½æµå¼å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿæä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 14. [MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare](https://arxiv.org/abs/2512.05365)

**Authors**: Zag ElSayed, Craig Erickson, Ernest Pedapati  
**Category**: cs.AI  
**Published**: 2025-12-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.05365v1  

#### Abstract
Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a sp...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰åŒ»ç–—AIç³»ç»Ÿé¢ä¸´ä¸‰å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **ç¼ºä¹ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›**ï¼šä¼ ç»ŸCDSSä¾èµ–é™æ€è§„åˆ™ï¼Œè€ŒLLMsè™½èƒ½ç”Ÿæˆåˆç†å™è¿°ï¼Œä½†æ— çŠ¶æ€è®°å¿†ã€ä»»åŠ¡é€»è¾‘å’ŒæŒç»­æ¨ç†èƒ½åŠ›ã€‚
- **çºµå‘ç®¡ç†ç¼ºå¤±**ï¼šéš¾ä»¥åœ¨é•¿æœŸè¯Šç–—æµç¨‹ä¸­ç»´æŒæ‚£è€…çŠ¶æ€å’Œå†³ç­–è¿ç»­æ€§ã€‚
- **äººæœºåä½œä¸é€æ˜**ï¼šç¼ºä¹å¯å®¡è®¡ã€å¯è¿½æº¯çš„å†³ç­–è·¯å¾„ï¼Œé™åˆ¶ä¸´åºŠä¿¡ä»»ä¸ç›‘ç®¡åˆè§„ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´AIåœ¨é«˜é£é™©åŒ»ç–—åœºæ™¯ä¸­çš„åº”ç”¨å—é™ï¼Œå°¤å…¶æ˜¯åœ¨æ…¢æ€§ç—…ç®¡ç†ã€ç½•è§ç—…è¯Šæ–­å’Œè·¨å­¦ç§‘åä½œä¸­ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **MCP-AI** â€”â€” ä¸€ç§åŸºäº **Model Context Protocol (MCP)** çš„æ–°å‹æ¶æ„ï¼Œç”¨äºå®ç°è‡ªä¸»ã€å¯è§£é‡Šã€åè®®é©±åŠ¨çš„ä¸´åºŠæ¨ç†æ¡†æ¶ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **MCP æ–‡ä»¶ä½œä¸ºâ€œè®¤çŸ¥å†…å­˜â€å¯¹è±¡**ï¼šæ¯ä¸ªMCPæ–‡ä»¶å°è£…äº†æ‚£è€…çš„ä¸´åºŠç›®æ ‡ã€ä¸Šä¸‹æ–‡ã€æ¨ç†çŠ¶æ€å’Œä»»åŠ¡é€»è¾‘ï¼Œå½¢æˆä¸€ä¸ª**å¯é‡ç”¨ã€å¯å®¡è®¡ã€ç‰ˆæœ¬æ§åˆ¶çš„è®°å¿†å•å…ƒ**ã€‚
- **åŒAIæ¨¡å—ååŒæœºåˆ¶**ï¼š
  - **Generative AI Modules**ï¼ˆå¦‚LLMsï¼‰è´Ÿè´£ç”Ÿæˆè¯Šæ–­å‡è®¾ã€æŠ¤ç†è®¡åˆ’ç­‰å™äº‹è¾“å‡ºï¼›
  - **Descriptive AI Modules**ï¼ˆå¦‚è§„åˆ™å¼•æ“ã€çŸ¥è¯†å›¾è°±ï¼‰è¿›è¡ŒæŒ‡å—éªŒè¯ã€é£é™©è¯„åˆ†å’Œå®‰å…¨æ€§æ£€æŸ¥ã€‚
- **äº”å±‚æ¨¡å—åŒ–æ¶æ„**ï¼šæ”¯æŒä»æ•°æ®è¾“å…¥åˆ°äººç±»éªŒè¯çš„å…¨æµç¨‹é—­ç¯ï¼ŒåŒ…æ‹¬æ„ŸçŸ¥å±‚ã€MCPå¼•æ“ã€æ¨ç†æ¨¡å—ã€ä»»åŠ¡ä»£ç†å’ŒåŒ»ç”Ÿæ¥å£ã€‚
- **åŒ»å¸ˆåœ¨ç¯ï¼ˆPhysician-in-the-loopï¼‰è®¾è®¡**ï¼šç¡®ä¿æ‰€æœ‰AIå»ºè®®å‡éœ€ç»åŒ»ç”Ÿå®¡æŸ¥ã€ä¿®æ”¹æˆ–æ‰¹å‡†ï¼Œä¿éšœä¸´åºŠä¸»å¯¼æƒã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»ŸCDSS / Prompt-based LLMs | MCP-AI |
|------|-------------------------------|--------|
| æ¨ç†æ¨¡å¼ | é™æ€ã€ä¸€æ¬¡æ€§å“åº” | åŠ¨æ€ã€æŒç»­ã€çºµå‘æ¨ç† |
| ä¸Šä¸‹æ–‡ä¿æŒ | æ— æŒä¹…çŠ¶æ€ | MCPæ–‡ä»¶æä¾›å®Œæ•´å†å²è®°å½• |
| å¯è§£é‡Šæ€§ | é»‘ç®±æˆ–ç®€å•è§„åˆ™è¿½æº¯ | å…¨é“¾è·¯å…ƒæ•°æ®æ—¥å¿—ï¼ˆä¿¡å¿ƒå€¼ã€ä¾æ®ã€æ¨¡å—æ¥æºï¼‰ |
| åä½œèƒ½åŠ› | å­¤ç«‹ç³»ç»Ÿ | æ”¯æŒå¤šæ™ºèƒ½ä½“åä½œä¸è·¨ç§‘å®¤äº¤æ¥ï¼ˆHandoffï¼‰ |
| åˆè§„æ€§ | éš¾ä»¥æ»¡è¶³HIPAA/FDA SaMDè¦æ±‚ | å†…å»ºå®¡è®¡æ—¥å¿—ã€ç‰ˆæœ¬æ§åˆ¶ã€å®‰å…¨çº¦æŸ |

> âœ… **æœ¬è´¨è½¬å˜**ï¼šä»â€œè¢«åŠ¨å†³ç­–æ”¯æŒâ€è½¬å‘â€œä¸»åŠ¨è®¤çŸ¥åä½œè€…â€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
è®ºæ–‡æœªä½¿ç”¨å…¬å¼€æ ‡å‡†æ•°æ®é›†ï¼Œè€Œæ˜¯æ„å»ºäº†ä¸¤ä¸ª**æ¨¡æ‹Ÿä¸´åºŠæ¡ˆä¾‹**æ¥éªŒè¯MCP-AIçš„æœ‰æ•ˆæ€§ï¼š

1. **Fragile X Syndrome with Comorbid Depression**
   - è™šæ„13å²æ‚£è€…ï¼Œå«è¡Œä¸ºéšœç¢ã€å‘è‚²è¿Ÿç¼“ã€å­¦ä¸šå›°éš¾
   - è¾“å…¥æ•°æ®ï¼šå®¶é•¿è®¿è°ˆã€è¡Œä¸ºè§‚å¯Ÿç¬”è®°ã€EEGæ³¢å½¢ã€æ•™è‚²è®°å½•ã€é—¨è¯Šç”µå­å¥åº·æ¡£æ¡ˆï¼ˆEHRï¼‰

2. **Type 2 Diabetes and Hypertension è¿œç¨‹åè°ƒç®¡ç†**
   - è™šæ„58å²æ‚£è€…ï¼Œè¡€ç³–æ³¢åŠ¨ã€ç”¨è¯ä¾ä»æ€§å·®
   - è¾“å…¥æ•°æ®ï¼šå¯ç©¿æˆ´è®¾å¤‡æ•°æ®ã€è¡€ç³–ä»ªæ—¥å¿—ã€HbA1cè¶‹åŠ¿ã€ç¤¾ä¼šå†³å®šå› ç´ ï¼ˆä½æˆ¿ä¸ç¨³å®šã€é£Ÿç‰©è·å–å›°éš¾ï¼‰

æ‰€æœ‰æ•°æ®é€šè¿‡HL7/FHIRæ¥å£é›†æˆè‡³MCP-AIç³»ç»Ÿã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### å®éªŒå½¢å¼
- **ä»¿çœŸæµ‹è¯•ï¼ˆSimulation-based Evaluationï¼‰**
- åœ¨å—æ§ç¯å¢ƒä¸­è¿è¡ŒMCP-AIå¤„ç†ä¸Šè¿°ä¸¤ä¸ªç—…ä¾‹ï¼Œè®°å½•å…¶æ¨ç†è¿‡ç¨‹ã€ä»»åŠ¡æ‰§è¡Œä¸è¾“å‡ºè´¨é‡

#### è¯„ä¼°ç»´åº¦
| ç»´åº¦ | æŒ‡æ ‡è¯´æ˜ |
|------|----------|
| **ä¸´åºŠå‡†ç¡®æ€§** | æ˜¯å¦ç¬¦åˆDSM-Vã€ICD-10ã€ADAæŒ‡å—ç­‰æ ‡å‡† |
| **å¯è§£é‡Šæ€§ä¸å¯è¿½æº¯æ€§** | MCPæ–‡ä»¶æ˜¯å¦å®Œæ•´è®°å½•æ¯ä¸€æ­¥æ¨ç†é€»è¾‘ã€ç½®ä¿¡åº¦ã€æ•°æ®æºã€æ¨¡å—è°ƒç”¨ |
| **å·¥ä½œæµæ•´åˆèƒ½åŠ›** | æ˜¯å¦èƒ½è‡ªåŠ¨ç”Ÿæˆæ£€éªŒç”³è¯·ã€éšè®¿æé†’ã€è½¬è¯Šå»ºè®®ï¼Œå¹¶ä¸EHRç³»ç»Ÿå¯¹æ¥ |
| **è·¨æä¾›è€…äº¤æ¥èƒ½åŠ›** | Handoff Agentèƒ½å¦ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ï¼Œæ”¯æŒæ— ç¼è¿‡æ¸¡ |
| **ç›‘ç®¡åˆè§„æ€§** | æ˜¯å¦æ»¡è¶³HIPAAéšç§è¦æ±‚ã€FDA SaMDåŸåˆ™ï¼ˆå¦‚å˜æ›´è¿½è¸ªã€ç‰ˆæœ¬æ§åˆ¶ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
è™½ç„¶æ²¡æœ‰ç›´æ¥æ•°å€¼å¯¹æ¯”å®éªŒï¼Œä½†æ–‡ä¸­æ˜ç¡®å°†MCP-AIä¸ä»¥ä¸‹åŸºçº¿ç³»ç»Ÿè¿›è¡Œå®šæ€§æ¯”è¾ƒï¼š
- **ä¼ ç»ŸCDSS**ï¼ˆå¦‚åŸºäºSNOMED CT/ICD-10çš„è§„åˆ™ç³»ç»Ÿï¼‰
- **Prompt-based LLMs**ï¼ˆå¦‚GPT-4, Med-PaLMï¼‰
- **å­¤ç«‹AIç®¡é“ï¼ˆSiloed AI Pipelinesï¼‰**

å¼ºè°ƒè¿™äº›æ–¹æ³•åœ¨**çŠ¶æ€æŒä¹…æ€§ã€ä»»åŠ¡ç¼–æ’ã€åä½œé€æ˜åº¦**æ–¹é¢çš„æ ¹æœ¬ç¼ºé™·ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆåŸºäºæ¡ˆä¾‹åˆ†æï¼‰
#### âœ… Fragile X Syndrome æ¡ˆä¾‹
- æˆåŠŸè¯†åˆ«å‡º**Fragile Xç»¼åˆå¾+æŠ‘éƒå…±ç—…**çš„å¯èƒ½æ€§
- è‡ªåŠ¨ç”Ÿæˆï¼š
  - FMR1åŸºå› æ£€æµ‹è¯·æ±‚
  - å‘ä¸´åºŠé—ä¼ å­¦å®¶è‡ªåŠ¨è½¬è¯Š
  - è¡Œä¸ºå¥åº·ç»¼åˆè¯„ä¼°å®‰æ’
- Descriptive AIæ¨¡å—æˆåŠŸéªŒè¯è¯Šæ–­é“¾å®Œæ•´æ€§ï¼Œæ ‡è®°æ½œåœ¨é—æ¼é¡¹ï¼ˆå¦‚å®¶æ—å²ç¼ºå¤±ï¼‰
- MCPæ–‡ä»¶è®°å½•äº†å®Œæ•´çš„æ¨ç†è½¨è¿¹ï¼ŒåŒ…æ‹¬ï¼š
  - åˆå§‹å‡è®¾ç”Ÿæˆæ—¶é—´æˆ³
  - å„AIæ¨¡å—è´¡çŒ®æ ‡è¯†
  - ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆå¦‚Depressionå¯èƒ½æ€§ï¼š78%ï¼‰
  - åŒ»ç”Ÿå®¡æ‰¹åè§¦å‘åç»­ä»»åŠ¡é’©å­ï¼ˆthree-week follow-up EEGï¼‰

#### âœ… Diabetes & Hypertension æ¡ˆä¾‹
- åŸºäºä¼ æ„Ÿå™¨å’Œç¤¾ä¼šå†³å®šå› ç´ åŠ¨æ€è°ƒæ•´æŠ¤ç†è®¡åˆ’
- è¾“å‡ºå»ºè®®åŒ…æ‹¬ï¼š
  - é¥®é£Ÿå’¨è¯¢ä»‹å…¥
  - äºŒç”²åŒèƒå‰‚é‡æ»´å®š
  - è€ƒè™‘å¼•å…¥SGLT2æŠ‘åˆ¶å‰‚ï¼ˆç»è‚¾åŠŸèƒ½æ’é™¤ç¦å¿Œï¼‰
- Descriptiveæ¨¡å—è®¡ç®—æ‚£è€…ä¾ä»æ¦‚ç‡ï¼ˆPatient Engagement Score: 62%ï¼‰
- Handoff Agentç”ŸæˆåµŒå…¥å¼MCPæ‘˜è¦ï¼ŒåŒ…å«ï¼š
  - æœ€è¿‘è°ƒæ•´çš„ç†ç”±
  - ç¼ºå¤±å®éªŒå®¤è­¦æŠ¥
  - ä¸‹ä¸€æ­¥éšè®¿ä»»åŠ¡æ¸…å•
- ç³»ç»Ÿé¢„æµ‹æœªæ¥è¡€ç³–/è¡€å‹è½¨è¿¹ï¼Œä¾›æ¥ç­åŒ»ç”Ÿå‚è€ƒè°ƒæ•´

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| èƒ½åŠ› | Prompt-based LLM | ä¼ ç»ŸCDSS | MCP-AI |
|------|------------------|-----------|---------|
| å¤šæ¨¡æ€æ•°æ®èåˆ | æœ‰é™ | å¼± | âœ… å¼ºï¼ˆEEG + EHR + ç¤¾ä¼šå› ç´ ï¼‰ |
| é•¿æœŸçŠ¶æ€ç»´æŠ¤ | âŒ æ— è®°å¿† | âŒ å›ºå®šè§„åˆ™ | âœ… MCPæ–‡ä»¶æŒç»­æ›´æ–° |
| è·¨ä¸“ä¸šäº¤æ¥ | âŒ ä¸æ”¯æŒ | âŒ æ–­è£‚ | âœ… ç»“æ„åŒ–æ¨ç†æ‘˜è¦ |
| å®‰å…¨éªŒè¯ | âŒ æ—  | âœ… è§„åˆ™æ ¡éªŒ | âœ… åŒé‡éªŒè¯ï¼ˆç”Ÿæˆ+æè¿°ï¼‰ |
| å¯å®¡è®¡æ€§ | âŒ é»‘ç®± | âœ… æ—¥å¿— | âœ… å…¨é“¾è·¯å…ƒæ•°æ®è®°å½• |

> âš ï¸ æ³¨ï¼šç”±äºæ˜¯æ¦‚å¿µéªŒè¯ç ”ç©¶ï¼Œå°šæœªæŠ¥å‘Šé‡åŒ–å‡†ç¡®ç‡ã€æ•æ„Ÿæ€§/ç‰¹å¼‚æ€§ç­‰ç»Ÿè®¡æŒ‡æ ‡ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆå¦‚æœ‰ï¼‰
è®ºæ–‡æœªå¼€å±•æ­£å¼æ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œä½†é€šè¿‡æ¶æ„è®¾è®¡è¯´æ˜å„ç»„ä»¶å¿…è¦æ€§ï¼š
- è‹¥ç§»é™¤Descriptive AI â†’ å¤±å»å®‰å…¨æ€§éªŒè¯èƒ½åŠ›
- è‹¥æ— MCP Engine â†’ æ— æ³•åè°ƒå¤šAgentåä½œ
- è‹¥ç¼ºå°‘Verification Module â†’ è¿åâ€œPhysician-in-the-loopâ€åŸåˆ™

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **MCP-AIå®ç°äº†çœŸæ­£çš„â€œè‡ªä¸»ä¸´åºŠæ¨ç†â€**  
   ä¸ä»…åšå‡ºæ¨èï¼Œè¿˜èƒ½ä¿ç•™æ¨ç†è·¯å¾„ã€é€‚åº”ç¯å¢ƒå˜åŒ–ã€è·¨æ—¶é—´ä¸ç©ºé—´å»¶ç»­å†³ç­–é€»è¾‘ã€‚

2. **MCPæ–‡ä»¶æ˜¯åŒ»ç–—AIçš„è®¤çŸ¥åŸºç¡€è®¾æ–½**  
   å°†AIå†³ç­–è½¬åŒ–ä¸º**æœºå™¨å¯è¯»+äººç±»å¯å®¡**çš„åè®®å¯¹è±¡ï¼Œè§£å†³äº†å½“å‰AIâ€œä¸å¯æ§ã€ä¸å¯ä¿¡ã€ä¸å¯ç®¡â€çš„ç—›ç‚¹ã€‚

3. **æ”¯æŒå¤æ‚ç–¾ç—…çš„ç«¯åˆ°ç«¯ç®¡ç†**  
   åœ¨ç½•è§ç—…ï¼ˆFragile Xï¼‰å’Œæ…¢æ€§ç—…ï¼ˆDiabetes/Hypertensionï¼‰ä¸­å‡å±•ç¤ºå‡ºå¼ºå¤§çš„æƒ…å¢ƒç†è§£ä¸ä»»åŠ¡è‡ªåŠ¨åŒ–èƒ½åŠ›ã€‚

4. **å¤©ç„¶å¥‘åˆåŒ»ç–—ç›‘ç®¡è¦æ±‚**  
   æ”¯æŒHL7/FHIRé›†æˆã€HIPAAåˆè§„ã€FDA SaMDè§„èŒƒï¼Œå…·å¤‡ä¸´åºŠéƒ¨ç½²æ½œåŠ›ã€‚

5. **æ¨åŠ¨AIè§’è‰²ä»â€œå·¥å…·â€å‘â€œåä½œè€…â€æ¼”è¿›**  
   åŒ»ç”Ÿä¸å†æ˜¯è¢«åŠ¨æ¥æ”¶å»ºè®®ï¼Œè€Œæ˜¯å‚ä¸ã€ä¿®æ­£ã€ç›‘ç£æ•´ä¸ªAIæ¨ç†è¿‡ç¨‹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å°šå¤„ä»¿çœŸé˜¶æ®µ**ï¼šæœªåœ¨çœŸå®ä¸´åºŠç¯å¢ƒä¸­è¿›è¡Œå‰ç»æ€§è¯•éªŒã€‚
- **ä¾èµ–é«˜è´¨é‡ç»“æ„åŒ–è¾“å…¥**ï¼šå¯¹éç»“æ„åŒ–æ–‡æœ¬çš„ç†è§£ä»ä¾èµ–LLMæ€§èƒ½ã€‚
- **MCPæ–‡ä»¶å¤æ‚æ€§å¢åŠ è¿ç»´æˆæœ¬**ï¼šéœ€è¦ä¸“é—¨å¹³å°ç®¡ç†å’Œè§£æã€‚
- **å°šæœªéªŒè¯æ³›åŒ–èƒ½åŠ›**ï¼šä»…å±•ç¤ºä¸¤ä¸ªæ¡ˆä¾‹ï¼Œéœ€æ›´å¤šç–¾ç—…é¢†åŸŸéªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
ä½œè€…æ˜ç¡®æå‡ºä»¥ä¸‹å‘å±•æ–¹å‘ï¼š
1. **é›†æˆå®æ—¶ç”Ÿç‰©ä¿¡å·åé¦ˆæœºåˆ¶**ï¼ˆå¦‚EEGã€ECGï¼‰ä»¥å¢å¼ºåŠ¨æ€ç›‘æµ‹èƒ½åŠ›
2. **æ‰©å±•ä»»åŠ¡ä»£ç†åº“**ï¼šåŠ å…¥åº·å¤ã€é¢„é˜²ä¿å¥ç­‰æ–°æ¨¡å—
3. **å‘å±•åˆ†å¸ƒå¼å­¦ä¹ æœºåˆ¶**ï¼šåœ¨ä¿æŠ¤éšç§çš„å‰æä¸‹å®ç°æ¨¡å‹è”åˆæ›´æ–°
4. **å¯åŠ¨å‰ç»æ€§ä¸´åºŠè¯•éªŒ**ï¼šä¸ç°æœ‰AI/MLè¯Šæ–­å·¥å…·è¿›è¡Œå¤´å¯¹å¤´æ¯”è¾ƒ
5. **æ‰“é€ æ ‡å‡†åŒ–MCPæ‰©å±•ç”Ÿæ€**ï¼šæ”¯æŒå½±åƒAIã€åŸºå› ç»„è§£è¯»å™¨ç­‰ç¬¬ä¸‰æ–¹æ¥å…¥

---

## æ€»ç»“

ğŸ“Œ **MCP-AIä¸æ˜¯å¦ä¸€ä¸ªAIè¯Šæ–­æ¨¡å‹ï¼Œè€Œæ˜¯ä¸€ä¸ªå…¨æ–°çš„åŒ»ç–—AIæ“ä½œç³»ç»ŸèŒƒå¼**ã€‚å®ƒé€šè¿‡**MCPåè®®**å°†ç”Ÿæˆå¼AIä¸æè¿°æ€§AIç»Ÿä¸€åœ¨ä¸€ä¸ªå¯å®¡è®¡ã€å¯æŒç»­ã€å¯åä½œçš„æ¡†æ¶ä¸‹ï¼ŒçœŸæ­£è¿ˆå‘â€œå¯ä¿¡ã€å¯æ§ã€å¯æŒç»­â€çš„ä¸´åºŠæ™ºèƒ½æ—¶ä»£ã€‚è¯¥å·¥ä½œä¸ºä¸‹ä¸€ä»£**Explainable Medical AI**å¥ å®šäº†æ¶æ„åŸºç¡€ï¼Œå…·æœ‰æ·±è¿œçš„å­¦æœ¯ä¸äº§ä¸šä»·å€¼ã€‚

</details>

---

### 15. [MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models](https://arxiv.org/abs/2512.05530)

**Authors**: Chuang Yu, Jinmiao Zhao, Mingxuan Zhao, Yunpeng Liu, Xiujun Shu, Yuanhao Feng, Bo Wang, Xiangyu Yue  
**Category**: cs.AI  
**Published**: 2025-12-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.05530v1  

#### Abstract
Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Multimodal Large Language Models (MLLMs)** åœ¨æ¨ç†ä»»åŠ¡ä¸­å­˜åœ¨ä»¥ä¸‹å…³é”®ç¼ºé™·ï¼š
- **å•ç†ç”±ç›‘ç£ï¼ˆSingle-rationale supervisionï¼‰** å¯¼è‡´æ¨¡å‹ä»…å­¦ä¹ åˆ°è¡¨é¢æ˜ å°„å…³ç³»ï¼Œæ— æ³•æ•æ‰äººç±»æ¨ç†çš„å¤šæ ·æ€§ä¸å¤æ‚æ€§ã€‚
- ç¼ºä¹å¯¹é”™è¯¯é€»è¾‘çš„è¯†åˆ«ä¸è‡ªæˆ‘ä¿®æ­£èƒ½åŠ›ï¼Œåœ¨é¢å¯¹è¯¯å¯¼æ€§æˆ–æ¨¡ç³Šä¿¡æ¯æ—¶è¡¨ç°å‡ºè„†å¼±çš„é€»è¾‘é²æ£’æ€§ã€‚
- æ¨ç†è¿‡ç¨‹ä¸ºâ€œè¢«åŠ¨æ¨¡ä»¿â€ï¼Œç¼ºä¹ä¸»åŠ¨çš„é€»è¾‘åˆ¤åˆ«ä¸åæ€æœºåˆ¶ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†é¦–ä¸ª **Multi-rationale INtegrated Discriminative (MIND)** æ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨èµ‹äºˆ MLLMs ç±»ä¼¼äººç±»çš„â€œ**Understand â†’ Rethink â†’ Correct**â€è®¤çŸ¥èƒ½åŠ›ï¼Œå®ç°ä»**è¢«åŠ¨æ¨¡ä»¿æ¨ç†**å‘**ä¸»åŠ¨åˆ¤åˆ«å¼æ¨ç†**çš„èŒƒå¼æ¼”è¿›ã€‚

#### æ ¸å¿ƒç»„ä»¶ï¼š
1. **Rationale Augmentation and Discrimination (RAD) èŒƒå¼**
   - è‡ªåŠ¨é«˜æ•ˆåœ°ç”Ÿæˆå¤šæ ·åŒ–çš„**æ­£å‘ç†ç”±ï¼ˆpositive rationalesï¼‰** å’Œè¯­ä¹‰åè½¬çš„**è´Ÿå‘ç†ç”±ï¼ˆnegative rationalesï¼‰**ã€‚
   - æ„å»ºç»Ÿä¸€ä¸”å¯æ‰©å±•çš„å¤šç†ç”±è®­ç»ƒæ•°æ®åŸºç¡€ï¼Œæ˜¾å¼å»ºæ¨¡æ­£ç¡®æ¨ç†ä¸æ½œåœ¨æ¨ç†é™·é˜±ã€‚

2. **Progressive Two-stage Correction Learning (P2CL) ç­–ç•¥**
   - **é˜¶æ®µ I (P2CL-I)**ï¼šå¤šç†ç”±æ­£å‘å­¦ä¹ ï¼Œå¢å¼ºè¯­ä¹‰ç†è§£ä¸é€»è¾‘å»ºæ¨¡ã€‚
   - **é˜¶æ®µ II (P2CL-II)**ï¼šä¸»åŠ¨é€»è¾‘åˆ¤åˆ«ä¸ä¿®æ­£ï¼Œåˆ©ç”¨æ­£/è´Ÿç†ç”±å¯¹è¿›è¡Œè”åˆç”Ÿæˆè®­ç»ƒï¼Œæå‡æ¨¡å‹çº é”™èƒ½åŠ›ã€‚

3. **Multi-rationale Contrastive Alignment (MCA) ä¼˜åŒ–ç­–ç•¥**
   - åœ¨åµŒå…¥ç©ºé—´ä¸­é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œèšåˆæ­£ç¡®çš„ç¡¬æ­£ä¾‹ç†ç”±ï¼Œåˆ†ç¦»é”™è¯¯çš„ç¡¬è´Ÿä¾‹ç†ç”±ã€‚
   - ç¼“è§£å¤šç†ç”±è¯­ä¹‰ç©ºé—´ä¸­çš„è¡¨ç¤ºçº ç¼ ï¼Œå¢å¼ºé€»è¾‘ä¸€è‡´æ€§ä¸åˆ¤åˆ«æ•æ„Ÿæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´ä¸°å¯Œçš„è¯­ä¹‰å»ºæ¨¡**ï¼šé€šè¿‡å¤šç†ç”±è®­ç»ƒï¼Œæ•æ‰äººç±»æ¨ç†çš„å¤šæ ·æ€§ã€‚
- **æ›´å¼ºçš„é€»è¾‘é²æ£’æ€§**ï¼šå¼•å…¥è´Ÿç†ç”±æš´éœ²æ¨ç†é™·é˜±ï¼Œæå‡æ¨¡å‹æŠ—å¹²æ‰°èƒ½åŠ›ã€‚
- **å…·å¤‡è‡ªçœä¸çº é”™èƒ½åŠ›**ï¼šP2CL å®ç°äº†â€œå…ˆç†è§£ã€å†åæ€ã€åçº æ­£â€çš„é—­ç¯æ¨ç†æœºåˆ¶ã€‚
- **ç«¯åˆ°ç«¯å¯è®­ç»ƒ**ï¼šMCA ä¸ P2CL ååŒä¼˜åŒ–ï¼Œæå‡æ•´ä½“æ¨ç†è´¨é‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªæ¶µç›–ä¸åŒé¢†åŸŸçš„å…¬å¼€ VQA æ•°æ®é›†ä¸Šè¿›è¡Œäº†ç³»ç»Ÿå®éªŒï¼š
- **ScienceQA**ï¼šç§‘å­¦é¢†åŸŸé—®ç­”ï¼Œ21,208 æ ·æœ¬ã€‚
- **A-OKVQA**ï¼šå¸¸è¯†æ¨ç†é—®ç­”ï¼Œ24,903 æ ·æœ¬ã€‚
- **MÂ³CoT**ï¼šèåˆç§‘å­¦ã€å¸¸è¯†ä¸æ•°å­¦çš„å¤šæ­¥æ¨ç†åŸºå‡†ï¼Œ11,328 æ ·æœ¬ã€‚

åŸºäº RAD èŒƒå¼æ„å»ºäº†æ‰©å±•ç‰ˆæœ¬ï¼š
- **ScienceQA-RAD**ï¼ˆÃ—1000ï¼‰
- **A-OKVQA-RAD**ï¼ˆÃ—1000ï¼‰
- **MÂ³CoT-RAD**ï¼ˆÃ—500ï¼‰

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº T5 çš„ encoder-decoder æ¶æ„ã€‚
- **æ¨¡å‹è§„æ¨¡**ï¼šBase (223M) å’Œ Large (738M)ã€‚
- **è§†è§‰ç¼–ç å™¨**ï¼šå†»ç»“çš„ BLIP2-flan-t5-xxlã€‚
- **å›¾åƒæè¿°ç”Ÿæˆ**ï¼šQwen2.5-VL-72Bã€‚
- **è®­ç»ƒå‚æ•°**ï¼šå­¦ä¹ ç‡ 8e-5ï¼Œbatch size 8ï¼Œæœ€å¤§åºåˆ—é•¿åº¦ 512ã€‚
- **è®­ç»ƒè½®æ•°**ï¼šScienceQA-RAD 200 è½®ï¼ŒA-OKVQA-RAD å’Œ MÂ³CoT 400 è½®ã€‚
- **ç¡¬ä»¶**ï¼š8Ã—NVIDIA H20 96GB GPUã€‚

### è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**Accuracy (%)**
- å¯¹æ¯”æ–¹æ³•åŒ…æ‹¬ï¼š
  - é›¶æ ·æœ¬æ–¹æ³•ï¼ˆå¦‚ GPT-3.5, GPT-4, Geminiï¼‰
  - å¾®è°ƒæ–¹æ³•ï¼ˆå¦‚ LLaVA, LaVINï¼‰
  - å¤šæ¨¡æ€ CoT æ–¹æ³•ï¼ˆå¦‚ Multimodal-CoT, MC-CoT, DPMM-CoT, T-SciQï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆSOTA è¡¨ç°ï¼‰

| æ•°æ®é›†       | æ–¹æ³•               | å‡†ç¡®ç‡ (%) |
|--------------|--------------------|------------|
| **ScienceQA** | MIND-base (Ours)   | **92.29**  |
|              | MIND-large (Ours)  | **æœªæŠ¥å‘Šå…·ä½“å€¼ï¼Œä¼˜äºæ‰€æœ‰åŸºçº¿** |
| **A-OKVQA**   | MIND-base (Ours)   | **70.6**   |
| **MÂ³CoT**     | MIND-base (Ours)   | **57.38**  |
|              | MIND-large (Ours)  | **61.56**  |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs. Multimodal-CoT**ï¼š
  - ScienceQA ä¸Šæå‡ **6.98%**ï¼ˆ85.31% â†’ 92.29%ï¼‰
  - A-OKVQA ä¸Šæå‡ **20.0%**ï¼ˆ50.6% â†’ 70.6%ï¼‰
  - MÂ³CoT ä¸Šæå‡ **12.53%**ï¼ˆ44.85% â†’ 57.38%ï¼‰

- **vs. å…¶ä»– SOTA æ–¹æ³•**ï¼š
  - åœ¨ ScienceQA ä¸Šè¶…è¶Š GPT-4 (83.99%) å’Œ Gemini (91.75%)ã€‚
  - åœ¨ A-OKVQA ä¸Šæ˜¾è‘—ä¼˜äº IPVRã€GPV-2 ç­‰æ–¹æ³•ã€‚
  - åœ¨ MÂ³CoT ä¸Šä¼˜äºé›¶æ ·æœ¬å¤§æ¨¡å‹ï¼ˆå¦‚ GPT-4V è¾¾ 56.95%ï¼ŒMIND-large è¾¾ 61.56%ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

| æ¨¡å‹å˜ä½“                     | ScienceQA å‡†ç¡®ç‡ (%) | æå‡ (%) |
|------------------------------|------------------------|----------|
| Baseline                     | 90.29                  | â€”        |
| + MCA only                   | 90.36                  | +0.07    |
| + P2CL only                  | 92.15                  | +1.86    |
| **Full MIND (P2CL + MCA)**   | **92.29**              | **+2.00**|

> âœ… ç»“è®ºï¼šP2CL æ˜¯æ€§èƒ½æå‡çš„ä¸»å› ï¼ŒMCA æä¾›é¢å¤–å¢ç›Šï¼ŒäºŒè€…ååŒäº§ç”Ÿâ€œ1+1 > 2â€çš„æ•ˆæœã€‚

å…¶ä»–æ¶ˆèåˆ†æè¿˜éªŒè¯äº†ï¼š
- æ›´é«˜è´¨é‡çš„ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚ Qwen3-235Bï¼‰ç”Ÿæˆçš„ç†ç”±èƒ½å¸¦æ¥æ›´é«˜æ€§èƒ½ã€‚
- ç†ç”±æ•°é‡å¢åŠ ï¼ˆè‡³ Ã—1000ï¼‰å¸¦æ¥æŒç»­ä½†è¶‹äºé¥±å’Œçš„æ€§èƒ½æå‡ã€‚
- æ›´å¼ºçš„è§†è§‰ç¼–ç å™¨ï¼ˆå¦‚ BLIP2-flan-t5-xxlï¼‰å’Œå›¾åƒæè¿°æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-VL-72Bï¼‰æœ‰åŠ©äºæå‡æ¨ç†ä¸€è‡´æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¤šç†ç”±è®­ç»ƒæ˜¯æå‡æ¨ç†é²æ£’æ€§çš„å…³é”®**ï¼šé€šè¿‡ RAD ç”Ÿæˆå¤šæ ·åŒ–æ­£/è´Ÿç†ç”±ï¼Œä½¿æ¨¡å‹å­¦ä¼šåŒºåˆ†æ­£ç¡®ä¸é”™è¯¯é€»è¾‘è·¯å¾„ã€‚
2. **â€œç†è§£â†’åæ€â†’çº æ­£â€èŒƒå¼æœ‰æ•ˆ**ï¼šP2CL ç­–ç•¥æˆåŠŸæ¨¡æ‹Ÿäººç±»è®¤çŸ¥å¾ªç¯ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„é€»è¾‘åˆ¤åˆ«ä¸è‡ªæˆ‘ä¿®æ­£èƒ½åŠ›ã€‚
3. **å¯¹æ¯”å¯¹é½ä¼˜åŒ–ï¼ˆMCAï¼‰æå‡è¯­ä¹‰è¾¹ç•Œæ¸…æ™°åº¦**ï¼šåœ¨åµŒå…¥ç©ºé—´ä¸­æ‹‰è¿‘æ­£ç¡®ç†ç”±ã€æ¨å¼€é”™è¯¯ç†ç”±ï¼Œå¼ºåŒ–äº†æ¨¡å‹çš„åˆ¤åˆ«æ•æ„Ÿæ€§ã€‚
4. **MIND å®ç°äº†è·¨é¢†åŸŸæ³›åŒ–ä¼˜åŠ¿**ï¼šåœ¨ç§‘å­¦ã€å¸¸è¯†ã€æ•°å­¦ç­‰ä¸åŒåœºæ™¯ä¸‹å‡è¾¾åˆ° SOTAï¼Œå±•ç°å‡ºå¼ºå¤§çš„é€šç”¨æ¨ç†èƒ½åŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–å¤–éƒ¨å¤§æ¨¡å‹ç”Ÿæˆç†ç”±**ï¼šRAD èŒƒå¼ä¾èµ–äºç°æœ‰å¼ºå¤§ LLMï¼ˆå¦‚ Qwenã€DeepSeekï¼‰ç”Ÿæˆé«˜è´¨é‡ç†ç”±ï¼Œå¯èƒ½å¼•å…¥åå·®ã€‚
- **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šå°½ç®¡é‡‡ç”¨æ‰¹é‡ç”Ÿæˆï¼Œå¤§è§„æ¨¡å¤šç†ç”±æ•°æ®æ„å»ºä»éœ€è¾ƒé«˜ç®—åŠ›ã€‚
- **è´Ÿç†ç”±æ„é€ ä¾èµ–æç¤ºå·¥ç¨‹**ï¼šè´Ÿç†ç”±çš„è´¨é‡å— Negative Prompt è®¾è®¡å½±å“è¾ƒå¤§ï¼Œè‡ªåŠ¨åŒ–ç¨‹åº¦æœ‰å¾…æé«˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„å¤šç†ç”±ç”Ÿæˆæœºåˆ¶ï¼Œå‡å°‘å¯¹å¤–éƒ¨æ¨¡å‹çš„ä¾èµ–ã€‚
- å°† MIND æ¡†æ¶åº”ç”¨äºæ›´å¤šæ¨¡æ€ï¼ˆå¦‚éŸ³é¢‘ã€è§†é¢‘é•¿åºåˆ—ï¼‰å’Œä»»åŠ¡ï¼ˆå¦‚å†³ç­–è§„åˆ’ã€å¯¹è¯ç³»ç»Ÿï¼‰ã€‚
- ç ”ç©¶å¦‚ä½•å°†å¤šç†ç”±åˆ¤åˆ«èƒ½åŠ›è¿ç§»åˆ°ä½èµ„æºæˆ–å°‘æ ·æœ¬åœºæ™¯ã€‚
- è¿›ä¸€æ­¥æ¢ç´¢äººç±»è®¤çŸ¥æœºåˆ¶ï¼ˆå¦‚å…ƒè®¤çŸ¥ã€æ³¨æ„åŠ›è°ƒæ§ï¼‰åœ¨ MLLMs ä¸­çš„å»ºæ¨¡ã€‚

---

> **æ€»ç»“**ï¼š  
> MIND æå‡ºäº†ä¸€ç§å…¨æ–°çš„å¤šç†ç”±é›†æˆåˆ¤åˆ«å¼æ¨ç†èŒƒå¼ï¼Œé€šè¿‡ **RAD + P2CL + MCA** ä¸‰é‡æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº† MLLMs çš„é€»è¾‘é²æ£’æ€§ã€è§£é‡Šæ€§ä¸è‡ªçº é”™èƒ½åŠ›ï¼Œåœ¨å¤šä¸ªåŸºå‡†ä¸Šå–å¾— SOTA æˆç»©ã€‚è¯¥å·¥ä½œä¸ºæ¨åŠ¨ MLLMs ä»â€œæ¨¡ä»¿â€èµ°å‘â€œçœŸæ­£è®¤çŸ¥æ™ºèƒ½â€æä¾›äº†é‡è¦æ€è·¯ã€‚

</details>

---

### 16. [Transformer-Enabled Diachronic Analysis of Vedic Sanskrit: Neural Methods for Quantifying Types of Language Change](https://arxiv.org/abs/2512.05364)

**Authors**: Ananth Hariharan, David Mortensen  
**Category**: cs.CL  
**Published**: 2025-12-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.05364v1  

#### Abstract
This study demonstrates how hybrid neural-symbolic methods can yield significant new insights into the evolution of a morphologically rich, low-resource language. We challenge the naive assumption that linguistic change is simplification by quantitatively analyzing over 2,000 years of Sanskrit, demo...

---

### 17. [Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems](https://arxiv.org/abs/2512.05580)

**Authors**: Aurprita Mahmood, Sabrin alam, Neloy kumer Sagor, Md. Abdul Hadi, Md. Sehab Al Islam, Minhajul Islam  
**Category**: cs.CL  
**Published**: 2025-12-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.05580v1  

#### Abstract
Mathematical Word Problems (MWPs) are among the most challenging tasks in natural language processing because they require both linguistic understanding and multi-step numerical reasoning. While Chain-of-Thought (CoT) prompting has shown promise, its linear structure often propagates errors, limitin...

---

### 18. [Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces](https://arxiv.org/abs/2512.05291)

**Authors**: Na Li, Hangguan Shan, Wei Ni, Wenjie Zhang, Xinyu Li  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.05291v1  

#### Abstract
Actor-critic (AC) methods are a cornerstone of reinforcement learning (RL) but offer limited interpretability. Current explainable RL methods seldom use state attributions to assist training. Rather, they treat all state features equally, thereby neglecting the heterogeneous impacts of individual st...

---

### 19. [Taxonomy-Adaptive Moderation Model with Robust Guardrails for Large Language Models](https://arxiv.org/abs/2512.05339)

**Authors**: Mahesh Kumar Nandwana, Youngwan Lim, Joseph Liu, Alex Yang, Varun Notibala, Nishchaie Khanna  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.05339v1  

#### Abstract
Large Language Models (LLMs) are typically aligned for safety during the post-training phase; however, they may still generate inappropriate outputs that could potentially pose risks to users. This challenge underscores the need for robust safeguards that operate across both model inputs and outputs...

---

### 20. [Bounded Graph Clustering with Graph Neural Networks](https://arxiv.org/abs/2512.05623)

**Authors**: Kibidi Neocosmos, Diego Baptista, Nicole Ludwig  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.05623v1  

#### Abstract
In community detection, many methods require the user to specify the number of clusters in advance since an exhaustive search over all possible values is computationally infeasible. While some classical algorithms can infer this number directly from the data, this is typically not the case for graph...

---

### 21. [Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations](https://arxiv.org/abs/2512.05156)

**Authors**: Igor Halperin  
**Category**: cs.AI  
**Published**: 2025-12-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.05156v1  

#### Abstract
Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden lay...

---

### 22. [Evolutionary System 2 Reasoning: An Empirical Proof](https://arxiv.org/abs/2512.05760)

**Authors**: Zeyuan Ma, Wenqi Huang, Guo-Huan Song, Hongshu Guo, Sijie Ma, Zhiguang Cao, Yue-Jiao Gong  
**Category**: cs.AI  
**Published**: 2025-12-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.05760v1  

#### Abstract
Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following cor...

---

### 23. [Using Large Language Models to Create Personalized Networks From Therapy Sessions](https://arxiv.org/abs/2512.05836)

**Authors**: Clarissa W. Ong, Hiba Arnaout, Kate Sheehan, Estella Fox, Eugen Owtscharow, Iryna Gurevych  
**Category**: cs.AI  
**Published**: 2025-12-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.05836v1  

#### Abstract
Recent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalabil...

---

### 24. [Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection Against LLM-Generated Threats](https://arxiv.org/abs/2512.05331)

**Authors**: Sadat Shahriar, Navid Ayoobi, Arjun Mukherjee, Mostafa Musharrat, Sai Vishnu Vamsi  
**Category**: cs.CL  
**Published**: 2025-12-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.05331v1  

#### Abstract
The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive articles requires a fine-grained analysis of their lin...

---

### 25. [GRASP: Graph Reasoning Agents for Systems Pharmacology with Human-in-the-Loop](https://arxiv.org/abs/2512.05502)

**Authors**: Omid Bazgir, Vineeth Manthapuri, Ilia Rattsev, Mohammad Jafarnejad  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.05502v1  

#### Abstract
Quantitative Systems Pharmacology (QSP) modeling is essential for drug development but it requires significant time investment that limits the throughput of domain experts. We present \textbf{GRASP} -- a multi-agent, graph-reasoning framework with a human-in-the-loop conversational interface -- that...

---

### 26. [BERTO: an Adaptive BERT-based Network Time Series Predictor with Operator Preferences in Natural Language](https://arxiv.org/abs/2512.05721)

**Authors**: Nitin Priyadarshini Shankar, Vaibhav Singh, Sheetal Kalyani, Christian Maciocco  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.05721v1  

#### Abstract
We introduce BERTO, a BERT-based framework for traffic prediction and energy optimization in cellular networks. Built on transformer architectures, BERTO delivers high prediction accuracy, while its Balancing Loss Function and prompt-based customization allow operators to adjust the trade-off betwee...

---

### 27. [Towards agent-based-model informed neural networks](https://arxiv.org/abs/2512.05764)

**Authors**: Nino Antulov-Fantulin  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.05764v1  

#### Abstract
In this article, we present a framework for designing neural networks that remain consistent with the underlying principles of agent-based models. We begin by highlighting the limitations of standard neural differential equations in modeling complex systems, where physical invariants (like energy) a...

---

### 28. [KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity](https://arxiv.org/abs/2512.05916)

**Authors**: Damien Lesens, Beheshteh T. Rakhshan, Guillaume Rabusseau  
**Category**: cs.LG  
**Published**: 2025-12-08  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.05916v1  

#### Abstract
The Key-Value (KV) cache is central to the efficiency of transformer-based large language models (LLMs), storing previously computed vectors to accelerate inference. Yet, as sequence length and batch size grow, the cache becomes a major memory bottleneck. Prior compression methods typically apply lo...

---

### 29. [A Greek Government Decisions Dataset for Public-Sector Analysis and Insight](https://arxiv.org/abs/2512.05647)

**Authors**: Giorgos Antoniou, Giorgos Filandrianos, Aggelos Vlachos, Giorgos Stamou, Lampros Kollimenos, Konstantinos Skianis, Michalis Vazirgiannis  
**Category**: cs.CL  
**Published**: 2025-12-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.05647v1  

#### Abstract
We introduce an open, machine-readable corpus of Greek government decisions sourced from the national transparency platform Diavgeia. The resource comprises 1 million decisions, featuring and high-quality raw text extracted from PDFs. It is released with raw extracted text in Markdown format, alongs...

---

### 30. [MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation](https://arxiv.org/abs/2512.05671)

**Authors**: Zhitao He, Haolin Yang, Zeyu Qin, Yi R Fung  
**Category**: cs.CL  
**Published**: 2025-12-08  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.05671v1  

#### Abstract
The significant gap between rising demands for clinical training and the scarcity of expert instruction poses a major challenge to medical education. With powerful capabilities in personalized guidance, Large Language Models (LLMs) offer a promising solution to bridge this gap. However, current rese...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
