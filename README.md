# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-16 05:56:25 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [HetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments](https://arxiv.org/abs/2512.12476)

**Authors**: Yongjun He, Shuai Zhang, Jiading Gai, Xiyuan Zhang, Boran Han, Bernie Wang, Huzefa Rangwala, George Karypis  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 13.5  
**Type**: new  
**ArXiv ID**: 2512.12476v1  

#### Abstract
As large language models (LLMs) continue to scale and new GPUs are released even more frequently, there is an increasing demand for LLM post-training in heterogeneous environments to fully leverage underutilized mid-range or previous-generation GPUs across regions and alleviate the shortage of homog...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šHetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è§„æ¨¡ä¸æ–­æ‰©å¤§ä»¥åŠæ–°å‹GPUé¢‘ç¹å‘å¸ƒï¼Œé«˜æ€§èƒ½åŒæ„GPUèµ„æºæ—¥ç›Šç´§ç¼ºï¼Œè€Œä¸­ç«¯æˆ–ä¸Šä¸€ä»£GPUåœ¨è·¨åŒºåŸŸæ•°æ®ä¸­å¿ƒä¸­å¤§é‡é—²ç½®ã€‚å½“å‰ä¸»æµçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒç³»ç»Ÿï¼ˆå¦‚ verlã€OpenRLHFï¼‰å‡é’ˆå¯¹**åŒæ„GPUç¯å¢ƒ**è®¾è®¡ï¼Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨è¿™äº›å¼‚æ„è®¡ç®—èµ„æºã€‚

ç„¶è€Œï¼ŒRLè®­ç»ƒæµç¨‹æ¶‰åŠå¤šä¸ªæ¨¡å‹ï¼ˆactorã€criticã€rewardã€referenceï¼‰å’Œå¤æ‚ä»»åŠ¡ä¾èµ–å…³ç³»ï¼Œåœ¨**å¼‚æ„GPUå’Œç½‘ç»œç¯å¢ƒ**ä¸‹è¿›è¡Œé«˜æ•ˆè°ƒåº¦æå…·æŒ‘æˆ˜ã€‚ç°æœ‰å¼‚æ„è°ƒåº¦ç®—æ³•å¤šé¢å‘å•æ¨¡å‹/å•ä»»åŠ¡åœºæ™¯ï¼Œç›´æ¥åº”ç”¨äºå¤šæ¨¡å‹ã€å¤šä»»åŠ¡çš„RLæµç¨‹æ—¢ä¸å®ç”¨ä¹Ÿä¸å¯æ‰©å±•ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **HetRL**ï¼Œä¸€ä¸ªä¸“ä¸ºå¼‚æ„ç¯å¢ƒè®¾è®¡çš„åˆ†å¸ƒå¼ç³»ç»Ÿï¼Œç”¨äºé«˜æ•ˆæ‰§è¡ŒLLMçš„RLè®­ç»ƒã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å°†å¼‚æ„ç¯å¢ƒä¸‹çš„RLè°ƒåº¦å»ºæ¨¡ä¸ºè”åˆä¼˜åŒ–é—®é¢˜**ï¼šåŒæ—¶ä¼˜åŒ–ä»»åŠ¡åˆ†ç»„ï¼ˆcolocationï¼‰ã€å¹¶è¡Œç­–ç•¥ï¼ˆTP/PP/DPï¼‰å’Œç»†ç²’åº¦è®¾å¤‡åˆ†é…ã€‚
- **æå‡ºå¤šçº§æœç´¢æ¡†æ¶ï¼ˆmulti-level search frameworkï¼‰**ï¼š
  1. **Task Grouping**ï¼šå°†ç›¸å…³ä»»åŠ¡åˆ†ç»„å…±ç½®ï¼›
  2. **Coarse-grained GPU Assignment**ï¼šåˆ’åˆ†GPUç»„ï¼›
  3. **Medium-grained Assignment**ï¼šåˆæ­¥åˆ†é…ä»»åŠ¡ç»„åˆ°å…·ä½“GPUï¼›
  4. **Intra-model Parallelization**ï¼šç¡®å®šå„ä»»åŠ¡å†…éƒ¨å¹¶è¡Œç­–ç•¥ï¼›
  5. **Fine-grained Assignment**ï¼šæœ€ç»ˆç»†ç²’åº¦ä»»åŠ¡å—ï¼ˆtaskletï¼‰åˆ°GPUçš„æ˜ å°„ã€‚
- **åŸºäºSuccessive Halvingçš„é¢„ç®—åˆ†é…æœºåˆ¶**ï¼šé€šè¿‡åµŒå¥—çš„Successive Halving Algorithmï¼ˆSHAï¼‰å¿«é€Ÿæ·˜æ±°ä½æ•ˆå€™é€‰æ–¹æ¡ˆï¼Œé›†ä¸­æœç´¢èµ„æºäºé«˜æ½œåŠ›è·¯å¾„ã€‚
- **ç»“åˆé—ä¼ ç®—æ³•ï¼ˆGAï¼‰ä¸ä¸¤çº§äº¤æ¢ç­–ç•¥**ï¼šåœ¨ä¸­/ç»†ç²’åº¦é˜¶æ®µä½¿ç”¨GAï¼Œå¹¶æ”¯æŒè·¨ä»»åŠ¡ç»„å’Œè·¨taskletç»„çš„GPUäº¤æ¢ï¼Œæå‡å…¨å±€æ¢ç´¢èƒ½åŠ›ã€‚
- **é›†æˆè½»é‡çº§è´Ÿè½½å‡è¡¡æœºåˆ¶**ï¼šåŠ¨æ€è°ƒæ•´DPç»„å†…batch sizeã€é•¿åºåˆ—åˆ†é…è‡³å¼ºGPUã€ä¼˜åŒ–pipelineå±‚åˆ†å¸ƒã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **é¦–æ¬¡ä¸“ä¸ºå¼‚æ„ç¯å¢ƒä¸‹å¤šæ¨¡å‹RLæµç¨‹è®¾è®¡è°ƒåº¦ç³»ç»Ÿ**ï¼Œä¸åŒäºä»…æ”¯æŒåŒæ„ç¯å¢ƒçš„ verl æˆ–ä»…ç²—ç²’åº¦æ‹†åˆ†çš„ StreamRLã€‚
- **æœç´¢æ•ˆç‡é«˜**ï¼šé€šè¿‡å¤šçº§åˆ†è§£å’ŒSHAé¿å…å…¨ç©ºé—´ç©·ä¸¾ï¼Œæ˜¾è‘—é™ä½æœç´¢å¼€é”€ã€‚
- **æ€§èƒ½æå‡æ˜¾è‘—**ï¼šåœ¨å¤šç§å¼‚æ„é…ç½®ä¸‹å®ç°é«˜è¾¾ **9.17Ã— ååæå‡**ï¼Œå¹³å‡è¾¾ **3.17Ã—**ã€‚
- **çµæ´»é€‚é…ä¸åŒRLç®—æ³•**ï¼šæ”¯æŒPPOã€GRPOç­‰åŒæ­¥/å¼‚æ­¥RLHFç®—æ³•ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **GSM8k**ï¼šOpenAIå‘å¸ƒçš„æ•°å­¦æ¨ç†åŸºå‡†æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - æ€»è®¡64å—GPUï¼š24Ã—A100ï¼ˆ40GBï¼‰ã€24Ã—L40Sã€16Ã—L4ã€‚
  - æ¨¡æ‹Ÿå››ç§ç½‘ç»œåœºæ™¯ä»¥ä½“ç°å¼‚æ„æ€§ï¼š
    1. **Single-Region**ï¼šæ ‡å‡†å•åŒºåŸŸé›†ç¾¤ï¼ˆæ— å¸¦å®½/å»¶è¿Ÿé™åˆ¶ï¼‰ã€‚
    2. **Multi-Region-Hybrid**ï¼šOhioä¸Virginiaé—´10mså»¶è¿Ÿã€5Gbpså¸¦å®½ï¼Œéƒ¨åˆ†è¾¹ç¼˜èŠ‚ç‚¹ä»…1Gbpsã€‚
    3. **Multi-Country**ï¼šæ¬§æ´²8ä¸ªåœ°åŒºï¼Œå»¶è¿Ÿ5â€“30msï¼Œå¸¦å®½1.9â€“5.0Gbpsã€‚
    4. **Multi-Continent**ï¼šæ¬§ç¾è·¨æ´²éƒ¨ç½²ï¼Œå»¶è¿Ÿ5â€“60msï¼Œå¸¦å®½0.9â€“5.0Gbpsã€‚
- **æ¨¡å‹ä¸RLç®—æ³•**ï¼š
  - ä½¿ç”¨ **Qwenç³»åˆ—**ï¼š4Bã€8Bã€14Bä¸‰ç§è§„æ¨¡ã€‚
  - æ”¯æŒ **PPO** å’Œ **GRPO**ï¼Œåˆ†åˆ«æµ‹è¯•åŒæ­¥ï¼ˆSyncï¼‰ä¸å¼‚æ­¥ï¼ˆAsyncï¼‰æ¨¡å¼ã€‚
- **è¶…å‚æ•°**ï¼š
  - åºåˆ—é•¿åº¦ï¼š1024ï¼ˆè¾“å…¥/è¾“å‡ºï¼‰
  - å…¨å±€batch sizeï¼š1024
  - æ¯promptç”Ÿæˆ8ä¸ªresponse
  - è®­ç»ƒä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆAdamï¼‰ï¼Œæ¨ç†ä½¿ç”¨BF16

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **verl (Sheng et al., 2025)**ï¼šå½“å‰æœ€å…ˆè¿›çš„åŒæ„ç¯å¢ƒRLè®­ç»ƒç³»ç»Ÿï¼Œä½œä¸ºä¸»è¦baselineã€‚
- **StreamRL (Zhong et al., 2025a)**ï¼šå”¯ä¸€æ”¯æŒå¼‚æ„ç¯å¢ƒçš„RLç³»ç»Ÿï¼Œå°†actor generationä¸å…¶ä»–ä»»åŠ¡åˆ†ç¦»éƒ¨ç½²äºä¸åŒæ•°æ®ä¸­å¿ƒã€‚
  - å› æœªå¼€æºï¼Œä½œè€…åœ¨å…¶åŸºç¡€ä¸Šå®ç°äº†å¼‚æ­¥ç‰ˆæœ¬å¹¶ä¸HetRLå¯¹æ¯”ã€‚

æ‰€æœ‰å˜ä½“ç»Ÿä¸€é‡‡ç”¨ **vLLM** ä½œä¸ºæ¨ç†å¼•æ“ã€**Megatron-LM** ä½œä¸ºè®­ç»ƒå¼•æ“ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- åœ¨æ€»è®¡ **20,000 GPUå°æ—¶** çš„å¤§è§„æ¨¡å®éªŒä¸­éªŒè¯æ€§èƒ½ã€‚
- HetRLåœ¨å„ç±»åœºæ™¯ä¸‹å‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼š
  - **æœ€é«˜ååæå‡è¾¾ 9.17Ã—**ï¼ˆvs. verlï¼‰
  - **å¹³å‡ååæå‡ 3.17Ã—**

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
| åœºæ™¯ | æ–¹æ³• | ååæå‡ï¼ˆvs. verlï¼‰ |
|------|------|------------------|
| **Single-Region** | HetRL-Sync | 1.51â€“2.05Ã— |
| | HetRL-Async | 1.10â€“1.31Ã— |
| **Multi-Region-Hybrid** | HetRL-Sync | 3.01â€“4.99Ã— |
| | HetRL-Async | 4.07â€“9.17Ã— |
| **Multi-Country** | HetRL-Sync | 1.40â€“3.07Ã— |
| | HetRL-Async | 1.71â€“4.00Ã— |
| **Multi-Continent** | HetRL-Sync | 2.24â€“5.46Ã— |
| | HetRL-Async | 4.38â€“10.76Ã— |

> æ³¨ï¼šHetRL-Asyncå§‹ç»ˆä¼˜äºHetRL-Syncï¼›è€Œverl-Asyncåœ¨æŸäº›åœºæ™¯ä¸‹åè€Œæ…¢äºverl-Syncï¼Œè¯´æ˜å…¶è°ƒåº¦æœªé€‚é…å¼‚æ„ç¯å¢ƒã€‚

### **æ¶ˆèå®éªŒç»“æœ**
- **è°ƒåº¦ç®—æ³•æœ‰æ•ˆæ€§ï¼ˆå›¾4ï¼‰**ï¼š
  - å¯¹æ¯” verl è°ƒåº¦å™¨ä¸ HetRLï¼ˆsimpleï¼‰â€”â€”å³ç¦ç”¨SHAã€ä»…æ¨¡å‹å†…äº¤æ¢çš„ç®€åŒ–ç‰ˆã€‚
  - ç»“æœæ˜¾ç¤ºï¼šHetRLåœ¨ç›¸åŒæœç´¢é¢„ç®—ä¸‹è¿œè¶…ä¸¤è€…ï¼Œè¯æ˜**å¤šçº§æœç´¢+SHA+è·¨ä»»åŠ¡GAäº¤æ¢**çš„æœ‰æ•ˆæ€§ã€‚
- **è´Ÿè½½å‡è¡¡å½±å“ï¼ˆå›¾5ï¼‰**ï¼š
  - å¼•å…¥è´Ÿè½½å‡è¡¡åï¼Œååè¿›ä¸€æ­¥æå‡ï¼š
    - **Single-Region**ï¼šæœ€é«˜æå‡ **12%**
    - **Cross-Region**ï¼šæœ€é«˜æå‡ **18%**
  - å°½ç®¡ç•¥ä½äºMetisï¼ˆ19â€“22%ï¼‰ï¼Œä½†å·²éªŒè¯å…¶æœ‰æ•ˆæ€§ï¼Œæœªæ¥å¯é€šè¿‡å¼•å…¥æ›´å…ˆè¿›ç­–ç•¥ç¼©å°å·®è·ã€‚
- **GPUç»„åˆå½±å“ï¼ˆå›¾6ï¼‰**ï¼š
  - å½“ä½¿ç”¨å…¨éƒ¨å¼‚æ„GPUæ—¶ï¼ŒHetRLæ¯”ä»…ç”¨24Ã—A100åŒæ„é›†ç¾¤å¿« **1.57â€“2.0Ã—**ã€‚
  - è¡¨æ˜HetRLèƒ½æœ‰æ•ˆæ•´åˆè·¨ä»£ã€è·¨å‹å·GPUèµ„æºï¼Œç¼“è§£é«˜ç«¯GPUçŸ­ç¼ºé—®é¢˜ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å¼‚æ„ç¯å¢ƒæ˜¯åŠ é€ŸRLè®­ç»ƒçš„æ–°æœºé‡**ï¼šå…¨çƒèŒƒå›´å†…å­˜åœ¨å¤§é‡æœªå……åˆ†åˆ©ç”¨çš„ä¸­ä½ç«¯GPUï¼ŒHetRLæˆåŠŸå°†å…¶æ•´åˆç”¨äºé«˜æ€§èƒ½RLè®­ç»ƒã€‚
2. **ä¼ ç»Ÿè°ƒåº¦æ–¹æ³•ä¸é€‚ç”¨äºå¤šæ¨¡å‹RLæµç¨‹**ï¼šå•æ¨¡å‹è°ƒåº¦ç®—æ³•æ— æ³•åº”å¯¹RLä¸­å¤æ‚çš„è·¨ä»»åŠ¡ä¾èµ–ä¸èµ„æºç«äº‰ã€‚
3. **HetRLå®ç°äº†å‰æ‰€æœªæœ‰çš„ååæå‡**ï¼šé€šè¿‡è”åˆä¼˜åŒ–ä»»åŠ¡åˆ†ç»„ã€å¹¶è¡Œç­–ç•¥ä¸è®¾å¤‡åˆ†é…ï¼Œåœ¨çœŸå®å¼‚æ„ç¯å¢ƒä¸­å®ç°å¹³å‡ **3.17Ã—**ã€å³°å€¼ **9.17Ã—** çš„æ€§èƒ½è¶…è¶Šã€‚
4. **å¼‚æ­¥è®­ç»ƒåœ¨HetRLä¸­è¡¨ç°æ›´ä¼˜**ï¼šå¾—ç›Šäºåˆç†çš„èµ„æºè°ƒåº¦ï¼ŒHetRL-Asyncå§‹ç»ˆä¼˜äºSyncæ¨¡å¼ï¼Œè€Œä¼ ç»Ÿç³»ç»Ÿåˆ™å¯èƒ½å› è°ƒåº¦ä¸å½“å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **GPUæ”¯æŒæœ‰é™**ï¼šç›®å‰ä»…æµ‹è¯•NVIDIA A100ã€L40Sã€L4ä¸‰ç±»GPUï¼Œå°šæœªæ”¯æŒå…¶ä»–å‚å•†æˆ–æ¶æ„ï¼ˆå¦‚AMDã€Intelï¼‰ã€‚
- **é€šä¿¡æ ˆä¾èµ–ç‰¹å®šæŠ€æœ¯**ï¼šä½¿ç”¨AWS OFI NCCLå’ŒEFAï¼ŒæœªéªŒè¯å…¶ä»–ç½‘ç»œåè®®æ ˆï¼ˆå¦‚RoCEã€InfiniBandï¼‰ä¸‹çš„è¡¨ç°ã€‚
- **æœªè€ƒè™‘ç²¾åº¦å…¼å®¹æ€§é—®é¢˜**ï¼šè·¨å¼‚æ„GPUäº¤æ¢æ¢¯åº¦å¯èƒ½å­˜åœ¨æ•°å€¼ç²¾åº¦å·®å¼‚ï¼Œå¯¹æ”¶æ•›æ€§çš„å½±å“æœªæ·±å…¥ç ”ç©¶ã€‚
- **æˆæœ¬æ•ˆç›Šæœªé‡åŒ–**ï¼šè™½å¼ºè°ƒèµ„æºåˆ©ç”¨ç‡ï¼Œä½†æœªæä¾›åŸºäºå¸‚åœºä»·æ ¼çš„æˆæœ¬åˆ†æã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•æ”¯æŒæ›´å¤šGPUç±»å‹å’Œé€šä¿¡åè®®ã€‚
- é›†æˆæ›´å…ˆè¿›çš„è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼ˆå¦‚Metisä¸­çš„DFSæœç´¢ï¼‰ã€‚
- æ¢ç´¢å¼‚æ„ç¯å¢ƒä¸‹RLè®­ç»ƒçš„æ”¶æ•›ç¨³å®šæ€§ä¸ç²¾åº¦ä¸€è‡´æ€§ã€‚
- æ„å»ºç«¯åˆ°ç«¯çš„æˆæœ¬-æ€§èƒ½æƒè¡¡æ¨¡å‹ï¼Œå®ç°ç»æµé«˜æ•ˆçš„RLè®­ç»ƒè°ƒåº¦ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **HetRL æ˜¯é¦–ä¸ªä¸“ä¸ºå¼‚æ„ç¯å¢ƒè®¾è®¡çš„é«˜æ•ˆLLMå¼ºåŒ–å­¦ä¹ è®­ç»ƒç³»ç»Ÿï¼Œé€šè¿‡å¤šçº§è”åˆä¼˜åŒ–è°ƒåº¦ï¼Œåœ¨çœŸå®è·¨åŒºåŸŸå¼‚æ„GPUé›†ç¾¤ä¸Šå®ç°äº†æœ€é«˜9.17å€çš„ååæå‡ï¼Œä¸ºè§£å†³é«˜ç«¯GPUèµ„æºçŸ­ç¼ºæä¾›äº†å¯è¡Œè·¯å¾„ã€‚**

</details>

---

### 2. [Janus: Disaggregating Attention and Experts for Scalable MoE Inference](https://arxiv.org/abs/2512.13525)

**Authors**: Zhexiang Zhang, Ye Wang, Xiangyu Wang, Yumiao Zhao, Jingzhe Jiang, Qizhen Weng, Shaohuai Shi, Yin Chen, Minchen Yu  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2512.13525v1  

#### Abstract
Large Mixture-of-Experts (MoE) model inference is challenging due to high resource demands and dynamic workloads. Existing solutions often deploy the entire model as a single monolithic unit, which applies a unified resource configuration to both attention and expert modules despite their different ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šJANUS: Disaggregating Attention and Experts for Scalable MoE Inference**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§å‹ **Mixture-of-Experts (MoE)** æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **åŠ¨æ€è´Ÿè½½**ï¼šåœ¨çº¿è¯·æ±‚çš„åˆ°è¾¾ç‡ã€è¾“å…¥è¾“å‡ºé•¿åº¦é«˜åº¦å¯å˜ï¼Œéš¾ä»¥æ»¡è¶³ä¸¥æ ¼çš„ **token-level SLO**ï¼ˆå¦‚ TPOTï¼‰ã€‚
- **å†…å­˜å‹åŠ›å¤§**ï¼šMoE æ¨¡å‹ä¸­ä¸“å®¶å‚æ•°å æ€»å†…å­˜çš„ **90%ä»¥ä¸Š**ï¼ˆè§ Table 1ï¼‰ï¼Œéœ€å¤§é‡ GPU æ‰èƒ½å®Œæ•´åŠ è½½ã€‚
- **å¼‚æ„èµ„æºéœ€æ±‚**ï¼šAttention å±‚ä¸ MoE å±‚è®¡ç®—ç‰¹æ€§å·®å¼‚æ˜¾è‘—ï¼Œä½†ç°æœ‰ç³»ç»Ÿé€šå¸¸å°†æ•´ä¸ªæ¨¡å‹ä½œä¸ºå•ä¸€å•å…ƒéƒ¨ç½²ï¼Œé‡‡ç”¨ç»Ÿä¸€çš„å¹¶è¡Œç­–ç•¥ï¼ˆå¦‚ DP å’Œ EP è€¦åˆï¼‰ï¼Œå¯¼è‡´èµ„æºæµªè´¹å’Œæ‰©å±•æ€§å·®ã€‚

è¿™äº›å› ç´ å…±åŒæ„æˆäº†ä¸€ä¸ªâ€œä¸‰éš¾å›°å¢ƒâ€ï¼š**é«˜ååã€ä½å»¶è¿Ÿã€é«˜èµ„æºåˆ©ç”¨ç‡éš¾ä»¥å…¼å¾—**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **JANUS**ï¼Œä¸€ç§é¢å‘å¤§è§„æ¨¡ MoE æ¨ç†çš„**è§£è€¦å¼ç³»ç»Ÿæ¶æ„**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **å°† Attention å’Œ MoE æ¨¡å—éƒ¨ç½²åœ¨ç‹¬ç«‹çš„ GPU å­é›†ç¾¤ä¸Šï¼Œå®ç°æ¨¡å—çº§çš„ç‹¬ç«‹èµ„æºç®¡ç†å’Œå¼¹æ€§ä¼¸ç¼©ã€‚**

#### **ä¸‰å¤§å…³é”®æŠ€æœ¯è®¾è®¡**ï¼š
1. **è‡ªé€‚åº”ä¸¤é˜¶æ®µé€šä¿¡æœºåˆ¶ï¼ˆAdaptive Two-Phase Communicationï¼‰**
   - åˆ©ç”¨èŠ‚ç‚¹å†…é«˜å¸¦å®½ NVLink è¿›è¡Œä¸­é—´ç»“æœèšåˆï¼Œå‡å°‘è·¨èŠ‚ç‚¹å°æ¶ˆæ¯æ•°é‡ã€‚
   - æ”¯æŒä¸¤ç§æ¨¡å¼ï¼šç›´æ¥ä¼ è¾“ï¼ˆé€‚ç”¨äºå°‘é‡ç›®æ ‡ï¼‰å’Œä¸­ç»§å¹¿æ’­ï¼ˆé€‚ç”¨äºå¤šç›®æ ‡ï¼‰ï¼ŒåŠ¨æ€é€‰æ‹©ä»¥æœ€å°åŒ–é€šä¿¡å¼€é”€ã€‚

2. **åŸºäºæ¿€æ´»è´Ÿè½½å‡è¡¡çš„è°ƒåº¦å™¨ï¼ˆActivation Load-Balanced Schedulingï¼‰**
   - è®¾è®¡è½»é‡çº§ GPU å†…æ ¸å®ç°çš„è°ƒåº¦ç®—æ³•ï¼ˆAEBSï¼‰ï¼Œåœ¨å¾®ç§’çº§å®Œæˆä¸“å®¶æ¿€æ´»è¯·æ±‚åˆ†é…ã€‚
   - ç›®æ ‡æ˜¯æœ€å°åŒ–æ¯ä¸ª MoE å®ä¾‹ä¸Šçš„**è¢«æ¿€æ´»ä¸“å®¶æ•°**ï¼Œè€Œéç®€å•å¹³è¡¡ token æ•°ã€‚
   - é€šè¿‡**å»ä¸­å¿ƒåŒ–ã€æ— åŒæ­¥**æ–¹å¼è¿è¡Œï¼šæ‰€æœ‰å®ä¾‹ä½¿ç”¨ç›¸åŒè¾“å…¥ç‹¬ç«‹æ‰§è¡Œç¡®å®šæ€§ç®—æ³•ï¼Œé¿å…è·¨ GPU åè°ƒå¼€é”€ã€‚

3. **ç»†ç²’åº¦èµ„æºä¸ä¸“å®¶ç®¡ç†ï¼ˆFine-grained Resource & Expert Managementï¼‰**
   - åŠ¨æ€è°ƒæ•´ Attention å’Œ MoE å­é›†ç¾¤è§„æ¨¡ï¼Œç‹¬ç«‹æ§åˆ¶å®ä¾‹æ•°é‡ã€‚
   - å¼•å…¥**æ¿€æ´»æ„ŸçŸ¥çš„ä¸“å®¶å¤åˆ¶ä¸æ”¾ç½®ç­–ç•¥**ï¼š
     - çƒ­é—¨ä¸“å®¶åˆ†é…æ›´å¤šå‰¯æœ¬ï¼›
     - é¢‘ç¹å…±æ¿€æ´»çš„ä¸“å®¶å°½é‡åˆ†æ•£åˆ°ä¸åŒ GPUï¼Œé™ä½å¹¶å‘æ´»è·ƒä¸“å®¶æ•°ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ SGLangï¼‰ | JANUS |
|------|------------------------|-------|
| æ¶æ„ | å•ä½“éƒ¨ç½²ï¼ˆMonolithicï¼‰ | è§£è€¦éƒ¨ç½²ï¼ˆDisaggregatedï¼‰ |
| å¹¶è¡Œé…ç½® | DP ä¸ EP å¿…é¡»åŒ¹é… | å¯ç‹¬ç«‹é…ç½® |
| æ‰©å±•ç²’åº¦ | æ•´ä¸ªæ¨¡å‹å¤åˆ¶æˆ–é‡å¯é‡é… | æŒ‰å­é›†ç¾¤å¢é‡ä¼¸ç¼© |
| ä¸“å®¶è°ƒåº¦ | éšæœºæˆ–é™æ€ç»‘å®š | åŠ¨æ€è´Ÿè½½å‡è¡¡ |
| èµ„æºæ•ˆç‡ | ä¸ºæ»¡è¶³ MoE éœ€æ±‚è€Œè¿‡åº¦é…ç½® Attention | æŒ‰éœ€åˆ†é…ï¼Œé¿å…æµªè´¹ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šJANUS å®ç°äº†æ›´é«˜çš„èµ„æºåˆ©ç”¨ç‡ã€æ›´ä½çš„å»¶è¿Ÿæ³¢åŠ¨ã€æ›´å¼ºçš„å¼¹æ€§æ‰©å±•èƒ½åŠ›ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸å·¥ä½œè´Ÿè½½**
- **çœŸå®è¯·æ±‚å›æ”¾**ï¼šåŸºäº `ShareGPT` æ•°æ®é›†ï¼Œå¹³å‡è¾“å…¥ 16 tokensï¼Œè¾“å‡º 256 tokensã€‚
- **åˆæˆåŠ¨æ€è´Ÿè½½**ï¼šä½¿ç”¨ `BurstGPT` å·¥å…·ç”Ÿæˆç¬¦åˆç”Ÿäº§ç¯å¢ƒç‰¹å¾çš„æµé‡æ¨¡å¼ï¼ˆæ¨¡æ‹Ÿæ˜¼å¤œå˜åŒ–ã€çªå‘è¯·æ±‚ç­‰ï¼‰ã€‚

### **æ¨¡å‹é…ç½®**
- ä¸»è¦æµ‹è¯•æ¨¡å‹ï¼š`DeepSeek-V2`ï¼ˆä»£è¡¨æ€§ MoE æ¨¡å‹ï¼‰
- è¡ç”Ÿå˜ä½“ï¼š`Scaled-DS-1`ï¼ˆ160 ä¸“å®¶ï¼‰ã€`Scaled-DS-2`ï¼ˆ200 ä¸“å®¶ï¼‰ï¼Œç”¨äºéªŒè¯æ³›åŒ–æ€§ã€‚

### **å®éªŒå¹³å°**
- æœ€å¤š 4 ä¸ªèŠ‚ç‚¹ï¼Œæ¯èŠ‚ç‚¹ 8 Ã— NVIDIA H100ï¼ˆ80GBï¼‰ï¼ŒNVLink + 400Gbps InfiniBandã€‚
- æ‰€æœ‰å‚æ•°ä¸ KV Cache ä½¿ç”¨ BF16 æ ¼å¼ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
- **Per-GPU Throughput**ï¼šå•ä½ GPU çš„ token/sï¼Œè¡¡é‡èµ„æºæ•ˆç‡ã€‚
- **TPOTï¼ˆTime Per Output Tokenï¼‰**ï¼šç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿï¼ŒSLO è®¾å®šä¸º 200msã€‚
- **é€šä¿¡å¼€é”€ã€è°ƒåº¦å»¶è¿Ÿã€è´Ÿè½½å‡è¡¡åº¦**ç­‰åº•å±‚æŒ‡æ ‡ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿ | æè¿° |
|------|------|
| **SGLang** | å½“å‰æœ€å…ˆè¿›çš„å•ä½“å¼ MoE æ¨ç†ç³»ç»Ÿï¼ŒDP ä¸ EP è€¦åˆï¼Œç²—ç²’åº¦æ‰©å±•ï¼ˆ16/32/64 GPUï¼‰ |
| **DisAgg** | åœ¨ JANUS ä»£ç åŸºç¡€ä¸Šæ„å»ºçš„è§£è€¦åŸºçº¿ï¼Œä½†ä½¿ç”¨éšæœºè°ƒåº¦ + èŠ‚ç‚¹çº§ï¼ˆ8 GPUï¼‰ç²—ç²’åº¦æ‰©ç¼©å®¹ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **æœ€é«˜æå‡è¾¾ 3.9Ã— çš„ per-GPU ååé‡**ï¼ˆvs. SGLangï¼‰ï¼Œåœ¨æ»¡è¶³ 200ms TPOT SLO çš„å‰æä¸‹ã€‚
- ç›¸æ¯” DisAggï¼Œååæå‡ **2.8Ã—**ã€‚
- åœ¨çœŸå®åŠ¨æ€è´Ÿè½½ä¸‹ï¼Œ**GPU æ¶ˆè€—å‡å°‘ 25%**ï¼ŒåŒæ—¶ä¿æŒæœåŠ¡è´¨é‡ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
| åœºæ™¯ | ç»“æœ |
|------|------|
| å°æ‰¹é‡ï¼ˆ4â€“64 tokensï¼‰ | JANUS ä½¿ç”¨æå° Attention é…ç½®ï¼ˆå¦‚ 1A6Eï¼‰ï¼Œé›†ä¸­èµ„æºäº MoEï¼Œæ˜¾è‘—ä¼˜äº SGLang çš„è¿‡åº¦é…ç½® |
| å¤§æ‰¹é‡ï¼ˆ512 tokensï¼‰ | JANUS åŠ¨æ€å¢åŠ  Attention å®ä¾‹ï¼ˆå¦‚ 8A14Eï¼‰ï¼Œé¿å…ç“¶é¢ˆï¼›SGLang ä»…èƒ½ä» 16â†’32 GPU è·³è·ƒå¼æ‰©å®¹ï¼Œçµæ´»æ€§ä¸è¶³ |
| é«˜åŠ¨æ€è´Ÿè½½ï¼ˆBurstGPTï¼‰ | JANUS æŒç»­å¾®è°ƒèµ„æºé…ç½®ï¼Œç´§å¯†è·Ÿè¸ªè´Ÿè½½æ›²çº¿ï¼›SGLang å› é…ç½®ç¦»æ•£ï¼Œé•¿æœŸå¤„äºè¿‡é…æˆ–æ¬ é…çŠ¶æ€ |

> ğŸ“Š å›¾ 7 æ˜¾ç¤ºï¼šJANUS åœ¨æ‰€æœ‰ batch size ä¸‹å‡æ»¡è¶³ SLOï¼Œä¸” per-GPU throughput æ˜¾è‘—é¢†å…ˆã€‚

### **æ¶ˆèå®éªŒç»“æœ**
é€šè¿‡é€æ­¥æ·»åŠ  JANUS çš„æ ¸å¿ƒç»„ä»¶è¿›è¡Œ ablation studyï¼ˆå›¾ 10ï¼‰ï¼š

| é…ç½® | ç›¸å¯¹ Base çš„ TPOT æ”¹å–„ |
|------|------------------------|
| **Base**ï¼ˆçº¯è§£è€¦ï¼Œæ— ä¼˜åŒ–ï¼‰ | â€” |
| **+2PC**ï¼ˆåŠ ä¸¤é˜¶æ®µé€šä¿¡ï¼‰ | â†“18% @ batch=512 |
| **+2PC+LB**ï¼ˆå…¨åŠŸèƒ½ JANUSï¼‰ | å†â†“7% @ batch=64â€“256 |

- **ä¸¤é˜¶æ®µé€šä¿¡**æœ‰æ•ˆç¼“è§£é€šä¿¡ç“¶é¢ˆï¼›
- **è´Ÿè½½å‡è¡¡è°ƒåº¦**åœ¨ä¸­å° batch ä¸‹æ•ˆæœæ›´æ˜æ˜¾ï¼ˆå› ä¸“å®¶æ¿€æ´»ç¨€ç–ï¼‰ï¼›
- å›¾ 11 æ˜¾ç¤ºï¼šJANUS å°†æœ€å¿™ä¸æœ€é—² GPU çš„æ¿€æ´»ä¸“å®¶æ•°å·®è·ä» ~8 é™è‡³ ~4ï¼Œæ˜¾è‘—æ”¹å–„è´Ÿè½½å‡è¡¡ã€‚

### **è°ƒåº¦å¼€é”€æµ‹è¯•ï¼ˆå›¾ 12ï¼‰**
- è°ƒåº¦å»¶è¿Ÿå§‹ç»ˆä½äº **100Î¼s**ï¼Œå³ä½¿ batch=512 æˆ– 16 GPU è§„æ¨¡ã€‚
- å¼€é”€å‡ ä¹ä¸éšè§„æ¨¡å¢é•¿ï¼Œè¯æ˜å…¶é€‚ç”¨äºå¤§è§„æ¨¡éƒ¨ç½²ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Attention ä¸ MoE å±‚å…·æœ‰æ ¹æœ¬ä¸åŒçš„æ‰©å±•è¡Œä¸º**ï¼š
   - Attention åœ¨å° batch ä¸‹å¢åŠ å®ä¾‹åè€Œå¢åŠ å»¶è¿Ÿï¼ˆé€šä¿¡ä¸»å¯¼ï¼‰ï¼›
   - MoE å§‹ç»ˆå—ç›Šäºæ›´å¤šå®ä¾‹ï¼ˆå†…å­˜å¸¦å®½ä¸»å¯¼ï¼‰ï¼›
   â†’ æ”¯æŒ**è§£è€¦éƒ¨ç½²**çš„å¿…è¦æ€§ã€‚

2. **MoE å±‚æ˜¯å†…å­˜å—é™çš„ï¼ˆMemory-Boundï¼‰**ï¼Œå…¶å»¶è¿Ÿä¸»è¦å–å†³äº**è¢«æ¿€æ´»çš„ä¸“å®¶æ•°é‡**ï¼Œè€Œé batch size æˆ–æ¿€æ´»æ¨¡å¼ã€‚

3. **ç»†ç²’åº¦è°ƒåº¦ä¸ç®¡ç†è‡³å…³é‡è¦**ï¼š
   - ä»…è§£è€¦ä¸è¶³ä»¥è§£å†³é—®é¢˜ï¼Œå¿…é¡»é…åˆ**å¾®ç§’çº§è°ƒåº¦**å’Œ**æ¿€æ´»æ„ŸçŸ¥çš„ä¸“å®¶å¤åˆ¶/æ”¾ç½®**æ‰èƒ½å……åˆ†å‘æŒ¥æ½œåŠ›ã€‚

4. **JANUS å®ç°äº†çœŸæ­£çš„å¼¹æ€§æ‰©å±•**ï¼š
   - å¯æŒ‰éœ€ç‹¬ç«‹è°ƒæ•´ Attention/MoE èµ„æºï¼Œé¿å…â€œä¸º MoE ä¹°å•å´æµªè´¹åœ¨ Attention ä¸Šâ€ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰å®ç°å‡è®¾ä¸“å®¶è¾ƒå°ä¸”æ•°é‡å¤šï¼ˆé€‚åˆ DP+EPï¼‰ï¼Œå¯¹æå°‘æ•°è¶…å¤§ä¸“å®¶ï¼ˆå¦‚å•ä¸“å®¶ > GPU æ˜¾å­˜ï¼‰æ”¯æŒæœ‰é™ã€‚
- è™½ç„¶æ”¯æŒ Tensor Parallelismï¼ˆTPï¼‰ï¼Œä½†æœªåœ¨å®éªŒä¸­æ·±å…¥è¯„ä¼°å¤æ‚æ··åˆå¹¶è¡Œåœºæ™¯ã€‚
- ä¸“å®¶å¤åˆ¶ä¸æ”¾ç½®ç­–ç•¥æ›´æ–°å‘¨æœŸè¾ƒé•¿ï¼ˆå°æ—¶çº§ï¼‰ï¼Œå¯èƒ½æ— æ³•åº”å¯¹æç«¯å¿«é€Ÿå˜åŒ–çš„å·¥ä½œè´Ÿè½½ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ”¯æŒæ›´å¤æ‚çš„å¹¶è¡Œç»„åˆï¼ˆDP+EP+TPï¼‰ä¸‹çš„è‡ªåŠ¨é…ç½®æœç´¢ã€‚
- æ¢ç´¢åŸºäºé¢„æµ‹çš„ proactive æ‰©ç¼©å®¹ï¼Œè¿›ä¸€æ­¥æå‡å“åº”é€Ÿåº¦ã€‚
- å°† JANUS æ€æƒ³åº”ç”¨äº **Prefill-Decoding è§£è€¦**åœºæ™¯ï¼Œåœ¨æ¯ä¸ªé˜¶æ®µå†…éƒ¨å†è¿›è¡Œ Attention-MoE è§£è€¦ã€‚
- æ‰©å±•è‡³å¼‚æ„ç¡¬ä»¶ï¼ˆå¦‚ H100 + A100 æ··åˆé›†ç¾¤ï¼‰ï¼Œç»“åˆ Helixã€Hetis ç­‰è°ƒåº¦æ¡†æ¶ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼š  
> **JANUS æ˜¯é¦–ä¸ªå°† Attention ä¸ MoE å®Œå…¨è§£è€¦å¹¶å®ç°ç»†ç²’åº¦ã€ä½å¼€é”€è°ƒåº¦ä¸ç®¡ç†çš„ MoE æ¨ç†ç³»ç»Ÿ**ã€‚å®ƒé€šè¿‡ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯çªç ´äº†ä¼ ç»Ÿå•ä½“æ¶æ„çš„èµ„æºæ•ˆç‡ç“¶é¢ˆï¼Œåœ¨çœŸå®åŠ¨æ€è´Ÿè½½ä¸‹å®ç°äº†é«˜è¾¾ **3.9Ã— çš„ per-GPU ååæå‡**å’Œ **25% çš„ GPU æˆæœ¬èŠ‚çœ**ï¼Œä¸ºå¤§è§„æ¨¡ MoE æ¨¡å‹çš„é«˜æ•ˆæœåŠ¡æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 3. [Fine-Grained Energy Prediction For Parallellized LLM Inference With PIE-P](https://arxiv.org/abs/2512.12801)

**Authors**: Anurag Dutt, Young Won Choi, Avirup Sil, Anshul Gandhi, Aruna Balasubramanian, Niranjan Balasubramanian  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.12801v1  

#### Abstract
With the widespread adoption of Large Language Models (LLMs), energy costs of running LLMs is quickly becoming a critical concern. However, precisely measuring the energy consumption of LLMs is often infeasible because hardware-based power monitors are not always accessible and software-based energy...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFine-Grained Energy Prediction for Parallelized LLM Inference with PIE-P

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šGPUä¸Šçš„å¹¶è¡Œæ¨ç†ä¸­å¹¿æ³›åº”ç”¨ï¼Œå…¶èƒ½è€—å·²æˆä¸ºæ•°æ®ä¸­å¿ƒæˆæœ¬å’Œç¯å¢ƒå½±å“çš„å…³é”®å› ç´ ã€‚ç„¶è€Œï¼Œç°æœ‰çš„èƒ½è€—é¢„æµ‹æ–¹æ³•å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š

- **ç¡¬ä»¶ä¾èµ–æ€§å¼º**ï¼šåŸºäºç¡¬ä»¶çš„åŠŸç‡ç›‘æµ‹å™¨ï¼ˆå¦‚Watts Up Proï¼‰é€šå¸¸ä¸å¯è®¿é—®ï¼Œå°¤å…¶æ˜¯åœ¨å¤šç§Ÿæˆ·é›†ç¾¤ä¸­ã€‚
- **ç²¾åº¦ä¸è¶³**ï¼šè½¯ä»¶å·¥å…·ï¼ˆå¦‚NVMLã€CodeCarbonï¼‰ä»…æµ‹é‡GPUåŠŸè€—ï¼Œä½ä¼°ç³»ç»Ÿæ€»èƒ½è€—ï¼Œä¸”æ— æ³•æ•æ‰ç»†ç²’åº¦é€šä¿¡å¼€é”€ã€‚
- **ä¸é€‚ç”¨äºå¹¶è¡Œåœºæ™¯**ï¼šç°æœ‰æ–¹æ³•ï¼ˆå¦‚IrEneï¼‰ä¸»è¦é’ˆå¯¹å•GPUç¯å¢ƒè®¾è®¡ï¼Œåœ¨å¤šGPUå¹¶è¡Œæ¨ç†ï¼ˆå°¤å…¶æ˜¯tensor parallelismï¼‰ä¸‹è¡¨ç°ä¸ä½³ã€‚

å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨è§£å†³**å¤šGPUå¹¶è¡Œæ¨ç†åœºæ™¯ä¸‹çš„ç»†ç²’åº¦ã€é«˜ç²¾åº¦èƒ½è€—é¢„æµ‹éš¾é¢˜**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **PIE-Pï¼ˆParallelized Inference Energy Predictorï¼‰**ï¼Œä¸€ä¸ªä¸“ä¸ºå¤šGPUå¹¶è¡Œæ¨ç†è®¾è®¡çš„ç»†ç²’åº¦èƒ½è€—é¢„æµ‹æ¡†æ¶ï¼Œæ”¯æŒä¸‰ç§ä¸»æµå¹¶è¡Œç­–ç•¥ï¼š

- **Tensor Parallelism**
- **Pipeline Parallelism**
- **Data Parallelism**

#### **æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬**ï¼š

1. **Synchronization Samplingï¼ˆåŒæ­¥é‡‡æ ·ï¼‰**
   - é’ˆå¯¹tensor parallelismä¸­AllReduceæ“ä½œå¸¦æ¥çš„éç¡®å®šæ€§ç­‰å¾…æ—¶é—´ï¼ˆGPUé—´åŒæ­¥å»¶è¿Ÿï¼‰ï¼Œé€šè¿‡å¤šæ¬¡é‡å¤è¿è¡Œæ•è·ç­‰å¾…æ—¶é—´å’Œç½‘ç»œä¼ è¾“æ—¶é—´çš„åˆ†å¸ƒï¼Œä»è€Œç²¾ç¡®åˆ†ç¦»â€œç©ºé—²ç­‰å¾…â€ä¸â€œå®é™…é€šä¿¡â€çš„èƒ½è€—ã€‚

2. **Expanded Model Tree Abstractionï¼ˆæ‰©å±•çš„æ¨¡å‹æ ‘æŠ½è±¡ï¼‰**
   - åœ¨IrEneçš„åŸºç¡€ä¸Šï¼Œå°†AllReduceã€AllGatherã€Point-to-Point Transferç­‰è·¨GPUé€šä¿¡æ“ä½œæ˜¾å¼å»ºæ¨¡ä¸ºæ¨¡å‹æ ‘ä¸­çš„èŠ‚ç‚¹ï¼Œä½¿èƒ½è€—é¢„æµ‹èƒ½è¦†ç›–è®¡ç®—ä¸é€šä¿¡å…¨è¿‡ç¨‹ã€‚

3. **Structural Model Featuresï¼ˆç»“æ„åŒ–æ¨¡å‹ç‰¹å¾ï¼‰**
   - å¼•å…¥æ¨¡å‹æ¶æ„ç‰¹å¾ï¼ˆå¦‚`attention heads`, `feed-forward dimension`ï¼‰æ¥åˆ»ç”»ä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹çš„é€šä¿¡æ¨¡å¼å·®å¼‚ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

4. **Aggregate Runtime Feature Representationï¼ˆèšåˆè¿è¡Œæ—¶ç‰¹å¾è¡¨ç¤ºï¼‰**
   - å¯¹å¤šä¸ªGPUçš„è¿è¡Œæ—¶ç‰¹å¾ï¼ˆå¦‚utilizationã€clock speedï¼‰è¿›è¡Œç»Ÿè®¡èšåˆï¼ˆmean, std, min, maxï¼‰ï¼Œå®ç°å¯æ‰©å±•ä¸”ç¨³å®šçš„è¾“å…¥è¡¨ç¤ºï¼Œé¿å…å› GPUæ•°é‡å˜åŒ–å¯¼è‡´ç»´åº¦ä¸ä¸€è‡´ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹æ³• | å±€é™æ€§ | PIE-Pä¼˜åŠ¿ |
|------|--------|-----------|
| **IrEne** | å•GPUè®¾è®¡ï¼Œå¿½ç•¥è·¨GPUé€šä¿¡ | æ˜¾å¼å»ºæ¨¡AllReduceç­‰é€šä¿¡æ¨¡å—ï¼Œé€‚ç”¨äºå¤šGPU |
| **CodeCarbon / NVML** | ä»…æŠ¥å‘ŠGPUåŠŸè€—ï¼Œä½ä¼°ç³»ç»Ÿæ€»èƒ½è€— | èåˆç³»ç»Ÿçº§ç›‘æ§ï¼Œé¢„æµ‹æ›´æ¥è¿‘çœŸå®æ€»èƒ½è€— |
| **Token-basedå›å½’ï¼ˆå¦‚Wilkins et al.ï¼‰** | å¿½ç•¥ç¡¬ä»¶åŠ¨æ€å’Œå¹¶è¡Œå¼€é”€ | ç»“åˆè¿è¡Œæ—¶ä¸ç»“æ„ç‰¹å¾ï¼Œé€‚åº”å¤æ‚å¹¶è¡Œè¡Œä¸º |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹å®¶æ—**

åœ¨å››ä¸ªä¸»æµå¼€æºLLMå®¶æ—ä¸Šè¿›è¡Œå®éªŒï¼Œæ¶µç›–å¤šç§è§„æ¨¡ï¼ˆ7Bâ€“70Bå‚æ•°ï¼‰ï¼š

- **Vicuna** (7B, 13B, 33B)
- **Mistral** (8B, 24B, 48B)
- **Llama** (7B, 13B, 70B)
- **Qwen** (8B, 14B, 32B)

æ‰€æœ‰æ¨¡å‹å‡é‡‡ç”¨**vLLM**ä½œä¸ºæ¨ç†å¼•æ“ï¼Œå¹¶æ”¯æŒä¸‰ç§å¹¶è¡Œç­–ç•¥ã€‚

---

### **å®éªŒè®¾ç½®**

- **ç¡¬ä»¶å¹³å°**ï¼š
  - CPU: AMD EPYC Milan 7543P (32æ ¸)
  - GPU: 4 Ã— NVIDIA RTX A6000 (48GB GDDR6, PCIe 4.0)
  - åŠŸç‡ç›‘æµ‹ï¼šå¤–éƒ¨ç”µè¡¨ Watts Up Proï¼ˆç”¨äºè·å–ground truthç³»ç»Ÿæ€»èƒ½è€—ï¼‰

- **å¹¶è¡Œé…ç½®**ï¼š
  - æ”¯æŒ2-GPUå’Œ4-GPUé…ç½®
  - æ‰€æœ‰å®éªŒåœ¨tensorã€pipelineã€data parallelismä¸‰ç§æ¨¡å¼ä¸‹åˆ†åˆ«æµ‹è¯•

- **è¾“å…¥é…ç½®å¤šæ ·æ€§**ï¼š
  - Batch size: 8, 16, 32, 64
  - Sequence length: 512, 1024
  - å¤šæ¬¡é‡‡æ ·ä»¥æ•æ‰éç¡®å®šæ€§è¡Œä¸º

---

### **è¯„ä¼°æŒ‡æ ‡**

- **MAPEï¼ˆMean Absolute Percentage Errorï¼‰**ï¼šä¸»è¯„ä»·æŒ‡æ ‡
  $$
  \text{MAPE} = \frac{1}{n}\sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right| \times 100\%
  $$
- æ¨¡å‹çº§ï¼ˆmodel-levelï¼‰ä¸æ¨¡å—çº§ï¼ˆmodule-levelï¼‰åŒå±‚è¯„ä¼°
- æ³›åŒ–èƒ½åŠ›æµ‹è¯•ï¼šLeave-One-Out Cross-Validationï¼ˆLOO-CVï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

1. **IrEne (Cao et al., 2021)**  
   - æ‰©å±•è‡³å¤šGPUç‰ˆæœ¬ï¼Œä½¿ç”¨èšåˆç‰¹å¾ï¼Œä½†æœªå»ºæ¨¡è·¨GPUé€šä¿¡
2. **CodeCarbon (Courty et al., 2024b)**  
   - åŸºäºNVML/RAPLçš„è½¯ä»¶èƒ½è€—ä¼°ç®—å·¥å…·ï¼Œå¹¿æ³›ç”¨äºç¢³æ’æ”¾è¿½è¸ª
3. **Wilkins et al. (2024)**  
   - åŸºäºè¾“å…¥/è¾“å‡ºtokenæ•°çš„å›å½’æ¨¡å‹ï¼š$e_K(T_{in}, T_{out}) = \alpha_0 T_{in} + \alpha_1 T_{out} + \alpha_2 T_{in}T_{out}$

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTensor Parallelism ä¸‹å¹³å‡ MAPEï¼‰**

| æ–¹æ³• | å¹³å‡ MAPE |
|------|----------|
| **PIE-P** | **17.6%** |
| CodeCarbon | 28.49% |
| IrEne | 40.45% |
| Wilkins et al. | 58.77% |

> âœ… PIE-Pæ¯”æœ€ä½³åŸºçº¿ï¼ˆCodeCarbonï¼‰è¯¯å·®é™ä½ **1.5â€“3å€**

---

### **ä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹çš„è¡¨ç°**

| å¹¶è¡Œç±»å‹ | PIE-P MAPE | æœ€ä½³åŸºçº¿ MAPE | æå‡å€æ•° |
|---------|------------|----------------|----------|
| **Tensor Parallelism** | 17.6% | 28.49% (CodeCarbon) | ~1.6Ã— |
| **Pipeline Parallelism** | 13.25% | 36.8% (CodeCarbon) | ~2.8Ã— |
| **Data Parallelism** | 14.36% | 30.25% (CodeCarbon) | ~2.1Ã— |

> ğŸ“Œ åœ¨æ‰€æœ‰ä¸‰ç§å¹¶è¡Œç­–ç•¥ä¸‹ï¼ŒPIE-På‡æ˜¾è‘—ä¼˜äºåŸºçº¿

---

### **æ¨¡å—çº§é¢„æµ‹è¯¯å·®ï¼ˆVicuna, 2/4-GPUï¼‰**

| æ¨¡å— | 2-GPU MAPE | 4-GPU MAPE |
|------|-----------|-----------|
| Self-Attention | 8.8% | 11.4% |
| MLP | 6.6% | 9.5% |
| **AllReduce** | **17.3%** | **19.4%** |
| LayerNorm | 6.4% | 7.3% |

> ğŸ” AllReduceè¯¯å·®è¾ƒé«˜ï¼Œæºäºé€šä¿¡éç¡®å®šæ€§ï¼Œä½†ä»ä¿æŒåˆç†èŒƒå›´

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **ç§»é™¤Synchronization Samplingçš„å½±å“**

- **PIE-Pï¼ˆå®Œæ•´ç‰ˆï¼‰**: MAPE = **17.6%**
- **PIE-P w/o waiting phase**: MAPE = **36.9%**
- â¡ï¸ è¯¯å·®ç¿»å€ï¼ˆ+19.3ä¸ªç™¾åˆ†ç‚¹ï¼‰ï¼Œè¯æ˜åŒæ­¥ç­‰å¾…å»ºæ¨¡è‡³å…³é‡è¦

#### **ç§»é™¤ç»“æ„åŒ–æ¨¡å‹ç‰¹å¾çš„å½±å“ï¼ˆNèŠ‚ï¼‰**

| Vicunaå˜ä½“ | å«ç»“æ„ç‰¹å¾ | ä¸å«ç»“æ„ç‰¹å¾ |
|-----------|-------------|---------------|
| 7B | 15.84% | 17.2% |
| 13B | 17.72% | 18.2% |
| 33B | 17.55% | 20.1% |

> âœ… ç»“æ„ç‰¹å¾æå‡æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶åœ¨æœªè§æ¨¡å‹ä¸Šæ•ˆæœæ˜æ˜¾

---

### **æ³›åŒ–èƒ½åŠ›æµ‹è¯•**

#### **Leave-One-Outï¼ˆLOOï¼‰è·¨å°ºå¯¸/æ‰¹å¤§å°æ³›åŒ–**

| ç±»å‹ | å¹³å‡ MAPE |
|------|----------|
| è·¨æ¨¡å‹å¤§å° | **19.99%** |
| è·¨æ‰¹å¤§å° | **19.05%** |

> è¡¨æ˜PIE-Pèƒ½æœ‰æ•ˆæ¨å¹¿åˆ°æœªè§è¿‡çš„æ¨¡å‹è§„æ¨¡å’Œbatché…ç½®

#### **è·¨æ¶æ„æ³›åŒ–ï¼ˆHold-outæ•´ä¸ªæ¨¡å‹å®¶æ—ï¼‰**

| æ’é™¤å®¶æ— | PIE-P MAPE | IrEne MAPE |
|--------|------------|------------|
| Vicuna | 24.1% | 49.3% |
| Mistral | 27.0% | 56.5% |
| Llama | 26.1% | 55.3% |
| Qwen | 27.6% | 58.4% |

> âœ… PIE-Påœ¨è·¨æ¶æ„åœºæ™¯ä¸‹ä»ä¿æŒè‰¯å¥½é¢„æµ‹èƒ½åŠ›ï¼Œç›¸å¯¹IrEneæå‡è¶…50%

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **å¹¶è¡Œæ¨ç†ä¸­çš„é€šä¿¡èƒ½è€—ä¸å¯å¿½è§†**  
   - AllReduceåœ¨tensor parallelismä¸­å æ¯”å¯è¾¾ **15%â€“35%**ï¼ˆè§Appendix Cï¼‰
   - å¿½ç•¥é€šä¿¡å°†å¯¼è‡´ç³»ç»Ÿæ€§ä½ä¼°ï¼Œä¸”è¯¯å·®éšGPUæ•°é‡å¢åŠ è€ŒåŠ å‰§

2. **éç¡®å®šæ€§åŒæ­¥æ˜¯é¢„æµ‹éš¾ç‚¹**  
   - GPUé—´è®¡ç®—é€Ÿåº¦å·®å¼‚å¯¼è‡´AllReduceé˜¶æ®µå‡ºç°â€œé¢†å…ˆ/è½åâ€ç°è±¡
   - é€šè¿‡ç¦»çº¿é‡‡æ ·å»ºæ¨¡ç­‰å¾…æ—¶é—´åˆ†å¸ƒæ˜¯æé«˜ç²¾åº¦çš„å…³é”®

3. **ç»“æ„åŒ–ç‰¹å¾å¢å¼ºæ³›åŒ–èƒ½åŠ›**  
   - attention headsã€FFN dimç­‰ç»“æ„ä¿¡æ¯æœ‰åŠ©äºæ•æ‰ä¸åŒæ¨¡å‹é—´çš„é€šä¿¡æ¨¡å¼å·®å¼‚

4. **PIE-På…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œå®ç”¨æ€§**  
   - é¢„æµ‹è¿‡ç¨‹æ— è¿è¡Œæ—¶å¼€é”€ï¼ˆoffline profilingï¼‰
   - å¯ç”¨äºæŒ‡å¯¼æ¨¡å‹éƒ¨ç½²å†³ç­–ï¼ˆå¦‚æƒè¡¡latency vs. energyï¼‰

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ç¡¬ä»¶ä¾èµ–æ€§å¼º**  
   - å½“å‰PIE-Péœ€ä¾èµ–ç‰¹å®šç¡¬ä»¶é…ç½®è¿›è¡Œè®­ç»ƒï¼Œç¼ºä¹è·¨å¹³å°é€šç”¨æ€§

2. **ä»…æ”¯æŒDecoder-onlyæ¶æ„**  
   - å°šæœªæ‰©å±•è‡³Encoderæˆ–Encoder-Decoderæ¨¡å‹ï¼ˆå¦‚T5ã€BARTï¼‰ï¼Œå› å…¶åŒå‘æ³¨æ„åŠ›å’Œä¸åŒæ‰§è¡Œæµå¸¦æ¥é¢å¤–å¤æ‚æ€§

3. **å¯¹é«˜åº¦å¤æ‚çš„æ³¨æ„åŠ›æœºåˆ¶æ•æ„Ÿ**  
   - Mistralï¼ˆGrouped-Query Attentionï¼‰ã€Qwenï¼ˆMulti-Queryï¼‰ç­‰å¤æ‚ç»“æ„é¢„æµ‹è¯¯å·®æ›´é«˜ï¼ˆMAPE >20%ï¼‰

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¼€å‘ç¡¬ä»¶æ— å…³çš„èƒ½è€—é¢„æµ‹æ¨¡å‹**ï¼ˆä½œè€…æ˜ç¡®åˆ—ä¸ºä¸‹ä¸€æ­¥å·¥ä½œï¼‰
2. **æ‰©å±•è‡³Encoder-basedå’ŒEncoder-Decoderæ¨¡å‹**
3. **è¿›ä¸€æ­¥å»ºæ¨¡å¤æ‚æ³¨æ„åŠ›æœºåˆ¶çš„é€šä¿¡è¡Œä¸º**
4. **ç»“åˆDVFSã€è°ƒåº¦ç­–ç•¥ç­‰ä¼˜åŒ–æ‰‹æ®µï¼Œæ„å»ºç«¯åˆ°ç«¯èŠ‚èƒ½æ¨ç†ç³»ç»Ÿ**

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> PIE-Pé¦–æ¬¡å®ç°äº†å¯¹å¤šGPUå¹¶è¡ŒLLMæ¨ç†çš„**ç»†ç²’åº¦ã€é«˜ç²¾åº¦ã€å¯æ³›åŒ–çš„èƒ½è€—é¢„æµ‹**ï¼Œé€šè¿‡å¼•å…¥**åŒæ­¥é‡‡æ ·ã€æ‰©å±•æ¨¡å‹æ ‘ã€ç»“æ„åŒ–ç‰¹å¾**ä¸‰å¤§æœºåˆ¶ï¼Œåœ¨tensorã€pipelineã€data parallelismä¸‹å‡æ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸ºç»¿è‰²AIå’Œèƒ½æ•ˆä¼˜åŒ–æä¾›äº†é‡è¦å·¥å…·ã€‚

</details>

---

### 4. [Optimal Resource Allocation for ML Model Training and Deployment under Concept Drift](https://arxiv.org/abs/2512.12816)

**Authors**: Hasan Burhan Beytur, Gustavo de Veciana, Haris Vikalo, Kevin S Chan  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.12816v1  

#### Abstract
We study how to allocate resources for training and deployment of machine learning (ML) models under concept drift and limited budgets. We consider a setting in which a model provider distributes trained models to multiple clients whose devices support local inference but lack the ability to retrain...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOptimal Resource Allocation for ML Model Training and Deployment under Concept Drift

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡ç ”ç©¶åœ¨**æ¦‚å¿µæ¼‚ç§»**ï¼ˆConcept Driftï¼‰ç¯å¢ƒä¸‹ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒä¸éƒ¨ç½²ä¸­çš„**èµ„æºåˆ†é…ä¼˜åŒ–é—®é¢˜**ã€‚å…·ä½“åœºæ™¯ä¸ºï¼š
- ä¸€ä¸ªä¸­å¿ƒåŒ–çš„æœåŠ¡æä¾›å•†è´Ÿè´£è®­ç»ƒæ¨¡å‹å¹¶åˆ†å‘ç»™å¤šä¸ªå®¢æˆ·ç«¯ï¼›
- å®¢æˆ·ç«¯ä»…æ”¯æŒæœ¬åœ°æ¨ç†ï¼Œæ— æ³•é‡æ–°è®­ç»ƒæ¨¡å‹ï¼›
- æ¨¡å‹æ€§èƒ½å› æ•°æ®åˆ†å¸ƒå˜åŒ–è€Œéšæ—¶é—´é€€åŒ–ï¼›
- æœåŠ¡å•†éœ€åœ¨æœ‰é™é¢„ç®—ä¸‹å†³å®šä½•æ—¶ã€å¦‚ä½•åˆ†é…è®¡ç®—èµ„æºè¿›è¡Œå†è®­ç»ƒï¼Œå¹¶å†³å®šä½•æ—¶å‘å®¢æˆ·ç«¯æ¨é€æ›´æ–°ã€‚

è¯¥é—®é¢˜åœ¨ç°å®ä¸–ç•Œä¸­å¹¿æ³›å­˜åœ¨ï¼Œå¦‚æ¨èç³»ç»Ÿã€åŒ»ç–—è¯Šæ–­ã€é‡‘èé£æ§ç­‰æŒç»­æ¼”è¿›çš„æ•°æ®ç¯å¢ƒä¸­ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§**æ¨¡å‹æ— å…³çš„åˆ†ææ¡†æ¶**ï¼ˆmodel-agnostic frameworkï¼‰ï¼Œç»Ÿä¸€å»ºæ¨¡ä»¥ä¸‹ä¸‰ä¸ªå…³é”®å› ç´ ä¹‹é—´çš„äº¤äº’å…³ç³»ï¼š
- **è®­ç»ƒèµ„æºåˆ†é…ç­–ç•¥**ï¼ˆTraining Resource Allocationï¼‰
- **æ¦‚å¿µæ¼‚ç§»åŠ¨æ€**ï¼ˆConcept Drift Dynamicsï¼‰
- **æ¨¡å‹éƒ¨ç½²è°ƒåº¦**ï¼ˆModel Deployment Schedulingï¼‰

#### ä¸»è¦ç†è®ºè´¡çŒ®åŒ…æ‹¬ï¼š

1. **æœ€ä¼˜è®­ç»ƒæ§åˆ¶ç­–ç•¥çš„ç»“æ„æ€§åˆ†æ**
   - å°†è®­ç»ƒèµ„æºåˆ†é…å»ºæ¨¡ä¸ºè¿ç»­æ—¶é—´æœ€ä¼˜æ§åˆ¶é—®é¢˜ï¼ˆOptimal Controlï¼‰ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–æœåŠ¡å™¨ç«¯é•¿æœŸå¹³å‡æœŸæœ›æŸå¤±ã€‚
   - å¼•å…¥ **Pontryaginâ€™s Maximum Principle (PMP)** åˆ†ææœ€ä¼˜è§£ç»“æ„ã€‚
   - å‘ç°æœ€ä¼˜ç­–ç•¥æ˜¯ **bang-bang æ§åˆ¶** ç±»å‹ï¼Œå³èµ„æºè¦ä¹ˆå…¨å¼€ï¼ˆMï¼‰ï¼Œè¦ä¹ˆå…³é—­ï¼ˆ0ï¼‰ã€‚

2. **æ­ç¤ºæ¦‚å¿µæŒç»­æ—¶é—´çš„ç»Ÿè®¡ç‰¹æ€§å¯¹ç­–ç•¥çš„å½±å“**
   - å®šä¹‰å¹¶åˆ©ç”¨ **Mean Residual Life (MRL)** å‡½æ•°æ¥åˆ»ç”»æ¦‚å¿µå¯¿å‘½çš„â€œè€åŒ–â€è¡Œä¸ºï¼š
     - **DMRL**ï¼ˆDecreasing MRLï¼‰ï¼šå¯¿å‘½è¶Šé•¿è¶Šå¯èƒ½ç»“æŸï¼ˆå¦‚æœºæ¢°æ•…éšœï¼‰ï¼›
     - **IMRL**ï¼ˆIncreasing MRLï¼‰ï¼šå­˜æ´»è¶Šä¹…è¶Šç¨³å®šï¼ˆå¦‚æŠ€æœ¯è¶‹åŠ¿ã€ä¼ä¸šç”Ÿå‘½å‘¨æœŸï¼‰ã€‚
   - **å…³é”®å®šç†**ï¼š
     - å½“æ¦‚å¿µæŒç»­æ—¶é—´æœä» **DMRL åˆ†å¸ƒ**æ—¶ï¼Œ**å‰è½½å¼è®­ç»ƒç­–ç•¥**ï¼ˆFront-loadingï¼ŒåˆæœŸé›†ä¸­æŠ•å…¥èµ„æºï¼‰æ˜¯æœ€ä¼˜çš„ã€‚
     - å½“æ¦‚å¿µæŒç»­æ—¶é—´æœä» **IMRL åˆ†å¸ƒ**æ—¶ï¼Œ**åè½½å¼ç­–ç•¥**ï¼ˆBack-loadingï¼Œå»¶è¿Ÿå¼€å§‹è®­ç»ƒï¼‰æ›´ä¼˜ï¼Œä¸”ç›´è§‚çš„å›ºå®šåˆ†é…ç­–ç•¥ï¼ˆFixed Allocationï¼‰æ˜¯æ¬¡ä¼˜çš„ã€‚

3. **éƒ¨ç½²è°ƒåº¦ä¼˜åŒ–ä¸éšæœºåŒ–ç­–ç•¥è®¾è®¡**
   - åœ¨é€šä¿¡å¸¦å®½å—é™ï¼ˆå³éƒ¨ç½²é¢‘ç‡å—é™ï¼‰æ¡ä»¶ä¸‹ï¼Œç ”ç©¶å®¢æˆ·ç«¯ä¾§æ€§èƒ½æœ€å¤§åŒ–é—®é¢˜ã€‚
   - è¯æ˜åœ¨æ¸©å’Œå‡è®¾ä¸‹ï¼Œéƒ¨ç½²ä¼˜åŒ–é—®é¢˜æ˜¯ **quasi-convex** çš„ã€‚
   - æå‡ºä¸€ç§ **éšæœºåŒ–éƒ¨ç½²ç­–ç•¥**ï¼ˆRandomized Deployment Policyï¼‰ï¼š
     - ç»“åˆä¸¤ä¸ªç›¸é‚»éƒ¨ç½²æ¬¡æ•°ä¸‹çš„ç¡®å®šæ€§æœ€ä¼˜è°ƒåº¦å™¨ï¼›
     - é€šè¿‡å‡¸ç»„åˆå®ç°ç²¾ç¡®åŒ¹é…éƒ¨ç½²ç‡çº¦æŸï¼›
     - å…·æœ‰ç†è®ºæ€§èƒ½ä¿è¯ï¼Œé€‚ç”¨äºéå‡¸ç”Ÿå­˜å‡½æ•°æƒ…å½¢ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡ä¼˜åŠ¿ |
|------|--------|---------|
| **å»ºæ¨¡èŒƒå¼** | å¤šä¸ºç»éªŒæ€§æˆ–ç‰¹å®šæ¨¡å‹é©±åŠ¨ | æå‡ºé€šç”¨ã€å¯è§£é‡Šçš„æ•°å­¦æ¡†æ¶ï¼Œé€‚ç”¨äºå„ç±»MLæ¨¡å‹ |
| **èµ„æºåˆ†é…é€»è¾‘** | å›ºå®šå‘¨æœŸé‡è®­ / å˜åŒ–æ£€æµ‹è§¦å‘ | åŸºäºæ¦‚å¿µå¯¿å‘½ç»Ÿè®¡ç‰¹æ€§çš„åŠ¨æ€æœ€ä¼˜ç­–ç•¥ |
| **ç†è®ºæ·±åº¦** | ç¼ºä¹å¯¹â€œä½•æ—¶è®­ç»ƒæœ€å¥½â€çš„æ ¹æœ¬è§£é‡Š | åˆ©ç”¨MRLç†è®ºç»™å‡ºç»“æ„æ€§æœ€ä¼˜æ¡ä»¶ |
| **éƒ¨ç½²è°ƒåº¦** | å‘¨æœŸæ€§æˆ–äº‹ä»¶é©±åŠ¨ | æ”¯æŒé€Ÿç‡çº¦æŸä¸‹çš„è¿‘ä¼¼æœ€ä¼˜è°ƒåº¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
æœ¬æ–‡æœªä½¿ç”¨çœŸå®æ•°æ®é›†è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œè€Œæ˜¯åŸºäº**ä»¿çœŸç¯å¢ƒ**éªŒè¯ç†è®ºç»“æœã€‚å…¶æ ¸å¿ƒä¾èµ–çš„æ˜¯ï¼š
- **åˆæˆçš„æ¦‚å¿µæ¼‚ç§»è¿‡ç¨‹**ï¼šç”±éšæœºå˜é‡ $ Y_i $ è¡¨ç¤ºæ¯ä¸ªæ¦‚å¿µçš„æŒç»­æ—¶é—´ï¼›
- **æœŸæœ›æŸå¤±å‡½æ•° $ g(t) $**ï¼šæ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡å‹æ€§èƒ½æå‡çš„è¿‡ç¨‹ã€‚

ä½¿ç”¨çš„å…¸å‹åˆ†å¸ƒåŒ…æ‹¬ï¼š
- **Exponential**(Î»)ï¼šæ— è®°å¿†æ€§ï¼ŒåŒæ—¶å±äº DMRL å’Œ IMRL è¾¹ç•Œæƒ…å†µï¼›
- **Weibull**(Î», k)ï¼šé€šè¿‡å½¢çŠ¶å‚æ•° $ k $ æ§åˆ¶ MRL ç‰¹æ€§ï¼š
  - $ k < 1 $ï¼šIMRLï¼›
  - $ k > 1 $ï¼šDMRLï¼›
- **Gamma**, **Uniform**, **Erlang-2** ç­‰ç”¨äºå¤šæ ·æ€§æµ‹è¯•ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ï¼ˆ1ï¼‰è®­ç»ƒèµ„æºåˆ†é…å®éªŒ
- **ç›®æ ‡**ï¼šæ¯”è¾ƒä¸åŒèµ„æºåˆ†é…ç­–ç•¥ä¸‹çš„é•¿æœŸå¹³å‡æœŸæœ›æŸå¤±ï¼ˆTime-average Expected Lossï¼‰ã€‚
- **é¢„ç®—çº¦æŸ**ï¼šæ€»èµ„æºæ¶ˆè€—å—å¹³å‡æˆæœ¬é™åˆ¶ $ B $ã€‚
- **ç­–ç•¥å¯¹æ¯”**ï¼š
  - **Optimal Policy**ï¼šæ ¹æ® MRL æ€§è´¨é€‰æ‹© front-/back-loadingï¼›
  - **Fixed Allocation**ï¼šå‡åŒ€åˆ†é…èµ„æºï¼ˆ$ e(t) = B/\alpha $ï¼‰ï¼›
  - **Delayed Block Allocation**ï¼šå»¶è¿Ÿä¸€æ®µæ—¶é—´åå†é›†ä¸­ä½¿ç”¨èµ„æºã€‚

#### ï¼ˆ2ï¼‰éƒ¨ç½²è°ƒåº¦å®éªŒ
- **ç›®æ ‡**ï¼šæœ€å°åŒ–å®¢æˆ·ç«¯ä¾§é•¿æœŸå¹³å‡æŸå¤± $ \mathbb{E}[L_c(t)] $ã€‚
- **çº¦æŸ**ï¼šæœ€å¤§å…è®¸éƒ¨ç½²é¢‘ç‡ $ r_p $ã€‚
- **ç­–ç•¥å¯¹æ¯”**ï¼š
  - **Periodic Policy**ï¼šå®šæœŸéƒ¨ç½²ï¼ˆbaselineï¼‰ï¼›
  - **Optimal Policy**ï¼šæ•°å€¼æ±‚è§£å¾—åˆ°çš„æœ€ä¼˜é™æ€è°ƒåº¦ï¼›
  - **Randomized Policy**ï¼šåŸºäºç›¸é‚» $ N_D $ å’Œ $ N_D+1 $ éƒ¨ç½²æ•°çš„å‡¸ç»„åˆã€‚

#### è¯„ä¼°æŒ‡æ ‡
- **ä¸»æŒ‡æ ‡**ï¼šé•¿æœŸå¹³å‡æœŸæœ›æŸå¤±ï¼ˆLower is betterï¼‰
- **è¾…åŠ©æŒ‡æ ‡**ï¼š
  - èµ„æºåˆ©ç”¨ç‡ï¼›
  - éƒ¨ç½²æœ‰æ•ˆç‡ï¼ˆEffective Deployment Rateï¼‰ï¼›
  - æ€§èƒ½å¢ç›Šç™¾åˆ†æ¯”ï¼ˆvs baselineï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰è®­ç»ƒèµ„æºåˆ†é…ç»“æœï¼ˆå›¾2ï¼‰

| åœºæ™¯ | æœ€ä¼˜ç­–ç•¥ | vs Fixed Allocation æå‡ |
|------|----------|--------------------------|
| $ Y \sim \text{Exp}(1), g(t)=e^{-t} $ | Front-loading (DMRL) | **æœ€é«˜è¾¾ 71.80%** æŸå¤±é™ä½ |
| $ Y \sim \text{Weibull}(k=0.4), g(t)=e^{-t} $ | Back-loading (IMRL) | å¼•å…¥å»¶è¿Ÿæ˜¾è‘—ä¼˜äºç«‹å³è®­ç»ƒ |
| ä¸åŒ $ g(t) $ æ›²çº¿ï¼ˆè§é™„å½•å›¾4ï¼‰ | â€”â€” | å‰æœŸè¡°å‡è¶Šå¿«ï¼Œfront-loading æ”¶ç›Šè¶Šå¤§ |

> âœ… **å…³é”®è§‚å¯Ÿ**ï¼šå½“é¢„ç®—è¾ƒä½æ—¶ï¼Œfront-loading åœ¨ DMRL ä¸‹ä¼˜åŠ¿æœ€æ˜æ˜¾ï¼›éšç€é¢„ç®—å¢åŠ ï¼Œå·®è·ç¼©å°ã€‚

---

### ï¼ˆ2ï¼‰éƒ¨ç½²è°ƒåº¦ç»“æœï¼ˆå›¾3ï¼‰

| åˆ†å¸ƒç±»å‹ | Periodic vs Optimal Loss Reduction | Randomized vs Optimal å·®è· |
|---------|------------------------------------|----------------------------|
| Exponential ($ \mathbb{E}[Y]=1 $) | **43.30%** | å‡ ä¹æ— å·®è·ï¼ˆnear-optimalï¼‰ |
| Weibull($k=2$)ï¼ˆDMRLï¼‰ | **39.25%** | æå°å·®è· |
| Erlang-2ï¼ˆä½æ–¹å·®ï¼‰ | è¾ƒå°ï¼ˆçº¦10â€“15%ï¼‰ | å­˜åœ¨å¯æµ‹å·®è· |

> âœ… **å…³é”®å‘ç°**ï¼š
> - Randomized Policy åœ¨å¤šæ•°æƒ…å†µä¸‹è¡¨ç°æ¥è¿‘æœ€ä¼˜ï¼›
> - åœ¨é«˜å˜å¼‚æ€§ï¼ˆhigh varianceï¼‰å’Œå¿«é€ŸæŸå¤±ä¸‹é™åœºæ™¯ä¸­ä¼˜åŠ¿æ˜¾è‘—ï¼›
> - å¯¹äºä½å˜å¼‚åˆ†å¸ƒï¼ˆå¦‚ Erlang-2ï¼‰ï¼Œæ‰€æœ‰ç­–ç•¥å·®å¼‚è¾ƒå°ã€‚

---

### æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
è™½ç„¶æ²¡æœ‰æ˜ç¡®å‘½åâ€œæ¶ˆèâ€ï¼Œä½†ä»¥ä¸‹åˆ†æèµ·åˆ°äº†ç±»ä¼¼ä½œç”¨ï¼š
- **æ”¹å˜ $ g(t) $ å½¢å¼**ï¼ˆé™„å½•å›¾4ï¼‰ï¼š
  - $ g(t) = 1/(1+t), 1/\sqrt{1+t}, t^{-0.3}, t^{-0.7} $
  - å‘ç°ï¼šåˆå§‹ä¸‹é™è¶Šé™¡å³­ï¼Œfront-loading æ•ˆæœè¶Šå¥½ã€‚
- **ä¸åŒ MRL ç±»å‹å¯¹æ¯”**ï¼ˆå›¾2bï¼‰ï¼š
  - æ˜¾ç¤º IMRL ä¸‹å¼•å…¥ delay å¯æå‡æ€§èƒ½ï¼Œè€Œ DMRL ä¸‹åˆ™æœ‰å®³ã€‚
- **é¢„ç®—æ•æ„Ÿæ€§åˆ†æ**ï¼š
  - ä½é¢„ç®—æ—¶ä¼˜åŒ–ç­–ç•¥æ”¶ç›Šæœ€å¤§ï¼›
  - é«˜é¢„ç®—ä¸‹å„ç­–ç•¥è¶‹åŒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. ğŸ”‘ **æœ€ä¼˜è®­ç»ƒç­–ç•¥å–å†³äºæ¦‚å¿µå¯¿å‘½çš„MRLæ€§è´¨**ï¼š
   - **DMRL â‡’ Front-loading æœ€ä¼˜**
   - **IMRL â‡’ Back-loading æ›´ä¼˜**
   - å¿½è§†è¿™ä¸€ç‰¹æ€§çš„å¯å‘å¼ç­–ç•¥ï¼ˆå¦‚å›ºå®šåˆ†é…ï¼‰æ˜¯**ç†è®ºä¸Šå¯è¯æ¬¡ä¼˜**çš„ã€‚

2. ğŸ”‘ **éƒ¨ç½²è°ƒåº¦é—®é¢˜å…·æœ‰ quasi-convex ç»“æ„**ï¼Œå¯åœ¨ä¸€å®šæ¡ä»¶ä¸‹é«˜æ•ˆæ±‚è§£ã€‚

3. ğŸ”‘ **æå‡ºçš„éšæœºåŒ–éƒ¨ç½²ç­–ç•¥**èƒ½åœ¨ä¸ä¾èµ–å¤æ‚éå‡¸ä¼˜åŒ–çš„å‰æä¸‹ï¼Œé€¼è¿‘æœ€ä¼˜æ€§èƒ½ï¼Œé€‚åˆå®é™…ç³»ç»Ÿé›†æˆã€‚

4. ğŸ”‘ **æ€§èƒ½å¢ç›Šé«˜åº¦ä¾èµ–äºç³»ç»Ÿå‚æ•°**ï¼š
   - æ¦‚å¿µå¯¿å‘½æ–¹å·®è¶Šå¤§ï¼Œä¼˜åŒ–ç©ºé—´è¶Šå¤§ï¼›
   - æŸå¤±å‡½æ•°å‰æœŸä¸‹é™è¶Šå¿«ï¼Œfront-loading è¶Šæœ‰åˆ©ï¼›
   - ä½é¢„ç®—åœºæ™¯ä¸‹ä¼˜åŒ–ä»·å€¼æœ€é«˜ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™æ€§ | è¯´æ˜ |
|-------|------|
| **ä¾èµ–åˆ†å¸ƒå…ˆéªŒçŸ¥è¯†** | éœ€è¦çŸ¥é“æˆ–ä¼°è®¡ $ Y $ çš„åˆ†å¸ƒåŠ MRL ç‰¹æ€§ï¼Œåœ¨å®è·µä¸­å¯èƒ½éœ€è¦é¢å¤–ç›‘æ§ä¸ç»Ÿè®¡æ£€éªŒ |
| **ç†æƒ³åŒ–æŸå¤±æ¨¡å‹** | ä½¿ç”¨â€œæœŸæœ›æ¦‚å¿µæŸå¤±â€ä½œä¸ºä»£ç†æŒ‡æ ‡ï¼Œå¿½ç•¥é‡‡æ ·å™ªå£°å’Œä»»åŠ¡ç‰¹å®šmetricï¼ˆå¦‚F1-scoreï¼‰ |
| **é™æ€ç­–ç•¥å‡è®¾** | æ‰€æœ‰ç­–ç•¥å‡ä¸ºé™æ€ï¼ˆstationaryï¼‰ï¼Œæœªè€ƒè™‘åœ¨çº¿è‡ªé€‚åº”è°ƒæ•´ |
| **æœªæ¶‰åŠè”åˆä¼˜åŒ–** | è®­ç»ƒä¸éƒ¨ç½²åˆ†å¼€å¤„ç†ï¼Œæœªæ¢ç´¢äºŒè€…ååŒä¼˜åŒ–çš„å¯èƒ½æ€§ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **åœ¨çº¿ä¼°è®¡ MRL ç‰¹æ€§**ï¼šå¼€å‘è½»é‡çº§ç®—æ³•å®æ—¶åˆ¤æ–­å½“å‰æ¼‚ç§»æ¨¡å¼å±äº DMRL è¿˜æ˜¯ IMRLã€‚
2. **è‡ªé€‚åº”è°ƒåº¦å™¨**ï¼šä»é™æ€ç­–ç•¥æ‰©å±•åˆ°åŠ¨æ€å“åº”æœºåˆ¶ï¼Œç»“åˆ change detection è¾“å‡ºã€‚
3. **è”åˆè®­ç»ƒ-éƒ¨ç½²ä¼˜åŒ–**ï¼šæ„å»ºç»Ÿä¸€æ¡†æ¶åŒæ—¶ä¼˜åŒ– $ e(t) $ å’Œ $ D_{i,j} $ã€‚
4. **åº”ç”¨äºçœŸå®ç³»ç»Ÿ**ï¼šåœ¨è¾¹ç¼˜è®¡ç®—ã€IoTã€æ¨èç³»ç»Ÿä¸­éƒ¨ç½²éªŒè¯ã€‚
5. **çº³å…¥èƒ½è€—ä¸é€šä¿¡ä»£ä»·**ï¼šå°† energy costã€latency ç­‰çº³å…¥å¤šç›®æ ‡ä¼˜åŒ–ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é¦–æ¬¡ä»**å¯é æ€§ç†è®ºä¸­çš„MRLè§†è§’**å‡ºå‘ï¼Œæ­ç¤ºäº†æ¦‚å¿µæ¼‚ç§»ä¸‹èµ„æºåˆ†é…çš„ç»“æ„æ€§æœ€ä¼˜è§„å¾‹ï¼Œå¹¶æå‡ºäº†å…¼å…·ç†è®ºä¸¥è°¨æ€§ä¸å·¥ç¨‹å¯è¡Œæ€§çš„è®­ç»ƒä¸éƒ¨ç½²ç­–ç•¥ï¼Œä¸º MLOps ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–ä¸æˆæœ¬æ•ˆç‡æä¾›äº†æ–°çš„ç†è®ºåŸºç¡€ã€‚

</details>

---

### 5. [Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments](https://arxiv.org/abs/2512.13060)

**Authors**: Kangning Gao, Yi Hu, Cong Nie, Wei Li  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.13060v1  

#### Abstract
This paper addresses the challenges of low scheduling efficiency, unbalanced resource allocation, and poor adaptability in ETL (Extract-Transform-Load) processes under heterogeneous data environments by proposing an intelligent scheduling optimization framework based on deep Q-learning. The framewor...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDeep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**å¼‚æ„æ•°æ®ç¯å¢ƒä¸‹çš„ETLï¼ˆExtract-Transform-Loadï¼‰æµç¨‹ä¸­å­˜åœ¨çš„è°ƒåº¦æ•ˆç‡ä½ã€èµ„æºåˆ†é…ä¸å‡ã€é€‚åº”æ€§å·®**ç­‰å…³é”®æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æ™ºèƒ½è°ƒåº¦ä¼˜åŒ–æ¡†æ¶ã€‚ä¼ ç»Ÿé™æ€æˆ–å¯å‘å¼è°ƒåº¦ç­–ç•¥éš¾ä»¥åº”å¯¹åŠ¨æ€ä»»åŠ¡ä¾èµ–ã€å¤šæºå¼‚æ„æ•°æ®è¾“å…¥ä»¥åŠèµ„æºç«äº‰ç­‰é—®é¢˜ï¼Œå¯¼è‡´ç³»ç»Ÿååé‡ä¸‹é™ã€å»¶è¿Ÿå¢åŠ ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
ä½œè€…æå‡ºä¸€ä¸ª**åŸºäºDeep Q-Learningï¼ˆDQLï¼‰çš„æ™ºèƒ½ETLè°ƒåº¦ä¼˜åŒ–æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- å°†ETLè°ƒåº¦è¿‡ç¨‹å»ºæ¨¡ä¸º**Markov Decision Process (MDP)**ï¼Œåˆ©ç”¨reinforcement learningå®ç°è‡ªé€‚åº”å†³ç­–ã€‚
- è®¾è®¡äº†ä¸€ä¸ªåŒ…å«**çŠ¶æ€è¡¨ç¤ºæ¨¡å—ã€ç‰¹å¾åµŒå…¥ç½‘ç»œã€Qå€¼ä¼°è®¡å™¨å’Œå¥–åŠ±è¯„ä¼°æœºåˆ¶**çš„å®Œæ•´DQNæ¶æ„ã€‚
- å¼•å…¥**å¤šç›®æ ‡å½’ä¸€åŒ–rewardå‡½æ•°**ï¼Œç»¼åˆå¹³è¡¡å¹³å‡è°ƒåº¦å»¶è¿Ÿï¼ˆASDï¼‰ã€ä»»åŠ¡å®Œæˆç‡ï¼ˆTCRï¼‰ã€ååé‡ï¼ˆTPï¼‰å’Œèµ„æºæ¶ˆè€—ï¼ˆRCï¼‰ç­‰å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ã€‚
- åˆ©ç”¨**éçº¿æ€§ç‰¹å¾æ˜ å°„å‡½æ•°**å¯¹é«˜ç»´å¼‚æ„çŠ¶æ€ç©ºé—´è¿›è¡Œæœ‰æ•ˆç¼–ç ï¼Œæå‡æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨å¾èƒ½åŠ›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
ç›¸æ¯”ä¼ ç»Ÿçš„è§„åˆ™é©±åŠ¨æˆ–å¯å‘å¼ç®—æ³•ï¼Œä»¥åŠç°æœ‰çš„RLæ–¹æ³•ï¼ˆå¦‚Q-Learningã€DDQNã€A3Cç­‰ï¼‰ï¼Œæœ¬æ–‡æå‡ºçš„DQLæ¡†æ¶å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

- èƒ½å¤Ÿåœ¨**é«˜ç»´ã€åŠ¨æ€ã€å¼‚æ„çš„çŠ¶æ€ç©ºé—´ä¸­ç¨³å®šæ”¶æ•›**ï¼Œé¿å…Qå€¼éœ‡è¡ã€‚
- æ”¯æŒ**ç«¯åˆ°ç«¯çš„è‡ªé€‚åº”è°ƒåº¦å†³ç­–**ï¼Œæ— éœ€äººå·¥å¹²é¢„å³å¯å“åº”ç¯å¢ƒå˜åŒ–ã€‚
- åœ¨å¤šèŠ‚ç‚¹å¼‚æ„é›†ç¾¤ä¸­å±•ç°å‡ºæ›´å¼ºçš„**å¯æ‰©å±•æ€§å’Œé²æ£’æ€§**ã€‚
- å®ç°äº†**å»¶è¿Ÿä¸èµ„æºåˆ©ç”¨ç‡ä¹‹é—´çš„æœ€ä¼˜æƒè¡¡**ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿæ•´ä½“æ€§èƒ½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **TPC-H Benchmark Dataset**ï¼šä½œä¸ºæ ‡å‡†æµ‹è¯•æ•°æ®æºï¼Œæ¨¡æ‹Ÿä¼ä¸šçº§æ•°æ®ä»“åº“åœºæ™¯ã€‚
  - åŒ…å«å¤šä¸ªå…³ç³»å‹è¡¨ï¼ˆå¦‚ORDERSã€CUSTOMERã€LINEITEMï¼‰ï¼Œé€šè¿‡å¤–é”®å½¢æˆå¤æ‚çš„ä¾èµ–å›¾ã€‚
  - æ•°æ®æ¶µç›–ç»“æ„åŒ–è¡¨æ ¼å’ŒåŠç»“æ„åŒ–æµå¼è®°å½•ï¼Œä½“ç°çœŸå®ç¯å¢ƒä¸­å¤šæºå¼‚æ„æ•°æ®çš„ç‰¹ç‚¹ã€‚
  - å¯è°ƒèŠ‚æ•°æ®è§„æ¨¡å’Œå¤æ‚åº¦ï¼Œæ”¯æŒä»å°è§„æ¨¡æœ¬åœ°è°ƒåº¦åˆ°å¤§è§„æ¨¡åˆ†å¸ƒå¼è°ƒåº¦çš„éªŒè¯ã€‚

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
#### å®éªŒé…ç½®ï¼š
- æ„å»ºå¤šé˜¶æ®µETLè°ƒåº¦å›¾ï¼Œæ¯ä¸ªä»»åŠ¡èŠ‚ç‚¹å¯¹åº”æ¸…æ´—ã€èšåˆã€è½¬æ¢ç­‰æ“ä½œã€‚
- æ¨¡æ‹Ÿä¸åŒè®¡ç®—èƒ½åŠ›ã€å­˜å‚¨å¸¦å®½å’Œç½‘ç»œå»¶è¿Ÿçš„å¼‚æ„èŠ‚ç‚¹é›†ç¾¤ã€‚
- AgentæŒç»­ä¸ç¯å¢ƒäº¤äº’ï¼Œå­¦ä¹ æœ€ä¼˜è°ƒåº¦ç­–ç•¥ã€‚

#### è¯„ä¼°æŒ‡æ ‡ï¼š
| ç¼©å†™ | å«ä¹‰ |
|------|------|
| **ASD â†“** | Average Scheduling Delayï¼ˆå¹³å‡è°ƒåº¦å»¶è¿Ÿï¼‰ï¼Œè¶Šå°è¶Šå¥½ |
| **TCR â†‘** | Task Completion Rateï¼ˆä»»åŠ¡å®Œæˆç‡ï¼‰ï¼Œè¶Šé«˜è¶Šå¥½ |
| **TP â†‘** | Throughputï¼ˆååé‡ï¼‰ï¼Œè¶Šé«˜è¶Šå¥½ |
| **RC â†“** | Resource Consumptionï¼ˆèµ„æºæ¶ˆè€—ï¼‰ï¼Œè¶Šä½è¶Šå¥½ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
è®ºæ–‡å¯¹æ¯”äº†å¤šç§ä¸»æµå¼ºåŒ–å­¦ä¹ è°ƒåº¦ç®—æ³•ä½œä¸ºbaselineï¼š
- **Q-Learning [15]**ï¼šç»å…¸tabularæ–¹æ³•ï¼Œé€‚ç”¨äºå°çŠ¶æ€ç©ºé—´
- **DDQN [16]**ï¼šå¼•å…¥target networkæå‡ç¨³å®šæ€§
- **A3C [17]**ï¼šå¼‚æ­¥ç­–ç•¥æ¢¯åº¦æ–¹æ³•ï¼Œæé«˜æ ·æœ¬æ•ˆç‡
- **DDPG [18]**ï¼šè¿ç»­åŠ¨ä½œç©ºé—´actor-criticæ–¹æ³•
- **SAC [19]**ï¼šåŸºäºç†µæ­£åˆ™åŒ–çš„off-policyæ–¹æ³•
- **PPO [20]**ï¼šç¨³å®šç­–ç•¥æ›´æ–°çš„on-policyæ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table 1ï¼‰
| Method | ASD â†“ | TCR â†‘ (%) | TP â†‘ | RC â†“ |
|--------|-------|-----------|------|-------|
| Q-Learning | 3.84 | 87.62 | 264.1 | 0.132 |
| DDQN | 3.22 | 90.18 | 278.4 | 0.115 |
| A3C | 3.06 | 91.25 | 283.7 | 0.109 |
| DDPG | 2.94 | 92.04 | 289.6 | 0.101 |
| SAC | 2.81 | 93.16 | 295.8 | 0.094 |
| PPO | 2.77 | 93.54 | 297.3 | 0.091 |
| **Ours (DQL-based)** | **2.43** | **95.82** | **312.7** | **0.079** |

> âœ… æ‰€æœ‰æŒ‡æ ‡å…¨é¢é¢†å…ˆï¼Œå°¤å…¶åœ¨**ASDé™ä½13.7%ã€TPæå‡çº¦5%ã€RCé™ä½13.2%**æ–¹é¢è¡¨ç°çªå‡ºã€‚

### ğŸ”¬ æ•æ„Ÿæ€§åˆ†æï¼ˆSensitivity Analysisï¼‰
#### ï¼ˆ1ï¼‰å­¦ä¹ ç‡ï¼ˆLearning Rateï¼‰å½±å“ï¼ˆFigure 2ï¼‰
- è¿‡ä½ï¼ˆâ‰¤5e-5ï¼‰ï¼šæ›´æ–°ç¼“æ…¢ï¼Œrewardå¢é•¿æ…¢ï¼›
- ä¸­ç­‰ï¼ˆ1e-4 ~ 5e-4ï¼‰ï¼šæ”¶æ•›å¿«ä¸”ç¨³å®šï¼Œrewardæœ€é«˜ï¼›
- è¿‡é«˜ï¼ˆâ‰¥1e-3ï¼‰ï¼šæ¢¯åº¦éœ‡è¡ï¼Œè®­ç»ƒä¸ç¨³å®šã€‚

ğŸ‘‰ æœ€ä½³å­¦ä¹ ç‡åŒºé—´ä¸º `1e-4` è‡³ `5e-4`ã€‚

#### ï¼ˆ2ï¼‰æŠ˜æ‰£å› å­ Î³ å¯¹ASDçš„å½±å“ï¼ˆFigure 3ï¼‰
- Î³ â‰¤ 0.85ï¼šè¿‡åº¦å…³æ³¨çŸ­æœŸæ”¶ç›Šï¼Œå¿½ç•¥é•¿æœŸä¾èµ– â†’ é«˜å»¶è¿Ÿï¼›
- Î³ â‰ˆ 0.9â€“0.95ï¼šçŸ­æœŸå“åº”ä¸é•¿æœŸè§„åˆ’å¹³è¡¡ â†’ **ASDæœ€ä½**ï¼›
- Î³ â‰¥ 0.97ï¼šè¿‡äºä¾èµ–é•¿æœŸé¢„æµ‹ï¼Œå¯¹å®æ—¶çŠ¶æ€ä¸æ•æ„Ÿ â†’ å»¶è¿Ÿå›å‡ã€‚

ğŸ‘‰ æ¨è Î³ è®¾ç½®åœ¨ **0.9~0.95** èŒƒå›´å†…ã€‚

#### ï¼ˆ3ï¼‰å¼‚æ„èŠ‚ç‚¹æ•°é‡å¯¹ASDçš„å½±å“ï¼ˆFigure 4ï¼‰
- èŠ‚ç‚¹æ•° < 8ï¼šèµ„æºä¸è¶³ï¼Œæ’é˜Ÿä¸¥é‡ â†’ é«˜å»¶è¿Ÿï¼›
- èŠ‚ç‚¹æ•° â‰ˆ 8ï¼šå¹¶è¡Œæ€§ä¸ä»»åŠ¡ç²’åº¦æœ€ä½³åŒ¹é… â†’ **ASDæœ€å°**ï¼›
- èŠ‚ç‚¹æ•° > 10ï¼šé€šä¿¡å¼€é”€ã€åŒæ­¥æˆæœ¬ä¸Šå‡ â†’ å»¶è¿Ÿå†æ¬¡å‡é«˜ã€‚

ğŸ‘‰ å­˜åœ¨â€œUå‹â€å…³ç³»ï¼Œè¡¨æ˜**å¹¶éèŠ‚ç‚¹è¶Šå¤šè¶Šå¥½**ï¼Œéœ€æƒè¡¡åˆ†å¸ƒä»£ä»·ã€‚

> â—å°½ç®¡æœªæ˜ç¡®æåŠæ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œä½†ä»å¤šç»„å‚æ•°æ•æ„Ÿæ€§åˆ†æä¸­å¯æ¨æ–­å‡ºå„ç»„ä»¶çš„é‡è¦æ€§ï¼Œä¾‹å¦‚ï¼š
> - ç‰¹å¾åµŒå…¥ç½‘ç»œæœ‰åŠ©äºæ•æ‰å¼‚æ„ç‰¹å¾é—´çš„éçº¿æ€§å…³ç³»ï¼›
> - å¤šç›®æ ‡rewardè®¾è®¡æ˜¯å®ç°å»¶è¿Ÿä¸èµ„æºå¹³è¡¡çš„å…³é”®ï¼›
> - Target networkæœºåˆ¶ä¿éšœäº†è®­ç»ƒç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Deep Q-Learningèƒ½å¤Ÿæœ‰æ•ˆè§£å†³å¼‚æ„ç¯å¢ƒä¸‹ETLè°ƒåº¦çš„å¤æ‚å†³ç­–é—®é¢˜**ï¼Œå°†è°ƒåº¦è½¬åŒ–ä¸ºMDPå»ºæ¨¡ï¼Œå®ç°äº†åŠ¨æ€è‡ªé€‚åº”ä¼˜åŒ–ã€‚
2. æ‰€ææ¡†æ¶åœ¨**å»¶è¿Ÿã€ååé‡ã€èµ„æºåˆ©ç”¨ç‡å’Œä»»åŠ¡å®Œæˆç‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰RLæ–¹æ³•**ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…æ•°æ®ç®¡é“ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚
3. é€šè¿‡åˆç†çš„rewardè®¾è®¡å’Œç½‘ç»œç»“æ„ï¼Œæ¨¡å‹èƒ½åœ¨**é«˜ç»´çŠ¶æ€ç©ºé—´ä¸­ç¨³å®šæ”¶æ•›**ï¼Œå…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚
4. å®éªŒéªŒè¯äº†**é€‚åº¦çš„å¹¶è¡Œèµ„æºè§„æ¨¡ï¼ˆçº¦8ä¸ªèŠ‚ç‚¹ï¼‰æœ€æœ‰åˆ©äºæ€§èƒ½ä¼˜åŒ–**ï¼Œè¿‡å¤šèŠ‚ç‚¹åè€Œå¼•å…¥é¢å¤–å¼€é”€ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¨¡å‹å‡è®¾ä»»åŠ¡å›¾ç»“æ„ç›¸å¯¹å›ºå®šï¼Œå¯¹äº**é¢‘ç¹å˜æ›´çš„ä»»åŠ¡æ‹“æ‰‘**å¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæˆ–å¼•å…¥meta-RLæœºåˆ¶ã€‚
- ä½¿ç”¨DQNå¤„ç†ç¦»æ•£åŠ¨ä½œç©ºé—´ï¼Œåœ¨æŸäº›ç»†ç²’åº¦èµ„æºåˆ†é…åœºæ™¯ä¸‹å¯èƒ½å­˜åœ¨è¡¨è¾¾èƒ½åŠ›é™åˆ¶ï¼ˆæœªæ¥å¯ç»“åˆDDPG/SACï¼‰ã€‚
- å®éªŒåŸºäºTPC-Hä»¿çœŸç¯å¢ƒï¼Œå°šæœªåœ¨çœŸå®ç”Ÿäº§çº§äº‘å¹³å°éƒ¨ç½²éªŒè¯ï¼Œå­˜åœ¨ä¸€å®šçš„**ç°å®å·®è·ï¼ˆsim-to-real gapï¼‰**ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. ç»“åˆ**Graph Neural Networks (GNNs)** å»ºæ¨¡ä»»åŠ¡ä¾èµ–å›¾ç»“æ„ï¼Œå¢å¼ºå¯¹åŠ¨æ€æ‹“æ‰‘å˜åŒ–çš„é€‚åº”èƒ½åŠ›ã€‚
2. å¼•å…¥**Meta-Reinforcement Learning** æˆ– **Self-Supervised Representation Learning**ï¼Œæå‡è·¨ç¯å¢ƒè¿ç§»èƒ½åŠ›ã€‚
3. æ‰©å±•è‡³**multi-agent setting**ï¼Œå®ç°è·¨åŒºåŸŸã€è·¨é›†ç¾¤çš„ååŒè°ƒåº¦ã€‚
4. åŠ å…¥**energy-aware** å’Œ **cost-aware** ç›®æ ‡ï¼ŒæœåŠ¡äºç»¿è‰²è®¡ç®—ä¸äº‘è®¡ç®—æˆæœ¬ä¼˜åŒ–ã€‚
5. æ¢ç´¢ä¸**LLM-driven workflow generation** çš„é›†æˆï¼Œæ„å»ºå…¨è‡ªåŠ¨æ™ºèƒ½data pipelineã€‚

---

## æ€»ç»“
æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº**Deep Q-Learningçš„æ™ºèƒ½ETLè°ƒåº¦æ¡†æ¶**ï¼ŒæˆåŠŸè§£å†³äº†å¼‚æ„æ•°æ®ç¯å¢ƒä¸‹è°ƒåº¦æ•ˆç‡ä½ã€èµ„æºåˆ©ç”¨ä¸å‡è¡¡ç­‰é—®é¢˜ã€‚é€šè¿‡å°†ETLè°ƒåº¦å»ºæ¨¡ä¸ºMDPï¼Œå¹¶è®¾è®¡é«˜æ•ˆçš„state representationä¸multi-objective rewardæœºåˆ¶ï¼Œè¯¥æ–¹æ³•åœ¨TPC-HåŸºå‡†ä¸Šå–å¾—äº†å…¨é¢ä¼˜äºç°æœ‰RLæ–¹æ³•çš„æ€§èƒ½è¡¨ç°ã€‚ç ”ç©¶ä¸ä»…ä¸ºæ™ºèƒ½æ•°æ®å·¥ç¨‹æä¾›äº†å¯æ‰©å±•çš„æŠ€æœ¯è·¯å¾„ï¼Œä¹Ÿä¸ºreinforcement learningåœ¨real-world data pipeline optimizationä¸­çš„è½åœ°å¥ å®šäº†åšå®åŸºç¡€ã€‚

</details>

---

### 6. [CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving](https://arxiv.org/abs/2512.11920)

**Authors**: Dong Liu, Yanxuan Yu  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.11920v1  

#### Abstract
Large Language Models (LLMs) have revolutionized natural language processing tasks, but their deployment in datacenter environments faces significant challenges due to the massive memory requirements of key-value (KV) caches. During the autoregressive decoding process, KV caches consume substantial ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•°æ®ä¸­å¿ƒæ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´**KV-cacheå†…å­˜å¢™**é—®é¢˜ã€‚åœ¨è‡ªå›å½’è§£ç é˜¶æ®µï¼ŒKey-Valueç¼“å­˜å ç”¨å¤§é‡GPUæ˜¾å­˜ï¼ˆä¾‹å¦‚LLaMA-2 70Bæ¨¡å‹å¯è¾¾640GBï¼‰ï¼Œè¿œè¶…å•å¡å®¹é‡ï¼ˆå¦‚A100ä¸º80GBï¼‰ï¼Œä¸¥é‡é™åˆ¶æ‰¹å¤„ç†å¤§å°ï¼ˆbatch sizeï¼‰å’Œç³»ç»Ÿååé‡ã€‚

ä¼ ç»Ÿæ–¹æ³•å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- **Memory offloading**ï¼ˆå¦‚FlexGenï¼‰å—é™äºPCIeå¸¦å®½ä½ã€å»¶è¿Ÿé«˜ï¼›
- **KV-cacheå‹ç¼©**ï¼ˆå¦‚INT8é‡åŒ–ï¼‰è™½èŠ‚çœå†…å­˜ä½†ç‰ºç‰²ç²¾åº¦ï¼›
- **Speculative decoding** æå‡è®¡ç®—æ•ˆç‡ä½†åŠ å‰§å†…å­˜å‹åŠ›ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **CXL-SpecKV** â€”â€”ä¸€ç§åŸºäº **CXLï¼ˆCompute Express Linkï¼‰** å’Œ **FPGAåŠ é€Ÿå™¨** çš„**è§£è€¦å¼ï¼ˆdisaggregatedï¼‰KV-cacheæ¶æ„**ï¼Œç»“åˆ**æ¨æµ‹æ€§é¢„å–ï¼ˆspeculative prefetchingï¼‰** æŠ€æœ¯ï¼Œå®ç°é«˜æ•ˆã€ä½æˆæœ¬çš„å¤§è§„æ¨¡LLMæœåŠ¡ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **CXL-based å†…å­˜è§£è€¦æ¡†æ¶**
   - åˆ©ç”¨CXL 2.0åè®®å°†KV-cacheä»GPU HBMè¿ç§»è‡³è¿œç¨‹FPGAè¿æ¥çš„é«˜å¸¦å®½å†…å­˜ï¼ˆHBMï¼‰ï¼Œæä¾›4â€“8Ã—å†…å­˜å®¹é‡æ‰©å±•ã€‚
   - æ”¯æŒç¼“å­˜ä¸€è‡´æ€§ï¼ˆcache coherenceï¼‰ï¼Œç¡®ä¿GPUä¸FPGAé—´æ•°æ®åŒæ­¥ã€‚

2. **Speculative KV-Cache Prefetching**
   - è®¾è®¡è½»é‡çº§LSTMé¢„æµ‹æ¨¡å‹ï¼ˆä»…128Kå‚æ•°ï¼‰ï¼Œæ ¹æ®å†å²tokenåºåˆ—é¢„æµ‹æœªæ¥kä¸ªtokenï¼Œå¹¶æå‰é¢„åŠ è½½å…¶å¯¹åº”çš„KV-cacheæ¡ç›®ã€‚
   - é¢„æµ‹å‡†ç¡®ç‡é«˜è¾¾95%ï¼ˆtop-4ï¼‰ï¼Œæœ‰æ•ˆéšè—CXLè®¿é—®å»¶è¿Ÿã€‚

3. **FPGAåŠ é€Ÿçš„KV-cacheå‹ç¼©å¼•æ“**
   - åœ¨FPGAä¸Šå®ç°é«˜æ•ˆçš„å‹ç¼©/è§£å‹æµæ°´çº¿ï¼Œæ”¯æŒINT8é‡åŒ– + Delta Encoding + Run-Length Encodingï¼ˆRLEï¼‰ã€‚
   - å‹ç¼©æ¯”è¾¾3â€“4Ã—ï¼Œä¸”ä¸æ¶ˆè€—GPUè®¡ç®—èµ„æºã€‚

4. **è½¯ç¡¬ä»¶ååŒè®¾è®¡ä¸ç³»ç»Ÿé›†æˆ**
   - å®Œæ•´åŸå‹ç³»ç»Ÿé›†æˆåˆ°ä¸»æµLLMæ¡†æ¶ï¼ˆvLLMã€TensorRT-LLMï¼‰ä¸­ï¼Œé€šè¿‡è‡ªå®šä¹‰å†…å­˜åˆ†é…æ’ä»¶æ— ç¼æ›¿æ¢åŸç”Ÿç®¡ç†å™¨ã€‚
   - å®ç°é€æ˜åŒ–KV-cacheç®¡ç†ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹ä»£ç ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | CXL-SpecKVä¼˜åŠ¿ |
|------|--------|----------------|
| GPU-only (vLLM) | æ˜¾å­˜æœ‰é™ï¼Œbatch sizeå—é™ | æ‰©å±•4â€“8Ã—å†…å­˜ï¼Œæ”¯æŒæ›´å¤§batch |
| CPU/Disk Offload (FlexGen) | PCIeå¸¦å®½ä½ï¼ˆ~16GB/sï¼‰ï¼Œå»¶è¿Ÿé«˜ï¼ˆ3â€“5Î¼sï¼‰ | CXLå¸¦å®½64GB/sï¼Œå»¶è¿Ÿ<400ns |
| KVå‹ç¼©ï¼ˆINT8ç­‰ï¼‰ | ç²¾åº¦æŸå¤±ï¼Œæ— æ³•çªç ´ç‰©ç†æ˜¾å­˜ä¸Šé™ | ç»“åˆå‹ç¼©+è§£è€¦ï¼Œå®ç°24Ã—æœ‰æ•ˆå®¹é‡ |
| Speculative Decodingï¼ˆMedusaç­‰ï¼‰ | å¢åŠ å¤šä¸ªå€™é€‰åºåˆ—çš„KV-cacheå‰¯æœ¬ï¼ŒåŠ é‡å†…å­˜è´Ÿæ‹… | æ¨æµ‹â€œè®¿é—®éœ€æ±‚â€è€Œéâ€œtokenå€¼â€ï¼Œäº’è¡¥ä¸”æ›´çœå†…å­˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹
- **æ¨¡å‹èŒƒå›´**ï¼šæ¶µç›–å¤šç§ä¸»æµLLMæ¶æ„ï¼Œå‚æ•°ä»1.8Båˆ°72Bï¼š
  - LLaMA-2 / LLaMA-3ï¼ˆ7Bâ€“70Bï¼‰
  - Qwenï¼ˆ1.8Bâ€“72Bï¼‰
  - Mistral / Mixtralï¼ˆMoEç»“æ„ï¼‰
  - Gemmaï¼ˆ2Bâ€“7Bï¼‰
  - CodeLLaMA / CodeQwenï¼ˆä»£ç ç”Ÿæˆï¼‰
- **æ¿€æ´»ç²¾åº¦**ï¼šFP16ï¼›æƒé‡ä½¿ç”¨SmoothQuantè¿›è¡ŒINT8é‡åŒ–ã€‚

### å·¥ä½œè´Ÿè½½ç±»å‹
å››ç§å…¸å‹åœºæ™¯ï¼Œè¾“å…¥/è¾“å‡ºé•¿åº¦ä¸åŒï¼š
- **Chatbot**ï¼š128/256
- **Summarization**ï¼š1024â€“2048 / 128â€“256
- **Code Generation**ï¼š256â€“512 / 512â€“1024
- **QA**ï¼š64â€“128 / 32â€“64  
è¯·æ±‚åˆ°è¾¾æœä»æ³Šæ¾åˆ†å¸ƒï¼ˆÎ» âˆˆ [5, 100] req/sï¼‰

---

### å®éªŒå¹³å°é…ç½®
- **GPU**ï¼š8Ã— NVIDIA A100 80GBï¼ˆHBMå¸¦å®½1.6TB/sï¼‰
- **FPGA**ï¼š4Ã— Intel Agilex-7ï¼ˆæ¯ç‰‡64GB HBMï¼ŒCXL 2.0æ§åˆ¶å™¨ï¼Œx16é“¾è·¯ï¼Œ64GB/så¸¦å®½ï¼‰
- **CPU**ï¼šåŒè·¯Sapphire Rapidsï¼ˆ96æ ¸ï¼Œ1TB DDR5ï¼‰
- **äº’è¿**ï¼šGPU â†” FPGA via PCIe Gen4 Ã—16ï¼›FPGA â†” CXLå†…å­˜æ‰©å±•å™¨

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Throughput (O)** | tokens/secï¼ˆç¨³æ€ï¼‰ |
| **Latency (L)** | TTFTï¼ˆé¦–tokenå»¶è¿Ÿï¼‰ã€decode latencyï¼ˆé€tokenå»¶è¿Ÿï¼‰ï¼Œå«median/P95/P99 |
| **Memory Efficiency** | å¯æ”¯æŒçš„æœ€å¤§batch sizeã€å•ä½è¯·æ±‚æˆæœ¬ |
| **Accuracy** | Perplexityï¼ˆWikiText-103ï¼‰ã€BLEUåˆ†æ•° vs FP16åŸºå‡† |
| **Energy Efficiency** | J/tokenï¼ˆèƒ½è€—ï¼‰ |
| **Scalability** | å¤šGPU/FPGAä¸‹çš„å¹¶è¡Œæ•ˆç‡ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **GPU-Only** | ä½¿ç”¨vLLMï¼Œé»˜è®¤HBMå­˜å‚¨KV-cache |
| **CPU Offload** | FlexGenæ–¹æ¡ˆï¼Œé€šè¿‡PCIeå°†KV-cacheå¸è½½è‡³CPUå†…å­˜ |
| **NVMe Offload** | å¸è½½è‡³SSDï¼Œæˆæœ¬ä½ä½†å»¶è¿Ÿæé«˜ |
| **Compression-Only** | GPUæœ¬åœ°INT8å‹ç¼©ï¼Œæ— è§£è€¦ |
| **CXL-NoSpec** | æœ¬ç³»ç»Ÿä½†å…³é—­æ¨æµ‹é¢„å–åŠŸèƒ½ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥LLaMA-2 70Bä¸ºä¾‹ï¼‰

| æŒ‡æ ‡ | CXL-SpecKV | GPU-Only | æå‡/å˜åŒ– |
|------|------------|----------|-----------|
| **Throughput** | 1,549 tokens/s | 487 tokens/s | **â†‘3.2Ã—** |
| **Max Batch Size** | 128 | 16 | **â†‘8Ã—** |
| **Decode Latency** | 19.8 ms | 18.3 ms | +8.2% |
| **P99 Latency** | 23.8 ms | 21.2 ms | +12.3% |
| **TTFT** | 47.1 ms | 45.2 ms | +4.2% |
| **Memory Cost per Request** | â€” | â€” | **â†“2.8Ã—** |
| **Energy Efficiency (J/token)** | 0.340 | 0.647 | **â†‘1.90Ã— æ›´ä¼˜** |
| **Parallel Efficiency @8 GPUs** | â€” | â€” | **87%** |

> æ³¨ï¼šå¯ç”¨å‹ç¼©åï¼ˆCXL-SpecKV+Compï¼‰ï¼Œæœ€å¤§batchå¯è¾¾384ï¼ˆ**24Ã—æ‰©å±•**ï¼‰

---

### ä¸å„åŸºçº¿å¯¹æ¯”ç»“æœ
- **vs GPU-Only**ï¼šå¹³å‡**2.4Ã—ååæå‡**ï¼ˆ2.1â€“3.2Ã—åŒºé—´ï¼‰ï¼Œå°¤å…¶å¯¹å¤§æ¨¡å‹æ˜¾è‘—ã€‚
- **vs CPU Offload**ï¼š**4.3Ã—æ›´é«˜åå**ï¼Œå¾—ç›ŠäºCXLæ›´é«˜å¸¦å®½ï¼ˆ64GB/s vs 16GB/sï¼‰å’Œæ›´ä½å»¶è¿Ÿã€‚
- **vs Compression-Only**ï¼šä»é«˜å‡º**1.8â€“2.3Ã—**ï¼Œå› åè€…å—GPUç‰©ç†å†…å­˜é™åˆ¶ã€‚
- **vs CXL-NoSpec**ï¼š**1.6â€“2.1Ã—æ€§èƒ½å¢ç›Š**ï¼Œè¯æ˜æ¨æµ‹é¢„å–æ˜¯éšè—å»¶è¿Ÿçš„å…³é”®ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æ¨æµ‹é¢„å–æ·±åº¦ $k$ å½±å“ï¼ˆTable 8ï¼‰
| $k$ | Hit Rate (%) | Precision (%) | Throughput (tok/s) |
|-----|--------------|---------------|--------------------|
| 1 | 87.2 | 96.1 | 1,287 |
| 2 | 92.3 | 93.5 | 1,426 |
| **4** | **94.7** | **87.2** | **1,549** âœ… |
| 8 | 95.8 | 78.3 | 1,573 |
| 16 | 96.4 | 68.7 | 1,581 |

> æœ€ä½³å¹³è¡¡ç‚¹ä¸º $k=4$ï¼Œç»§ç»­å¢åŠ æ”¶ç›Šé€’å‡ä¸”æµªè´¹å¸¦å®½ã€‚

#### ï¼ˆ2ï¼‰å‹ç¼©ç»„ä»¶æ¶ˆèï¼ˆTable 9ï¼‰
| æ–¹æ¡ˆ | å‹ç¼©æ¯” | Perplexity å¢åŠ  |
|------|--------|------------------|
| FP16ï¼ˆæ— å‹ç¼©ï¼‰ | 1.00Ã— | 0% |
| INT8 Only | 2.00Ã— | +0.6% |
| +Delta Encoding | 2.73Ã— | +0.9% |
| **+RLEï¼ˆå®Œæ•´ï¼‰** | **3.21Ã—** | **+1.2%** âœ… |

> Deltaç¼–ç è´¡çŒ®æœ€å¤§ï¼ˆ+36%å‹ç¼©æ¯”ï¼‰ï¼ŒRLEè¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å†…å­˜è§£è€¦ + æ¨æµ‹é¢„å–å¯æœ‰æ•ˆçªç ´LLMæ¨ç†å†…å­˜ç“¶é¢ˆ**  
   CXL-SpecKVé¦–æ¬¡å°†CXLç”¨äºLLM KV-cacheç®¡ç†ï¼ŒéªŒè¯äº†è§£è€¦æ¶æ„åœ¨AIæ¨ç†ä¸­çš„å¯è¡Œæ€§ã€‚

2. **æ¨æµ‹æ€§é¢„å–èƒ½é«˜æ•ˆéšè—CXLå»¶è¿Ÿ**  
   è½»é‡LSTMæ¨¡å‹å®ç°95%é¢„æµ‹å‡†ç¡®ç‡ï¼Œä½¿å†…å­˜è®¿é—®æ—¶é—´ä»8.7msï¼ˆCXL-NoSpecï¼‰é™è‡³2.1msï¼Œ**æ©ç›–76%å»¶è¿Ÿå¼€é”€**ã€‚

3. **FPGAåŠ é€Ÿå‹ç¼©æ˜¾è‘—é™ä½å¸¦å®½å‹åŠ›**  
   3â€“4Ã—å‹ç¼©æ¯”å‡è½»CXLé“¾è·¯è´Ÿæ‹…ï¼Œä½¿å…¶ä¸å†æ˜¯ç³»ç»Ÿç“¶é¢ˆã€‚

4. **æˆæœ¬æ•ˆç›Šæ˜¾è‘—æå‡**  
   ä½¿ç”¨å»‰ä»·FPGAæ‰©å±•å†…å­˜ï¼Œç›¸æ¯”å…¨é«˜ç«¯GPUé›†ç¾¤ï¼Œ**åŸºç¡€è®¾æ–½æˆæœ¬é™ä½30â€“40%**ï¼Œæ€§ä»·æ¯”æå‡1.75â€“2.2Ã—ã€‚

5. **è‰¯å¥½å¯æ‰©å±•æ€§**  
   åœ¨8-GPUé…ç½®ä¸‹è¾¾åˆ°87%å¹¶è¡Œæ•ˆç‡ï¼Œæ”¯æŒå¤§è§„æ¨¡éƒ¨ç½²ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–CXLç¡¬ä»¶ç”Ÿæ€æ™®åŠ**ï¼šå½“å‰CXLè®¾å¤‡å°šæœªå¹¿æ³›éƒ¨ç½²ï¼Œéœ€å‚å•†æ”¯æŒã€‚
2. **é¢„æµ‹é”™è¯¯å¯¼è‡´å¸¦å®½æµªè´¹**ï¼šè™½ç„¶ç²¾åº¦é«˜ï¼Œä½†ä»æœ‰çº¦13%çš„prefetchæœªè¢«ä½¿ç”¨ã€‚
3. **FPGAå¼€å‘é—¨æ§›è¾ƒé«˜**ï¼šRTLè®¾è®¡ä¸ç»¼åˆéœ€è¦ä¸“ä¸šçŸ¥è¯†ï¼Œå½±å“æ¨å¹¿é€Ÿåº¦ã€‚
4. **å¤šç§Ÿæˆ·éš”ç¦»æœºåˆ¶æœªæ·±å…¥æ¢è®¨**ï¼šå…±äº«CXLå†…å­˜æ± æ—¶çš„å®‰å…¨ä¸QoSä¿éšœæœ‰å¾…åŠ å¼ºã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **åŠ¨æ€ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶é€‚é…**ï¼šç»“åˆactivation sparsityè¿›ä¸€æ­¥å‡å°‘KV-cacheä½“ç§¯ã€‚
2. **é•¿ä¸Šä¸‹æ–‡ä¼˜åŒ–ï¼ˆ32Kâ€“128Kï¼‰**ï¼šé‡‡ç”¨åˆ†å±‚é¢„æµ‹ç­–ç•¥åº”å¯¹æ›´å¤æ‚è®¿é—®æ¨¡å¼ã€‚
3. **è®­ç»ƒ/å¾®è°ƒåœºæ™¯æ‰©å±•**ï¼šæ”¯æŒåŒå‘æ³¨æ„åŠ›ä¸æ¢¯åº¦æ›´æ–°ã€‚
4. **CXL 3.0å‡çº§**ï¼šåˆ©ç”¨128GB/så¸¦å®½ä¸memory-side cachingèƒ½åŠ›ã€‚
5. **å¼‚æ„å†…å­˜å±‚çº§**ï¼šèåˆHBM/DDR/NVMæ„å»ºå¤šçº§å­˜å‚¨ä½“ç³»ã€‚
6. **å®‰å…¨ä¸éš”ç¦»æœºåˆ¶**ï¼šé˜²æ­¢è·¨ç§Ÿæˆ·å†…å­˜æ³„éœ²ï¼Œæ”¯æŒå¤šç§Ÿæˆ·QoSã€‚
7. **ä¸å…¶ä»–äº’è”æŠ€æœ¯æ¯”è¾ƒ**ï¼šå¦‚NVLink-C2Cã€Infinity Fabricç­‰ã€‚

---

> âœ… **å¼€æºä¿¡æ¯**ï¼šä½œè€…å·²å°†ä»£ç å¼€æº â†’ [GitHubé“¾æ¥](https://github.com/FastLM/CXL-SpecKV)

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼šCXL-SpecKVé€šè¿‡**CXLå†…å­˜è§£è€¦ + FPGAå‹ç¼© + æ¨æµ‹é¢„å–**ä¸‰ä½ä¸€ä½“è®¾è®¡ï¼Œåœ¨å‡ ä¹ä¸å½±å“ç²¾åº¦çš„å‰æä¸‹ï¼Œå®ç°äº†**3.2Ã—ååæå‡ã€8Ã—å†…å­˜æ‰©å±•ã€2.8Ã—æˆæœ¬ä¸‹é™**ï¼Œä¸ºä¸‹ä¸€ä»£æ•°æ®ä¸­å¿ƒLLMæœåŠ¡æä¾›äº†é«˜æ•ˆã€å¯æŒç»­çš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 7. [FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection](https://arxiv.org/abs/2512.12949)

**Authors**: Ziyu Huang, Yangjie Zhou, Zihan Liu, Xinhao Luo, Yijia Diao, Minyi Guo, Jidong Zhai, Yu Feng, Chen Zhang, Anbang Wu, Jingwen Leng  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.12949v1  

#### Abstract
The scaling of computation throughput continues to outpace improvements in memory bandwidth, making many deep learning workloads memory-bound. Kernel fusion is a key technique to alleviate this problem, but the fusion strategies of existing compilers and frameworks are limited to using local scratch...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå°¤å…¶æ˜¯å¤§è¯­è¨€æ¨¡å‹ LLM å’Œå·ç§¯ç¥ç»ç½‘ç»œ CNNï¼‰ä¸­ï¼Œ**è®¡ç®—ååé‡çš„å¢é•¿è¿œè¶…å†…å­˜å¸¦å®½çš„å¢é•¿**ï¼Œå¯¼è‡´è®¸å¤šå·¥ä½œè´Ÿè½½æˆä¸º **memory-bound**ï¼ˆå†…å­˜ç“¶é¢ˆï¼‰ã€‚å°½ç®¡ **kernel fusion** æ˜¯ç¼“è§£è¯¥é—®é¢˜çš„æœ‰æ•ˆæ‰‹æ®µï¼Œä½†ç°æœ‰ç¼–è¯‘å™¨å’Œæ¡†æ¶å—é™äºå•ä¸ª SMï¼ˆStreaming Multiprocessorï¼‰çš„ **shared memory (SMEM)** å®¹é‡ï¼Œå½“ä¸­é—´ç»“æœè¿‡å¤§æ—¶ï¼ˆå¦‚ FFN å±‚ï¼‰ï¼Œæ— æ³•è¿›è¡Œèåˆï¼Œå¿…é¡»å›é€€åˆ°å…¨å±€å†…å­˜ï¼ˆglobal memoryï¼‰ï¼Œé€ æˆå¤§é‡å†—ä½™çš„æ•°æ®è¯»å†™ã€‚

æ­¤å¤–ï¼Œè™½ç„¶ç°ä»£ GPUï¼ˆå¦‚ NVIDIA H100ï¼‰å¼•å…¥äº† **Distributed Shared Memory (DSM)**ï¼Œé€šè¿‡å¤š SM é—´çš„äº’è¿æä¾›æ›´å¤§ã€æ›´é«˜å¸¦å®½ã€æ›´ä½å»¶è¿Ÿçš„ç‰‡ä¸Šå†…å­˜æ± ï¼Œä½†å½“å‰è½¯ä»¶æ¡†æ¶å°šæœªæœ‰æ•ˆåˆ©ç”¨è¿™ä¸€ç¡¬ä»¶ç‰¹æ€§ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä¸ºå¡«è¡¥ç¡¬ä»¶æ½œåŠ›ä¸è½¯ä»¶èƒ½åŠ›ä¹‹é—´çš„é¸¿æ²Ÿï¼Œæœ¬æ–‡æå‡º **FlashFuser**ï¼Œè¿™æ˜¯é¦–ä¸ªåœ¨ç°ä»£ GPU ä¸Šåˆ©ç”¨ **inter-core connection**ï¼ˆå³ DSMï¼‰å®ç°å¤§è§„æ¨¡ kernel fusion çš„ç¼–è¯‘å™¨æ¡†æ¶ã€‚å…¶ä¸‰å¤§æ ¸å¿ƒè´¡çŒ®å¦‚ä¸‹ï¼š

#### **(1) åŸºäº DSM çš„é€šä¿¡æŠ½è±¡ `dsm_comm` primitive**
- æå‡ºäº†ä¸€å¥—ç»Ÿä¸€çš„é€šä¿¡åŸè¯­ï¼ˆå¦‚ `dsm_all_exchange`, `dsm_shuffle`, `dsm_reduce_scatter`ï¼‰ï¼Œç”¨äºå½¢å¼åŒ–æè¿°åŸºäºé›†ç¾¤ï¼ˆclusterï¼‰çš„å¤æ‚æ•°æ®äº¤æ¢æ¨¡å¼ï¼ˆå¦‚ reduceã€shuffleã€multiplyï¼‰ã€‚
- æ”¯æŒçµæ´»é…ç½® **cluster size** å’Œ **shuffle/reduce ç»´åº¦**ï¼Œé€‚åº”ä¸åŒé—®é¢˜è§„æ¨¡å’Œç¡¬ä»¶æ‹“æ‰‘ã€‚

#### **(2) æ•°æ®æµåˆ†æå™¨ï¼ˆDataflow Analyzerï¼‰**
- å°†ä¼ ç»Ÿçš„ loop schedulingã€èµ„æºæ˜ å°„å’Œ tile é€‰æ‹©æ‰©å±•åˆ°åˆ†å¸ƒå¼å†…å­˜å±‚æ¬¡ï¼ˆregister â†’ SMEM â†’ DSM â†’ L2/globalï¼‰ã€‚
- èƒ½å¤Ÿé‡åŒ–è·¨å†…å­˜å±‚çº§çš„æ•°æ®ç§»åŠ¨å¼€é”€ï¼Œå¹¶å†³å®šæœ€ä¼˜çš„æ‰§è¡Œé¡ºåºå’Œ tile å¤§å°ï¼Œå®ç°ä»é«˜é€Ÿç¼“å­˜å‘ä½é€Ÿç¼“å­˜çš„æ¸è¿›å¼æº¢å‡ºï¼ˆspillingï¼‰ã€‚

#### **(3) èåˆæœç´¢å¼•æ“ï¼ˆFusion Search Engineï¼‰**
- æ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆçš„æœç´¢ç³»ç»Ÿï¼Œç»“åˆ **è§£æå¼æˆæœ¬æ¨¡å‹**ï¼ˆanalytical cost modelï¼‰å’Œ **DSM-aware çš„å‰ªæç­–ç•¥**ï¼Œåœ¨ç”± DSM å¼•å…¥çš„å·¨å¤§æœç´¢ç©ºé—´ä¸­å¿«é€Ÿæ‰¾åˆ°æœ€ä¼˜æ‰§è¡Œè®¡åˆ’ã€‚
- æ˜¾è‘—é™ä½äº†ä¼ ç»Ÿæš´åŠ›æœç´¢çš„æ—¶é—´å¼€é”€ï¼ˆåŠ é€Ÿ 12â€“68 å€ï¼‰ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç‰¹æ€§ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Chimera, BOLTï¼‰ | FlashFuser |
|------|-------------------------------|-----------|
| å†…å­˜å±‚çº§æ”¯æŒ | ä»… reg / SMEM | æ”¯æŒ reg / SMEM / **DSM** |
| èåˆèŒƒå›´ | å—é™äºå• SM çš„ SMEM å®¹é‡ | åˆ©ç”¨ DSM æ‰©å±•èåˆè¾¹ç•Œï¼Œæ”¯æŒæ›´å¤§ç®—å­é“¾ |
| é€šä¿¡å»ºæ¨¡ | å¿½ç•¥è·¨ SM é€šä¿¡ | æ˜¾å¼å»ºæ¨¡ DSM é€šä¿¡æ¨¡å¼ä¸å¼€é”€ |
| æœç´¢æ•ˆç‡ | æ‰‹åŠ¨è°ƒä¼˜æˆ–æœ‰é™æ¢ç´¢ | åˆ†æé©±åŠ¨ + é«˜æ•ˆå‰ªæï¼Œè‡ªåŠ¨åŒ–å¯»ä¼˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸å­å›¾é…ç½®**

å®éªŒè¦†ç›–å¤šç§å…¸å‹è®¡ç®—å¯†é›†å‹ç®—å­é“¾ï¼Œå…·ä½“é…ç½®è§ä¸‹è¡¨ï¼š

| ç±»å‹ | ç¤ºä¾‹æ¨¡å‹/ä»»åŠ¡ | é…ç½®æ¥æº |
|------|----------------|----------|
| **GEMM Chain** | GPT-6.7B, OPT-1.3B, BERT, DLRM ç­‰ | Table VII |
| **Convolution Chain** | ResNet é£æ ¼å·ç§¯å—ï¼ˆå¦‚ conv1x1 + conv3x3ï¼‰ | Table V |
| **Gated FFN** | LLaMA, Qwen ç³»åˆ—æ¨¡å‹ä¸­çš„ SwiGLU ç»“æ„ | Table VI |

æ‰€æœ‰æµ‹è¯•å‡ä»¥ **sequence length = 128 æˆ– 256** è¿›è¡Œæ¨ç†åœºæ™¯æ¨¡æ‹Ÿã€‚

### **å®éªŒå¹³å°**

- **ç¡¬ä»¶**ï¼šNVIDIA H100 GPU (SXM)ï¼ŒåŒè·¯ Intel Xeon Platinum 8468 CPU
- **è½¯ä»¶æ ˆ**ï¼šCUDA 12.4, PyTorch 2.6, TVM 0.9, Triton 3.2, Nsight Compute 2025.2.0

### **è¯„ä¼°æŒ‡æ ‡**

- **æ€§èƒ½åŠ é€Ÿæ¯”**ï¼ˆSpeedupï¼‰ï¼šç›¸å¯¹äºåŸºçº¿çš„è¿è¡Œæ—¶é—´æå‡
- **å…¨å±€å†…å­˜è®¿é—®é‡**ï¼ˆGlobal Memory Accessï¼‰
- **TFLOPS**ï¼šå®é™…è¾¾åˆ°çš„è®¡ç®—åå
- **ç«¯åˆ°ç«¯æ¨ç†é€Ÿåº¦**ï¼ˆEnd-to-End Inference Speedupï¼‰
- **ç¼–è¯‘æ—¶é—´å¼€é”€**ï¼ˆCompilation Overheadï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|------|--------|
| **åº“çº§ä¼˜åŒ–** | PyTorch (with `torch.compile`), NVIDIA TensorRT |
| **ç ”ç©¶å‹ç¼–è¯‘å™¨** | TVM/Relay, TASO, BOLT, Chimera |
| **å…¶ä»–** | SGLangï¼ˆç”¨äºç«¯åˆ°ç«¯è¯„ä¼°ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **å¹³å‡ kernel åŠ é€Ÿæ¯”ï¼ˆvs. é«˜åº¦è°ƒä¼˜åº“ï¼‰** | **3.3Ã—** |
| **å¹³å‡ kernel åŠ é€Ÿæ¯”ï¼ˆvs. SOTA ç¼–è¯‘å™¨ï¼‰** | **4.1Ã—** |
| **å…¨å±€å†…å­˜è®¿é—®å‡å°‘** | **58%** |
| **ç«¯åˆ°ç«¯æ¨ç†åŠ é€Ÿ** | **1.24Ã—** |

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### **GEMM Chainsï¼ˆå›¾10aï¼‰**
- FlashFuser å¹³å‡ä¼˜äºï¼š
  - BOLT: **5.4Ã—**
  - Chimera: **4.6Ã—**
  - Relay: **4.7Ã—**
  - TASO: **3.4Ã—**
  - TensorRT: **2.4Ã—**
  - PyTorch: **3.1Ã—**
- åœ¨ GPT-6.7B ç­‰å¤§æ¨¡å‹ä¸Šï¼ŒChimera å› è¶…å‡º SMEM å®¹é‡è€Œ **fusion å¤±è´¥**ï¼ŒFlashFuser æˆåŠŸèåˆå¹¶æ˜¾è‘—æé€Ÿã€‚

#### **Convolution Chainsï¼ˆå›¾10bï¼‰**
- FlashFuser å¹³å‡ä¼˜äºï¼š
  - BOLT: **6.3Ã—**
  - Chimera: **6.4Ã—**
  - å…¶ä»–éèåˆæ–¹æ³•ï¼š3.3Ã—â€“5.6Ã—
- å¯¹äºå¤§å°ºå¯¸å·ç§¯ï¼ŒBOLT å’Œ Chimera å‡æ”¾å¼ƒèåˆï¼ŒFlashFuser åˆ©ç”¨ DSM æˆåŠŸç»´æŒèåˆã€‚

#### **Gated FFNï¼ˆå›¾10cï¼‰**
- FlashFuser åœ¨å¤æ‚åˆ†æ”¯ç»“æ„ï¼ˆå¦‚ SwiGLUï¼‰ä¸­ä»ä¿æŒé«˜æ•ˆèåˆï¼Œæ€§èƒ½é¢†å…ˆæ˜æ˜¾ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆå›¾15ï¼‰**

å¯¹ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶è¿›è¡Œéš”ç¦»æµ‹è¯•ï¼ˆä»¥ no-fusion ä¸ºåŸºå‡†ï¼‰ï¼š

| é…ç½® | åŠ é€Ÿæ¯” |
|------|--------|
| **DA**ï¼ˆä»…ä½¿ç”¨ SMEM/globalï¼‰ | 1.52Ã— |
| **DC + DA**ï¼ˆå›ºå®šé…ç½®ï¼Œå« DSMï¼‰ | 2.11Ã— |
| **All**ï¼ˆå®Œæ•´ FlashFuserï¼‰ | **3.29Ã—** |

è¯´æ˜ï¼š
- DSM æœ¬èº«å¸¦æ¥æ˜¾è‘—æ”¶ç›Šï¼ˆ1.52Ã— â†’ 2.11Ã—ï¼‰
- æœç´¢å¼•æ“ä¸æˆæœ¬æ¨¡å‹è¿›ä¸€æ­¥é‡Šæ”¾æ½œåŠ›ï¼ˆ2.11Ã— â†’ 3.29Ã—ï¼‰

### **å…¶ä»–éªŒè¯å®éªŒ**

- **æˆæœ¬æ¨¡å‹æœ‰æ•ˆæ€§**ï¼ˆå›¾12aï¼‰ï¼šTop-11 é…ç½®ä¸­ï¼Œæˆæœ¬æ¨¡å‹èƒ½ç¨³å®šé€‰å‡ºæœ€ä¼˜æˆ–è¿‘ä¼˜æ–¹æ¡ˆã€‚
- **ç¼–è¯‘æ•ˆç‡**ï¼ˆè¡¨ VIIIï¼‰ï¼šç›¸æ¯”æš´åŠ›æœç´¢ï¼Œæœç´¢å¼•æ“åŠ é€Ÿ **12.25Ã— ~ 68.26Ã—**ã€‚
- **DSM åŸè¯­æ€§èƒ½**ï¼ˆå›¾13ï¼‰ï¼š`dsm_shuffle`ã€`dsm_mul`ã€`dsm_reduce` åœ¨ä¸åŒ cluster size ä¸‹å‡ä¿æŒé«˜å¸¦å®½åˆ©ç”¨ç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **DSM æ˜¯çªç ´ kernel fusion è§„æ¨¡é™åˆ¶çš„å…³é”®**ï¼šé€šè¿‡å°†å¤šä¸ª SM çš„ SMEM è”é€šå½¢æˆæ›´å¤§çš„ç‰‡ä¸Šå†…å­˜æ± ï¼ŒFlashFuser æˆåŠŸå®ç°äº†ä¼ ç»Ÿæ–¹æ³•æ— æ³•å®Œæˆçš„å¤§è§„æ¨¡ç®—å­èåˆï¼ˆå¦‚ FFNï¼‰ã€‚
2. **æ˜¾å¼å»ºæ¨¡è·¨æ ¸é€šä¿¡è‡³å…³é‡è¦**ï¼š`dsm_comm` æŠ½è±¡ä½¿å¾—ç¼–è¯‘å™¨èƒ½å¤Ÿç²¾ç¡®æ§åˆ¶æ•°æ®åˆ†å¸ƒä¸äº¤æ¢æ¨¡å¼ï¼Œé¿å…ç›²ç›®ä¾èµ–å…¨å±€å†…å­˜ã€‚
3. **åˆ†æé©±åŠ¨çš„æœç´¢ä¼˜äºå¯å‘å¼è°ƒä¼˜**ï¼šç»“åˆæˆæœ¬æ¨¡å‹ä¸å‰ªæè§„åˆ™ï¼Œå¯åœ¨å·¨å¤§æœç´¢ç©ºé—´ä¸­é«˜æ•ˆå®šä½æœ€ä¼˜è§£ï¼Œä¸”æ— éœ€äººå·¥å¹²é¢„ã€‚
4. **æ€§èƒ½æå‡æºäºå†…å­˜è®¿é—®å‡å°‘**ï¼šFlashFuser å‡å°‘ 58% çš„å…¨å±€å†…å­˜è®¿é—®ï¼Œæ˜¯å…¶è·å¾— 3.3Ã—â€“4.1Ã— kernel åŠ é€Ÿçš„æ ¸å¿ƒåŸå› ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- å½“å‰å®ç°åŸºäº **NVIDIA H100** æ¶æ„ï¼Œè™½è®¾è®¡ä¸Šå…·æœ‰æ‹“æ‰‘æ— å…³æ€§ï¼ˆtopology-agnosticï¼‰ï¼Œä½†åœ¨ mesh æ¶æ„ï¼ˆå¦‚ Cerebrasï¼‰ä¸Šçš„æ˜ å°„ä»éœ€é€‚é…ã€‚
- ä»…é’ˆå¯¹ **compute-intensive operators**ï¼ˆå¦‚ GEMMã€Convï¼‰è¿›è¡Œäº†ä¼˜åŒ–ï¼Œæœªæ¶‰åŠé«˜åº¦ irregular çš„æ“ä½œï¼ˆå¦‚ sparse attentionï¼‰ã€‚
- ç¼–è¯‘é˜¶æ®µä»æœ‰ä¸€å®šå¼€é”€ï¼Œå°½ç®¡å·²é€šè¿‡ **binning + lookup table** å®ç°è¿è¡Œæ—¶å¿«é€Ÿé€‰æ‹©ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- å°† FlashFuser æ‰©å±•è‡³æ›´å¤šç®—å­ç±»å‹ï¼ˆå¦‚ attentionã€layernormï¼‰å’Œæ›´å¤æ‚çš„ DAG ç»“æ„ã€‚
- æ¢ç´¢åœ¨ **multi-GPU** åœºæ™¯ä¸‹ååŒåˆ©ç”¨ DSM ä¸ NVLink çš„å¯èƒ½æ€§ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ– `dsm_comm` åŸè¯­çš„åº•å±‚å®ç°ï¼Œæå‡å°ç²’åº¦é€šä¿¡æ•ˆç‡ã€‚
- å°†è¯¥æ€æƒ³æ¨å¹¿è‡³å…¶ä»–æ”¯æŒ inter-core connection çš„ AI åŠ é€Ÿå™¨ï¼ˆå¦‚ Graphcore IPUã€Cerebras WSEï¼‰ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> FlashFuser é¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°† **DSM** å¼•å…¥ kernel fusion ç¼–è¯‘å™¨ï¼Œé€šè¿‡ **é€šä¿¡æŠ½è±¡ + æ•°æ®æµåˆ†æ + é«˜æ•ˆæœç´¢** ä¸‰é‡æœºåˆ¶ï¼Œåœ¨ H100 ä¸Šå®ç°äº†é«˜è¾¾ **4.1Ã— çš„ kernel åŠ é€Ÿ** å’Œ **1.24Ã— çš„ç«¯åˆ°ç«¯æé€Ÿ**ï¼Œä¸ºè§£å†³ç°ä»£ GPU çš„â€œå†…å­˜å¢™â€é—®é¢˜æä¾›äº†æ–°çš„è½¯ä»¶èŒƒå¼ã€‚

</details>

---

### 8. [Context-Aware Agentic Power Resources Optimisation in EV using Smart2ChargeApp](https://arxiv.org/abs/2512.12048)

**Authors**: Muddsair Sharif, Huseyin Seker  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.12048v1  

#### Abstract
This paper presents a novel context-sensitive multi\-agent coordination for dynamic resource allocation (CAMAC-DRA) framework for optimizing smart electric vehicle (EV) charging ecosystems through the Smart2Charge application. The proposed system coordinates autonomous charging agents across network...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šContext-Aware Agentic Power Resources Optimisation in EV using Smart2Charge App

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ç”µåŠ¨æ±½è½¦ï¼ˆEVï¼‰å……ç”µç”Ÿæ€ç³»ç»Ÿé¢ä¸´å¤šæ™ºèƒ½ä½“åè°ƒä¸è¶³ã€èµ„æºåˆ†é…ä½æ•ˆã€åˆ©ç›Šç›¸å…³æ–¹ç›®æ ‡å†²çªç­‰é—®é¢˜ã€‚ä¼ ç»Ÿé›†ä¸­å¼ä¼˜åŒ–æ–¹æ³•éš¾ä»¥åº”å¯¹åŠ¨æ€ç¯å¢ƒä¸‹çš„å®æ—¶å†³ç­–éœ€æ±‚ï¼Œå°¤å…¶åœ¨æ•´åˆå¤©æ°”ã€äº¤é€šã€ç”µç½‘è´Ÿè·ã€ç”µä»·ç­‰**å¤šç»´ä¸Šä¸‹æ–‡ä¿¡æ¯**æ—¶è¡¨ç°ä¸ä½³ã€‚æ­¤å¤–ï¼Œç°æœ‰ç³»ç»Ÿå¾€å¾€å¿½è§†å¯¹**å¤šæ–¹åˆ©ç›Šç›¸å…³è€…**ï¼ˆå¦‚ç”¨æˆ·ã€ç”µç½‘è¿è¥å•†ã€å……ç”µç«™è¿è¥å•†ã€è½¦é˜Ÿç®¡ç†è€…ã€ç¯å¢ƒå› ç´ ï¼‰çš„ç»¼åˆæƒè¡¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **CAMAC-DRA**ï¼ˆContext-Aware Multi-Agent Coordination for Dynamic Resource Allocationï¼‰çš„æ¡†æ¶ï¼Œå¹¶é€šè¿‡ **Smart2Charge App** å®ç°å…¶åº”ç”¨ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **Context-Aware Multi-Agent Coordination Framework (CAMAC-DRA)**  
  æ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„åˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“åè°ƒæ¶æ„ï¼Œç»“åˆ **Graph Neural Networks (GNN)** å’Œ **æ³¨æ„åŠ›æœºåˆ¶**ï¼Œå®ç°å¯¹250è¾†EVå’Œ45ä¸ªå……ç”µç«™çš„å¤§è§„æ¨¡åè°ƒã€‚ç³»ç»Ÿèƒ½å®æ—¶æ„ŸçŸ¥å¹¶å“åº”20ç§ä¸Šä¸‹æ–‡ç‰¹å¾ï¼ˆå¦‚å¤©æ°”ã€äº¤é€šã€ç”µç½‘è´Ÿè½½ã€ç”µä»·ã€å¯å†ç”Ÿèƒ½æºå¯ç”¨æ€§ç­‰ï¼‰ï¼Œè¿›è¡Œè‡ªé€‚åº”å†³ç­–ã€‚

- **Multi-Stakeholder State-Action-Reward Formalization**  
  é¦–æ¬¡å½¢å¼åŒ–å®šä¹‰äº†äº”ç±»åˆ©ç›Šç›¸å…³è€…çš„çŠ¶æ€-åŠ¨ä½œ-å¥–åŠ±ç©ºé—´ï¼Œå¹¶å¼•å…¥åŠ æƒåè°ƒæœºåˆ¶ï¼š
  - EVç”¨æˆ·ï¼ˆ25%ï¼‰
  - ç”µç½‘è¿è¥å•†ï¼ˆ20%ï¼‰
  - å……ç”µç«™è¿è¥å•†ï¼ˆ20%ï¼‰
  - è½¦é˜Ÿè¿è¥å•†ï¼ˆ20%ï¼‰
  - ç¯å¢ƒå› ç´ ï¼ˆ15%ï¼‰  
  é€šè¿‡åŠ¨æ€è°ƒæ•´æƒé‡å’Œå…±è¯†åè®®ï¼Œå¹³è¡¡å„æ–¹ç«äº‰æ€§ç›®æ ‡ã€‚

- **Smart2Charge DRL Algorithm**  
  è®¾è®¡äº†ä¸€ç§æ–°å‹æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆCAMA-DRLï¼‰ï¼Œèåˆä»¥ä¸‹æŠ€æœ¯ï¼š
  - åŸºäº **Upper Confidence Bound (UCB)** çš„ä¸Šä¸‹æ–‡æ¢ç´¢ç­–ç•¥
  - åŠ¨æ€å¥–åŠ±è®¡ç®—æ¨¡å—ï¼Œå¤„ç†20ç»´ä¸Šä¸‹æ–‡è¾“å…¥
  - å¤šå¤´Qç½‘ç»œï¼ˆMulti-Head Q-Networkï¼‰ç»“æ„ï¼Œæ”¯æŒå„åˆ©ç›Šæ–¹ç‹¬ç«‹ä¼˜åŒ–
  - å¼•å…¥ **ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆoffline RLï¼‰** æŠ€æœ¯ä»¥æå‡è®­ç»ƒç¨³å®šæ€§

- **Hierarchical Coordination Protocol**  
  é‡‡ç”¨ä¸¤é˜¶æ®µåè°ƒæœºåˆ¶ï¼š
  - ä¸Šå±‚ä½¿ç”¨ **Particle Swarm Optimization (PSO)** è¿›è¡ŒåŒºåŸŸç”µåŠ›åˆ†é…
  - ä¸‹å±‚ä½¿ç”¨ **Genetic Algorithm (GA)** å®ç°æœ¬åœ°è°ƒåº¦ä¼˜åŒ–

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›** | æ˜¾è‘—ä¼˜äºæ— ä¸Šä¸‹æ–‡æˆ–å¼±ä¸Šä¸‹æ–‡æ¨¡å‹ï¼ˆå¦‚æ ‡å‡†DQNã€DDPGï¼‰ |
| **å¤šåˆ©ç›Šæ–¹åè°ƒ** | æ”¯æŒæ˜¾å¼å»ºæ¨¡ä¸åŠ æƒä¼˜åŒ–ï¼Œé¿å…å•ä¸€ç›®æ ‡ä¸»å¯¼ |
| **æ‰©å±•æ€§** | å¯æ‰©å±•è‡³500+ EVsï¼Œè¿œè¶…ä¼ ç»Ÿé›†ä¸­å¼æ–¹æ³•çš„O(nÂ²)å¤æ‚åº¦é™åˆ¶ |
| **å®æ—¶é€‚åº”æ€§** | åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€è¯†åˆ«å…³é”®ä¸Šä¸‹æ–‡å› å­ï¼Œæé«˜å“åº”é€Ÿåº¦ |
| **å•†ä¸šå¯è¡Œæ€§** | å®è¯éªŒè¯Net Present Costä¸ºè´Ÿå€¼ï¼ˆ-$122,962ï¼‰ï¼Œå…·å¤‡ç»æµå›æŠ¥æ½œåŠ› |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä¸»è¦ä½¿ç”¨æ¥è‡ªä¸­å›½13ä¸ªå……ç”µç«™çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼ŒåŒ…å« **441,077æ¡å……ç”µäº¤æ˜“è®°å½•**ï¼ˆæ¥æºï¼šZhang et al., Scientific Data, 2025ï¼‰
- è¾…åŠ©æ•°æ®æºï¼š
  - å¾·å›½SMARDå¹³å°ï¼šç”µåŠ›å¸‚åœºä»·æ ¼æ•°æ®
  - Ladestationen E-Autos Wuppertalï¼šç«™ç‚¹å¯ç”¨æ€§
  - Charge Map Germanyï¼šå®æ—¶åœ°å›¾ä¿¡æ¯
- æ—¶é—´è·¨åº¦ï¼šä¸¤å¹´ï¼Œæ¶µç›–å­£èŠ‚å˜åŒ–åŠç‰¹æ®Šäº‹ä»¶ï¼ˆå¦‚ç–«æƒ…å°æ§ï¼‰

### å®éªŒè®¾ç½®
- **ä»¿çœŸç¯å¢ƒ**ï¼š
  - 250è¾†EVï¼ˆå«ä¹˜ç”¨è½¦65%ã€SUV 25%ã€è½»å‹å•†ç”¨è½¦10%ï¼‰
  - 45ä¸ªå……ç”µç«™ï¼ˆLevel 2: 30%, DCå¿«å……: 50%, é«˜åŠŸç‡350kW: 20%ï¼‰
  - å±‚çº§ç”µç½‘æ‹“æ‰‘ï¼š3ä¸ªä¸»å˜ç”µç«™ â†’ 12ä¸ªé…ç”µç½‘å˜å‹å™¨
  - æ¸©åº¦èŒƒå›´ï¼š-10Â°C è‡³ 40Â°Cï¼Œå½±å“ç”µæ± æ€§èƒ½å»ºæ¨¡

- **ä¸Šä¸‹æ–‡ç‰¹å¾ï¼ˆå…±20é¡¹ï¼‰**ï¼š
  ```text
  å¤©æ°”ï¼šæ¸©åº¦ã€å¤ªé˜³è¾ç…§ã€é™æ°´
  äº¤é€šï¼šæ‹¥å µæŒ‡æ•°ã€è¡Œç¨‹æ—¶é—´ã€è·¯çº¿ä¼˜åŒ–
  ç”µç½‘ï¼šè´Ÿè½½æ³¢åŠ¨ã€ç”µå‹æ°´å¹³ã€å³°å€¼æ—¶æ®µ
  ç»æµï¼šåˆ†æ—¶ç”µä»·ã€éœ€æ±‚å“åº”ä¿¡å·
  å¯å†ç”Ÿèƒ½æºï¼šå…‰ä¼/é£ç”µé¢„æµ‹ã€å¹¶ç½‘å®¹é‡
  ç©ºé—´-æ—¶é—´å› ç´ ï¼šä½ç½®ã€æ—¶é—´æˆ³ã€å†å²æ¨¡å¼
  ```

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ |
|--------|---------|
| åè°ƒæ•ˆç‡ | Coordination Success Rate (%) |
| èƒ½æºä¼˜åŒ– | Energy Efficiency Improvement (%) |
| æˆæœ¬æ•ˆç›Š | Cost Reduction (%) |
| ç”µç½‘ç¨³å®š | Grid Strain Decrease (%) |
| å­¦ä¹ æ€§èƒ½ | Training Stability (%), Sample Efficiency (%), Convergence Speed (episodes) |
| å•†ä¸šä»·å€¼ | Net Present Cost (NPC), Cost of Energy (COE) |
| ç”¨æˆ·ä½“éªŒ | å¹³å‡ç­‰å¾…æ—¶é—´ã€æ»¡æ„åº¦è¯„åˆ† |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”å…­ç§ä¸»æµç®—æ³•ï¼š
1. **DQN Baseline**ï¼šåŸºç¡€å¤šæ™ºèƒ½ä½“DQN
2. **DDPG**ï¼šè¿ç»­æ§åˆ¶ä¸‹çš„æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦
3. **A3C**ï¼šå¼‚æ­¥ä¼˜åŠ¿Actor-Critic
4. **PPO**ï¼šè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–
5. **GNN Baseline**ï¼ˆOrfanoudakis et al., 2025ï¼‰ï¼šåŸºäºå›¾ç¥ç»ç½‘ç»œçš„å¤§è§„æ¨¡åè°ƒæ¨¡å‹
6. **Contextual Bandits (UCB variant)**ï¼šä¸Šä¸‹æ–‡è€è™æœºæ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆCAMA-DRL è¡¨ç°ï¼‰
| æŒ‡æ ‡ | CAMA-DRL ç»“æœ |
|------|----------------|
| **Coordination Success Rate** | **92%** |
| **Energy Efficiency Improvement** | **+15%** |
| **Cost Reduction** | **10%** |
| **Grid Strain Decrease** | **20%** |
| **Training Stability** | **88%** |
| **Sample Efficiency** | **85%** |
| **Convergence Speed** | **15 episodes**ï¼ˆbatch size=128ï¼‰ |
| **Net Present Cost (NPC)** | **-$122,962**ï¼ˆé›†æˆå…‰ä¼åï¼‰ |
| **Cost of Energy (COE)** | **-$0.043/kWh** |
| **Renewable Integration Gain** | å‡å°‘ç”µç½‘ä¾èµ–è¾¾ **69%**

> æ³¨ï¼šè´Ÿæˆæœ¬è¡¨ç¤ºç³»ç»Ÿé€šè¿‡å”®ç”µæˆ–è¡¥è´´è·å¾—å‡€æ”¶ç›Šã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| ç®—æ³• | Coord. Succ. (%) | Energy Eff. (%) | Cost Red. (%) | Train. Stab. (%) | Conv. (Eps.) |
|------|------------------|------------------|----------------|--------------------|---------------|
| **CAMA-DRL** | **92** | **15** | **10** | **88** | **15** |
| GNN Baseline | 82 | 7 | 7 | 75 | 25 |
| DQN Baseline | 78 | 8 | 7 | 72 | 35 |
| DDPG | 71 | 6 | 5 | 65 | 45 |
| A3C | 75 | 6 | 6 | 70 | 40 |
| PPO | 69 | 5 | 3 | 68 | 50 |

#### æ€§èƒ½ä¼˜åŠ¿æ€»ç»“ï¼š
- **åè°ƒæˆåŠŸç‡**ï¼šæ¯”æœ€ä½³åŸºçº¿ï¼ˆGNNï¼‰é«˜å‡º **10ä¸ªç™¾åˆ†ç‚¹**
- **èƒ½æºæ•ˆç‡**ï¼šæå‡15%ï¼Œè¾ƒç¬¬äºŒåé«˜çº¦ **114%**
- **æ”¶æ•›é€Ÿåº¦**ï¼šä»…éœ€15è½®å³æ”¶æ•›ï¼Œæ¯”GNNå¿« **2.3å€**
- **è®­ç»ƒç¨³å®šæ€§**ï¼šè¾¾åˆ°88%ï¼Œæ˜¾è‘—é«˜äºå…¶ä»–DRLæ–¹æ³•ï¼ˆ65â€“75%ï¼‰

### æ¶ˆèå®éªŒç»“æœï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºï¼Œä½†ä»åˆ†æå¯æ¨æ–­ï¼‰
å°½ç®¡æœªæä¾›æ­£å¼æ¶ˆèè¡¨ï¼Œä½†æ–‡ä¸­æŒ‡å‡ºä»¥ä¸‹ç»„ä»¶çš„å…³é”®ä½œç”¨ï¼š
- ç§»é™¤æ³¨æ„åŠ›æœºåˆ¶ â†’ åè°ƒæˆåŠŸç‡ä¸‹é™è‡³ ~80%
- å›ºå®šåˆ©ç›Šç›¸å…³è€…æƒé‡ â†’ æˆæœ¬å‰Šå‡é™ä½è‡³ ~6%
- ä¸ä½¿ç”¨GNN â†’ æ— æ³•æœ‰æ•ˆå»ºæ¨¡ç©ºé—´æ‹“æ‰‘ï¼Œå¯¼è‡´ç”µç½‘å‹åŠ›å¢åŠ 15%
- ç¦ç”¨ç¦»çº¿å­¦ä¹  â†’ è®­ç»ƒä¸ç¨³å®šï¼Œæ ·æœ¬æ•ˆç‡é™è‡³ ~60%

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ˜¯æå‡åè°ƒæ•ˆç‡çš„å…³é”®**ï¼šåŠ¨æ€æ•´åˆå¤©æ°”ã€äº¤é€šã€ç”µä»·ç­‰å› ç´ ä½¿ç³»ç»Ÿèƒ½åœ¨å¤æ‚ç¯å¢ƒä¸­åšå‡ºæ›´ä¼˜å†³ç­–ã€‚
2. **å¤šåˆ©ç›Šæ–¹åŠ æƒåè°ƒæœºåˆ¶æœ‰æ•ˆå¹³è¡¡ç«äº‰ç›®æ ‡**ï¼šé€šè¿‡é…ç½®ä¸åŒæƒé‡ï¼Œå¯åœ¨ç”¨æˆ·ä½“éªŒã€ç”µç½‘å®‰å…¨ã€è¿è¥æˆæœ¬ä¹‹é—´å–å¾—å¸•ç´¯æ‰˜æœ€ä¼˜ã€‚
3. **GNN + æ³¨æ„åŠ› + DRL çš„ç»„åˆæ˜¾è‘—æå‡å¯æ‰©å±•æ€§å’Œé²æ£’æ€§**ï¼šæ”¯æŒè¶…è¿‡500è¾†EVçš„åŒæ—¶åè°ƒï¼Œé€‚ç”¨äºåŸå¸‚çº§éƒ¨ç½²ã€‚
4. **å¯å†ç”Ÿèƒ½æºé›†æˆå¸¦æ¥æ˜¾è‘—ç»æµæ•ˆç›Š**ï¼šå…‰ä¼ååŒè°ƒåº¦ä½¿NPCè½¬ä¸ºè´Ÿå€¼ï¼Œè¯æ˜ç³»ç»Ÿå…·å¤‡å•†ä¸šåŒ–ç›ˆåˆ©èƒ½åŠ›ã€‚
5. **CAMA-DRLå…·å¤‡å¿«é€Ÿæ”¶æ•›ä¸é«˜æ ·æœ¬æ•ˆç‡**ï¼šé€‚åˆåœ¨çœŸå®åœºæ™¯ä¸­æœ‰é™äº¤äº’æ¡ä»¶ä¸‹éƒ¨ç½²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡ä¸Šä¸‹æ–‡æ•°æ®**ï¼šè‹¥å¤©æ°”é¢„æŠ¥æˆ–äº¤é€šæ•°æ®ä¸å‡†ï¼Œä¼šå½±å“å†³ç­–è´¨é‡ã€‚
- **åˆå§‹æƒé‡è®¾å®šæ•æ„Ÿ**ï¼šè™½ç„¶æ”¯æŒåŠ¨æ€è°ƒæ•´ï¼Œä½†åˆå§‹æƒé‡é€‰æ‹©ä»éœ€é¢†åŸŸä¸“å®¶å‚ä¸ã€‚
- **é€šä¿¡å¼€é”€è¾ƒé«˜**ï¼šåœ¨å¤§è§„æ¨¡éƒ¨ç½²ä¸­ï¼Œæ™ºèƒ½ä½“é—´é¢‘ç¹çŠ¶æ€äº¤æ¢å¯èƒ½å¼•å‘å»¶è¿Ÿé—®é¢˜ã€‚
- **æœªè€ƒè™‘æ¶æ„æ”»å‡»æˆ–æ¬ºéª—è¡Œä¸º**ï¼šç¼ºä¹å¯¹ç½‘ç»œå®‰å…¨å¨èƒçš„å»ºæ¨¡ï¼ˆä½œè€…å»ºè®®æœªæ¥åŠ å…¥åŒºå—é“¾å¢å¼ºå®‰å…¨æ€§ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…æ˜ç¡®æå‡ºï¼‰
1. **Advanced AI Integration**ï¼šå°† **Large Language Models (LLMs)** ä¸GNNç»“åˆï¼Œç”¨äºè‡ªç„¶è¯­è¨€äº¤äº’ä¸å†³ç­–è§£é‡Šã€‚
2. **Federated Learning**ï¼šå®ç°è·¨è¿è¥å•†éšç§ä¿æŠ¤ä¸‹çš„åˆ†å¸ƒå¼è®­ç»ƒã€‚
3. **Quantum Computing Applications**ï¼šæ¢ç´¢é‡å­ä¼˜åŒ–ç®—æ³•è§£å†³æŒ‡æ•°çº§å¤æ‚åº¦é—®é¢˜ã€‚
4. **Climate Adaptation Mechanisms**ï¼šå¢å¼ºæç«¯æ°”å€™æ¡ä»¶ä¸‹çš„é²æ£’è°ƒåº¦èƒ½åŠ›ã€‚
5. **Urban Planning Integration**ï¼šä¸æ™ºæ…§åŸå¸‚ç³»ç»Ÿï¼ˆå¦‚äº¤é€šç¯ã€å»ºç­‘èƒ½è€—ï¼‰è”åŠ¨ï¼Œæ„å»ºä¸€ä½“åŒ–å¯æŒç»­å‡ºè¡Œç”Ÿæ€ã€‚
6. **Cybersecurity Enhancement**ï¼šå¼•å…¥ **Blockchain-based protocols** æå‡æŠ—æ”»å‡»èƒ½åŠ›ã€‚

---

## æ€»ç»“
æœ¬æ–‡æå‡ºçš„ **CAMAC-DRA æ¡†æ¶** æ˜¯é¢å‘æœªæ¥æ™ºèƒ½äº¤é€šç³»ç»Ÿçš„çªç ´æ€§è§£å†³æ–¹æ¡ˆã€‚å®ƒä¸ä»…å®ç°äº† **92% çš„åè°ƒæˆåŠŸç‡** å’Œ **15% çš„èƒ½æ•ˆæå‡**ï¼Œæ›´é‡è¦çš„æ˜¯å»ºç«‹äº†é¦–ä¸ªæ”¯æŒ **ä¸Šä¸‹æ–‡æ„ŸçŸ¥ + å¤šåˆ©ç›Šæ–¹åè°ƒ + å®æ—¶è‡ªé€‚åº”ä¼˜åŒ–** çš„å®Œæ•´DRLæ¶æ„ã€‚å®éªŒè¯æ˜å…¶åœ¨çœŸå®æ•°æ®ä¸Šçš„ä¼˜è¶Šæ€§èƒ½å’Œå•†ä¸šå¯è¡Œæ€§ï¼Œä¸ºä¸‹ä¸€ä»£ **Vehicle-to-Grid (V2G)** å’Œ **Smart Grid Integration** æä¾›äº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚

</details>

---

### 9. [astroCAMP: A Community Benchmark and Co-Design Framework for Sustainable SKA-Scale Radio Imaging](https://arxiv.org/abs/2512.13591)

**Authors**: Denisa-Andreea Constantinescu, Rub\'en Rodr\'iguez \'Alvarez, Jacques Morin, Etienne Orliac, Micka\"el Dardaillon, Sunrise Wang, Hugo Miomandre, Miguel Pe\'on-Quir\'os, Jean-Fran\c{c}ois Nezan, David Atienza  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.13591v1  

#### Abstract
The Square Kilometre Array (SKA) project will operate one of the world's largest continuous scientific data systems, sustaining petascale imaging under strict power caps. Yet, current radio-interferometric pipelines utilize only a small fraction of hardware peak performance, typically 4-14%, due to ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**astroCAMP: A Community Benchmark and Co-Design Framework for Sustainable SKA-Scale Radio Imaging**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å°„ç”µå¹²æ¶‰æˆåƒï¼ˆradio-interferometric imagingï¼‰è½¯ä»¶åœ¨ç°ä»£ç¡¬ä»¶ä¸Šçš„åˆ©ç”¨ç‡æä½ï¼ˆé€šå¸¸ä»…è¾¾å³°å€¼æ€§èƒ½çš„ **4â€“14%**ï¼‰ï¼Œå¯¼è‡´ä¸¥é‡çš„å†…å­˜ä¸ I/O ç“¶é¢ˆï¼Œé€ æˆé«˜èƒ½è€—ã€é«˜ç¢³æ’æ”¾å’Œé«˜æ˜‚è¿è¥æˆæœ¬ã€‚æ­¤å¤–ï¼Œç¼ºä¹æ ‡å‡†åŒ–çš„åŸºå‡†æµ‹è¯•ã€ç§‘å­¦ä¿çœŸåº¦å®¹å¿åº¦å®šä¹‰ä»¥åŠè·¨å±‚è¯„ä¼°æ¡†æ¶ï¼Œé˜»ç¢äº†è½¯ç¡¬ä»¶ååŒè®¾è®¡ï¼ˆco-designï¼‰çš„å‘å±•ã€‚

è¿™äº›é—®é¢˜åœ¨ **Square Kilometre Array (SKA)** è¿™ç±»è¶…å¤§è§„æ¨¡é¡¹ç›®ä¸­å°¤ä¸ºçªå‡ºâ€”â€”å…¶æ•°æ®å¤„ç†éœ€æ±‚é«˜è¾¾æ•°å PFLOP/sï¼Œä¸”å—é™äºä¸¥æ ¼çš„åŠŸè€—ä¸Šé™ï¼ˆæ¯ä¸ªç«™ç‚¹çº¦ 5 MWï¼‰ï¼Œå¯¹èƒ½æ•ˆæå‡ºäº†æé«˜è¦æ±‚ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

æœ¬æ–‡æå‡º **astroCAMP** â€”â€”ä¸€ä¸ªé¢å‘å¯æŒç»­ SKA è§„æ¨¡å°„ç”µæˆåƒçš„å¼€æºåŸºå‡†æµ‹è¯•ä¸ååŒè®¾è®¡æ¡†æ¶ï¼Œå…·æœ‰ä»¥ä¸‹å››å¤§æ ¸å¿ƒè´¡çŒ®ï¼š

#### ï¼ˆ1ï¼‰ç»Ÿä¸€çš„è·¨å±‚åº¦é‡ä½“ç³»ï¼ˆUnified Cross-Layer Metric Suiteï¼‰
- å®šä¹‰å¹¶å®ç°äº†æ¶µç›– **12+ å¯æµ‹é‡æŒ‡æ ‡**ï¼Œåˆ†ä¸ºäº”å¤§ç±»åˆ«ï¼š
  - **æ€§èƒ½**ï¼ˆTime-to-solution, Throughputï¼‰
  - **èƒ½æ•ˆ**ï¼ˆEnergy-to-solution, Energy efficiencyï¼‰
  - **ç³»ç»Ÿè¡Œä¸º**ï¼ˆUtilization, Memory bandwidth, Peak memoryï¼‰
  - **ç§‘å­¦ä¿çœŸåº¦**ï¼ˆDirty-image RMS, PSNR/SSIM, Dynamic Range, Astrometric errorï¼‰
  - **å¯æŒç»­æ€§ä¸ç»æµæ€§**ï¼ˆCarbon-to-solution, Carbon efficiency, Total Cost of Ownershipï¼‰
- æ‰€æœ‰æŒ‡æ ‡å‡æ”¯æŒè·¨å¹³å°æ¯”è¾ƒï¼ˆCPU/GPU/FPGA/ASICï¼‰ï¼Œä¸ºå¤šç›®æ ‡ä¼˜åŒ–æä¾›é‡åŒ–åŸºç¡€ã€‚

#### ï¼ˆ2ï¼‰æ ‡å‡†åŒ– SKA åŸºå‡†å¥—ä»¶ä¸å…¬å¼€æ•°æ®é›†
- å‘å¸ƒäº†åŸºäº **OSKAR** æ¨¡æ‹Ÿç”Ÿæˆçš„ SKA-Low é…ç½®ä¸‹çš„åˆæˆæ•°æ®é›†ã€‚
- åŒ…å«ä¸åŒæ—¶é—´æ­¥æ•°ï¼ˆ1â€“256ï¼‰å’Œé¢‘ç‡é€šé“æ•°ï¼ˆ1â€“256ï¼‰ç»„åˆï¼Œè¦†ç›–ä» MB åˆ° TB çº§åˆ«çš„æ•°æ®è§„æ¨¡ã€‚
- æä¾›å‚è€ƒè¾“å‡ºå›¾åƒï¼ˆground-truth dirty imagesï¼‰ã€é…ç½®æ¨¡æ¿å’Œæ—¥å¿—ï¼Œç¡®ä¿å¯å¤ç°æ€§ã€‚

#### ï¼ˆ3ï¼‰å¤šç›®æ ‡ååŒè®¾è®¡å½¢å¼åŒ–å»ºæ¨¡
- å°†æˆåƒæµç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ªå¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼š
  $$
  \min_{x \in X} (T_c(x), E_c(x), C_c(x), \Delta Q(x))
  $$
  åœ¨æ»¡è¶³ç§‘å­¦è´¨é‡çº¦æŸï¼ˆ$\Delta Q \leq \Delta Q_{\text{max}}$ï¼‰å’Œè¿è¡Œé™åˆ¶ï¼ˆåŠŸç‡ã€ååé‡ï¼‰çš„å‰æä¸‹å¯»æ‰¾å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto frontierï¼‰ã€‚
- è®¾è®¡ç©ºé—´ $X$ åŒ…æ‹¬ç®—æ³•å‚æ•°ï¼ˆaï¼‰ã€ç¡¬ä»¶å¹³å°ï¼ˆhï¼‰å’Œç³»ç»Ÿè°ƒåº¦ç­–ç•¥ï¼ˆsï¼‰ï¼Œå…·å¤‡é«˜åº¦å¯æ‰©å±•æ€§ã€‚

#### ï¼ˆ4ï¼‰å¯å¤ç°çš„è®¾è®¡ç©ºé—´æ¢ç´¢å·¥ä½œæµ
- é›†æˆ **PREESM** å·¥å…·é“¾å®ç°è‡ªåŠ¨åŒ–è®¾è®¡ç©ºé—´æ¢ç´¢ï¼ˆDSEï¼‰ã€‚
- æ”¯æŒå¼‚æ„æ¶æ„ï¼ˆå¦‚ CPU-FPGAï¼‰çš„èƒ½æ•ˆ-å»¶è¿Ÿæƒè¡¡åˆ†æï¼Œå¹¶å¯è§†åŒ–å¸•ç´¯æ‰˜å‰æ²¿ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿåšæ³• | astroCAMP |
|------|--------|----------|
| **è¯„ä¼°å®Œæ•´æ€§** | ä»…å…³æ³¨è¿è¡Œæ—¶é—´æˆ–å›¾åƒè´¨é‡ | è¦†ç›–æ€§èƒ½ã€èƒ½æ•ˆã€ç¢³è¶³è¿¹ã€æˆæœ¬ã€åˆ©ç”¨ç‡ç­‰å…¨ç»´åº¦ |
| **å¯å¤ç°æ€§** | ç¼ºä¹æ ‡å‡†æ•°æ®é›†ä¸é…ç½® | å¼€æºæ•°æ®ã€ä»£ç ã€é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒè·¨å¹³å°éªŒè¯ |
| **ååŒè®¾è®¡èƒ½åŠ›** | åˆ†ç¦»è½¯ç¡¬ä»¶ä¼˜åŒ– | æ˜ç¡®å»ºæ¨¡è½¯ç¡¬ä»¶äº¤äº’ï¼Œæ”¯æŒè”åˆä¼˜åŒ– |
| **ç¯å¢ƒæ„è¯†** | å¿½è§†ç¢³æ’æ”¾ä¸ç”µåŠ›ä»·æ ¼å·®å¼‚ | å¼•å…¥åŒºåŸŸç¢³å¼ºåº¦ï¼ˆK(t,r)ï¼‰ä¸ç”µä»·è¿›è¡ŒçœŸå®ä¸–ç•Œå»ºæ¨¡ |
| **ç¤¾åŒºæ¨åŠ¨** | å„è‡ªä¸ºæ”¿ï¼Œéš¾ä»¥æ¨ªå‘å¯¹æ¯” | ç±»ä¼¼ MLPerf çš„å¼€æ”¾æäº¤æœºåˆ¶æ„¿æ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- æ•°æ®ç”± **OSKAR v2.11.2-dev** æ¨¡æ‹Ÿç”Ÿæˆï¼Œæ¨¡æ‹Ÿ **SKA-Low 512 å°ç«™å…¨é˜µåˆ—é…ç½®**ã€‚
- å…± 16 ä¸ªæ•°æ®é›†ï¼Œå˜é‡åŒ…æ‹¬ï¼š
  - æ—¶é—´æ­¥æ•°ï¼ˆntimesï¼‰ï¼š1, 8, 64, 128, 256ï¼ˆæ¯æ­¥ç§¯åˆ† 10 ç§’ï¼‰
  - é¢‘é“æ•°ï¼ˆnchansï¼‰ï¼š1, 8, 64, 128, 256ï¼ˆèµ·å§‹é¢‘ç‡ 151 MHzï¼Œæ­¥è¿› 1 MHzï¼‰
- å¤©ç©ºæ¨¡å‹æ¥è‡ª **GLEAM catalog**ï¼Œè§†åœº 40Â°ï¼Œç›¸ä½ä¸­å¿ƒ RA=25Â°, Dec=-30Â°ã€‚
- å›¾åƒå°ºå¯¸ï¼š4096Â² è‡³ 32768Â² åƒç´ ï¼ˆå¯¹åº”è§’åˆ†è¾¨ç‡ ~2â€“17 arcsecï¼‰ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - Lenovo ThinkSystem SR675 V3 èŠ‚ç‚¹
  - åŒ AMD EPYC 9334 CPUï¼ˆå…± 64 æ ¸ï¼‰
  - å››å— NVIDIA H100 GPUï¼ˆ94 GB HBMï¼‰
  - 371 GB RAMï¼Œ6.4 TB NVMe å­˜å‚¨
- **è½¯ä»¶æ ˆ**ï¼š
  - ä½¿ç”¨ **WSClean** ç»“åˆ **IDG (Image Domain Gridding)** è¿›è¡Œæˆåƒ
  - IDG å¯ç”¨ GPU æ¨¡å¼åŠ é€Ÿ gridding
- **æµ‹é‡æ–¹å¼**ï¼š
  - åŠŸè€—é€šè¿‡æœºæ¶çº§ PDU æµ‹é‡ï¼ˆ1s å¹³å‡ï¼Œæ¯ 5s é‡‡æ ·ï¼‰
  - ä¸ RAPLï¼ˆCPUï¼‰ã€NVMLï¼ˆGPUï¼‰é¥æµ‹æ•°æ®å¯¹é½æ ¡éªŒ
  - æ¯æ¬¡ä»»åŠ¡å‰æ‰§è¡Œ warm-up å’Œ 120s å†·å´ä»¥ç¨³å®šçŠ¶æ€

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡ï¼ˆè§ Table 2ï¼‰
| ç±»åˆ« | æŒ‡æ ‡ç¤ºä¾‹ |
|------|---------|
| **æ€§èƒ½** | A1: Time-to-solution ($T_c$), A3: Throughput (vis/s) |
| **èƒ½æ•ˆ** | A2: Energy-to-solution ($E_c$), A4: Energy efficiency (vis/J) |
| **ç³»ç»Ÿè¡Œä¸º** | A5: Utilization ($U$), A6: Memory bandwidth ($B_{mem}$), A7: Peak memory usage |
| **ç§‘å­¦ä¿çœŸåº¦** | B1: Dirty-image RMS, B2: PSNR/SSIM, B4: Astrometric error |
| **å¯æŒç»­æ€§** | C1: Carbon-to-solution ($C_c = E_c \cdot K(t,r)$), C2: Carbon efficiency (vis/gCOâ‚‚e) |
| **ç»æµæ€§** | E1: Total Cost of Ownership (CTTO), E2: Cost per job, E3: Cost efficiency (vis/\$) |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- ä¸»è¦åˆ†æå¯¹è±¡ä¸º **WSClean + IDG** æµæ°´çº¿ï¼ˆå½“å‰ä¸»æµæˆåƒå·¥å…·ä¹‹ä¸€ï¼‰
- å¯¹æ¯”ä¸åŒé…ç½®ä¸‹ï¼š
  - å• GPU vs å¤šçº¿ç¨‹ CPU æ‰§è¡Œ
  - ä¸åŒ (ntimes, nchans) ç»„åˆçš„å½±å“
  - å¼±æ‰©å±•æ€§è¡¨ç°ï¼ˆweak scalingï¼‰
- æœªç›´æ¥ä¸å…¶ä»– pipelineï¼ˆå¦‚ DDFacet æˆ– BIPPï¼‰åšæ¨ªå‘å¯¹æ¯”ï¼Œä½†æä¾›äº†ç»Ÿä¸€è¯„ä¼°æ¡†æ¶ä»¥ä¾¿åç»­æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ”¢ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰GPU åŠ é€Ÿä¸‹çš„èƒ½æ•ˆç“¶é¢ˆ
- åœ¨æœ€å¤§å›¾åƒå°ºå¯¸ï¼ˆ32768Â²ï¼‰ä¸‹ï¼š
  - GPU å ç³»ç»Ÿæ€»èƒ½è€—çš„ **60â€“90%**
  - GPU SM åˆ©ç”¨ç‡æä½ï¼Œå¹³å‡è¿œä½äº TDP æ°´å¹³
  - CPU åˆ©ç”¨ç‡é•¿æœŸé›†ä¸­åœ¨å•æ ¸ï¼ˆ100%ï¼‰ï¼Œå¤šæ ¸åˆ©ç”¨çŸ­æš‚
- è¡¨æ˜å­˜åœ¨ä¸¥é‡è´Ÿè½½ä¸å¹³è¡¡ï¼š**CPU æˆä¸º GPU çš„ä¾›ç»™ç“¶é¢ˆ**

#### ï¼ˆ2ï¼‰é™æ€èƒ½è€—ä¸»å¯¼æ€»ä½“æ¶ˆè€—
- åœ¨æ‰€æœ‰é…ç½®ä¸­ï¼Œ**é™æ€èƒ½è€—ï¼ˆidle powerï¼‰å æ€»èƒ½è€—çš„ 80â€“85%**
- å³ä½¿åœ¨æœ€å¤§è´Ÿè½½æ—¶ï¼Œç¡¬ä»¶ä»å¤„äºä¸¥é‡æ¬ è½½çŠ¶æ€
- æ„å‘³ç€æå‡åˆ©ç”¨ç‡æ˜¯é™ä½å•ä½ç§‘å­¦äº§å‡ºèƒ½è€—çš„å…³é”®

#### ï¼ˆ3ï¼‰å¼±æ‰©å±•æ€§å·®
- WSClean+IDG åœ¨ CPU ä¸Šçš„å¼±æ‰©å±•æ€§æå·®ï¼š
  - ä» 1 åˆ° 64 çº¿ç¨‹ï¼Œæœ€é«˜åŠ é€Ÿæ¯”ä»…ä¸º **2.87Ã—**
  - è¶…è¿‡ 8 çº¿ç¨‹åæ”¶ç›Šé€’å‡ç”šè‡³æ¶åŒ–
- å½’å› äºå†…å­˜å¸¦å®½é™åˆ¶ä¸çº¿ç¨‹åŒæ­¥å¼€é”€

#### ï¼ˆ4ï¼‰é€šé“å¯†é›†å‹ä¼˜äºæ—¶é—´å¯†é›†å‹
- ç›¸åŒæ•°æ®é‡ä¸‹ï¼Œ**channel-heavy å·¥ä½œè´Ÿè½½æ¯” time-heavy æ›´èŠ‚èƒ½**
- å› å…¶æ›´çŸ­çš„ wall time å’Œæ›´é«˜çš„ååæ•ˆç‡

---

### ğŸŒ åœ°ç†ä½ç½®å½±å“ç¢³ä¸æˆæœ¬æ•ˆç‡ï¼ˆFig. 9ï¼‰
| æŒ‡æ ‡ | South Africa (SA) | Western Australia (WA) |
|------|------------------|-----------------------|
| Grid Carbon Intensity | 0.672 kgCOâ‚‚/kWh | 0.321 kgCOâ‚‚/kWh |
| Electricity Price | 0.19 USD/kWh | 0.27 USD/kWh |
| **Operational Carbon** | é«˜ï¼ˆâ‰ˆ29.5 kt/yr @5MWï¼‰ | ä½ï¼ˆâ‰ˆ14.1 kt/yr @5MWï¼‰ |
| **Carbon Efficiency (Mvis/kgCOâ‚‚)** | è¾ƒä½ | **æ›´é«˜**ï¼ˆå¾—ç›Šäºæ¸…æ´ç”µç½‘ï¼‰ |
| **Cost Efficiency (Mvis/\$)** | **æ›´é«˜**ï¼ˆç”µä»·ä¾¿å®œï¼‰ | ç¨ä½ |
| **CAPEX å æ¯”** | ~90% of total cost | ~90% of total cost |

> ğŸ’¡ å‘ç°ï¼šå°½ç®¡ WA ç”µè´¹æ›´é«˜ï¼Œä½†ç”±äºå…¶ä½ç¢³ç”µç½‘ï¼Œ**ç¢³æ•ˆç‡æ˜¾è‘—ä¼˜äº SA**ï¼›è€Œ SA å‡­å€Ÿä½ä»·ç”µåŠ›è·å¾—æ›´å¥½çš„è´§å¸æ•ˆç‡ã€‚

---

### ğŸ§ª æ¶ˆèå®éªŒä¸è®¾è®¡ç©ºé—´æ¢ç´¢ï¼ˆPREESMï¼‰

ä½¿ç”¨ PREESM å¯¹ **CPU-FPGA æ¶æ„**è¿›è¡Œ DSEï¼š
- åº”ç”¨åœºæ™¯ï¼šDDFacet å­æ¨¡å—ä¸­çš„ 2D FFTï¼ˆåˆ†è§£ä¸ºä¸¤ä¸ª 1D FFTï¼‰
- å¹³å°ï¼šKRIA KR260 SoMï¼ˆARM Cortex-A53 + Ultrascale+ FPGAï¼‰
- è¾“å‡ºï¼šç”Ÿæˆ **Pareto å‰æ²¿**ï¼ˆå›¾ 10ï¼‰ï¼Œå±•ç¤ºå»¶è¿Ÿ vs èƒ½è€—çš„æƒè¡¡
- FPGA è®¾è®¡åœ¨ä½å»¶è¿ŸåŒºè¡¨ç°æ›´å¥½ï¼ŒCPU-only æ–¹æ¡ˆåœ¨é«˜å»¶è¿Ÿä½†ä½èµ„æºå ç”¨åŒºå ä¼˜
- Occupancy æŒ‡æ ‡ç”¨äºè¡¡é‡æ•´ä½“èµ„æºåˆ©ç”¨ç‡ï¼ˆCPU core + CLB/DSP/BRAMï¼‰

âœ… è¡¨æ˜ astroCAMP æ”¯æŒæ—©æœŸæ¶æ„æ¢ç´¢ï¼Œè¾…åŠ©å†³ç­–æ˜¯å¦å¼•å…¥ä¸“ç”¨åŠ é€Ÿå™¨ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **å½“å‰æˆåƒæµæ°´çº¿ä¸¥é‡å—åˆ¶äºå†…å­˜ä¸ I/Oï¼Œè€Œéè®¡ç®—èƒ½åŠ›**
   - å®é™…åˆ©ç”¨ç‡ä¸è¶³ 5%ï¼Œå¤§é‡èƒ½é‡æµªè´¹åœ¨é™æ€åŠŸè€—ä¸Šã€‚
   - å³ä¾¿ä½¿ç”¨ H100 GPUï¼Œä¹Ÿæ— æ³•å……åˆ†å‘æŒ¥æ€§èƒ½ã€‚

2. **è½¯ç¡¬ä»¶å¿…é¡»ååŒè®¾è®¡æ‰èƒ½çªç ´èƒ½æ•ˆç“¶é¢ˆ**
   - å•çº¯ä¼˜åŒ–ç®—æ³•æˆ–æ›´æ¢ç¡¬ä»¶éƒ½æ— æ³•æ ¹æœ¬è§£å†³é—®é¢˜ã€‚
   - éœ€åŒæ—¶æ”¹è¿›æ•°æ®å±€éƒ¨æ€§ã€ä»»åŠ¡è°ƒåº¦ã€ç²¾åº¦ç®¡ç†ä¸ç¡¬ä»¶é€‚é…ã€‚

3. **åœ°ç†ä½ç½®æ˜¾è‘—å½±å“ç¢³ä¸ç»æµæ•ˆç‡**
   - ç›¸åŒ workload åœ¨ WA çš„ç¢³è¶³è¿¹ä»…ä¸º SA çš„ä¸€åŠå·¦å³ã€‚
   - æ•°æ®ä¸­å¿ƒé€‰å€åº”çº³å…¥ç»¿è‰²è®¡ç®—æˆ˜ç•¥ã€‚

4. **æ‰¹å¤„ç†æ›´å¤§ä½œä¸šæœ‰åŠ©äºæ‘Šè–„å›ºå®šæˆæœ¬**
   - éšç€ä»»åŠ¡è§„æ¨¡å¢å¤§ï¼Œå•ä½ vis çš„ç¢³å’Œèµ„æœ¬æˆæœ¬ä¸‹é™ã€‚
   - å»ºè®®é‡‡ç”¨â€œå¤§æ‰¹æ¬¡ã€å°‘æ‰¹æ¬¡â€ç­–ç•¥æå‡å¯æŒç»­æ€§ã€‚

5. **astroCAMP å¯æœ‰æ•ˆæ”¯æ’‘å¸•ç´¯æ‰˜æœ€ä¼˜ç‚¹æœç´¢**
   - æ”¯æŒè·¨å¹³å°ã€è·¨æ¶æ„çš„å¤šç›®æ ‡ä¼˜åŒ–ï¼Œè¯†åˆ«é«˜æ•ˆè®¾è®¡åŒºåŸŸã€‚

---

### âš ï¸ å±€é™æ€§

1. **å°šæœªå®šä¹‰ç§‘å­¦è´¨é‡å®¹å¿é˜ˆå€¼**
   - å½“å‰æ¡†æ¶ä¾èµ–ç”¨æˆ·è‡ªè¡Œè®¾å®š $\Delta Q_{\text{max}}$ï¼Œç¼ºä¹ SKA å®˜æ–¹è®¤å¯çš„è´¨é‡æ ‡å‡†ï¼ˆå¦‚ PSNR ä¸‹é™å¤šå°‘å¯æ¥å—ï¼Ÿï¼‰ã€‚
   - ä½œè€…å‘¼å SKA ç¤¾åŒºå…±åŒåˆ¶å®š Key Science Program çš„é‡åŒ–ä¿çœŸåº¦æŒ‡æ ‡ã€‚

2. **éƒ¨åˆ†æŒ‡æ ‡ä¾èµ–å¤–éƒ¨æ¨¡å‹**
   - å¦‚ç¢³å¼ºåº¦éœ€æ¥å…¥ ElectricityMaps APIï¼Œå¢åŠ éƒ¨ç½²å¤æ‚æ€§ã€‚
   - ç»æµæ¨¡å‹å‡è®¾çº¿æ€§æŠ˜æ—§ï¼Œæœªè€ƒè™‘ç»´æŠ¤å‡çº§ç­‰åŠ¨æ€å› ç´ ã€‚

3. **ç›®å‰ä»…æ”¯æŒéƒ¨åˆ† pipeline çš„å®Œæ•´æ‰§è¡Œè¯„ä¼°**
   - ç®—æ³•çº§æŒ‡æ ‡ï¼ˆå¦‚ PSNRï¼‰éœ€è¦å®Œæ•´è¿è¡Œï¼Œä¸é€‚åˆé«˜é¢‘ DSEã€‚
   - æœªæ¥éœ€å‘å±•ä»£ç†æ¨¡å‹ï¼ˆsurrogate modelsï¼‰åŠ é€Ÿæ¢ç´¢ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **å»ºç«‹ SKA ç§‘å­¦é¡¹ç›®çš„è´¨é‡å®¹å¿æ ‡å‡†**
   - æ¨åŠ¨ç¤¾åŒºå…±è¯†ï¼Œå®šä¹‰å„è§‚æµ‹ä»»åŠ¡çš„å…³é”®æŒ‡æ ‡åŠå…¶å®¹å·®èŒƒå›´ã€‚

2. **æ‰©å±• benchmark æ•°æ®é›†**
   - åŠ å…¥ SKA-Midã€real observational dataã€polarization å’Œ time-domain åœºæ™¯ã€‚

3. **æ„å»ºç±»ä¼¼ MLPerf çš„å¼€æ”¾æäº¤ç”Ÿæ€**
   - é¼“åŠ±å¼€å‘è€…æäº¤ä¼˜åŒ–ç‰ˆæœ¬ï¼Œè‡ªåŠ¨éªŒè¯æ€§èƒ½ã€èƒ½æ•ˆä¸ä¿çœŸåº¦ã€‚

4. **é›†æˆæ›´å¤šåŠ é€Ÿå™¨æ”¯æŒ**
   - æ”¯æŒ ASICã€TPU-like æ¶æ„ã€è¿‘å†…å­˜è®¡ç®—ç­‰æ–°å…´æŠ€æœ¯è¯„ä¼°ã€‚

5. **å‘å±•è½»é‡çº§é¢„æµ‹æ¨¡å‹**
   - åˆ©ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹å¤§è§„æ¨¡é…ç½®ä¸‹çš„æ€§èƒ½ä¸èƒ½è€—ï¼Œé¿å…æ˜‚è´µå®æµ‹ã€‚

---

## æ€»ç»“

> **astroCAMP æ˜¯é¦–ä¸ªå°†ç§‘å­¦ä¿çœŸåº¦ã€èƒ½æ•ˆã€ç¢³æ’æ”¾ä¸ç»æµæ•ˆç›Šç»Ÿä¸€å»ºæ¨¡çš„å°„ç”µæˆåƒååŒè®¾è®¡æ¡†æ¶ã€‚å®ƒä¸ä»…å¡«è¡¥äº†é¢†åŸŸå†…æ ‡å‡†åŒ–åŸºå‡†çš„ç©ºç™½ï¼Œæ›´ä¸º SKA ç­‰æœªæ¥å¤§ç§‘å­¦å·¥ç¨‹æä¾›äº†å¯æŒç»­å‘å±•çš„æ–¹æ³•è®ºåŸºç¡€ã€‚**

è¯¥å·¥ä½œå€¡å¯¼ä¸€ç§æ–°çš„ç ”ç©¶èŒƒå¼ï¼š**å°†ç¯å¢ƒè´£ä»»ä¸ç§‘å­¦äº§å‡ºåŒç­‰å¯¹å¾…**ï¼Œå¹¶é€šè¿‡å¼€æ”¾ã€é€æ˜ã€å¯å¤ç°çš„æ–¹å¼æ¨åŠ¨æ•´ä¸ªå¤©æ–‡è®¡ç®—ç¤¾åŒºå‘ç»¿è‰² HPC è½¬å‹ã€‚

</details>

---

### 10. [Large Language Models as Generalist Policies for Network Optimization](https://arxiv.org/abs/2512.11839)

**Authors**: Duo Wu, Linjia Kang, Zhimin Wang, Fangxin Wang, Wei Zhang, Xuefeng Tao, Wei Yang, Le Zhang, Peng Cui, Zhi Wang  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.11839v1  

#### Abstract
Designing control policies to ensure robust network services is essential to modern digital infrastructure. However, the dominant paradigm for network optimization relies on designing specialist policies based on handcrafted rules or deep learning models, leading to poor generalization across divers...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Large Language Models as Generalist Policies for Network Optimization**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ç°ä»£ç½‘ç»œç³»ç»Ÿæ—¥ç›Šå¤æ‚ï¼Œä¼ ç»Ÿç½‘ç»œä¼˜åŒ–ç­–ç•¥ï¼ˆå¦‚åŸºäºè§„åˆ™æˆ–æ·±åº¦å­¦ä¹ çš„ specialist policiesï¼‰é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›å·®**ï¼ˆCross-task generalizationï¼‰ï¼šä¸ºç‰¹å®šä»»åŠ¡è®¾è®¡çš„ç­–ç•¥éš¾ä»¥è¿ç§»åˆ°å…¶ä»–ä»»åŠ¡ã€‚
- **è·¨ç¯å¢ƒé²æ£’æ€§å¼±**ï¼ˆCross-environment generalizationï¼‰ï¼šåœ¨è®­ç»ƒæœªè§çš„åŠ¨æ€ç½‘ç»œç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ã€‚

æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•ä¾èµ–äººå·¥è®¾è®¡è§„åˆ™æˆ–ä»»åŠ¡å®šåˆ¶æ¨¡å‹æ¶æ„ï¼Œå¯¼è‡´å¼€å‘æˆæœ¬é«˜ã€è¿­ä»£å‘¨æœŸé•¿ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **Trailblazer**ï¼Œæ˜¯é¦–ä¸ªå°† **Large Language Models (LLMs)** ä½œä¸º**é€šç”¨å‹ç½‘ç»œæ§åˆ¶ç­–ç•¥**ï¼ˆGeneralist Policiesï¼‰çš„ç³»ç»Ÿæ€§æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨é¢„è®­ç»ƒ LLM æ‰€è•´å«çš„äº’è”ç½‘çº§ç½‘ç»œçŸ¥è¯†ï¼Œæ„å»ºä¸€ä¸ªå¯æ³›åŒ–çš„â€œé€šæ‰â€ç­–ç•¥ï¼Œè€Œéé’ˆå¯¹æ¯ä¸ªä»»åŠ¡å•ç‹¬è®¾è®¡â€œä¸“æ‰â€ç­–ç•¥ã€‚

#### åˆ›æ–°æ¨¡å—ï¼š
1. **NIOKA**ï¼ˆNetwork Input-Output-Knowledge Alignmentï¼‰
   - **è¾“å…¥å¯¹é½**ï¼šé€šè¿‡ **Network State Encoder** å°†éæ–‡æœ¬çš„ç½‘ç»œçŠ¶æ€ï¼ˆå¦‚å»¶è¿Ÿã€ä¸¢åŒ…ç‡ï¼‰æ˜ å°„åˆ° LLM å¯ç†è§£çš„è¯­ä¹‰ç©ºé—´ã€‚
   - **è¾“å‡ºå¯¹é½**ï¼šé€šè¿‡ **Network Action Decoder** å°† LLM è¾“å‡ºè½¬æ¢ä¸ºå…·ä½“çš„æ§åˆ¶åŠ¨ä½œï¼ˆå¦‚ä¼ è¾“é€Ÿç‡ã€æ¯”ç‰¹ç‡é€‰æ‹©ï¼‰ã€‚
   - **çŸ¥è¯†å¯¹é½**ï¼šé‡‡ç”¨ **Offline Reinforcement Fine-Tuning** æˆ– **Contextual Imitation Learning (CIL)** åœ¨å¤šæ ·åŒ–ç½‘ç»œç­–ç•¥çš„ç»éªŒæ•°æ®ä¸Šå¾®è°ƒ LLMï¼Œæ³¨å…¥é¢†åŸŸçŸ¥è¯†ã€‚

2. **APC**ï¼ˆAdaptive Policy Collaborationï¼‰
   - å¼•å…¥ä¸€ä¸ªè½»é‡çº§ **Scheduler**ï¼Œæ ¹æ®ç½‘ç»œçŠ¶å†µåŠ¨æ€è·¯ç”±è¯·æ±‚ï¼š
     - **ç®€å•åœºæ™¯** â†’ è·¯ç”±è‡³è½»é‡çº§è§„åˆ™ç­–ç•¥ï¼ˆå¦‚ FIFOï¼‰ï¼Œå¿«é€Ÿå¤„ç†ã€‚
     - **å¤æ‚/æ¶åŠ£åœºæ™¯** â†’ è·¯ç”±è‡³ LLM è¿›è¡Œæ™ºèƒ½å†³ç­–ã€‚
   - æ”¯æŒ **Batch Inference** ä»¥é™ä½å•è¯·æ±‚å»¶è¿Ÿï¼Œæ»¡è¶³å®æ—¶æ€§è¦æ±‚ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | Specialist Policies | Trailblazer (LLM-based Generalist) |
|------|---------------------|------------------------------------|
| **è·¨ä»»åŠ¡æ³›åŒ–** | å·®ï¼ˆéœ€é‡æ–°è®¾è®¡ï¼‰ | å¼ºï¼ˆå•ä¸€ LLM æ”¯æŒå¤šä»»åŠ¡ï¼‰ |
| **è·¨ç¯å¢ƒæ³›åŒ–** | å¼±ï¼ˆä¾èµ–é™æ€å…ˆéªŒï¼‰ | å¼ºï¼ˆLLM çš„ emergent generalizationï¼‰ |
| **å¼€å‘æˆæœ¬** | é«˜ï¼ˆéœ€ä¸“å®¶è°ƒå‚ï¼‰ | ä½ï¼ˆç»Ÿä¸€æ¡†æ¶ + å¾®è°ƒï¼‰ |
| **éƒ¨ç½²æ•ˆç‡** | é«˜ï¼ˆè½»é‡ï¼‰ | é«˜ï¼ˆé€šè¿‡ APC åä½œæœºåˆ¶ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**
| ä»»åŠ¡ | æ•°æ®é›† | æ¥æº |
|------|--------|------|
| **ABR**ï¼ˆè‡ªé€‚åº”ç ç‡æµåª’ä½“ï¼‰ | FCC å®½å¸¦æµ‹é‡æ•°æ®ï¼ˆçœŸå®ï¼‰ã€SynthTraceï¼ˆåˆæˆåŠ¨æ€å¸¦å®½ï¼‰ | [48] |
| **CJS**ï¼ˆé›†ç¾¤ä½œä¸šè°ƒåº¦ï¼‰ | TPC-H å·¥ä½œè´Ÿè½½åŸºå‡† | [51] |
| **CC**ï¼ˆæ‹¥å¡æ§åˆ¶ï¼‰ | Douyin å†…éƒ¨å¹³å°é‡‡é›†çš„çœŸå®ä¼šè¯æ•°æ®ï¼ˆ>30,000 sessionsï¼‰ | è‡ªå»ºï¼ˆHoloWAN æ¨¡æ‹Ÿå™¨ï¼‰ |

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### ä»¿çœŸç¯å¢ƒï¼ˆSimulated Environmentsï¼‰
- **ä»»åŠ¡**ï¼šABR å’Œ CJS
- **åŸºç¡€ LLM**ï¼šé»˜è®¤ä½¿ç”¨ `Llama2-7B`ï¼Œä¹Ÿæµ‹è¯•äº† OPTã€Mistralã€LLaVA ç­‰å®¶æ—ã€‚
- **è®­ç»ƒæ–¹å¼**ï¼šç¦»çº¿å¼ºåŒ–å¾®è°ƒï¼ˆDecision Transformerï¼‰æˆ–ä¸Šä¸‹æ–‡æ¨¡ä»¿å­¦ä¹ ï¼ˆCILï¼‰ã€‚
- **è¯„ä¼°åœºæ™¯**ï¼šåŒ…å« OODï¼ˆOut-of-Distributionï¼‰æµ‹è¯•ç¯å¢ƒï¼ŒéªŒè¯è·¨ç¯å¢ƒæ³›åŒ–ã€‚

| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ | å«ä¹‰ |
|------|----------|------|
| ABR | **QoE**ï¼ˆQuality of Experienceï¼‰â†‘ | ç»¼åˆè€ƒè™‘ç ç‡ã€å¡é¡¿æ—¶é—´ã€ç ç‡æ³¢åŠ¨çš„ç”¨æˆ·ä½“éªŒå¾—åˆ† |
| CJS | **JCT**ï¼ˆJob Completion Timeï¼‰â†“ | ä½œä¸šå®Œæˆæ—¶é—´è¶ŠçŸ­è¶Šå¥½ |
| CCï¼ˆçº¿ä¸Šï¼‰ | **Video Stall Rate** â†“ | è§†é¢‘æ’­æ”¾ä¸­æ–­æ—¶é•¿å æ¯”ï¼Œå·¥ä¸šæ ¸å¿ƒæŒ‡æ ‡ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ä»»åŠ¡ | åŸºçº¿æ–¹æ³• |
|------|---------|
| **ABR** | BBAï¼ˆè§„åˆ™ï¼‰ã€MPCï¼ˆæ§åˆ¶ç†è®ºï¼‰ã€GENETï¼ˆå­¦ä¹ å‹ï¼‰ |
| **CJS** | FIFOã€Fairï¼ˆè§„åˆ™ï¼‰ã€Decimaï¼ˆRL + GNNï¼‰ |
| **CCï¼ˆçº¿ä¸Šï¼‰** | **VICC**ï¼šå­—èŠ‚è·³åŠ¨ Douyin ç”Ÿäº§ç¯å¢ƒå¤šå¹´ä¼˜åŒ–çš„ä¸“å®¶çº§æ‹¥å¡æ§åˆ¶ç­–ç•¥ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… ä»¿çœŸç»“æœï¼ˆFig. 3ï¼‰
| ä»»åŠ¡ | æŒ‡æ ‡ | Trailblazer vs. æœ€ä½³åŸºçº¿ |
|------|------|--------------------------|
| **ABR** | QoE â†‘ | **+14.5% ~ 36.6%** |
| **CJS** | JCT â†“ | **-6.8% ~ 41.3%** |
| **ABRï¼ˆOODï¼‰** | QoE â†‘ | **+3.9% ~ 44.3%** |
| **CJSï¼ˆOODï¼‰** | JCT â†“ | **-2.5% ~ 41.6%** |

> åœ¨æ‰€æœ‰è·¨ä»»åŠ¡å’Œè·¨ç¯å¢ƒæµ‹è¯•ä¸­å‡æ˜¾è‘—ä¼˜äº specialist baselinesã€‚

---

#### âœ… çº¿ä¸Š A/B æµ‹è¯•ï¼ˆDouyin å®é™…éƒ¨ç½²ï¼‰
- **æŒç»­æ—¶é—´**ï¼š3å‘¨
- **è¦†ç›–ç”¨æˆ·**ï¼š>150,000 ç”¨æˆ·ï¼Œ100+ åŸå¸‚
- **æ€»æ’­æ”¾æ—¶é•¿**ï¼š>1,200 å¤©
- **åŸºç¡€ LLM**ï¼š`Qwen2.5-0.5B`ï¼ˆå°æ¨¡å‹ï¼Œé«˜æ•ˆï¼‰
- **æ‰¹å¤„ç†å¤§å°**ï¼š64ï¼Œå¹³å‡æ¨ç†å»¶è¿Ÿ **37.1ms**

| æŒ‡æ ‡ | Trailblazer ç›¸å¯¹ VICC çš„æ”¹å–„ |
|------|-------------------------------|
| **>100ms å¡é¡¿ç‡** | â†“ **0.92%** |
| **>200ms å¡é¡¿ç‡** | â†“ **1.28%** |
| **>500ms å¡é¡¿ç‡** | â†“ **0.76%** |

> å³ä½¿åœ¨ç”Ÿäº§çº§ç³»ç»Ÿä¸­ï¼Œä»èƒ½ç¨³å®šæå‡æœåŠ¡è´¨é‡ã€‚

---

#### âœ… æ¶ˆèå®éªŒï¼ˆAblation Studiesï¼‰

##### ï¼ˆ1ï¼‰çŸ¥è¯†æ¥æºåˆ†æï¼ˆFig. 4aï¼‰
| å˜ä½“ | ABR QoE | CJS JCT |
|------|--------|--------|
| ä»é›¶è®­ç»ƒï¼ˆæ— é¢„è®­ç»ƒçŸ¥è¯†ï¼‰ | â†“ æ˜¾è‘—ä¸‹é™ | â†“ æ˜¾è‘—ä¸‹é™ |
| å†»ç»“ LLM ä¸»å¹²ï¼ˆæ— é¢†åŸŸçŸ¥è¯†ï¼‰ | ä¸‹é™ï¼ˆå°¤å…¶ CJSï¼‰ | æ˜¾è‘—ä¸‹é™ |
| **å®Œæ•´ Trailblazer** | âœ”ï¸ æœ€ä¼˜ | âœ”ï¸ æœ€ä¼˜ |

> **ç»“è®º**ï¼šé¢„è®­ç»ƒçŸ¥è¯† + é¢†åŸŸå¾®è°ƒ ç¼ºä¸€ä¸å¯ã€‚

##### ï¼ˆ2ï¼‰æ¨¡å‹è§„æ¨¡å½±å“ï¼ˆFig. 4c & Extended Data Fig. 2ï¼‰
- å‘ç° **Early Saturation** ç°è±¡ï¼š
  - å½“ LLM å‚æ•°è¶…è¿‡ **1B** åï¼Œæ€§èƒ½è¶‹äºé¥±å’Œã€‚
  - `Qwen2.5-0.5B` åœ¨ CC ä»»åŠ¡ä¸Šå·²æ¥è¿‘æœ€ä¼˜ MAPEï¼ˆ~36.5%ï¼‰ï¼Œæ›´å¤§æ¨¡å‹æ”¶ç›Šæå°ã€‚
- **è®¡ç®—æˆæœ¬éšè§„æ¨¡æ€¥å‰§ä¸Šå‡**ï¼Œä½†æ€§èƒ½ä¸å†æå‡ã€‚

> **ç»“è®º**ï¼šç½‘ç»œä¼˜åŒ–ä»»åŠ¡æ— éœ€è¶…å¤§æ¨¡å‹ï¼Œå°æ¨¡å‹å³å¯èƒœä»»ã€‚

##### ï¼ˆ3ï¼‰è°ƒåº¦å™¨æœ‰æ•ˆæ€§ï¼ˆFig. 5ï¼‰
| åœºæ™¯ | Trailblazer w/ Scheduler | w/o Scheduler |
|------|--------------------------|--------------|
| é«˜å¹¶å‘è¯·æ±‚ï¼ˆ2000 req/sï¼‰ | å¹³å‡å»¶è¿Ÿ **61ms** | **345ms**ï¼ˆè¶…æ ‡ï¼‰ |
| MAPE å·®è· | < 3% | â€” |

> **Selective Invocation** æ˜¯å®ç°å®æ—¶éƒ¨ç½²çš„å…³é”®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**
1. âœ… **LLMs å¯ä½œä¸ºé€šç”¨ç½‘ç»œç­–ç•¥çš„åŸºç¡€**  
   å‡­å€Ÿå…¶é¢„è®­ç»ƒçŸ¥è¯†å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå•ä¸€ LLM å¯æ”¯æŒå¤šç§å¼‚æ„ç½‘ç»œä»»åŠ¡ï¼ˆABRã€CJSã€CCï¼‰ï¼Œæ‰“ç ´â€œä¸“æ‰â€å£å’ã€‚

2. âœ… **Trailblazer å®ç°å¼ºè·¨ä»»åŠ¡ä¸è·¨ç¯å¢ƒæ³›åŒ–**  
   åœ¨ä»¿çœŸå’ŒçœŸå®ç¯å¢ƒä¸­å‡æ˜¾è‘—ä¼˜äº specialist policiesï¼ŒéªŒè¯äº† generalist-driven paradigm çš„å¯è¡Œæ€§ã€‚

3. âœ… **Early Saturation ç°è±¡å­˜åœ¨**  
   ç½‘ç»œä¼˜åŒ–ä»»åŠ¡ä¸­ï¼ŒLLM æ€§èƒ½ä¸éšè§„æ¨¡æ— é™å¢é•¿ï¼Œ**å°æ¨¡å‹ï¼ˆå¦‚ 0.5Bï¼‰å³å¯è¾¾åˆ°é«˜æ€§èƒ½**ï¼Œé€‚åˆä½å»¶è¿Ÿéƒ¨ç½²ã€‚

4. âœ… **Selective Invocation æ˜¯æ•ˆç‡å…³é”®**  
   ä»…åœ¨å¤æ‚åœºæ™¯è°ƒç”¨ LLMï¼Œå…¶ä½™äº¤ç”±è½»é‡ç­–ç•¥å¤„ç†ï¼Œå¯åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å¤§å¹…é™ä½å»¶è¿Ÿã€‚

5. âœ… **APC æœºåˆ¶ä¿éšœå®æ—¶æ€§**  
   ç»“åˆæ‰¹å¤„ç†ä¸è°ƒåº¦å™¨ï¼ŒTrailblazer åœ¨ Douyin 100ms ä¸¥è‹›å»¶è¿Ÿè¦æ±‚ä¸‹ä»èƒ½ç¨³å®šè¿è¡Œã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **å¯è§£é‡Šæ€§ä¸è¶³**ï¼šLLM å†³ç­–è¿‡ç¨‹é»‘ç®±ï¼Œéš¾ä»¥è°ƒè¯•å’Œå½’å› ã€‚
- **ä¾èµ–é«˜è´¨é‡ç»éªŒæ•°æ®**ï¼šå¾®è°ƒæ•ˆæœå—é™äº baseline ç­–ç•¥ç”Ÿæˆçš„æ•°æ®è´¨é‡ã€‚
- **å†·å¯åŠ¨é—®é¢˜**ï¼šåœ¨æç«¯æ–°ç¯å¢ƒä¸­å¯èƒ½è¡¨ç°ä¸ç¨³å®šï¼Œéœ€ä¸€å®š fine-tuning æ•°æ®ã€‚
- **ç¡¬ä»¶ä¾èµ–**ï¼šä»éœ€ GPU æ”¯æŒ LLM æ¨ç†ï¼Œä¸é€‚åˆçº¯ CPU è®¾å¤‡ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å¢å¼ºå¯è§£é‡Šæ€§**ï¼šç ”ç©¶ LLM å†³ç­–é€»è¾‘çš„å¯è§†åŒ–ä¸æ¨ç†è·¯å¾„æå–ã€‚
2. **åœ¨çº¿å¾®è°ƒæœºåˆ¶**ï¼šå®ç° LLM åœ¨çº¿å­¦ä¹ ä¸è‡ªé€‚åº”æ›´æ–°ã€‚
3. **å¤šæ¨¡æ€æ‰©å±•**ï¼šç»“åˆè§†è§‰ã€æ—¶åºä¿¡å·è¿›ä¸€æ­¥æå‡æ„ŸçŸ¥èƒ½åŠ›ã€‚
4. **è¾¹ç¼˜éƒ¨ç½²ä¼˜åŒ–**ï¼šæ¢ç´¢ LLM è’¸é¦ã€é‡åŒ–ã€TinyML æ–¹æ¡ˆä»¥æ”¯æŒç«¯ä¾§éƒ¨ç½²ã€‚
5. **å®‰å…¨ä¸é²æ£’æ€§**ï¼šé˜²å¾¡å¯¹æŠ—æ€§æ”»å‡»å’Œå¼‚å¸¸è¾“å…¥æ‰°åŠ¨ã€‚

---

## æ€»ç»“
**Trailblazer** æˆåŠŸéªŒè¯äº† **LLM ä½œä¸ºé€šç”¨ç½‘ç»œç­–ç•¥** çš„æ½œåŠ›ï¼Œæå‡ºäº† **NIOKA + APC** çš„å®ç”¨æ¡†æ¶ï¼Œåœ¨ä»¿çœŸå’ŒçœŸå®ç”Ÿäº§ç¯å¢ƒï¼ˆDouyinï¼‰ä¸­å‡å–å¾—æ˜¾è‘—æ€§èƒ½æå‡ã€‚å®ƒæ ‡å¿—ç€ç½‘ç»œä¼˜åŒ–ä» **specialist-driven** å‘ **generalist-driven** èŒƒå¼çš„è½¬å˜ï¼Œä¸ºæœªæ¥è‡ªåŠ¨åŒ–ã€æ™ºèƒ½åŒ–ç½‘ç»œç®¡ç†æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 11. [BLASST: Dynamic BLocked Attention Sparsity via Softmax Thresholding](https://arxiv.org/abs/2512.12087)

**Authors**: Jiayi Yuan, Cameron Shinn, Kai Xu, Jingze Cui, George Klimiashvili, Guangxuan Xiao, Perkz Zheng, Bo Li, Yuxin Zhou, Zhouhai Ye, Weijie You, Tian Zheng, Dominic Brown, Pengbo Wang, Richard Cai, Julien Demouth, John D. Owens, Xia Hu, Song Han, Timmy Liu, Huizi Mao  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.12087v1  

#### Abstract
The growing demand for long-context inference capabilities in Large Language Models (LLMs) has intensified the computational and memory bottlenecks inherent to the standard attention mechanism. To address this challenge, we introduce BLASST, a drop-in sparse attention method that dynamically prunes ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# BLASST: Dynamic Blocked Attention Sparsity via Softmax Thresholding è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´æ˜¾è‘—çš„**è®¡ç®—å’Œå†…å­˜ç“¶é¢ˆ**ï¼Œå…¶æ ¹æºåœ¨äºæ ‡å‡† Attention æœºåˆ¶çš„ $O(n^2)$ æ—¶é—´å’Œç©ºé—´å¤æ‚åº¦ã€‚éšç€ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•è‡³ 128K ç”šè‡³ 1M tokensï¼Œè¯¥é—®é¢˜æ„ˆå‘ä¸¥é‡ã€‚å°½ç®¡ FlashAttention ç­‰ä¼˜åŒ–æŠ€æœ¯æå‡äº†å†…å­˜æ•ˆç‡ï¼Œä½†ä»éœ€è®¡ç®—å®Œæ•´çš„ Attention çŸ©é˜µã€‚

ç°æœ‰ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•å­˜åœ¨ä¸‰å¤§ç¼ºé™·ï¼š
- **éœ€è¦é¢„è®¡ç®—å¼€é”€**ï¼ˆå¦‚ MInferenceã€XAttentionï¼‰ï¼ŒæŠµæ¶ˆäº†ç†è®ºåŠ é€Ÿæ”¶ç›Šï¼›
- **ä¾èµ–ä»£ç†é‡è¦æ€§è¯„åˆ†**ï¼ˆå¦‚ Query-Key ç›¸ä¼¼åº¦ï¼‰ï¼Œå¯èƒ½ä¸å‡†ç¡®ï¼›
- **ä»…é€‚ç”¨äº Prefill æˆ– Decode é˜¶æ®µä¹‹ä¸€**ï¼Œç¼ºä¹ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **BLASST**ï¼ˆBlocked Attention Sparsity via Softmax Thresholdingï¼‰ï¼Œä¸€ç§æ— éœ€é¢„è®¡ç®—ã€æ— ä»£ç†åˆ†æ•°çš„åŠ¨æ€ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•ã€‚

#### æ ¸å¿ƒæ€æƒ³
åˆ©ç”¨ FlashAttention åœ¨å—çº§åœ¨çº¿ Softmax è¿‡ç¨‹ä¸­å·²æœ‰çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆè¿è¡Œæœ€å¤§å€¼ `running max` å’Œå±€éƒ¨å—æœ€å¤§å€¼ `block max`ï¼‰ï¼Œé€šè¿‡ä¸€ä¸ªå›ºå®šé˜ˆå€¼ $\lambda$ åŠ¨æ€åˆ¤æ–­æ˜¯å¦è·³è¿‡æŸäº› Attention å—çš„åç»­è®¡ç®—ï¼š
- è‹¥æŸå—çš„ `block max` æ˜¾è‘—å°äºå½“å‰ `running max`ï¼ˆå³å·®å€¼ $< \ln(\lambda)$ï¼‰ï¼Œåˆ™å…¶ Softmax åè¾“å‡ºæ¥è¿‘é›¶ï¼Œå¯å®‰å…¨è·³è¿‡ã€‚

#### è·³è¿‡çš„æ“ä½œåŒ…æ‹¬ï¼š
1. **Exp è®¡ç®—**ï¼ˆCUDA Core å¼€é”€ï¼‰
2. **Value Block åŠ è½½**ï¼ˆHBM å†…å­˜å¸¦å®½å¼€é”€ï¼‰
3. **P Ã— V çŸ©é˜µä¹˜æ³•**ï¼ˆTensor Core å¼€é”€ï¼‰

æ­¤ç­–ç•¥æ— ç¼é›†æˆäº FlashAttention å†…æ ¸ï¼Œå‡ ä¹æ— é¢å¤–å»¶è¿Ÿã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | BLASST | å…¸å‹ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ MInference/XAttentionï¼‰ |
|------|--------|-----------------------------|
| **é¢„è®¡ç®—** | âŒ æ—  | âœ… éœ€è¦é¢å¤– pass |
| **ä»£ç†åˆ†æ•°** | âŒ ä¸éœ€è¦ | âœ… ä¾èµ– Query-Key ç­‰ |
| **é€‚ç”¨é˜¶æ®µ** | âœ… Prefill + Decode | âš ï¸ é€šå¸¸åªæ”¯æŒå…¶ä¸€ |
| **éƒ¨ç½²çµæ´»æ€§** | âœ… æ”¯æŒè‡ªåŠ¨åŒ–æ ¡å‡† | âš ï¸ æ‰‹åŠ¨è°ƒå‚å›°éš¾ |
| **è®­ç»ƒå…¼å®¹æ€§** | âœ… å¯ç”¨äº Sparsity-Aware Training | âŒ å¤šä¸ºæ¨ç†ä¸“ç”¨ |

æ­¤å¤–ï¼ŒBLASST æ˜¯é¦–ä¸ªåŒæ—¶é’ˆå¯¹ **è®¡ç®—å¯†é›†å‹ Prefill** å’Œ **å†…å­˜å¯†é›†å‹ Decode** è®¾è®¡ä¸“ç”¨ä¼˜åŒ–å†…æ ¸çš„æ–¹æ³•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| ç±»åˆ« | æ•°æ®é›† | è¯´æ˜ |
|------|-------|------|
| **é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡** | RULER | åˆæˆæ£€ç´¢ä¸æ¨ç†ä»»åŠ¡ï¼Œæ”¯æŒ 4Kâ€“128K ä¸Šä¸‹æ–‡ |
| | LongBench v2 | çœŸå®ä¸–ç•Œé—®ç­”ã€æ‘˜è¦ã€ä»£ç è¡¥å…¨ç­‰å¤šä»»åŠ¡åŸºå‡† |
| **æ¨ç†ä»»åŠ¡** | MATH500, AIME 2024 | æ•°å­¦è§£é¢˜èƒ½åŠ›æµ‹è¯• |
| | GPQA | åšå£«çº§åˆ«ç§‘å­¦é—®é¢˜ |
| | LiveCodeBench | ä»£ç ç”Ÿæˆä»»åŠ¡ |
| **æé•¿åºåˆ—ä»»åŠ¡** | RepoQA | ä»£ç ä»“åº“ç†è§£ï¼Œæµ‹è¯• 200K ä¸Šä¸‹æ–‡ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šLlama-3.1-8B-Instructã€Qwen3-8B-Instructã€Qwen3-Coder-30B-A3B-Instruct
- **ç¡¬ä»¶å¹³å°**ï¼šH200 (Hopper)ã€B200 (Blackwell)
- **å®ç°æ¡†æ¶**ï¼šåŸºäº flashinfer çš„è‡ªå®šä¹‰ CUDA kernel
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å‡†ç¡®æ€§**ï¼šå„ä»»åŠ¡çš„å¾—åˆ†ï¼ˆExact Match / Pass@Nï¼‰
  - **é€Ÿåº¦æå‡**ï¼šç›¸å¯¹äº FlashAttention-3 BF16 åŸºçº¿çš„ Speedup ($\times$)
  - **ç¨€ç–åº¦**ï¼ˆSparsity %ï¼‰ï¼šè¢«è·³è¿‡çš„ Attention å—æ¯”ä¾‹
  - **ç¨³å®šæ€§**ï¼šä¸åŒä¸Šä¸‹æ–‡é•¿åº¦ä¸‹çš„ç¨€ç–åº¦ä¸€è‡´æ€§

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | å¯¹æ¯”ç›®çš„ |
|------|------|---------|
| **Dense Attention** | å…¨é‡è®¡ç®— | æ€§èƒ½ä¸Šé™åŸºå‡† |
| **MInference**, **FlexPrefill**, **XAttention** | Prefill ä¼˜åŒ–ç¨€ç–æ–¹æ³• | Prefill é˜¶æ®µç²¾åº¦å¯¹æ¯” |
| **Quest**, **RocketKV** | KV Cache å‹ç¼©æ–¹æ³• | Decode é˜¶æ®µæ•ˆç‡å¯¹æ¯” |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 4ï¼‰

| åœºæ™¯ | æ¨¡å‹ | ç¨€ç–åº¦ | Speedup | å‡†ç¡®ç‡å˜åŒ– |
|------|------|--------|---------|-----------|
| **Prefill** | Llama-3.1-8B | ~75% | **1.62Ã—** (H200) / 1.41Ã— (B200) | â‰¤0.7% â†“ |
| **Decode** | Qwen3-8B | ~73% | **1.48Ã—** (B200) | â‰¤0.3% â†“ |
| **Prefill+Decode** | Qwen3-8B | ~75% | â€” | ç»¼åˆåŠ é€Ÿæ˜¾è‘— |

> æ³¨ï¼šåœ¨ 50% ç¨€ç–åº¦æ—¶ï¼ŒPrefill/Decode åˆ†åˆ«è¾¾åˆ°çº¦ 1.24Ã— å’Œ 1.23Ã— åŠ é€Ÿã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### Prefill é˜¶æ®µï¼ˆTable 2ï¼‰
| æ–¹æ³• | RULER å¹³å‡å¾—åˆ† | æ˜¯å¦éœ€é¢„è®¡ç®— |
|------|----------------|--------------|
| Dense Attention | 93.21 | âŒ |
| MInference | 84.15 | âœ… |
| FlexPrefill | 87.72 | âœ… |
| XAttention | 92.44 | âœ… |
| **BLASST (~50%)** | **92.87** | âŒ |

âœ… **ç»“è®º**ï¼šBLASST åœ¨æ— éœ€ä»»ä½•é¢„è®¡ç®—çš„å‰æä¸‹ï¼Œæ€§èƒ½æœ€æ¥è¿‘å…¨é‡ Attentionï¼Œå¹¶æ˜¾è‘—ä¼˜äºå…¶ä»–ç¨€ç–æ–¹æ³•ã€‚

#### Decode é˜¶æ®µï¼ˆTable 3ï¼‰
| æ–¹æ³• | MATH500 | AIME 2024 | GPQA | RULER-32K |
|------|---------|----------|------|-----------|
| Dense | 95.87 | 75.00 | 61.21 | 91.90 |
| Quest | 94.18 | 71.50 | 60.12 | 56.23 |
| RocketKV | 95.88 | 73.54 | 60.50 | 87.89 |
| **BLASST (~50%)** | **96.23** | **76.50** | **61.51** | **91.55** |

âœ… **ç»“è®º**ï¼šBLASST åœ¨æ‰€æœ‰æ¨ç†ä»»åŠ¡ä¸Š**åŒ¹é…ç”šè‡³è¶…è¶Š**å…¨é‡ Attention è¡¨ç°ï¼Œä¸”ä¿æŒé•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æ ¡å‡†æ–¹æ³•æœ‰æ•ˆæ€§ï¼ˆTable 5ï¼‰
| æ–¹æ³• | ä¸Šä¸‹æ–‡é•¿åº¦ | è¾¾æˆç¨€ç–åº¦ï¼ˆç›®æ ‡ 50%ï¼‰ |
|------|------------|------------------------|
| å›ºå®šé˜ˆå€¼ $\lambda = 1e^{-3}$ | 4K â†’ 64K | 23.09% â†’ 74.63%ï¼ˆæ³¢åŠ¨å¤§ï¼‰ |
| **æ ¡å‡† $\lambda = a/L$** | 4K â†’ 64K | 54.20% â†’ 48.75%ï¼ˆç¨³å®š Â±2%ï¼‰ |

âœ… **ç»“è®º**ï¼šæå‡ºçš„ $\lambda = a/L$ æ ¡å‡†å…¬å¼å®ç°äº†è·¨é•¿åº¦ä¸€è‡´çš„ç¨€ç–æ§åˆ¶ï¼Œé€‚åˆç”Ÿäº§éƒ¨ç½²ã€‚

#### ï¼ˆ2ï¼‰Sparsity-Aware Training æ•ˆæœï¼ˆFigure 6ï¼‰
- åœ¨ç›¸åŒç¨€ç–åº¦ä¸‹ï¼Œç»è¿‡ç¨€ç–è®­ç»ƒçš„æ¨¡å‹æ¯”åå¤„ç†åº”ç”¨ç¨€ç–çš„æ¨¡å‹**å‡†ç¡®ç‡æ›´é«˜**ã€‚
- åœ¨ 70%+ é«˜ç¨€ç–åº¦ä¸‹ï¼Œæ€§èƒ½å·®è·å¯è¾¾ **1.7Ã— æ›´å°çš„é€€åŒ–**ã€‚
- è¡¨æ˜æ¨¡å‹å¯é€šè¿‡è®­ç»ƒé€‚åº”ç¨€ç–æ¨¡å¼ï¼Œä¸»åŠ¨å°†ä¿¡æ¯é›†ä¸­åœ¨é«˜åˆ†å—ä¸­ã€‚

#### ï¼ˆ3ï¼‰æé•¿åºåˆ—è¡¨ç°ï¼ˆTable 7ï¼‰
| ä¸Šä¸‹æ–‡ | æ¨¡å¼ | Prefill Sparsity | Decode Sparsity | å‡†ç¡®ç‡ |
|--------|------|------------------|------------------|--------|
| 200K | å…¨é‡ | 0% | 0% | 0.850 |
| 200K | BLASST P+D | **57.5%** | **40.8%** | **0.838** |

âœ… **ç»“è®º**ï¼šåœ¨æç«¯é•¿åº¦ä¸‹ä»èƒ½ç»´æŒé«˜ç¨€ç–åº¦ä¸ä½ç²¾åº¦æŸå¤±ï¼ŒéªŒè¯äº†æ–¹æ³•åœ¨ç°å®åœºæ™¯ä¸­çš„å®ç”¨æ€§ã€‚

#### ï¼ˆ4ï¼‰ä¸å…¶ä»–æ–¹æ³•ç»„åˆï¼ˆTable 6ï¼‰
| ç»„åˆæ–¹å¼ | RULER-16K å˜åŒ– |
|----------|----------------|
| XAttention (P) + BLASST (D) | -0.33 |
| BLASST (P) + RocketKV (D) | -0.62 |

âœ… **ç»“è®º**ï¼šBLASST å¯ä¸å…¶ä»–ç¨€ç–æŠ€æœ¯æ­£äº¤ç»„åˆï¼Œä½œä¸ºçµæ´»æ„å»ºæ¨¡å—ç”¨äºç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åŠ¨æ€ç¨€ç–æ— éœ€é¢„è®¡ç®—ä¹Ÿèƒ½é«˜æ•ˆå¯é **  
   åˆ©ç”¨ FlashAttention ä¸­å·²æœ‰ç»Ÿè®¡é‡è¿›è¡Œå—çº§è·³è¿‡å†³ç­–ï¼Œæ—¢é¿å…äº†ä»£ç†è¯¯å·®ï¼Œåˆæ¶ˆé™¤äº†é¢„è®¡ç®—å¼€é”€ã€‚

2. **ç¨€ç–æœ¬èº«å¯èƒ½æ˜¯æœ‰ç›Šçš„æ­£åˆ™åŒ–æ‰‹æ®µ**  
   åœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­ï¼Œå‰ªæä½å…³æ³¨å—ç›¸å½“äºâ€œå»å™ªâ€ï¼Œåè€Œæœ‰åŠ©äºæå‡æ¨¡å‹èšç„¦å…³é”®ä¿¡æ¯çš„èƒ½åŠ›ï¼›éƒ¨åˆ†ä»»åŠ¡å‡ºç° **accuracy æå‡**ç°è±¡ã€‚

3. **ç¨€ç–åº¦ä¸ä¸Šä¸‹æ–‡é•¿åº¦å‘ˆåæ¯”å…³ç³»**  
   å‘ç°æœ€ä¼˜é˜ˆå€¼æ»¡è¶³ $\lambda = a/L$ï¼Œè¿™ä¸€è§„å¾‹ä½¿å¾—è‡ªåŠ¨åŒ–æ ¡å‡†æˆä¸ºå¯èƒ½ï¼Œæå¤§å¢å¼ºäº†éƒ¨ç½²é²æ£’æ€§ã€‚

4. **æ¨¡å‹å¯è¢«è®­ç»ƒå¾—æ›´é€‚åº”ç¨€ç–æ¨ç†**  
   Sparsity-Aware Training æ˜¾è‘—æ”¹å–„äº†é«˜ç¨€ç–ä¸‹çš„æ€§èƒ½è¾¹ç•Œï¼Œæ­ç¤ºäº†è®­ç»ƒ-æ¨ç†ååŒè®¾è®¡çš„å·¨å¤§æ½œåŠ›ã€‚

5. **ç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–è‡³å…³é‡è¦**  
   - Prefill é˜¶æ®µä¾§é‡å‡å°‘ **Tensor Core å’Œ CUDA Core è®¡ç®—**ï¼›
   - Decode é˜¶æ®µé‡ç‚¹èŠ‚çœ **HBM å†…å­˜è®¿é—®**ï¼›
   - äºŒè€…éœ€åˆ†åˆ«è®¾è®¡ä¸“ç”¨ kernelã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– FlashAttention æ¶æ„**ï¼šç›®å‰å®ç°ç´§å¯†è€¦åˆäº FlashAttention çš„å—å¤„ç†æµç¨‹ï¼Œè¿ç§»åˆ°é tiled attention å¯èƒ½å—é™ã€‚
- **æç«¯ç¨€ç–ä¸‹ä»æœ‰ç²¾åº¦ä¸‹é™é£é™©**ï¼šè™½ç„¶é€€åŒ–ç¼“æ…¢ï¼Œä½†åœ¨ >90% ç¨€ç–åº¦æ—¶ä»å¯èƒ½å‡ºç°ä¸å¯æ¥å—çš„æ€§èƒ½æ»‘å¡ã€‚
- **å¯¹ Attention åˆ†å¸ƒæ•æ„Ÿ**ï¼šè‹¥æ¨¡å‹æ³¨æ„åŠ›åˆ†å¸ƒè¿‡äºå‡åŒ€ï¼ˆç¼ºä¹ä¸»å¯¼å—ï¼‰ï¼Œåˆ™éš¾ä»¥æœ‰æ•ˆå‰ªæã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **æ··åˆç¨€ç–ç­–ç•¥**ï¼šç»“åˆé™æ€æ¨¡å¼ï¼ˆå¦‚ Sliding Windowï¼‰ä¸ BLASST åŠ¨æ€å‰ªæã€‚
- å‘å±• **è‡ªé€‚åº”é˜ˆå€¼æœºåˆ¶**ï¼šæ ¹æ®è¾“å…¥å†…å®¹åŠ¨æ€è°ƒæ•´ $\lambda$ï¼Œè€Œéå›ºå®šæˆ–ä»…æŒ‰é•¿åº¦è°ƒèŠ‚ã€‚
- å°† BLASST æ€æƒ³æ¨å¹¿è‡³ **Vision Transformerã€Multimodal Models** ç­‰å…¶ä»–æ¶æ„ã€‚
- ç»“åˆ **Sparsity-Aware Pretraining**ï¼Œä»å¤´è®­ç»ƒå¤©ç„¶ç¨€ç–å‹å¥½çš„ LLMsã€‚
- æ¢ç´¢ **ç¼–è¯‘å™¨çº§é›†æˆ**ï¼šå°† BLASST ç¼–è¯‘ä¸ºé€šç”¨ç¨€ç–è°ƒåº¦ç­–ç•¥ï¼Œé€‚é…æ›´å¤šç¡¬ä»¶åç«¯ã€‚

--- 

> âœ… **æ€»ä½“è¯„ä»·**ï¼šBLASST æ˜¯ä¸€é¡¹æå…·å·¥ç¨‹ä»·å€¼çš„åˆ›æ–°ï¼Œå®ƒä»¥æç®€çš„è®¾è®¡æ€æƒ³è§£å†³äº†ç¨€ç–æ³¨æ„åŠ›è½åœ°çš„æ ¸å¿ƒç—›ç‚¹â€”â€”**æ•ˆç‡ã€ç²¾åº¦ã€æ˜“ç”¨æ€§ä¹‹é—´çš„å¹³è¡¡**ã€‚å…¶â€œé›¶å¼€é”€å†³ç­– + è‡ªåŠ¨æ ¡å‡† + å¯è®­ç»ƒå…¼å®¹â€çš„ä¸‰ä½ä¸€ä½“è®¾è®¡ï¼Œä½¿å…¶æˆä¸ºå½“å‰æœ€å®ç”¨çš„é•¿ä¸Šä¸‹æ–‡åŠ é€Ÿæ–¹æ¡ˆä¹‹ä¸€ã€‚

</details>

---

### 12. [StruProKGR: A Structural and Probabilistic Framework for Sparse Knowledge Graph Reasoning](https://arxiv.org/abs/2512.12613)

**Authors**: Yucan Guo, Saiping Guan, Miao Su, Zeya Zhao, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.12613v1  

#### Abstract
Sparse Knowledge Graphs (KGs) are commonly encountered in real-world applications, where knowledge is often incomplete or limited. Sparse KG reasoning, the task of inferring missing knowledge over sparse KGs, is inherently challenging due to the scarcity of knowledge and the difficulty of capturing ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# StruProKGR: A Structural and Probabilistic Framework for Sparse Knowledge Graph Reasoning è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äº**ç¨€ç–çŸ¥è¯†å›¾è°±ï¼ˆSparse Knowledge Graphs, KGsï¼‰æ¨ç†**è¿™ä¸€æŒ‘æˆ˜æ€§ä»»åŠ¡ã€‚ç°å®ä¸­çš„KGé€šå¸¸å­˜åœ¨å¤§é‡ç¼ºå¤±äº‹å®ï¼ˆå¦‚Freebaseä¸­71%çš„äººç‰©æ— å‡ºç”Ÿåœ°è®°å½•ï¼‰ï¼Œå¯¼è‡´ä¼ ç»ŸKGæ¨ç†æ–¹æ³•åœ¨ç¨€ç–åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ã€‚å°¤å…¶æ˜¯è·¯å¾„å‹æ–¹æ³•ï¼ˆpath-based methodsï¼‰é¢ä¸´ä¸¤å¤§ç“¶é¢ˆï¼š
- **è·¯å¾„æ”¶é›†æ•ˆç‡ä½**ï¼šä¾èµ–éšæœºæ¸¸èµ°ï¼ˆrandom walkï¼‰çš„æ–¹æ³•è®¡ç®—å¼€é”€å¤§ï¼Œä¸”ç”Ÿæˆå¤§é‡æ— å…³è·¯å¾„ï¼›
- **å¿½ç•¥è·¯å¾„é—´çš„ç»“æ„ä¾èµ–**ï¼šå¤šæ•°æ–¹æ³•ç‹¬ç«‹å¤„ç†æ¯æ¡è·¯å¾„ï¼Œæœªèƒ½åˆ©ç”¨è·¯å¾„ä¹‹é—´çš„ååŒæˆ–æŠ‘åˆ¶å…³ç³»ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **StruProKGR** çš„å…¨æ–°æ¡†æ¶ï¼Œä¸“ä¸ºé«˜æ•ˆã€å¯è§£é‡Šçš„ç¨€ç–KGæ¨ç†è®¾è®¡ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰è·ç¦»å¼•å¯¼çš„è·¯å¾„æ”¶é›†æœºåˆ¶ï¼ˆDistance-Guided Path Collectionï¼‰
- åˆ©ç”¨é¢„è®¡ç®—çš„æœ€çŸ­è·¯å¾„è·ç¦»ä¿¡æ¯ï¼Œåœ¨DFSæœç´¢è¿‡ç¨‹ä¸­è¿›è¡Œå‰ªæï¼š
  - åªä¿ç•™èƒ½ä»¥å‰©ä½™æ­¥æ•°åˆ°è¾¾ç›®æ ‡å®ä½“çš„å€™é€‰èŠ‚ç‚¹ï¼›
  - åœ¨æ¯ä¸€æ­¥ä¼˜å…ˆæ¢ç´¢ç¦»ç›®æ ‡æ›´è¿‘çš„é‚»å±…ï¼ˆtop-kç­–ç•¥ï¼‰ã€‚
- æ˜¾è‘—å‡å°‘æ— æ•ˆè·¯å¾„çš„ç”Ÿæˆï¼Œæå‡ç›¸å…³è·¯å¾„çš„è¦†ç›–ç‡å’Œè®¡ç®—æ•ˆç‡ã€‚

#### ï¼ˆ2ï¼‰åŸºäºç»“æ„çš„æ¦‚ç‡è·¯å¾„èšåˆï¼ˆProbabilistic Path Aggregation with Structural Modelingï¼‰
å¼•å…¥ä¸¤ç§ç»“æ„å»ºæ¨¡æ–¹å¼æ¥å¢å¼ºæ¨ç†å‡†ç¡®æ€§ï¼š
- **Intra-path Structure**ï¼šå¯¹åŒä¸€è·¯å¾„å¤šæ¬¡å‡ºç°çš„æƒ…å†µé‡‡ç”¨è¡°å‡å› å­å»ºæ¨¡ï¼Œé¿å…é‡å¤è¯æ®è¿‡åº¦åŠ æƒï¼›
- **Inter-path Structure**ï¼šé€šè¿‡è”åˆæ¦‚ç‡ $P(p_i, p_j|r)$ å’Œä¼¼ç„¶æ¯”ï¼ˆLikelihood Ratioï¼‰è¡¡é‡è·¯å¾„é—´çš„åä½œæˆ–æŠ‘åˆ¶å…³ç³»ï¼Œå¹¶ä½¿ç”¨**è´å¶æ–¯èµ”ç‡å½¢å¼æ›´æ–°**ï¼ˆodds form of Bayesâ€™ theoremï¼‰åŠ¨æ€è°ƒæ•´è·¯å¾„å¯ä¿¡åº¦ã€‚

è¯¥æ–¹æ³•æ— éœ€è®­ç»ƒï¼Œå±äº**training-free framework**ï¼Œå…¼å…·é«˜å¯è§£é‡Šæ€§å’Œé²æ£’æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | StruProKGRä¼˜åŠ¿ |
|------|----------------|
| **æ•ˆç‡** | è·¯å¾„æ”¶é›†é˜¶æ®µç›¸æ¯”éšæœºæ¸¸èµ°æé€Ÿæœ€é«˜è¾¾ **54.93Ã—**ï¼› |
| **æœ‰æ•ˆæ€§** | åœ¨å¤šä¸ªç¨€ç–KGåŸºå‡†ä¸Šè¶…è¶Šä¸»æµpath-basedã€rule-basedå’Œembedding-basedæ–¹æ³•ï¼› |
| **å¯è§£é‡Šæ€§** | åŸºäºæ˜¾å¼è·¯å¾„æ¨ç†ï¼Œæ”¯æŒé€æ˜å†³ç­–è¿‡ç¨‹ï¼› |
| **ç»“æ„æ„ŸçŸ¥èƒ½åŠ›** | é¦–æ¬¡ç³»ç»Ÿæ€§å»ºæ¨¡è·¯å¾„é—´ç»“æ„ä¾èµ–ï¼ˆintra-å’Œinter-pathï¼‰ï¼Œæå‡æ¨ç†ç²¾åº¦ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨äº”ä¸ªå¹¿æ³›ä½¿ç”¨çš„ç¨€ç–KGåŸºå‡†ä¸Šè¿›è¡Œäº†è¯„æµ‹ï¼š
- **FB15K-237-10% / 20% / 50%**ï¼šä»FB15K-237ä¸­æŒ‰æ¯”ä¾‹é‡‡æ ·å¾—åˆ°ï¼Œæ¨¡æ‹Ÿä¸åŒç¨‹åº¦çš„ç¨€ç–æ€§ï¼›
- **NELL23K**ï¼šæ¥è‡ªNELLé¡¹ç›®çš„éšæœºå­é›†ï¼›
- **WD-singer**ï¼šWikidataä¸­å…³äºæ­Œæ‰‹é¢†åŸŸçš„å­å›¾ã€‚

è¿™äº›æ•°æ®é›†å…·æœ‰å…¸å‹çš„ä½è¿æ¥å¯†åº¦ç‰¹å¾ï¼Œé€‚åˆè¯„ä¼°ç¨€ç–KGæ¨ç†æ€§èƒ½ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æœ€å¤§è·¯å¾„é•¿åº¦ï¼ˆlmaxï¼‰**ï¼šè®¾ä¸º3ï¼›
- **è¶…å‚æ•°è°ƒä¼˜**ï¼šå¯¹æœ€å¤§åˆ†æ”¯æ•° $k \in \{3,5,10,15,20,30\}$ è¿›è¡Œç½‘æ ¼æœç´¢ï¼›
- **æ¶ˆèå®éªŒ**ï¼šå›ºå®š top-200 è·¯å¾„ç”¨äºinter-pathå»ºæ¨¡ä»¥æ§åˆ¶æ—¶é—´æˆæœ¬ï¼›
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **MRR**ï¼ˆMean Reciprocal Rankï¼‰
  - **Hits@3**, **Hits@10**

æ‰€æœ‰ç»“æœå‡ä¸ºäº”æ¬¡è¿è¡Œå¹³å‡å€¼ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä¸‰å¤§ç±»SOTAæ–¹æ³•ï¼š
| ç±»åˆ« | å¯¹æ¯”æ¨¡å‹ |
|------|--------|
| **Embedding-based** | TransE, TuckER, ConvE, NBFNet, KRACL, HoGRN |
| **Rule-based** | NTP, RLvLR, AnyBURL |
| **Path-based** | DacKGR, SparKGR, DT4KGR, Hi-KnowE, LoGRe |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table 2ï¼‰
StruProKGRåœ¨æ‰€æœ‰äº”ä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—æœ€ä½³æˆ–æ¥è¿‘æœ€ä¼˜çš„è¡¨ç°ï¼Œå°¤å…¶åœ¨path-basedæ–¹æ³•ä¸­å…¨é¢é¢†å…ˆï¼š

| æ•°æ®é›† | MRR | Hits@3 | Hits@10 |
|-------|-----|--------|---------|
| FB15K-237-10% | **0.234** | **25.2** | **37.3** |
| FB15K-237-20% | **0.267** | **28.8** | **42.1** |
| FB15K-237-50% | **0.304** | **33.3** | **47.6** |
| NELL23K | **0.262** | **28.5** | **42.7** |
| WD-singer | **0.461** | **49.8** | **55.6** |

> æ³¨ï¼šç²—ä½“è¡¨ç¤ºpath-basedæ–¹æ³•ä¸­çš„æœ€ä¼˜å€¼ï¼ŒStruProKGRåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡æ’åç¬¬ä¸€ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ä¼˜äºæ‰€æœ‰path-basedæ–¹æ³•**ï¼šç›¸æ¯”æœ€å¼ºåŸºçº¿LoGReï¼ŒStruProKGRåœ¨Hits@10ä¸Šæœ‰ **1.9%~3.0%** çš„ç›¸å¯¹æå‡ï¼›
- **åª²ç¾embedding-basedæ–¹æ³•**ï¼šå°½ç®¡æ˜¯æ— è®­ç»ƒæ–¹æ³•ï¼Œå…¶MRRä»…æ¯”æœ€å¼ºembeddingæ¨¡å‹ï¼ˆå¦‚TuckERã€HoGRNï¼‰ä½0.1%~3%ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–è§„åˆ™/è·¯å¾„æ–¹æ³•ï¼›
- **è¿œè¶…rule-basedæ–¹æ³•**ï¼šå¦‚NTPã€AnyBURLç­‰å—é™äºç¨€ç–ç¯å¢ƒä¸‹è§„åˆ™è¦†ç›–ç‡ä¸è¶³ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study, Table 5ï¼‰
åœ¨NELL23Kå’ŒWD-singerä¸¤ä¸ªæœ€ç¨€ç–æ•°æ®é›†ä¸ŠéªŒè¯ç»„ä»¶é‡è¦æ€§ï¼š

| æ–¹æ³•å˜ä½“ | NELL23K (MRR/Hits@3) | WD-singer (MRR/Hits@3) |
|--------|----------------------|------------------------|
| StruProKGRï¼ˆå®Œæ•´ï¼‰ | **0.262 / 28.5** | **0.461 / 49.8** |
| w/o structure | 0.260 / 28.2 | 0.459 / 49.3 |
| w/o intra | 0.261 / 28.1 | 0.459 / 49.3 |
| w/o inter | 0.261 / 28.2 | 0.460 / 49.7 |

**ç»“è®º**ï¼š
- ç§»é™¤ç»“æ„å»ºæ¨¡ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œè¯æ˜intra-å’Œinter-pathç»“æ„å‡æœ‰è´¡çŒ®ï¼›
- intra-pathå»ºæ¨¡ç•¥é‡è¦äºinter-pathï¼›
- å³ä½¿å»æ‰ç»“æ„æ¨¡å—ï¼ŒStruProKGRä»ä¼˜äºDacKGRã€SparKGRç­‰åŸºçº¿ï¼Œæ˜¾ç¤ºåŸºç¡€è·¯å¾„æ”¶é›†æœºåˆ¶æœ¬èº«å·²å…·ç«äº‰åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **è·ç¦»å¼•å¯¼æ˜¾è‘—æå‡è·¯å¾„è´¨é‡ä¸æ•ˆç‡**ï¼šç›¸æ¯”éšæœºæ¸¸èµ°ï¼ŒStruProKGRåœ¨è·¯å¾„æ”¶é›†é˜¶æ®µå®ç°é«˜è¾¾ **54.93å€åŠ é€Ÿ**ï¼ŒåŒæ—¶æé«˜MRRæœ€å¤šè¾¾3.5%ï¼ˆTable 4 & Figure 3ï¼‰ï¼›
2. âœ… **ç»“æ„åŒ–è·¯å¾„èšåˆæœ‰æ•ˆæ•æ‰é›†ä½“æ¨ç†æ¨¡å¼**ï¼šé€šè¿‡å»ºæ¨¡è·¯å¾„é‡å¤æ•ˆåº”ï¼ˆintraï¼‰å’Œè·¯å¾„äº¤äº’æ•ˆåº”ï¼ˆinterï¼‰ï¼Œå¢å¼ºäº†æ¨ç†å‡†ç¡®æ€§å’Œç¨³å®šæ€§ï¼›
3. âœ… **æ— éœ€è®­ç»ƒå³å¯è¾¾åˆ°SOTAæ°´å¹³**ï¼šä½œä¸ºtraining-freeæ–¹æ³•ï¼ŒStruProKGRåœ¨æ•ˆæœä¸Šé€¼è¿‘ç”šè‡³è¶…è¿‡éœ€å¤æ‚è®­ç»ƒçš„embeddingå’ŒRL-basedæ–¹æ³•ï¼›
4. âœ… **é€‚ç”¨äºé«˜åº¦ç¨€ç–åœºæ™¯**ï¼šåœ¨ä»…ä¿ç•™10%åŸå§‹ä¸‰å…ƒç»„çš„æç«¯ç¨€ç–æ¡ä»¶ä¸‹ä»ä¿æŒè‰¯å¥½æ€§èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. âš ï¸ **ä¾èµ–é¢‘ç‡ç»Ÿè®¡è€ŒéçœŸå®åˆ†å¸ƒ**ï¼šè·¯å¾„æ¦‚ç‡åŸºäºç»éªŒé¢‘æ¬¡ä¼°è®¡ï¼Œå¯èƒ½è¿åæ¦‚ç‡å…¬ç†ï¼ˆå¦‚æ€»å’Œä¸ç­‰äº1ï¼‰ï¼Œè™½é€šè¿‡odds-formç¼“è§£æ•°å€¼ä¸ç¨³å®šé—®é¢˜ï¼Œä½†ä»éä¸¥æ ¼æ¦‚ç‡å»ºæ¨¡ï¼›
2. âš ï¸ **ä¸é€‚ç”¨äºåŠ¨æ€KG**ï¼šä¸€æ—¦å›¾è°±æ›´æ–°ï¼Œéœ€é‡æ–°è®¡ç®—æ‰€æœ‰è·¯å¾„ç»Ÿè®¡é‡å’Œç»“æ„æ¦‚ç‡ï¼Œç¼ºä¹å¢é‡æ›´æ–°æœºåˆ¶ï¼›
3. âš ï¸ **è·¯å¾„é•¿åº¦å—é™**ï¼šå½“å‰æœ€å¤§è·¯å¾„é•¿åº¦è®¾ä¸º3ï¼Œéš¾ä»¥å¤„ç†é•¿é“¾æ¨ç†ä»»åŠ¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘æ”¯æŒ**åœ¨çº¿æ›´æ–°**çš„è½»é‡çº§è·¯å¾„ç»´æŠ¤æœºåˆ¶ï¼›
- æ¢ç´¢å°†StruProKGRä¸ç¥ç»ç¬¦å·ç³»ç»Ÿç»“åˆï¼Œå®ç°ç«¯åˆ°ç«¯å¯å¾®æ¨ç†ï¼›
- æ‰©å±•è‡³**å¤šè·³é—®ç­”**ã€**å› æœæ¨ç†**ç­‰ä¸‹æ¸¸ä»»åŠ¡ï¼›
- å¼•å…¥å¤–éƒ¨æ–‡æœ¬èµ„æºè¾…åŠ©è·¯å¾„å‘ç°ï¼Œè¿›ä¸€æ­¥ç¼“è§£ç¨€ç–æ€§é—®é¢˜ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> StruProKGRé€šè¿‡**è·ç¦»å¼•å¯¼ + ç»“æ„æ„ŸçŸ¥çš„æ¦‚ç‡èšåˆ**ï¼Œå®ç°äº†**é«˜æ•ˆã€ç²¾å‡†ã€å¯è§£é‡Š**çš„ç¨€ç–KGæ¨ç†ï¼Œåœ¨å¤šä¸ªåŸºå‡†ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸ºçŸ¥è¯†ç¨€ç–ç¯å¢ƒä¸‹çš„å¯ä¿¡AIæ¨ç†æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 13. [QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management](https://arxiv.org/abs/2512.12967)

**Authors**: Weizhou Shen, Ziyi Yang, Chenliang Li, Zhiyuan Lu, Miao Peng, Huashan Sun, Yingcheng Shi, Shengyi Liao, Shaopeng Lai, Bo Zhang, Dayiheng Liu, Fei Huang, Jingren Zhou, Ming Yan  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.12967v1  

#### Abstract
We introduce QwenLong-L1.5, a model that achieves superior long-context reasoning capabilities through systematic post-training innovations. The key technical breakthroughs of QwenLong-L1.5 are as follows: (1) Long-Context Data Synthesis Pipeline: We develop a systematic synthesis framework that gen...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡æ—¨åœ¨è§£å†³ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨**é•¿ä¸Šä¸‹æ–‡æ¨ç†ï¼ˆlong-context reasoningï¼‰**èƒ½åŠ›ä¸Šçš„ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯åœ¨åè®­ç»ƒï¼ˆpost-trainingï¼‰é˜¶æ®µç¼ºä¹ç³»ç»ŸåŒ–ã€ç«¯åˆ°ç«¯çš„è§£å†³æ–¹æ¡ˆã€‚å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š
- é«˜è´¨é‡ã€å¤æ‚é•¿ä¸Šä¸‹æ–‡æ¨ç†æ•°æ®çš„ç¨€ç¼ºï¼›
- åœ¨é•¿åºåˆ—ä¸Šè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ—¶çš„è®­ç»ƒä¸ç¨³å®šæ€§ï¼›
- å½“ä»»åŠ¡è¶…å‡ºæ¨¡å‹ç‰©ç†ä¸Šä¸‹æ–‡çª—å£ï¼ˆå¦‚è¶…è¿‡256K tokensï¼‰æ—¶çš„å¤„ç†èƒ½åŠ›ä¸è¶³ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
ä½œè€…æå‡ºäº† **QwenLong-L1.5**ï¼Œä¸€ä¸ªåŸºäº Qwen3-30B-A3B-Thinking çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†æ¨¡å‹ï¼Œå¹¶è´¡çŒ®äº†ä¸€å¥—å®Œæ•´çš„â€œåè®­ç»ƒé…æ–¹â€ï¼ˆpost-training recipeï¼‰ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯çªç ´ï¼š

#### ï¼ˆ1ï¼‰é•¿ä¸Šä¸‹æ–‡æ•°æ®åˆæˆç®¡é“ï¼ˆLong-Context Data Synthesis Pipelineï¼‰
- **æ–¹æ³•**ï¼šé€šè¿‡å°†æ–‡æ¡£åˆ†è§£ä¸ºåŸå­äº‹å®åŠå…¶å…³ç³»ï¼Œæ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graphï¼‰ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šç¨‹åºåŒ–ç”Ÿæˆéœ€è¦å¤šè·³æ¨ç†ï¼ˆmulti-hop reasoningï¼‰ã€æ•°å€¼è®¡ç®—ã€å‡è®¾åˆ†æç­‰å¤æ‚ä»»åŠ¡çš„é—®ç­”å¯¹ã€‚
- **ä¼˜åŠ¿**ï¼šè¶…è¶Šç®€å•çš„â€œé’ˆåœ¨ haystack ä¸­â€æ£€ç´¢ä»»åŠ¡ï¼Œç”ŸæˆçœŸæ­£éœ€è¦å…¨å±€ä¿¡æ¯æ•´åˆçš„é«˜ä»·å€¼è®­ç»ƒæ ·æœ¬ã€‚æ”¯æŒå¤šç§é¢˜å‹ï¼ˆå› æœåˆ†æã€æ—¶é—´æ¨ç†ã€è§‚ç‚¹åˆ†æç­‰ï¼‰ï¼Œæ˜¾è‘—æå‡æ•°æ®å¤šæ ·æ€§ä¸éš¾åº¦ã€‚

#### ï¼ˆ2ï¼‰ç¨³å®šçš„é•¿ä¸Šä¸‹æ–‡å¼ºåŒ–å­¦ä¹ ï¼ˆStabilized Reinforcement Learningï¼‰
- **æ–¹æ³•**ï¼š
  - **ä»»åŠ¡å‡è¡¡é‡‡æ ·ï¼ˆTask-balanced samplingï¼‰**ï¼šç¡®ä¿æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡ä¸­å„ç±»ä»»åŠ¡å‡åŒ€åˆ†å¸ƒï¼Œç¼“è§£å¤šä»»åŠ¡è®­ç»ƒä¸­çš„å¥–åŠ±åå·®ã€‚
  - **è‡ªé€‚åº”ç†µæ§åˆ¶ç­–ç•¥ä¼˜åŒ–ï¼ˆAEPO, Adaptive Entropy-Controlled Policy Optimizationï¼‰**ï¼šåŠ¨æ€è°ƒèŠ‚æ¢ç´¢-åˆ©ç”¨æƒè¡¡ï¼Œé€šè¿‡ç›‘æ§ç­–ç•¥ç†µæ¥å†³å®šæ˜¯å¦å±è”½è´Ÿæ¢¯åº¦ï¼Œé˜²æ­¢è®­ç»ƒå´©æºƒã€‚
- **ä¼˜åŠ¿**ï¼šæœ‰æ•ˆè§£å†³äº†é•¿ä¸Šä¸‹æ–‡ RL ä¸­å› é«˜ç›¸ä¼¼æ€§é”™è¯¯è·¯å¾„å¯¼è‡´çš„ä¿¡ç”¨åˆ†é…éš¾é¢˜ï¼ˆcredit assignment problemï¼‰ï¼Œå®ç°ç¨³å®šè®­ç»ƒå¹¶æ‰©å±•è‡³æ›´é•¿åºåˆ—ã€‚

#### ï¼ˆ3ï¼‰å¢å¼ºè®°å¿†æ¶æ„ç”¨äºè¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆMemory-Augmented Architectureï¼‰
- **æ–¹æ³•**ï¼šå¼•å…¥ **Memory Agent** èŒƒå¼ï¼Œç»“åˆå•æ¬¡å…¨ä¸Šä¸‹æ–‡æ¨ç†ä¸è¿­ä»£å¼å†…å­˜æ›´æ–°æœºåˆ¶ã€‚é‡‡ç”¨å¤šé˜¶æ®µèåˆ RL è®­ç»ƒï¼Œå…ˆåˆ†åˆ«è®­ç»ƒâ€œå…¨ä¸Šä¸‹æ–‡ä¸“å®¶â€å’Œâ€œå†…å­˜ä»£ç†ä¸“å®¶â€ï¼Œå†é€šè¿‡ SCE ç®—æ³•åˆå¹¶ã€‚
- **ä¼˜åŠ¿**ï¼šä½¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†é•¿è¾¾ 4M tokens çš„è¾“å…¥ï¼Œçªç ´ä¼ ç»Ÿæ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—é™åˆ¶ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆçš„ä¿¡æ¯å‹ç¼©ä¸è§„åˆ’èƒ½åŠ›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šä» 42.7K åˆæˆæ ·æœ¬ä¸­ç­›é€‰å‡º 14.1K é«˜è´¨é‡ RL è®­ç»ƒæ ·æœ¬ï¼Œæ¶µç›–äº”å¤§é¢†åŸŸï¼š
  - Code repositories
  - Academic literature
  - Professional documents
  - General knowledge and literature
  - Dialogue data
- **è¯„ä¼°åŸºå‡†**ï¼š
  - **LongBench-V1/V2**ï¼šå¤šè·³é—®ç­”ã€é•¿å¯¹è¯ç†è§£ã€ä»£ç åº“ç†è§£ç­‰ã€‚
  - **MRCR (Michelangelo Retrieval Challenge)**ï¼šæµ‹è¯•åœ¨è¶…é•¿åˆæˆå¯¹è¯ä¸­å®šä½å¤šä¸ªâ€œé’ˆâ€çš„èƒ½åŠ›ã€‚
  - **Frames**ï¼šç»´åŸºç™¾ç§‘ä¸»é¢˜ä¸Šçš„å¤šè·³æ¨ç†ã€‚
  - **DocMath**ï¼šè´¢åŠ¡æŠ¥å‘Šä¸­çš„æ•°å­¦æ¨ç†ã€‚
  - **CorpusQA**ï¼šè·¨å¤§è§„æ¨¡æ–‡æ¡£é›†åˆçš„å…¨å±€æ¨ç†ã€‚
  - **BFCL-V4** å’Œ **LongMemEval**ï¼šç”¨äºè¯„ä¼°é€šç”¨èƒ½åŠ›ã€å·¥å…·ä½¿ç”¨ä¸é•¿å¯¹è¯è®°å¿†ã€‚

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šQwen3-30B-A3B-Thinking-2507
- **è®­ç»ƒæ¡†æ¶**ï¼šVeRLï¼Œé‡‡ç”¨ GRPOï¼ˆGroup Relative Policy Optimizationï¼‰ä½œä¸º RL ç®—æ³•ã€‚
- **è®­ç»ƒç­–ç•¥**ï¼šæ¸è¿›å¼é•¿åº¦æ‰©å±•ï¼ˆprogressive length extensionï¼‰ï¼Œåˆ†å››é˜¶æ®µé€æ­¥å¢åŠ æœ€å¤§è¾“å…¥/è¾“å‡ºé•¿åº¦ï¼ˆæœ€é«˜è¾¾ 120K / 50K tokensï¼‰ã€‚
- **è¯„ä¼°é…ç½®**ï¼šç»Ÿä¸€ä½¿ç”¨ 128K è¾“å…¥é•¿åº¦ã€50K è¾“å‡ºé•¿åº¦ï¼›æ¸©åº¦ 0.7ï¼Œtop-p 0.95ã€‚
- **è¯„åˆ†æ–¹å¼**ï¼š
  - å¤šé€‰é¢˜ï¼šAccuracy
  - MRCRï¼šSequenceMatcher ratio
  - å¤šè·³ QAï¼šCEMï¼ˆCover Exact Matchï¼‰æˆ– LLM-as-a-judgeï¼ˆä½¿ç”¨ DeepSeek-V3 åˆ¤æ–­è¯­ä¹‰ç­‰ä»·ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **æ——èˆ°æ¨¡å‹**ï¼šGPT-5ã€Gemini-2.5-Pro
- **è½»é‡çº§æ¨ç†æ¨¡å‹**ï¼šGemini-2.5-Flash-Thinkingã€DeepSeek-R1-0528ã€Qwen3-Max-Thinking
- **åŸºçº¿æ¨¡å‹**ï¼šQwen3-30B-A3B-Thinking-2507ï¼ˆç›´æ¥æ¯”è¾ƒå¯¹è±¡ï¼‰
- **å…¶ä»–ä»£ç†æ–¹æ³•**ï¼šMemAgent-14Bã€Qwen-Flash-Thinking-1M

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | å¹³å‡å¾—åˆ† | MRCR | CorpusQA | LongBench-V2 |
|------|----------|-------|-----------|---------------|
| Qwen3-30B-A3B-Thinking-2507 | 61.92 | 51.27 | 71.56 | 49.11 |
| **QwenLong-L1.5-30B-A3B** | **71.82** | **82.99** | **81.25** | **55.27** |

- åœ¨å…­é¡¹ä¸»æµé•¿ä¸Šä¸‹æ–‡æ¨ç†åŸºå‡†ä¸Šï¼ŒQwenLong-L1.5 ç›¸æ¯”å…¶åŸºçº¿å¹³å‡æå‡ **+9.90 åˆ†**ã€‚
- åœ¨ MRCR ä¸Šè¾¾åˆ° **82.99**ï¼Œæ¥è¿‘ GPT-5ï¼ˆ77.29ï¼‰å’Œ Gemini-2.5-Proï¼ˆ79.92ï¼‰ã€‚
- åœ¨ CorpusQA ä¸Šå¾—åˆ†ä¸º **81.25**ï¼Œåª²ç¾ GPT-5ï¼ˆ81.56ï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- æ€§èƒ½ä¼˜äºæ‰€æœ‰è½»é‡çº§æ¨¡å‹ï¼ˆå¦‚ Gemini-2.5-Flash-Thinkingã€DeepSeek-R1-0528ï¼‰ã€‚
- æ•´ä½“è¡¨ç°å¯ä¸ GPT-5 å’Œ Gemini-2.5-Pro ç­‰é¡¶çº§é—­æºæ¨¡å‹ç›¸åª²ç¾ã€‚
- åœ¨ **è¶…é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ï¼ˆ1M~4M tokensï¼‰** ä¸Šï¼Œå…¶ Memory-Agent æ¶æ„ç›¸æ¯”åŸºçº¿ä»£ç†é…ç½®æå‡ **+9.48 åˆ†**ã€‚

### æ¶ˆèå®éªŒç»“æœ
| æ–¹æ³• | å¹³å‡å¾—åˆ† | ç›¸æ¯” GRPO æå‡ |
|------|----------|----------------|
| GRPO baseline | 56.07 | â€” |
| + Task-balanced sampling | 56.86 | +0.79 |
| + Task-balanced + Task-specific advantage | 58.62 | **+2.55** |
| + AEPO | **59.36** | **+3.29** |

- **AEPO** æ˜¾è‘—æå‡è®­ç»ƒç¨³å®šæ€§ï¼Œåœ¨ Qwen3-4B-Thinking ä¸Šå¸¦æ¥ +3.29 åˆ†å¢ç›Šã€‚
- **ä»»åŠ¡ç‰¹å®šä¼˜åŠ¿ä¼°è®¡** å¯¹å¯†é›†å¥–åŠ±ä»»åŠ¡ï¼ˆå¦‚ MRCRï¼‰å°¤å…¶æœ‰æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åˆæˆé«˜è´¨é‡é•¿ä¸Šä¸‹æ–‡æ•°æ®æ˜¯æå‡æ¨ç†èƒ½åŠ›çš„å…³é”®**ï¼šé€šè¿‡ç»“æ„åŒ–çŸ¥è¯†æå–ä¸å¤šè·³è·¯å¾„æ„é€ ï¼Œç”Ÿæˆçš„æ•°æ®æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„å¤šè·³æ¨ç†ä¸ä¿¡æ¯èšåˆèƒ½åŠ›ã€‚
2. **ç¨³å®š RL æ˜¯é•¿ä¸Šä¸‹æ–‡è®­ç»ƒçš„å‰æ**ï¼šAEPO å’Œä»»åŠ¡å‡è¡¡é‡‡æ ·æœ‰æ•ˆç¼“è§£äº†é•¿åºåˆ— RL çš„ä¸ç¨³å®šæ€§ï¼Œä½¿å¾—æ¨¡å‹èƒ½åœ¨æ›´é•¿è¾“å…¥ä¸ŠæŒç»­å­¦ä¹ ã€‚
3. **Memory Agent å¯æ‰©å±•è‡³æç«¯é•¿åº¦**ï¼šåœ¨ 4M tokens è§„æ¨¡ä¸‹ä»èƒ½ä¿æŒæœ‰æ•ˆæ¨ç†ï¼ŒéªŒè¯äº†è¯¥æ¶æ„çš„å¯æ‰©å±•æ€§ã€‚
4. **é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›å…·æœ‰æ³›åŒ–æ•ˆåº”**ï¼šä¸ä»…åœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¿˜åœ¨ç§‘å­¦æ¨ç†ï¼ˆAIME25 +3.65ï¼‰ã€å·¥å…·ä½¿ç”¨ï¼ˆMemory-KV +5.80ï¼‰å’Œé•¿å¯¹è¯è®°å¿†ï¼ˆLongMemEval +15.60ï¼‰ä¸Šå–å¾—æ˜¾è‘—æå‡ã€‚

### å±€é™æ€§
- å½“å‰æ•°æ®åˆæˆä¾èµ–å¤–éƒ¨ LLM æˆ– APIï¼Œå­˜åœ¨æˆæœ¬ä¸èµ„æºç“¶é¢ˆã€‚
- å¥–åŠ±æœºåˆ¶ä»ä»¥è§„åˆ™+LLM-as-a-judgeä¸ºä¸»ï¼Œéš¾ä»¥åº”å¯¹å¼€æ”¾æ€§ä»»åŠ¡ã€‚
- ç¼ºä¹å¯¹é•¿è¾“å…¥+é•¿è¾“å‡ºåœºæ™¯çš„æ”¯æŒï¼ˆå¦‚æŠ¥å‘Šç”Ÿæˆã€ç« èŠ‚ä¿®è®¢ï¼‰ã€‚
- å°šæœªæ”¯æŒå¤šæ¨¡æ€é•¿åºåˆ—æ¨ç†ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ„å»ºé—­ç¯æ•°æ®é£è½®ï¼ˆClosed-Loop Data Flywheelï¼‰**ï¼šåˆ©ç”¨å·²è®­ç»ƒçš„å¼ºæ¨¡å‹è‡ªèº«ç”Ÿæˆæ–°çš„è®­ç»ƒæ•°æ®ä¸æ€ç»´è½¨è¿¹ï¼Œé™ä½å¯¹å¤–éƒ¨èµ„æºä¾èµ–ã€‚
2. **å‘å±•ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…æœºåˆ¶**ï¼šä»åºåˆ—çº§å¥–åŠ±è½¬å‘ token-level æˆ– step-level credit assignmentï¼Œæé«˜å­¦ä¹ æ•ˆç‡ã€‚
3. **ç ”å‘æ›´å¤æ‚çš„å¥–åŠ±æ¨¡å‹**ï¼šæ¢ç´¢åŸºäº rubric çš„è¯„åˆ†ç³»ç»Ÿï¼Œæ”¯æŒä¸»è§‚ã€å¤šç»´åº¦çš„ä»»åŠ¡è¯„ä»·ã€‚
4. **æ‰©å±•ä»»åŠ¡ç±»å‹ä¸æ¨¡æ€**ï¼šè¦†ç›–é•¿è¾“å…¥-é•¿è¾“å‡ºä»»åŠ¡ï¼Œå¹¶å‘å›¾åƒã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€é•¿åºåˆ—æ¨ç†å»¶ä¼¸ã€‚

--- 

> âœ… **æ€»ç»“**ï¼šQwenLong-L1.5 æä¾›äº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†å¢å¼ºæ–¹æ¡ˆï¼Œè¯æ˜äº†é€šè¿‡é«˜è´¨é‡æ•°æ®åˆæˆã€ç¨³å®š RL è®­ç»ƒå’Œè®°å¿†å¢å¼ºæ¶æ„ï¼Œå¼€æºæ¨¡å‹å¯ä»¥è¾¾åˆ°ç”šè‡³é€¼è¿‘é¡¶çº§é—­æºæ¨¡å‹çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†æ°´å¹³ï¼Œä¸”å…·å¤‡è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

</details>

---

### 14. [Accelerating Sparse Matrix-Matrix Multiplication on GPUs with Processing Near HBMs](https://arxiv.org/abs/2512.12036)

**Authors**: Shiju Li, Younghoon Min, Hane Yie, Hoshik Kim, Soohong Ahn, Joonseop Sim, Chul-Ho Lee, Jongryool Kim  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.12036v1  

#### Abstract
Sparse General Matrix-Matrix Multiplication (SpGEMM) is a fundamental operation in numerous scientific computing and data analytics applications, often bottlenecked by irregular memory access patterns. This paper presents Hash based Multi-phase SpGEMM on GPU and the Acceleration of Indirect Memory A...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAccelerating Sparse Matrix-Matrix Multiplication on GPUs with Processing Near HBMs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³çš„é—®é¢˜**
ç¨€ç–çŸ©é˜µ-çŸ©é˜µä¹˜æ³•ï¼ˆSpGEMMï¼‰æ˜¯ç§‘å­¦è®¡ç®—ã€å›¾åˆ†æå’Œå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ä¸­çš„æ ¸å¿ƒæ“ä½œï¼Œä½†åœ¨ç°ä»£GPUä¸Šæ‰§è¡Œæ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ä¸è§„åˆ™å†…å­˜è®¿é—®æ¨¡å¼**å¯¼è‡´ç¼“å­˜å‘½ä¸­ç‡ä½ã€ç©ºé—´å±€éƒ¨æ€§å·®ï¼›
- è¾“å‡ºçŸ©é˜µéé›¶å…ƒæ•°é‡æœªçŸ¥ï¼Œéš¾ä»¥é«˜æ•ˆåˆ†é…èµ„æºï¼›
- å¹¶è¡Œæ’å…¥æ“ä½œå¼€é”€å¤§ï¼Œè´Ÿè½½å‡è¡¡å›°éš¾ï¼›
- å…ƒæ•°æ®è®¿é—®é¢‘ç¹ï¼Œå‹ç¼©å­˜å‚¨æ ¼å¼å¸¦æ¥é¢å¤–å¼€é”€ã€‚

è¿™äº›é—®é¢˜ä½¿å¾—ä¼ ç»ŸGPUå®ç°éš¾ä»¥å……åˆ†å‘æŒ¥å…¶é«˜å¸¦å®½å’Œå¹¶è¡Œèƒ½åŠ›ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ä¸ª**è½¯ç¡¬ä»¶ååŒè®¾è®¡æ¡†æ¶**ï¼Œé€šè¿‡åœ¨GPUçš„é«˜å¸¦å®½å†…å­˜ï¼ˆHBMï¼‰é™„è¿‘å¼•å…¥ä¸“ç”¨å¤„ç†å•å…ƒæ¥ä¼˜åŒ–SpGEMMæ€§èƒ½ã€‚ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**Hash-based Multi-phase SpGEMM ç®—æ³•ï¼ˆè½¯ä»¶å±‚ï¼‰**
- é‡‡ç”¨ä¸‰é˜¶æ®µç­–ç•¥ï¼š**Row-grouping â†’ Allocation â†’ Accumulation**ã€‚
- å¼•å…¥åŸºäºå¯¹æ•°åˆ†æ¡¶çš„**è¡Œåˆ†ç»„æœºåˆ¶ï¼ˆRow-groupingï¼‰**ï¼Œå®ç°åŠ¨æ€è´Ÿè½½å‡è¡¡ã€‚
- è®¾è®¡ä¸¤ç§çº¿ç¨‹åˆ†é…ç­–ç•¥ï¼š
  - **PWPRï¼ˆPartial Warp Per Rowï¼‰**ï¼šè½»è´Ÿè½½ä½¿ç”¨4çº¿ç¨‹/è¡Œï¼›
  - **TBPRï¼ˆThread Block Per Rowï¼‰**ï¼šé‡è´Ÿè½½ä½¿ç”¨å®Œæ•´Blockå¤„ç†å•è¡Œã€‚
- åˆ©ç”¨å…±äº«å†…å­˜å“ˆå¸Œè¡¨è¿›è¡Œé«˜æ•ˆç´¯ç§¯ï¼Œå¹¶æ”¯æŒå›é€€åˆ°å…¨å±€å†…å­˜ä»¥åº”å¯¹å¤§è§„æ¨¡è¡Œã€‚

#### ï¼ˆ2ï¼‰**Processing-Near-HBM åŠ é€ŸæŠ€æœ¯ï¼šAIAï¼ˆAcceleration of Indirect memory Accessï¼‰**
- åœ¨HBMæ§åˆ¶å™¨ä¸­é›†æˆ**AIAå¼•æ“**ï¼Œä½äºGPUæ ¸å¿ƒä¸HBMå †æ ˆä¹‹é—´ã€‚
- æ”¯æŒ**Ranged Indirect Access**åŠŸèƒ½ï¼Œå°†SpGEMMä¸­çš„ä¸¤çº§é—´æ¥è®¿é—®ï¼ˆå¦‚ `x[a[i]]`, `x[a[i]+1]...`ï¼‰è½¬æ¢ä¸ºæ‰¹é‡è¿ç»­æµå¼è®¿é—®ã€‚
- å°†åŸæœ¬éœ€è¦å¤šæ¬¡å¾€è¿”ä¸»å­˜çš„æ“ä½œåˆå¹¶ä¸ºä¸€æ¬¡è¯·æ±‚-å“åº”äº¤äº’ï¼Œæ˜¾è‘—å‡å°‘å»¶è¿Ÿå’Œå†…å­˜æµé‡ã€‚

#### ï¼ˆ3ï¼‰**è½¯ç¡¬ååŒæ¶æ„è®¾è®¡**
- è½¯ä»¶ç®—æ³•é€‚é…ç¡¬ä»¶ç‰¹æ€§ï¼ˆå¦‚åˆ†ç»„æ˜ å°„åˆ°AIAè¯·æ±‚ï¼‰ï¼Œç¡¬ä»¶åé¦ˆæå‡ç¼“å­˜åˆ©ç”¨ç‡ã€‚
- AIAç›´æ¥ä½œç”¨äºHBMå±‚çº§ï¼Œé¿å…ä¸­é—´ç¼“å­˜æ±¡æŸ“ï¼Œæå‡L1/L2ç¼“å­˜æ•ˆç‡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ€§èƒ½** | æ˜¾è‘—ä¼˜äºcuSPARSEï¼Œåœ¨å¤šç§åº”ç”¨ä¸­å®ç°é«˜è¾¾76.5%çš„æ—¶é—´å‡å°‘ |
| **èƒ½æ•ˆä¸å¸¦å®½åˆ©ç”¨** | å‡å°‘æ— æ•ˆæ•°æ®ç§»åŠ¨ï¼Œæé«˜HBMåˆ©ç”¨ç‡ |
| **å¯æ‰©å±•æ€§** | å¯¹å¤§è§„æ¨¡ç¨€ç–å›¾è¡¨ç°æ›´ä¼˜ï¼Œå°¤å…¶é€‚ç”¨äºGNNç­‰è¿­ä»£å‹ä»»åŠ¡ |
| **é€šç”¨æ€§** | å¯åº”ç”¨äºå›¾èšç±»ã€å›¾æ”¶ç¼©ã€GNNè®­ç»ƒç­‰å¤šç§åœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

#### ï¼ˆ1ï¼‰**é€šç”¨SpGEMMæµ‹è¯•çŸ©é˜µ**
æ¥è‡ªUniversity of Florida Sparse Matrix Collectionï¼š
- `RoadTX`, `p2p-Gnutella04`, `amazon0601`, `web-Google`, `scircuit`, `cit-Patents`, `Economics`, `webbase-1M`, `wb-edu`, `cage15`, `Wind Tunnel`, `Protein`

æ¶µç›–ä¸åŒè§„æ¨¡ã€å¯†åº¦å’ŒNNZåˆ†å¸ƒçš„çŸ©é˜µã€‚

#### ï¼ˆ2ï¼‰**å›¾åˆ†æåº”ç”¨æ•°æ®é›†**
ç”¨äºè¯„ä¼°Markov Clustering (MCL) å’Œ Graph Contractionï¼š
- åŒä¸Šéƒ¨åˆ†çŸ©é˜µï¼Œé‡ç‚¹å…³æ³¨`RoadNet-TX`, `Wind Tunnel`, `Protein`, `Economics`

#### ï¼ˆ3ï¼‰**GNNè®­ç»ƒåŸºå‡†æ•°æ®é›†**
å…±6ä¸ªï¼Œè¦†ç›–ç¤¾äº¤ã€ç”Ÿç‰©ã€ç”µå•†ç­‰é¢†åŸŸï¼š
| Dataset | Nodes | Edges | Avg Degree |
|--------|-------|-------|------------|
| Flickr | 89K | 0.99M | 22.16 |
| ogbn-proteins | 132K | 79M | 1,193.92 |
| ogbn-arxiv | 169K | 1.3M | 15.77 |
| Reddit | 233K | 115M | 985.99 |
| Yelp | 717K | 14M | 38.93 |
| ogbn-products | 2.45M | 126M | 103.05 |

æ¨¡å‹ï¼šGCN, GIN, GraphSAGE

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

- **ç¡¬ä»¶å¹³å°**ï¼š
  - CPU: AMD EPYC 9555 64-core @ 3.2GHz
  - GPU: NVIDIA H200ï¼ˆé›†æˆAIAæ¨¡å—ï¼‰
  - å†…å­˜: 1.5TB RAM
- **è½¯ä»¶ç¯å¢ƒ**ï¼šLinuxç³»ç»Ÿï¼ŒCUDAæ”¯æŒ
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - æ‰§è¡Œæ—¶é—´ï¼ˆRuntimeï¼‰
  - GFLOPSï¼ˆåŸºäºä¸­é—´äº§ç‰©æ•°é‡è®¡ç®—ï¼‰
  - L1 Cache Hit Ratio
  - è®­ç»ƒæ—¶é—´åŠ é€Ÿæ¯”ï¼ˆé’ˆå¯¹GNNï¼‰
  - Speedup / Time Reduction ç›¸å¯¹äºåŸºçº¿

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **cuSPARSE** | NVIDIAå®˜æ–¹ç¨€ç–åº“ï¼Œä½œä¸ºä¸»è¦å¯¹æ¯”åŸºå‡† |
| **Software-only Implementation** | æœ¬æ–‡æå‡ºçš„Hash-basedå¤šç›¸ç®—æ³•ä½†æ— AIAç¡¬ä»¶åŠ é€Ÿï¼Œç”¨äºæ¶ˆèç ”ç©¶ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

| åº”ç”¨ç±»åˆ« | æŒ‡æ ‡ | ç»“æœ |
|--------|------|------|
| **åŸºç¡€SpGEMMï¼ˆè‡ªä¹˜ï¼‰** | å¹³å‡è¿è¡Œæ—¶é—´é™ä½ | **80.5%** vs cuSPARSE |
| | å¹³å‡ååé‡æå‡ | **6.87Ã—** GFLOPSæå‡ |
| | æœ€ä½³æ¡ˆä¾‹ï¼ˆWind Tunnelï¼‰ | è¾¾åˆ° **9.4Ã—** ååé‡æå‡ |
| **L1 Cacheå‘½ä¸­ç‡** | Accumulationé˜¶æ®µ | ä»64.41% â†’ **75.14%** |
| | Allocationé˜¶æ®µ | ä»64.66% â†’ **88.15%** |
| **Graph Contraction** | å¹³å‡æ—¶é—´å‡å°‘ | **76.5%** vs cuSPARSE |
| | æœ€é«˜æå‡ï¼ˆProteinï¼‰ | **91.1%** æ—¶é—´å‡å°‘ |
| **Markov Clustering (MCL)** | å¹³å‡æ—¶é—´å‡å°‘ | **58.4%** vs cuSPARSE |
| | æœ€é«˜æå‡ï¼ˆEconomicsï¼‰ | **88.7%** æ—¶é—´å‡å°‘ |
| **GNNè®­ç»ƒï¼ˆå«ç»“æ„åŒ–å‰ªæï¼‰** | å¹³å‡è®­ç»ƒæ—¶é—´å‡å°‘ï¼ˆvs è½¯ä»¶ç‰ˆï¼‰ | **30.3%** |
| | å¹³å‡è®­ç»ƒæ—¶é—´å‡å°‘ï¼ˆvs cuSPARSEï¼‰ | **48.6%** |
| | æœ€å¤§åŠ é€Ÿï¼ˆProductsæ•°æ®é›†ï¼‰ | **76.1%** æ—¶é—´å‡å°‘ï¼ˆå³çº¦4.18Ã— speedupï¼‰ |
| | å¹³å‡é€Ÿåº¦æå‡ï¼ˆvs cuSPARSEï¼‰ | **1.95Ã—** |

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **vs cuSPARSE**ï¼š
  - åœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸‹å‡å¤§å¹…é¢†å…ˆï¼›
  - ç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡ã€é«˜ç¨€ç–åº¦å›¾ä¸Šä¼˜åŠ¿æ˜æ˜¾ï¼ˆå¦‚`ogbn-products`ï¼‰ï¼›
  - å¯¹å¤æ‚è¿­ä»£ç®—æ³•ï¼ˆå¦‚MCLï¼‰æ•ˆæœå°¤ä¸ºçªå‡ºã€‚

- **vs è½¯ä»¶-onlyå®ç°**ï¼š
  - AIAå¸¦æ¥é¢å¤– **10â€“27%** çš„è¿è¡Œæ—¶é—´ç¼©å‡ï¼›
  - è¡¨æ˜ç¡¬ä»¶åŠ é€Ÿç¡®å®æœ‰æ•ˆç¼“è§£äº†å†…å­˜å¢™é—®é¢˜ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

- **AIAå¯¹Cacheçš„å½±å“**ï¼š
  - L1 Cache Hit Ratioåœ¨Allocationé˜¶æ®µæå‡è¶…è¿‡23ä¸ªç™¾åˆ†ç‚¹ï¼›
  - è¯´æ˜AIAæˆåŠŸå°†éšæœºè®¿é—®è½¬åŒ–ä¸ºé¡ºåºæµï¼Œæå¤§æ”¹å–„ç¼“å­˜è¡Œä¸ºã€‚

- **å›¾è§„æ¨¡ä¸æ€§èƒ½å¢ç›Šçš„å…³ç³»**ï¼š
  - Pearsonç›¸å…³ç³»æ•°è¾¾ **r = 0.94**ï¼Œæ˜¾ç¤ºAIAæ”¶ç›Šéšå›¾èŠ‚ç‚¹æ•°å¢é•¿è€Œä¸Šå‡ï¼›
  - å°å›¾ï¼ˆå¦‚Flickrï¼‰ä»…è·~15%æ”¹è¿›ï¼›
  - å¤§å›¾ï¼ˆå¦‚Productsï¼‰è¾¾åˆ° **89.16%** æ—¶é—´å‡å°‘ï¼ˆvs è½¯ä»¶ç‰ˆï¼‰ï¼›
  - è¶…çº¿æ€§æ‰©å±•è¶‹åŠ¿å‡ºç°åœ¨ >500KèŠ‚ç‚¹å›¾ä¸­ã€‚

- **ä¸åŒGNNæ¶æ„ä¸€è‡´æ€§å¥½**ï¼š
  - GCNã€GINã€GraphSAGEä¸‰è€…æ€§èƒ½æå‡æ–¹å·®å°äº3%ï¼Œè¡¨æ˜æ–¹æ³•å…·æœ‰**æ¶æ„æ— å…³æ€§**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **Processing-Near-HBM æ˜¯è§£å†³SpGEMMå†…å­˜ç“¶é¢ˆçš„æœ‰æ•ˆè·¯å¾„**  
   AIAé€šè¿‡åœ¨HBMå±‚çº§å¤„ç†é—´æ¥è®¿é—®ï¼Œä»æ ¹æœ¬ä¸Šæ”¹å˜äº†æ•°æ®æµåŠ¨æ¨¡å¼ï¼Œæ˜¾è‘—æå‡äº†ç¼“å­˜æ•ˆç‡å’Œå¸¦å®½åˆ©ç”¨ç‡ã€‚

2. **è½¯ç¡¬ä»¶ååŒè®¾è®¡è‡³å…³é‡è¦**  
   å•çº¯è½¯ä»¶ä¼˜åŒ–å·²è¾¾ç“¶é¢ˆï¼›ç»“åˆå®šåˆ¶åŒ–è¿‘å†…å­˜å¤„ç†å•å…ƒï¼ˆAIAï¼‰æ‰èƒ½çªç ´â€œå†…å­˜å¢™â€ã€‚

3. **AIAåœ¨çœŸå®åº”ç”¨åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²**  
   ä¸ä»…åœ¨åŸºç¡€SpGEMMä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œåœ¨**å›¾æ”¶ç¼©ã€MCLèšç±»ã€GNNè®­ç»ƒ**ç­‰å¤æ‚åº”ç”¨ä¸­ä¹Ÿå–å¾—æ˜¾è‘—åŠ é€Ÿã€‚

4. **æ€§èƒ½å¢ç›Šéšå›¾è§„æ¨¡æ‰©å¤§è€Œå¢å¼º**  
   éªŒè¯äº†è¯¥æ–¹æ¡ˆç‰¹åˆ«é€‚åˆ**å¤§è§„æ¨¡å›¾å¤„ç†å’Œç”Ÿäº§çº§GNNè®­ç»ƒ**ã€‚

5. **ç»“æ„åŒ–å‰ªæ + AIA å®ç°ä¹˜æ³•æ•ˆåº”**  
   ç®—æ³•çº§ç¨€ç–æ€§ä¸æ¶æ„çº§ä¼˜åŒ–ç›¸ç»“åˆï¼Œå¸¦æ¥å åŠ æ”¶ç›Šã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–ç‰¹å®šHBMæ¶æ„æ”¹é€ **  
   AIAéœ€åµŒå…¥HBMæ§åˆ¶å™¨ï¼Œç›®å‰å°šå±å®šåˆ¶åŒ–è®¾è®¡ï¼Œå°šæœªæ ‡å‡†åŒ–ï¼Œéƒ¨ç½²æˆæœ¬è¾ƒé«˜ã€‚

2. **ç¼–ç¨‹æ¨¡å‹å¤æ‚åº¦å¢åŠ **  
   å¼€å‘è€…éœ€ç†è§£AIAæ¥å£ï¼ˆå¦‚`AIA_range`è°ƒç”¨ï¼‰ï¼Œå¢åŠ äº†ç¼–ç¨‹è´Ÿæ‹…ã€‚

3. **é¢ç§¯ä¸åŠŸè€—å¼€é”€æœªè¯¦ç»†é‡åŒ–**  
   æ–‡ä¸­æœªæä¾›AIAå¼•æ“çš„å…·ä½“é¢ç§¯/åŠŸè€—å½±å“ï¼Œå¯èƒ½é™åˆ¶å…¶åœ¨ç§»åŠ¨ç«¯æˆ–ä½åŠŸè€—è®¾å¤‡çš„åº”ç”¨ã€‚

4. **ä»…éªŒè¯äºH200 GPU**  
   ç¼ºä¹è·¨å¹³å°æ³›åŒ–èƒ½åŠ›éªŒè¯ï¼ˆå¦‚Ampereã€Adaç­‰å…¶ä»–æ¶æ„ï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ¨å¹¿AIAè‡³æ›´å¤šç¨€ç–æ“ä½œ**  
   å¦‚SpMVã€ç¨€ç–Attentionã€ç¨€ç–å·ç§¯ç­‰ï¼Œæ„å»ºç»Ÿä¸€çš„PNMç¨€ç–åŠ é€Ÿç”Ÿæ€ã€‚

2. **è‡ªåŠ¨åŒ–ç¼–è¯‘å™¨æ”¯æŒ**  
   å¼€å‘è‡ªåŠ¨è¯†åˆ«SpGEMMæ¨¡å¼å¹¶ç”ŸæˆAIAè°ƒç”¨ä»£ç çš„ç¼–è¯‘å™¨å·¥å…·é“¾ã€‚

3. **æ ‡å‡†åŒ–AIAæŒ‡ä»¤é›†**  
   æ¨åŠ¨è¡Œä¸šæ ‡å‡†åˆ¶å®šï¼Œä½¿AIAæˆä¸ºä¸‹ä¸€ä»£GPUçš„æ ‡å‡†åŠŸèƒ½æ¨¡å—ã€‚

4. **æ¢ç´¢æ›´å¤šè¿‘å†…å­˜åŠŸèƒ½å•å…ƒç»„åˆ**  
   ç»“åˆPIMï¼ˆProcessing-in-Memoryï¼‰ä¸å…¶ä»–ä¸“ç”¨å•å…ƒï¼Œæ‰“é€ æ›´å¼ºå¤§çš„è¿‘å†…å­˜è®¡ç®—èŒƒå¼ã€‚

5. **æ‰©å±•è‡³åˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯**  
   åˆ©ç”¨AIAå‡å°‘è·¨èŠ‚ç‚¹é€šä¿¡å¼€é”€ï¼Œæ”¯æŒæ›´å¤§è§„æ¨¡å›¾çš„åˆ†å¸ƒå¼SpGEMMã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäº**Processing-Near-HBM**çš„æ–°å‹SpGEMMåŠ é€Ÿæ¶æ„AIAï¼Œé€šè¿‡è½¯ç¡¬ä»¶ååŒè®¾è®¡ï¼Œå°†ä¸è§„åˆ™å†…å­˜è®¿é—®è½¬åŒ–ä¸ºé«˜æ•ˆæµå¼è®¿é—®ï¼Œåœ¨å„ç±»å›¾åº”ç”¨ä¸­å®ç°äº†æœ€é«˜è¾¾**76.5%çš„è¿è¡Œæ—¶é—´å‡å°‘**å’Œ**6.87Ã—ååé‡æå‡**ï¼Œä¸ºè§£å†³GPUä¸Šçš„ç¨€ç–è®¡ç®—â€œå†…å­˜å¢™â€é—®é¢˜æä¾›äº†æå…·å‰æ™¯çš„æŠ€æœ¯è·¯çº¿ã€‚

</details>

---

### 15. [Link-Aware Energy-Frugal Continual Learning for Fault Detection in IoT Networks](https://arxiv.org/abs/2512.13340)

**Authors**: Henrik C. M. Frederiksen, Junya Shiraishi, Cedomir Stefanovic, Hei Victor Cheng, Shashi Raj Pandey  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.13340v1  

#### Abstract
The use of lightweight machine learning (ML) models in internet of things (IoT) networks enables resource constrained IoT devices to perform on-device inference for several critical applications. However, the inference accuracy deteriorates due to the non-stationarity in the IoT environment and limi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Link-Aware Energy-Frugal Continual Learning for Fault Detection in IoT Networks*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨èµ„æºå—é™çš„ IoT è®¾å¤‡ä¸Šéƒ¨ç½²è½»é‡çº§ Machine Learningï¼ˆMLï¼‰æ¨¡å‹è¿›è¡Œ **on-device inference**ï¼ˆå¦‚æ•…éšœæ£€æµ‹ï¼‰æ—¶ï¼Œé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- åˆå§‹è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œéš¾ä»¥è¦†ç›–æ‰€æœ‰æ½œåœ¨æ•…éšœï¼›
- ç¯å¢ƒéå¹³ç¨³æ€§å¯¼è‡´æ¨¡å‹æ€§èƒ½éšæ—¶é—´ä¸‹é™ï¼›
- é¢‘ç¹æ›´æ–°æ¨¡å‹ä¼šå¸¦æ¥é«˜æ˜‚çš„é€šä¿¡èƒ½è€—ï¼Œè€Œ IoT è®¾å¤‡é€šå¸¸èƒ½é‡å—é™ï¼›
- å›ºå®šå‘¨æœŸçš„æ•°æ®ä¸Šä¼ å’Œæ¨¡å‹æ›´æ–°ç­–ç•¥æ— æ³•é€‚åº”åŠ¨æ€å˜åŒ–çš„æ— çº¿é“¾è·¯æ¡ä»¶å’Œèƒ½é‡é¢„ç®—ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ **æœ‰é™çš„èƒ½é‡å’Œå¸¦å®½çº¦æŸä¸‹**ï¼ŒæŒç»­æå‡æ¨¡å‹çš„æ¨ç†å‡†ç¡®ç‡ï¼ˆå°¤å…¶æ˜¯å¯¹ç½•è§æ•…éšœçš„æ£€æµ‹èƒ½åŠ›ï¼‰ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„å…³é”®é—®é¢˜ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šACORD
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **ACORD**ï¼ˆAdaptive Compression Online Resource-aware fault Detectionï¼‰çš„ **äº‹ä»¶é©±åŠ¨å‹ã€èŠ‚èƒ½çš„æŒç»­å­¦ä¹ æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… åˆ›æ–°ç‚¹ 1ï¼šäº‹ä»¶é©±åŠ¨é€šä¿¡æœºåˆ¶
- IoT è®¾å¤‡ä»…åœ¨æ£€æµ‹åˆ°æ½œåœ¨å¼‚å¸¸äº‹ä»¶ï¼ˆå³å¯èƒ½ä¸ºæ•…éšœï¼‰æ—¶æ‰è§¦å‘æ•°æ®ä¸Šä¼ ï¼Œé¿å…æ— æ„ä¹‰çš„å‘¨æœŸæ€§é‡‡æ ·ï¼Œæ˜¾è‘—é™ä½é€šä¿¡å¼€é”€ã€‚
- å¼•å…¥â€œcontext windowâ€æœºåˆ¶ï¼Œä¸Šä¼ å½“å‰æ ·æœ¬åŠå…¶å‰å $2W+1$ ä¸ªç›¸å…³æ—¶åºæ ·æœ¬ï¼Œå¢å¼ºè¾¹ç¼˜æœåŠ¡å™¨ï¼ˆESï¼‰çš„è®­ç»ƒæ•°æ®ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

#### âœ… åˆ›æ–°ç‚¹ 2ï¼šé“¾è·¯æ„ŸçŸ¥çš„è‡ªé€‚åº”æ¨¡å‹å‹ç¼©
- åœ¨ ES æ›´æ–°æ¨¡å‹åï¼Œæ ¹æ®å½“å‰ä¼°è®¡çš„ä¸‹è¡Œé“¾è·¯é€Ÿç‡ $R_{DL}$ å’Œå¯ç”¨èƒ½é‡é¢„ç®— $E_{\text{th}}$ï¼ŒåŠ¨æ€è°ƒæ•´æ¨¡å‹å‹ç¼©å‚æ•°ï¼š
  - **Pruning Level (PL)**ï¼šå‰ªææ¯”ä¾‹
  - **Quantization Level (QL)**ï¼šé‡åŒ–ä½æ•°ï¼ˆå¦‚ 8-bit æˆ– 32-bitï¼‰
- å‹ç¼©ç­–ç•¥åŸºäºçº¿æ€§å›å½’å»ºæ¨¡ä¼ è¾“æ—¶é—´ä¸æ¨¡å‹å¤§å°çš„å…³ç³»ï¼Œå¹¶ç»“åˆç›®æ ‡å»¶è¿Ÿ $t_{DL}$ è¿›è¡Œä¼˜åŒ–ï¼Œç¡®ä¿åœ¨èƒ½è€—é™åˆ¶å†…å®Œæˆæ¨¡å‹ä¸‹å‘ã€‚

#### âœ… åˆ›æ–°ç‚¹ 3ï¼šè”åˆä¼˜åŒ–é€šä¿¡ä¸æ¨ç†å‚æ•°
- åŒæ—¶ä¼˜åŒ–ä¸‰ä¸ªå…³é”®å‚æ•°ï¼š
  1. ä¸Šè¡Œæ•°æ®å‹ç¼©ä¸­çš„ **context window å¤§å° $W$**
  2. ä¸‹è¡Œæ¨¡å‹å‹ç¼©ä¸­çš„ **PL å’Œ QL**
  3. æ•…éšœåˆ¤æ–­é˜ˆå€¼ **$T_{\text{th}}$**
- æ‰€æœ‰å‚æ•°å‡ä¾æ®å®æ—¶é“¾è·¯çŠ¶æ€å’Œèƒ½é‡æ¶ˆè€—åŠ¨æ€è°ƒæ•´ï¼Œå®ç°èƒ½æ•ˆä¸ç²¾åº¦çš„å¹³è¡¡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ACORD | åŸºçº¿æ–¹æ³•ï¼ˆHawk / Periodic Samplingï¼‰ |
|------|-------|-------------------------------|
| èƒ½é‡æ•ˆç‡ | â­ é«˜ï¼šæŒ‰éœ€ä¸Šä¼  + è‡ªé€‚åº”å‹ç¼© | âŒ ä½ï¼šå›ºå®šé«˜å¼€é”€æˆ–ç›²ç›®ä¸Šä¼  |
| æ¨¡å‹æ›´æ–°è´¨é‡ | â­ é«˜ï¼šåªä¼ æœ‰ä»·å€¼æ•°æ®ï¼Œæå‡è®­ç»ƒæœ‰æ•ˆæ€§ | âŒ ä¸­/ä½ï¼šå¯èƒ½åŒ…å«å†—ä½™æˆ–æ— å…³æ•°æ® |
| é“¾è·¯é€‚åº”æ€§ | â­ æ”¯æŒï¼šæ ¹æ® $R_{UL}/R_{DL}$ åŠ¨æ€è°ƒèŠ‚ | âŒ ä¸æ”¯æŒï¼šé™æ€é…ç½® |
| æ¨ç†å‡†ç¡®æ€§ï¼ˆrecallï¼‰ | â­ æ˜¾è‘—æ›´é«˜ï¼Œå°¤å…¶åœ¨ä½èƒ½é‡åœºæ™¯ | âŒ å—é™äºæ—©æœŸè€—å°½èƒ½é‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **pump_sensor_data**ï¼ˆæ¥è‡ª Kaggleï¼‰
  - åŒ…å«çº¦ 220,000 æ¡è®°å½•ï¼Œæ¯æ¡æœ‰ 50 ç»´ä¼ æ„Ÿå™¨ç‰¹å¾
  - æ ‡ç­¾ç±»åˆ«ï¼š`NORMAL`, `RECOVERING`, `BROKEN`
  - å°† `BROKEN` è§†ä¸ºæ•…éšœçŠ¶æ€ï¼ˆæ­£ç±»ï¼‰ï¼Œå…¶ä½™ä¸ºæ­£å¸¸
  - æ•°æ®é›†ä¸­ä»…æœ‰ **7 ä¸ªæ•…éšœäº‹ä»¶**ï¼Œä½“ç°â€œç½•è§æ•…éšœâ€çš„å®é™…æŒ‘æˆ˜
  - åˆå§‹è®­ç»ƒé›†å  10%ï¼Œæµ‹è¯•é›†å  90%ï¼Œä¸”æ‰€æœ‰æ•…éšœä¿ç•™åœ¨æµ‹è¯•é›†ä¸­

---

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šUbuntu 24.04 ä¸»æœºæ¨¡æ‹Ÿ IoT è®¾å¤‡ä¸ Edge Serverï¼ˆESï¼‰ï¼Œé€šè¿‡ Wi-Fi è·¯ç”±å™¨è¿æ¥
- **é€šä¿¡åè®®**ï¼šTCP åè®®ä¿éšœå¯é ä¼ è¾“
- **æ¨¡å‹ç±»å‹**ï¼š
  - Autoencoder (AE)ï¼šç”¨äºé‡æ„è¯¯å·®-based å¼‚å¸¸æ£€æµ‹
  - Binary Classifier (BC)ï¼šç›´æ¥åˆ†ç±»
- **æ¨¡å‹éƒ¨ç½²å·¥å…·**ï¼šTensorFlow Lite Micro
- **èƒ½è€—æ¨¡å‹**ï¼š
  - å‘å°„åŠŸç‡ $\xi_{tx} = 0.79\,\text{W}$ï¼Œæ¥æ”¶åŠŸç‡ $\xi_{rx} = 0.33\,\text{W}$
  - å•æ¬¡æ¨ç†èƒ½è€— $E_{\text{inf}}$ï¼šQL=8 æ—¶ä¸º 1.4 Î¼Jï¼›QL=32 æ—¶ä¸º 6.6 Î¼J
- **å‚è€ƒèƒ½é‡ $E_{\text{ref}} = 60\,\text{J}$**

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Recallï¼ˆå¬å›ç‡ï¼‰** | æ­£ç¡®è¯†åˆ«å‡ºçš„å®é™…æ•…éšœå æ¯”ï¼Œå³ $\frac{\text{TP}}{\text{TP} + \text{FN}}$ |
| **Energy Consumption ($E_{\text{total}}$)** | æ¯è½®é€šä¿¡ï¼ˆä¸Šè¡Œ+ä¸‹è¡Œï¼‰ä¸è®¡ç®—ï¼ˆæ¨ç†ï¼‰æ€»èƒ½è€— |
| **ROC Curve & TPR/FPR** | è¡¡é‡ä¸åŒ $T_{\text{th}}$ ä¸‹çš„çœŸé˜³æ€§ç‡ä¸å‡é˜³æ€§ç‡æƒè¡¡ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Hawk [4]**ï¼š
   - éè‡ªé€‚åº” CL æ–¹æ³•
   - å›ºå®šå‚æ•°ï¼š$PL=0$, $QL=32$, $W=200$
   - è‹¥æŸè½®è¶…å‡ºèƒ½é‡é¢„ç®—ï¼Œåˆ™åœæ­¢æ›´æ–°ç”šè‡³ç»ˆæ­¢ä»»åŠ¡
2. **Periodic Sampling**ï¼š
   - å®šæœŸä¸Šä¼ æ•°æ®ï¼Œä¸è€ƒè™‘æ•°æ®é‡è¦æ€§
   - ä¸Šä¸‹æ–‡çª—å£ $W=200$ï¼Œå‘¨æœŸæ ¹æ® $E_{\text{th}}$ è°ƒæ•´ä»¥æ»¡è¶³èƒ½è€—çº¦æŸ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Fig. 1b å’Œ 1cï¼‰

#### ğŸ”¹ åœ¨ä¸åŒèƒ½é‡çº¦æŸä¸‹çš„ Recall è¡¨ç°ï¼ˆFig. 1bï¼‰
- å½“ $E_{\text{th}} = 60\,\text{J}$ æ—¶ï¼š
  - **ACORD** çš„ recall è¾¾åˆ° **~0.75**
  - **Hawk** çº¦ä¸º **0.55**
  - **Periodic Sampling** çº¦ä¸º **0.45**
- åœ¨ä½èƒ½é‡æ¡ä»¶ä¸‹ï¼ˆå¦‚ $E_{\text{th}} < 30\,\text{J}$ï¼‰ï¼ŒACORD æ˜¾è‘—ä¼˜äºä¸¤è€…ï¼Œ**æœ€é«˜æå‡è¾¾ 42.8%**

> ğŸ’¡ åŸå› ï¼šACORD æ›´é«˜æ•ˆåœ°åˆ©ç”¨æœ‰é™èƒ½é‡è¿›è¡Œâ€œæœ‰æ„ä¹‰â€çš„æ•°æ®äº¤æ¢å’Œæ¨¡å‹æ›´æ–°ï¼Œå»¶é•¿äº†æœ‰æ•ˆè¿è¡Œæ—¶é—´ã€‚

#### ğŸ”¹ åœ¨ä¸åŒç½‘ç»œå¸¦å®½ä¸‹çš„ Recall è¡¨ç°ï¼ˆFig. 1cï¼‰
- å½“å¸¦å®½ä» 1 Mbps å¢åŠ åˆ° 10 Mbpsï¼š
  - æ‰€æœ‰æ–¹æ³• recall å‡ä¸Šå‡ï¼ˆæ›´å¤šé€šä¿¡æœºä¼šï¼‰
  - ä½†åœ¨ **ä½å¸¦å®½åŒºåŸŸï¼ˆ< 3 Mbpsï¼‰**ï¼ŒACORD æ˜æ˜¾é¢†å…ˆ
- åœ¨ 1 Mbps ä¸‹ï¼š
  - ACORD recall â‰ˆ 0.75
  - Hawk â‰ˆ 0.5
  - Periodic â‰ˆ 0.35

> ğŸ’¡ åŸå› ï¼šACORD åˆ©ç”¨é“¾è·¯æ„ŸçŸ¥å‹ç¼©ï¼Œå‡å°‘ä¼ è¾“æ—¶é—´ï¼Œåœ¨ä½é€Ÿé“¾è·¯ä¸Šä»å¯å®Œæˆå®Œæ•´æ›´æ–°æµç¨‹ã€‚

#### ğŸ”¹ åˆ†ç±»å™¨æ¯”è¾ƒï¼ˆFig. 1aï¼‰
- **Autoencoder (AE)** æ˜æ˜¾ä¼˜äº Binary Classifier (BC)
  - AE åœ¨ä¿æŒä½ FPR çš„åŒæ—¶è·å¾—æ›´é«˜ TPR
  - å› å…¶æŸå¤±å‡½æ•°è®¾è®¡å…è®¸ä» FP å’Œ TP æ ·æœ¬ä¸­å…±åŒå­¦ä¹ ï¼ˆé€šè¿‡è´Ÿæƒé‡ $\lambda_1 = -0.1$ æŠ‘åˆ¶æ•…éšœæ ·æœ¬é‡å»ºï¼‰
- æœ€ç»ˆé€‰æ‹© AE ä½œä¸ºé»˜è®¤ FD æ¨¡å‹

---

### æ¶ˆèåˆ†æï¼ˆéšå«åœ¨å‚æ•°ä¼˜åŒ–è¿‡ç¨‹ï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†ä»å‚æ•°ä¼˜åŒ–æµç¨‹å¯è§ï¼š
- **è‡ªé€‚åº”å‹ç¼©ï¼ˆPL/QLï¼‰** å¯¹æ»¡è¶³èƒ½é‡çº¦æŸè‡³å…³é‡è¦ï¼›
- **context window å¤§å° $W$** å½±å“è®­ç»ƒæ•°æ®ä¸°å¯Œåº¦ï¼Œè¿‡å¤§å¢åŠ èƒ½è€—ï¼Œè¿‡å°å½±å“æ¨¡å‹æ”¹è¿›ï¼›
- **å†³ç­–é˜ˆå€¼ $T_{\text{th}}$** é€šè¿‡ ROC æ›²çº¿ä¼˜åŒ–ï¼Œæ‰¾åˆ°æœ€ä½³ FPR-TPR å¹³è¡¡ç‚¹ï¼›
- è”åˆä¼˜åŒ–ä¸‰è€…å®ç°äº†ç«¯åˆ°ç«¯æ€§èƒ½æœ€å¤§åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **äº‹ä»¶é©±åŠ¨ + è‡ªé€‚åº”å‹ç¼© = é«˜æ•ˆæŒç»­å­¦ä¹ **
   - ä»…åœ¨å¿…è¦æ—¶é€šä¿¡ï¼Œé…åˆé“¾è·¯æ„ŸçŸ¥å‹ç¼©ï¼Œå¯åœ¨ä¸¥è‹›èƒ½é‡é™åˆ¶ä¸‹ç»´æŒé•¿æœŸæ¨¡å‹æ›´æ–°ã€‚
2. **ACORD æ˜¾è‘—ä¼˜äºå›ºå®šç­–ç•¥**
   - åœ¨ä½èƒ½é‡ï¼ˆ<60 Jï¼‰å’Œä½å¸¦å®½ï¼ˆ<3 Mbpsï¼‰ç¯å¢ƒä¸‹ï¼Œrecall æå‡é«˜è¾¾ **42.8%**
   - ç‰¹åˆ«é€‚åˆå·¥ä¸š IoT ä¸­ç½•è§æ•…éšœæ£€æµ‹ç­‰é•¿å°¾åº”ç”¨åœºæ™¯ã€‚
3. **AE æ¯” BC æ›´é€‚åˆå°æ ·æœ¬å¼‚å¸¸æ£€æµ‹**
   - åˆ©ç”¨ reconstruction error å’Œå®šåˆ¶åŒ– loss å‡½æ•°ï¼Œèƒ½åœ¨ç¼ºä¹æ­£ä¾‹æƒ…å†µä¸‹æœ‰æ•ˆå­¦ä¹ ã€‚
4. **ç³»ç»Ÿçº§è”åˆä¼˜åŒ–æ˜¯å…³é”®**
   - å•ç‹¬ä¼˜åŒ–é€šä¿¡æˆ–æ¨¡å‹æ— æ³•è¾¾åˆ°æœ€ä¼˜ï¼Œå¿…é¡»ååŒè®¾è®¡æ•°æ®ä¸Šä¼ ã€æ¨¡å‹å‹ç¼©ã€æ¨ç†é˜ˆå€¼ç­‰æ¨¡å—ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **å•è®¾å¤‡å‡è®¾**ï¼š
   - å½“å‰æ¡†æ¶åŸºäºå•ä¸€ IoT è®¾å¤‡ä¸ ES äº¤äº’ï¼Œæœªè€ƒè™‘å¤šèŠ‚ç‚¹ç«äº‰ä¿¡é“çš„æƒ…å†µã€‚
2. **ä¾èµ–å¯é æ ‡ç­¾åé¦ˆ**ï¼š
   - æ¨¡å‹è®­ç»ƒä¾èµ–ç³»ç»Ÿæ‰€æœ‰è€…æä¾›çš„æ•…éšœæ ‡ç­¾ï¼Œåœ¨æ— äººå·¥å¹²é¢„åœºæ™¯ä¸‹éš¾ä»¥æ‰©å±•ã€‚
3. **çº¿æ€§å›å½’è¿‘ä¼¼ä¼ è¾“æ—¶é—´**ï¼š
   - ä½¿ç”¨çº¿æ€§æ¨¡å‹æ‹Ÿåˆ $b(PL,QL)$ ä¸ä¼ è¾“æ—¶é—´å…³ç³»ï¼Œå¯èƒ½åœ¨å¤æ‚ç½‘ç»œç¯å¢ƒä¸­ä¸å¤Ÿç²¾ç¡®ã€‚
4. **æœªè€ƒè™‘æœ¬åœ°è®¡ç®—å»¶è¿Ÿ**ï¼š
   - å¿½ç•¥ MCU ä¸Šæ¨ç†ä»¥å¤–çš„æ“ä½œå»¶è¿Ÿï¼ˆå¦‚è°ƒåº¦ã€å†…å­˜è®¿é—®ç­‰ï¼‰ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **å¤šè®¾å¤‡å¹¶å‘åœºæ™¯**ï¼Œè®¾è®¡å…¬å¹³é«˜æ•ˆçš„ä¿¡é“æ¥å…¥ä¸æ¨¡å‹æ›´æ–°åè°ƒæœºåˆ¶ï¼›
2. æ¢ç´¢ **åŠç›‘ç£æˆ–æ— ç›‘ç£æ ‡ç­¾ç”Ÿæˆæœºåˆ¶**ï¼Œå‡å°‘å¯¹å¤–éƒ¨æ ‡æ³¨çš„ä¾èµ–ï¼›
3. å¼•å…¥æ›´ç²¾ç»†çš„ **é“¾è·¯é¢„æµ‹æ¨¡å‹**ï¼ˆå¦‚ LSTMï¼‰æ›¿ä»£çº¿æ€§å›å½’ï¼Œæå‡å‹ç¼©å†³ç­–å‡†ç¡®æ€§ï¼›
4. ç»“åˆ **semantic communication** æ€æƒ³ï¼Œè¿›ä¸€æ­¥å‹ç¼©è¯­ä¹‰ä¸Šæœ‰ä»·å€¼çš„ä¿¡æ¯è€ŒéåŸå§‹æ•°æ®ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> ACORD é€šè¿‡**äº‹ä»¶é©±åŠ¨é€šä¿¡ + é“¾è·¯æ„ŸçŸ¥æ¨¡å‹å‹ç¼© + è”åˆå‚æ•°ä¼˜åŒ–**ï¼Œå®ç°äº†åœ¨èƒ½é‡ä¸å¸¦å®½å—é™çš„ IoT ç½‘ç»œä¸­é«˜æ•ˆã€å¯æŒç»­çš„æ•…éšœæ£€æµ‹ï¼Œæ˜¾è‘—æå‡äº† recallï¼Œç‰¹åˆ«æ˜¯åœ¨èµ„æºæåº¦ç´§å¼ çš„çœŸå®åœºæ™¯ä¸­è¡¨ç°å‡ºå¼ºå¤§ä¼˜åŠ¿ã€‚

</details>

---

### 16. [DP-EMAR: A Differentially Private Framework for Autonomous Model Weight Repair in Federated IoT Systems](https://arxiv.org/abs/2512.13460)

**Authors**: Chethana Prasad Kabgere, Shylaja S S  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.13460v1  

#### Abstract
Federated Learning (FL) enables decentralized model training without sharing raw data, but model weight distortion remains a major challenge in resource constrained IoT networks. In multi tier Federated IoT (Fed-IoT) systems, unstable connectivity and adversarial interference can silently alter tran...

---

### 17. [Log Anomaly Detection with Large Language Models via Knowledge-Enriched Fusion](https://arxiv.org/abs/2512.11997)

**Authors**: Anfeng Peng, Ajesh Koyatan Chathoth, Stephen Lee  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.11997v1  

#### Abstract
System logs are a critical resource for monitoring and managing distributed systems, providing insights into failures and anomalous behavior. Traditional log analysis techniques, including template-based and sequence-driven approaches, often lose important semantic information or struggle with ambig...

---

### 18. [Personalized QoE Prediction: A Demographic-Augmented Machine Learning Framework for 5G Video Streaming Networks](https://arxiv.org/abs/2512.12736)

**Authors**: Syeda Zunaira Ahmed, Hejab Tahira Beg, Maryam Khalid  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.12736v1  

#### Abstract
Quality of Experience (QoE) prediction is a critical component of modern multimedia systems, particularly for adaptive video streaming in 5G networks. Accurate QoE estimation enables intelligent resource management and supports user centric service delivery. Existing QoE prediction approaches primar...

---

### 19. [AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning](https://arxiv.org/abs/2512.13278)

**Authors**: Jiaru Zou, Ling Yang, Yunzhe Qi, Sirui Chen, Mengting Ai, Ke Shen, Jingrui He, Mengdi Wang  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.13278v1  

#### Abstract
Agentic reinforcement learning has advanced large language models (LLMs) to reason through long chain-of-thought trajectories while interleaving external tool use. Existing approaches assume a fixed inventory of tools, limiting LLM agents' adaptability to new or evolving toolsets. We present AutoToo...

---

### 20. [AIR: Post-training Data Selection for Reasoning via Attention Head Influence](https://arxiv.org/abs/2512.13279)

**Authors**: Jinrui Liu, Jeff Wu, Xuanguang Pan, Gavin Cheung, Shuai Ma, Chongyang Tao  
**Category**: cs.CL  
**Published**: 2025-12-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.13279v1  

#### Abstract
LLMs achieve remarkable multi-step reasoning capabilities, yet effectively transferring these skills via post-training distillation remains challenging. Existing data selection methods, ranging from manual curation to heuristics based on length, entropy, or overall loss, fail to capture the causal i...

---

### 21. [Anchoring Values in Temporal and Group Dimensions for Flow Matching Model Alignment](https://arxiv.org/abs/2512.12387)

**Authors**: Yawen Shao, Jie Xiao, Kai Zhu, Yu Liu, Wei Zhai, Yang Cao, Zheng-Jun Zha  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.12387v1  

#### Abstract
Group Relative Policy Optimization (GRPO) has proven highly effective in enhancing the alignment capabilities of Large Language Models (LLMs). However, current adaptations of GRPO for the flow matching-based image generation neglect a foundational conflict between its core principles and the distinc...

---

### 22. [On Approaches to Building Surrogate ODE Models for Diffusion Bridges](https://arxiv.org/abs/2512.12671)

**Authors**: Maria Khilchuk, Vladimir Latypov, Pavel Kleshchev, Alexander Hvatov  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.12671v1  

#### Abstract
Diffusion and Schr\"{o}dinger Bridge models have established state-of-the-art performance in generative modeling but are often hampered by significant computational costs and complex training procedures. While continuous-time bridges promise faster sampling, overparameterized neural networks describ...

---

### 23. [Noise-Resilient Quantum Aggregation on NISQ for Federated ADAS Learning](https://arxiv.org/abs/2512.13196)

**Authors**: Chethana Prasad Kabgere, Sudarshan T S B  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.13196v1  

#### Abstract
Advanced Driver Assistance Systems (ADAS) increasingly employ Federated Learning (FL) to collaboratively train models across distributed vehicular nodes while preserving data privacy. Yet, conventional FL aggregation remains susceptible to noise, latency, and security constraints inherent to real-ti...

---

### 24. [Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection](https://arxiv.org/abs/2512.13240)

**Authors**: Zihui Zhao, Zechang Li  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.13240v1  

#### Abstract
Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which...

---

### 25. [LightTopoGAT: Enhancing Graph Attention Networks with Topological Features for Efficient Graph Classification](https://arxiv.org/abs/2512.13617)

**Authors**: Ankit Sharma, Sayan Roy Gupta  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.13617v1  

#### Abstract
Graph Neural Networks have demonstrated significant success in graph classification tasks, yet they often require substantial computational resources and struggle to capture global graph properties effectively. We introduce LightTopoGAT, a lightweight graph attention network that enhances node featu...

---

### 26. [AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org](https://arxiv.org/abs/2512.11935)

**Authors**: Jaehyung Lee, Justin Ely, Kent Zhang, Akshaya Ajith, Charles Rhys Campbell, Kamal Choudhary  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.11935v1  

#### Abstract
Artificial intelligence is reshaping scientific discovery, yet its use in materials research remains limited by fragmented computational ecosystems, reproducibility challenges, and dependence on commercial large language models (LLMs). Here we introduce AGAPI (AtomGPT.org API), an open-access agenti...

---

### 27. [MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations](https://arxiv.org/abs/2512.13154)

**Authors**: Emre Can Acikgoz, Jinoh Oh, Joo Hyuk Jeon, Jie Hao, Heng Ji, Dilek Hakkani-T\"ur, Gokhan Tur, Xiang Li, Chengyuan Ma, Xing Fan  
**Category**: cs.AI  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.13154v1  

#### Abstract
Conversational agents often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-agent architectures to manage complex conversational scenarios efficiently, ambiguity resolution remain...

---

### 28. [SPARS: A Reinforcement Learning-Enabled Simulator for Power Management in HPC Job Scheduling](https://arxiv.org/abs/2512.13268)

**Authors**: Muhammad Alfian Amrizal, Raka Satya Prasasta, Santana Yuda Pradata, Kadek Gemilang Santiyuda, Reza Pulungan, Hiroyuki Takizawa  
**Category**: cs.DC  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.13268v1  

#### Abstract
High-performance computing (HPC) clusters consume enormous amounts of energy, with idle nodes as a major source of waste. Powering down unused nodes can mitigate this problem, but poorly timed transitions introduce long delays and reduce overall performance. To address this trade-off, we present SPA...

---

### 29. [Meta-Continual Mobility Forecasting for Proactive Handover Prediction](https://arxiv.org/abs/2512.11841)

**Authors**: Sasi Vardhan Reddy Mandapati  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.11841v1  

#### Abstract
Short-term mobility forecasting is a core requirement for proactive handover (HO) in cellular networks. Real-world mobility is highly non-stationary: abrupt turns, rapid speed changes, and unpredictable user behavior cause conventional predictors to drift, leading to mistimed or failed handovers. We...

---

### 30. [Tiny Recursive Models on ARC-AGI-1: Inductive Biases, Identity Conditioning, and Test-Time Compute](https://arxiv.org/abs/2512.11847)

**Authors**: Antonio Roye-Azar, Santiago Vargas-Naranjo, Dhruv Ghai, Nithin Balamurugan, Rayan Amir  
**Category**: cs.LG  
**Published**: 2025-12-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.11847v1  

#### Abstract
Tiny Recursive Models (TRM) were proposed as a parameter-efficient alternative to large language models for solving Abstraction and Reasoning Corpus (ARC) style tasks. The original work reports strong performance and suggests that recursive latent updates enable non-trivial reasoning, but it remains...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
