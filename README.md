# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-15 05:57:29 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [xGR: Efficient Generative Recommendation Serving at Scale](https://arxiv.org/abs/2512.11529)

**Authors**: Qingxiao Sun, Tongxuan Liu, Shen Zhang, Siyu Wu, Peijun Yang, Haotian Liang, Menxin Li, Xiaolong Ma, Zhiwei Liang, Ziyi Ren, Minchao Zhang, Xinyu Liu, Ke Zhang, Depei Qian, Hailong Yang  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.11529v1  

#### Abstract
Recommendation system delivers substantial economic benefits by providing personalized predictions. Generative recommendation (GR) integrates LLMs to enhance the understanding of long user-item sequences. Despite employing attention-based architectures, GR's workload differs markedly from that of LL...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šxGR: Efficient Generative Recommendation Serving at Scale

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**ç”Ÿæˆå¼æ¨èç³»ç»Ÿï¼ˆGenerative Recommendation, GRï¼‰åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹çš„ä½å»¶è¿ŸæœåŠ¡æŒ‘æˆ˜**ï¼Œè¯†åˆ«å‡ºä¸‰ä¸ªæ ¸å¿ƒç“¶é¢ˆï¼š
1. **é•¿æç¤ºã€çŸ­è¾“å‡ºå¯¼è‡´çš„å†…å­˜ä¸è®¡ç®—å†—ä½™**ï¼šGRè¾“å…¥ä¸ºç”¨æˆ·é•¿æœŸè¡Œä¸ºåºåˆ—ï¼ˆæ•°ç™¾è‡³æ•°åƒtokenï¼‰ï¼Œè¾“å‡ºä»…ä¸ºå°‘æ•°å‡ ä¸ªtokenï¼Œä¼ ç»Ÿæ³¨æ„åŠ›æœºåˆ¶åœ¨beam searchä¸­é‡å¤åŠ è½½å…±äº«KVç¼“å­˜ï¼Œé€ æˆä¸¥é‡å†…å­˜å¸¦å®½å‹åŠ›ã€‚
2. **å¤§è§„æ¨¡itemç©ºé—´ä¸­çš„beam searchæ•ˆç‡ä½ä¸‹**ï¼šå¤§beam widthï¼ˆå¦‚512ï¼‰å’ŒTop-Kç­›é€‰å¸¦æ¥å·¨å¤§çš„æ’åºå¼€é”€å’Œæ— æ•ˆitemç”Ÿæˆé—®é¢˜ã€‚
3. **ç³»ç»Ÿçº§æµæ°´çº¿è°ƒåº¦ä¸å……åˆ†**ï¼šhost-deviceé—´ç¼ºä¹é‡å ï¼Œå¤šè¯·æ±‚ã€å¤šé˜¶æ®µå¹¶è¡Œåº¦ä¸è¶³ï¼Œå°¤å…¶å¯¹å°æ¨¡å‹è€Œè¨€ï¼Œhost-sideè°ƒåº¦å¼€é”€å æ¯”æ˜¾è‘—ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **xGR** â€”â€”ä¸€ä¸ªé¢å‘ç”Ÿæˆå¼æ¨èçš„ç«¯åˆ°ç«¯é«˜æ•ˆæ¨ç†æœåŠ¡ç³»ç»Ÿï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰xAttentionï¼šä¼˜åŒ–æ³¨æ„åŠ›è®¡ç®—
- **KV Cacheåˆ†ç¦»ç®¡ç†**ï¼šå°†KVç¼“å­˜åˆ†ä¸º**å…±äº«éƒ¨åˆ†**ï¼ˆpromptï¼‰å’Œ**éå…±äº«éƒ¨åˆ†**ï¼ˆdecodeé˜¶æ®µç”Ÿæˆçš„tokenï¼‰ï¼Œé¿å…beamä¹‹é—´é‡å¤åŠ è½½ç›¸åŒå‰ç¼€ã€‚
- **åˆ†é˜¶æ®µè®¡ç®—åˆ†é…ï¼ˆStaged Computation Allocationï¼‰**ï¼š
  - å°†æ³¨æ„åŠ›è®¡ç®—åˆ’åˆ†ä¸º **å…±äº«é˜¶æ®µã€éå…±äº«é˜¶æ®µã€åˆå¹¶é˜¶æ®µ**ï¼Œåˆ†åˆ«åœ¨ä¸åŒCore Groupï¼ˆCGï¼‰ä¸Šå¹¶è¡Œæ‰§è¡Œã€‚
  - å¼•å…¥ **OnlineSoftmax** å®ç°è·¨tileçš„æ¦‚ç‡å½’ä¸€åŒ–ã€‚
  - ä½¿ç”¨è½»é‡çº§å†³ç­–æ ‘å›å½’å™¨åŠ¨æ€é¢„æµ‹æœ€ä¼˜CGèµ„æºåˆ’åˆ†ç­–ç•¥ï¼Œå®ç°è´Ÿè½½å‡è¡¡ã€‚

#### ï¼ˆ2ï¼‰xBeamï¼šæå‡beam searchæ•ˆç‡
- **æœ‰æ•ˆè·¯å¾„çº¦æŸï¼ˆValid Path Constraintï¼‰**ï¼š
  - åˆ©ç”¨é¢„æ„å»ºçš„åˆæ³•itemè¯è¡¨ç”Ÿæˆ**item mask**ï¼Œé€šè¿‡maskè¿‡æ»¤éæ³•tokenç»„åˆï¼Œé˜²æ­¢â€œå¹»è§‰â€itemç”Ÿæˆã€‚
  - é‡‡ç”¨**ç¨€ç–+å¯†é›†æ··åˆå­˜å‚¨**ç­–ç•¥ï¼šæ—©æœŸdenseé¢„ç”Ÿæˆï¼ŒåæœŸsparseåŸåœ°æ›´æ–°ï¼Œé™ä½maskç”Ÿæˆå¼€é”€ã€‚
- **æ—©åœæ’åºæœºåˆ¶ï¼ˆEarly Sorting Terminationï¼‰**ï¼š
  - ç»´æŠ¤å¤§å°ä¸º`beam width`çš„å…¨å±€æœ€å°å †ï¼Œéå†beamæ—¶è‹¥å½“å‰log_probå°äºå †é¡¶åˆ™æå‰ç»ˆæ­¢è¯¥beamæœç´¢ï¼Œå¤§å¹…å‡å°‘æ’åºæ—¶é—´ã€‚
- **æ•°æ®ç»“æ„å¤ç”¨ï¼ˆData Structure Reuseï¼‰**ï¼š
  - å¤ç”¨è¢«æ·˜æ±°beamçš„æ•°æ®ç»“æ„ç©ºé—´ï¼Œé¿å…é¢‘ç¹å†…å­˜åˆ†é…/é‡Šæ”¾ï¼Œé™ä½GCå‹åŠ›ã€‚

#### ï¼ˆ3ï¼‰xScheduleï¼šç³»ç»Ÿçº§è°ƒåº¦ä¼˜åŒ–
- **ä¸‰çº§æµæ°´çº¿æ¶æ„**ï¼šScheduler â†’ Engine â†’ Workerï¼Œæ”¯æŒè·¨æ‰¹ã€è·¨è¯·æ±‚ã€è·¨é˜¶æ®µçš„å¤šå±‚æ¬¡å¹¶è¡Œã€‚
- **Host-Deviceé‡å **ï¼š
  - Hostä¾§filter maskç”Ÿæˆä¸Deviceä¾§forwardè®¡ç®—é‡å ï¼›
  - H2Dä¼ è¾“maskä¸self-attentionè®¡ç®—é‡å ã€‚
- **å›¾æäº¤ä¼˜åŒ–ï¼ˆKernel Graph Dispatchï¼‰**ï¼šå°†ä¸€ç³»åˆ—kernelæ“ä½œæ‰“åŒ…æˆé™æ€å›¾ä¸€æ¬¡æ€§æäº¤ï¼Œå‡å°‘CPUå¹²é¢„å’Œlaunchå¼€é”€ã€‚
- **å¤šæµå¹¶è¡Œï¼ˆMulti-stream Parallelismï¼‰**ï¼šå¤šä¸ªstreamå¹¶å‘å¤„ç†ä¸åŒbatchï¼Œå……åˆ†åˆ©ç”¨åŠ é€Ÿå™¨å¹¶è¡Œèƒ½åŠ›ï¼Œæ‘Šé”€hostè°ƒåº¦å¼€é”€ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚vLLM/xLLMï¼‰ | xGR |
|------|------------------------|-----|
| KVç®¡ç† | PagedAttentionï¼Œå¿½ç•¥å…±äº«å‰ç¼€ï¼Œé‡å¤åŠ è½½ | åˆ†ç¦»KVç¼“å­˜ï¼Œç‰©ç†å…±äº«å‰ç¼€ |
| å†…å­˜æ•ˆç‡ | å­˜åœ¨å¤§é‡block copyå’Œç¢ç‰‡ | é¿å…copyï¼Œtokenç²’åº¦ç®¡ç† |
| æ’åºå¼€é”€ | å…¨å±€æ’åºæ‰€æœ‰å€™é€‰ | æ—©åœæœºåˆ¶æ˜¾è‘—é™ä½æ’åºé‡ |
| è¿‡æ»¤æœºåˆ¶ | åŠ¨æ€ç”Ÿæˆmaskæˆ–å…¨é‡æ£€æŸ¥ï¼Œé«˜å»¶è¿Ÿ | è®¾å¤‡é©»ç•™maskèåˆï¼Œå¼€é”€æä½ |
| è°ƒåº¦ç²’åº¦ | å•ä¸€æµæ°´çº¿ï¼Œhost-deviceè€¦åˆç´§ | å¤šå±‚æ¬¡é‡å +å¤šstreamå¹¶è¡Œ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **Amazon Review**ï¼šå…¬å¼€æ¨èä»»åŠ¡åŸºå‡†æ•°æ®é›†ã€‚
- **JD Trace**ï¼šæ¥è‡ªäº¬ä¸œç”Ÿäº§ç¯å¢ƒçš„çœŸå®æµé‡traceï¼Œå…·æœ‰åŠ¨æ€è¯·æ±‚æ¨¡å¼ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - **Ascendé›†ç¾¤**ï¼š64èŠ‚ç‚¹ï¼Œæ¯èŠ‚ç‚¹16 Ascend NPUï¼ˆ64GBï¼‰ï¼Œé€šè¿‡HCCSäº’è”ã€‚
  - **GPUé›†ç¾¤**ï¼š8èŠ‚ç‚¹ï¼Œæ¯èŠ‚ç‚¹8 NVIDIA H800 GPUï¼ˆ80GBï¼‰ï¼Œé€šè¿‡NVLinkäº’è”ã€‚
- **æ¨¡å‹**ï¼š
  - **Qwen3**ï¼ˆ0.6B ~ 4Bå‚æ•°ï¼‰
  - **OneRec**ï¼ˆ0.1B ~ 3Bå‚æ•°ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å¹³å‡å»¶è¿Ÿï¼ˆAverage Latencyï¼‰**
  - **P99å»¶è¿Ÿï¼ˆP99 Latencyï¼‰**
  - **ååé‡ï¼ˆThroughput / RPSï¼‰**
  - **å³°å€¼å†…å­˜å ç”¨ï¼ˆPeak Memory Usageï¼‰**
  - **Kernelçº§æ€§èƒ½åˆ†æ**ï¼ˆå»¶è¿Ÿã€ç®—åŠ›åˆ©ç”¨ç‡ã€è®¿å­˜å¼€é”€ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **vLLM**ï¼šåŸºäºPagedAttentionçš„ä¸»æµLLMæ¨ç†å¼•æ“ï¼Œåœ¨Ascendä¸Šä½¿ç”¨vllm-ascendç§»æ¤ç‰ˆæœ¬ã€‚
- **xLLM**ï¼šå·¥ä¸šçº§æ¨ç†æ¡†æ¶ï¼Œä¸“ä¸ºAscendä¼˜åŒ–ï¼Œä¹Ÿä½¿ç”¨PagedAttentionæœºåˆ¶ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- åœ¨ä¸¥æ ¼P99å»¶è¿Ÿ â‰¤ 200msçº¦æŸä¸‹ï¼Œ**xGRç›¸æ¯”state-of-the-artåŸºçº¿å®ç°è‡³å°‘3.49Ã—çš„ååæå‡**ã€‚
- ç”Ÿäº§éƒ¨ç½²å·²æŒç»­è¿è¡Œ3ä¸ªæœˆï¼ŒæœåŠ¡æ•°äº¿ç”¨æˆ·ï¼Œå³°å€¼RPSè¾¾æ•°ä¸‡ï¼ŒP99å»¶è¿Ÿç¨³å®šæ§åˆ¶åœ¨200msä»¥å†…ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰ç«¯åˆ°ç«¯æ€§èƒ½ï¼ˆFigure 13 & 14ï¼‰
- æ‰€æœ‰æµ‹è¯•é…ç½®ä¸‹ï¼ŒxGRå‡æ˜¾è‘—ä¼˜äºvLLMå’ŒxLLMã€‚
- éšç€RPSå¢åŠ ï¼ŒåŸºçº¿å»¶è¿Ÿæ€¥å‰§ä¸Šå‡å¹¶å¾ˆå¿«çªç ´SLOï¼›è€ŒxGRä¿æŒå¹³ç¼“å¢é•¿ã€‚
- åœ¨å¤§beam widthï¼ˆå¦‚512ï¼‰åœºæ™¯ä¸‹ï¼Œæ€§èƒ½å·®è·è¿›ä¸€æ­¥æ‹‰å¤§ï¼ŒxGRä»èƒ½ç»´æŒç¨³å®šä½å»¶è¿Ÿã€‚

#### ï¼ˆ2ï¼‰å†…å­˜æ•ˆç‡ï¼ˆFigure 15 & 16ï¼‰
- **å›ºå®šè¾“å…¥é•¿åº¦1kï¼ŒBWä»128å¢è‡³512**ï¼š
  - xGRå†…å­˜åŸºæœ¬ç¨³å®šåœ¨~10GBï¼›
  - xLLMä»~15GBé£™å‡è‡³**46.3GB**ï¼ˆè¶…çº¿æ€§å¢é•¿ï¼‰ã€‚
- **å›ºå®šBW=256ï¼Œè¾“å…¥é•¿åº¦ä»1kåˆ°3k**ï¼š
  - xGRå³°å€¼ä»…**12.0GB**ï¼›
  - xLLMå§‹ç»ˆç»´æŒçº¦**30GB**ï¼Œå—åºåˆ—é•¿åº¦å½±å“å¤§ã€‚

#### ï¼ˆ3ï¼‰Kernelæ•ˆç‡ï¼ˆFigure 17ï¼‰
- **å»¶è¿Ÿ**ï¼šxAttentionç›¸è¾ƒPagedAttentioné™ä½çº¦**6.6Ã—**ã€‚
- **è®¡ç®—åå**ï¼šæå‡è¾¾**7Ã—**ã€‚
- **è®¿å­˜å¼€é”€**ï¼š
  - PagedAttentionå†…å­˜ç®¡é“å¿™æ—¶é«˜è¾¾**93.4%**ï¼ˆä¸¥é‡memory-boundï¼‰ï¼›
  - xAttentioné™è‡³**52%**ï¼ŒæˆåŠŸè½¬ä¸ºcompute-boundï¼Œç¡¬ä»¶åˆ©ç”¨ç‡æ›´é«˜ã€‚

#### ï¼ˆ4ï¼‰æ¶ˆèå®éªŒï¼ˆFigure 18ï¼‰
ä½¿ç”¨OneRec-0.1Bè¿›è¡Œè°ƒåº¦æ¨¡å—æ¶ˆèï¼š
- **Baselineï¼ˆä»…xAttention+xBeamï¼‰**ï¼šéšRPSä¸Šå‡å»¶è¿Ÿå¿«é€Ÿæ¶åŒ–ã€‚
- **+Valid Item Filtering**ï¼šå‡ ä¹æ— é¢å¤–å¼€é”€ï¼ŒéªŒè¯è®¾å¤‡å†…è¿‡æ»¤æœ‰æ•ˆæ€§ã€‚
- **+Kernel Graph Dispatch**ï¼šæ˜¾è‘—é™ä½kernel launchå¼€é”€ï¼Œå»¶è¿Ÿä¸‹é™æ˜æ˜¾ã€‚
- **+Multi-stream Execution**ï¼šå®ç°host-deviceå®Œå…¨é‡å ï¼Œæœ€ç»ˆæ€§èƒ½æœ€ä½³ã€‚

#### ï¼ˆ5ï¼‰GPUå¹³å°å¯ç§»æ¤æ€§éªŒè¯ï¼ˆFigure 19ï¼‰
- åœ¨NVIDIA H800 GPUé›†ç¾¤ä¸Šï¼ŒxGRåŒæ ·æ˜¾è‘—ä¼˜äºvLLMã€‚
- è¡¨æ˜å³ä½¿æ‹¥æœ‰é«˜å¸¦å®½ç¡¬ä»¶ï¼Œ**å•çº¯ç¡¬ä»¶å‡çº§æ— æ³•è§£å†³GRç‰¹æœ‰æŒ‘æˆ˜**ï¼Œå¿…é¡»ä¾èµ–ç³»ç»Ÿçº§é‡æ„ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç”Ÿæˆå¼æ¨èçš„å·¥ä½œè´Ÿè½½ç‰¹æ€§ä¸é€šç”¨LLMå­˜åœ¨æœ¬è´¨å·®å¼‚**ï¼šé•¿promptã€çŸ­è¾“å‡ºã€å¤§beam widthã€é«˜å¹¶å‘ã€ä¸¥SLOï¼Œå†³å®šäº†ä¸èƒ½ç›´æ¥å¥—ç”¨LLMæ¨ç†ç³»ç»Ÿã€‚
2. **å…±äº«å‰ç¼€çš„KVç¼“å­˜å¤ç”¨æ˜¯æ€§èƒ½å…³é”®**ï¼šxAttentioné€šè¿‡åˆ†ç¦»KVç®¡ç†å’Œåˆ†é˜¶æ®µè®¡ç®—ï¼Œæœ‰æ•ˆæ¶ˆé™¤å†—ä½™è®¿å­˜ï¼Œæ˜¯æ€§èƒ½æå‡çš„æ ¸å¿ƒé©±åŠ¨åŠ›ã€‚
3. **ç®—æ³•-ç³»ç»ŸååŒè®¾è®¡è‡³å…³é‡è¦**ï¼šxBeamç»“åˆvalid path constraintä¸early terminationï¼Œåœ¨ä¿è¯æ¨èè´¨é‡çš„åŒæ—¶æå¤§é™ä½æœç´¢å¼€é”€ã€‚
4. **ç³»ç»Ÿçº§é‡å ä¸å¹¶è¡Œä¸å¯å¿½è§†**ï¼šxScheduleé€šè¿‡multi-stream + kernel graph dispatch + host-device overlapï¼Œå……åˆ†æŒ–æ˜ç¡¬ä»¶æ½œåŠ›ï¼Œå°¤å…¶å¯¹å°è§„æ¨¡GRæ¨¡å‹æ„ä¹‰é‡å¤§ã€‚
5. **xGRå…·å¤‡è‰¯å¥½å¯ç§»æ¤æ€§**ï¼šå¯åœ¨Ascend NPUå’ŒNVIDIA GPUä¸Šé«˜æ•ˆè¿è¡Œï¼Œå¾—ç›Šäºç»Ÿä¸€æŠ½è±¡å’Œç»†ç²’åº¦ä¼˜åŒ–ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å‡è®¾**decodeæ­¥æ•°å›ºå®š**ï¼ˆå¦‚3æ­¥ç”Ÿæˆä¸€ä¸ªitem IDï¼‰ï¼Œå¯èƒ½é™åˆ¶æ›´çµæ´»çš„å˜é•¿ç”Ÿæˆåœºæ™¯ã€‚
- **item maskéœ€é¢„å…ˆæ„å»º**ï¼Œä¾èµ–ä¸šåŠ¡ä¾§æä¾›åˆæ³•itemé›†åˆï¼Œå¯¹å†·å¯åŠ¨æˆ–åŠ¨æ€æ–°å¢itemçš„æ”¯æŒéœ€é¢å¤–æœºåˆ¶ã€‚
- å¯¹**è¶…å¤§è§„æ¨¡æ¨¡å‹ï¼ˆ>10Bï¼‰** çš„æ‰©å±•æ€§å°šæœªå……åˆ†éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ”¯æŒ**åŠ¨æ€é•¿åº¦ç”Ÿæˆ**çš„beam searchæœºåˆ¶ã€‚
- ç»“åˆ**ç¼“å­˜æœºåˆ¶**ï¼ˆå¦‚IC-Cacheï¼‰è¿›ä¸€æ­¥åŠ é€Ÿé‡å¤ç”¨æˆ·è¯·æ±‚ã€‚
- æ¢ç´¢**è®­ç»ƒ-æ¨ç†è”åˆä¼˜åŒ–**ï¼Œä¾‹å¦‚ç»“æ„åŒ–å‰ªæä»¥å‡å°‘æœç´¢ç©ºé—´ã€‚
- æ‰©å±•è‡³**å¤šæ¨¡æ€ç”Ÿæˆå¼æ¨è**åœºæ™¯ï¼ˆæ–‡æœ¬+å›¾åƒ+è§†é¢‘ï¼‰ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> xGRé¦–æ¬¡ç³»ç»Ÿæ€§é‡æ„äº†ç”Ÿæˆå¼æ¨èçš„æœåŠ¡èŒƒå¼ï¼Œé€šè¿‡**operator-levelï¼ˆxAttentionï¼‰ã€algorithm-levelï¼ˆxBeamï¼‰ã€system-levelï¼ˆxScheduleï¼‰** ä¸‰å±‚ååŒä¼˜åŒ–ï¼Œåœ¨çœŸå®ç”Ÿäº§ç¯å¢ƒä¸­å®ç°äº†**3.49Ã—ä»¥ä¸Šååæå‡**ï¼ŒåŒæ—¶æ»¡è¶³é«˜å¹¶å‘ä¸‹çš„ä¸¥æ ¼ä½å»¶è¿Ÿè¦æ±‚ï¼Œä¸ºä¸‹ä¸€ä»£æ¨èç³»ç»ŸåŸºç¡€è®¾æ–½æä¾›äº†é‡è¦å‚è€ƒã€‚

</details>

---

### 2. [A Multi-Criteria Automated MLOps Pipeline for Cost-Effective Cloud-Based Classifier Retraining in Response to Data Distribution Shifts](https://arxiv.org/abs/2512.11541)

**Authors**: Emmanuel K. Katalay, David O. Dimandja, Jordan F. Masakuna  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.11541v1  

#### Abstract
The performance of machine learning (ML) models often deteriorates when the underlying data distribution changes over time, a phenomenon known as data distribution drift. When this happens, ML models need to be retrained and redeployed. ML Operations (MLOps) is often manual, i.e., humans trigger the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Multi-Criteria Automated MLOps Pipeline for Cost-Effective Cloud-Based Classifier Retraining in Response to Data Distribution Shifts

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å› æ•°æ®åˆ†å¸ƒæ¼‚ç§»ï¼ˆdata distribution driftï¼‰å¯¼è‡´æ€§èƒ½ä¸‹é™**çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚ä¼ ç»Ÿåšæ³•ä¸­ï¼Œæ¨¡å‹é‡è®­ç»ƒé€šå¸¸ä¾èµ–äººå·¥è§¦å‘æˆ–å›ºå®šå‘¨æœŸæ‰§è¡Œï¼Œå®¹æ˜“é€ æˆèµ„æºæµªè´¹æˆ–å“åº”ä¸åŠæ—¶ã€‚

### æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
ä½œè€…è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ª**å¤šæ ‡å‡†è‡ªåŠ¨åŒ–çš„ MLOps Pipelineï¼ˆAuto-MLOpsï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨å¤šç§ç»Ÿè®¡æŒ‡æ ‡è”åˆæ£€æµ‹æ•°æ®åˆ†å¸ƒå˜åŒ–ï¼›
- åªæœ‰å½“æ£€æµ‹åˆ°æ˜¾è‘—æ¼‚ç§»æ—¶æ‰è§¦å‘æ¨¡å‹é‡è®­ç»ƒï¼›
- åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶æœ€å°åŒ–äº‘è®¡ç®—æˆæœ¬ã€‚

è¯¥ Pipeline é›†æˆäº† Continuous Integration / Continuous Deployment (CI/CD) æ¶æ„ï¼Œå¹¶å¼•å…¥åŠ æƒç»„åˆçš„æ¼‚ç§»è¯„åˆ†æœºåˆ¶ï¼ˆDrift Score, DSï¼‰ï¼Œå®ç°ç§‘å­¦ã€å¯å®¡è®¡çš„é‡è®­ç»ƒå†³ç­–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è‡ªåŠ¨åŒ–ç¨‹åº¦** | å®Œå…¨è‡ªåŠ¨åŒ–çš„ CI/CD æµç¨‹ï¼Œå‡å°‘äººå·¥å¹²é¢„ |
| **æˆæœ¬æ•ˆç‡** | é¿å…ä¸å¿…è¦çš„é‡è®­ç»ƒï¼Œæ˜¾è‘—é™ä½äº‘èµ„æºæ¶ˆè€— |
| **æ£€æµ‹ç²¾åº¦** | å¤šæŒ‡æ ‡èåˆï¼ˆKSã€KLã€PSIã€MMDã€Accuracy/F1 å˜åŒ–ï¼‰æå‡æ¼‚ç§»è¯†åˆ«å¯é æ€§ |
| **å¯è§£é‡Šæ€§** | æä¾›â€œä¸ºä½•éœ€è¦é‡è®­ç»ƒâ€çš„è¯Šæ–­ä¾æ®ï¼Œå¢å¼ºè¿ç»´é€æ˜åº¦ |
| **ä¸ CARA çš„å…³ç³»** | æ˜¯å¯¹ Cost-Aware Retraining Algorithm (CARA) çš„æ‰©å±•ï¼Œå¢åŠ äº†ä¸¥æ ¼çš„æ¼‚ç§»æ£€æµ‹æœºåˆ¶ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåŸºäºå¤šä¸ªåŸºå‡†å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ï¼Œæ¶µç›–ç½‘ç»œã€é‡‘èã€åŒ»ç–—ç­‰é¢†åŸŸï¼Œå…·ä½“å¦‚ä¸‹ï¼š

| æ•°æ®é›† | æ ·æœ¬æ•° | å±æ€§æ•° | å¼‚å¸¸æ¯”ä¾‹ (%) |
|--------|--------|--------|--------------|
| CICIOT [19] | 416,985 | 41 | 45% |
| CREDIT24 | 234,333 | 30 | 0.2% |
| ECG [10] | 4,998 | 140 | 58% |
| IDSS221 | 430,256 | 95 | 43% |
| KITSUNE18 | 210,171 | 116 | 23% |
| MVTec3 | 5,354 | 1,048,576 | 58% |
| Visa [26] | 10,821 | 95 | 11% |

> æ³¨ï¼šMVTec3 ä¸ºé«˜ç»´å›¾åƒæ•°æ®ï¼Œå…¶ä½™å¤šä¸ºç»“æ„åŒ–æˆ–æ—¶é—´åºåˆ—æ•°æ®ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šé‡‡ç”¨ Auto-Encoder (AE) è¿›è¡Œå¼‚å¸¸æ£€æµ‹ä»»åŠ¡
- **è¶…å‚æ•°é…ç½®**ï¼š
  - Weight decay: 1e-6
  - Batch size: 64
  - Epochs: 100
  - Early stopping patience: 5
  - Learning rate: 1e-3
  - Optimizer: Adam
- **æ¼‚ç§»æ¨¡æ‹Ÿ**ï¼šé€šè¿‡é€æ­¥å¼•å…¥åˆ†å¸ƒå˜åŒ–æ¥æ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸­çš„ drift progression

### è¯„ä¼°æŒ‡æ ‡
- **Accuracy**ï¼šè¡¡é‡æ¨¡å‹é¢„æµ‹æ­£ç¡®ç‡
- **F1-score**ï¼šå¹³è¡¡ precision ä¸ recallï¼Œé€‚ç”¨äºç±»åˆ«ä¸å¹³è¡¡åœºæ™¯
- **Cloud cost**ï¼šä¼°ç®—æ¯æ¬¡é‡è®­ç»ƒæ‰€æ¶ˆè€—çš„äº‘èµ„æºå¼€é”€
- **Retraining frequency**ï¼šå•ä½æ—¶é—´å†…è§¦å‘é‡è®­ç»ƒçš„æ¬¡æ•°
- **Drift Score (DS)**ï¼šç»¼åˆå¤šä¸ªç»Ÿè®¡é‡çš„åŠ æƒå¾—åˆ†ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦é‡è®­ç»ƒ

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±æ¯”è¾ƒå››ç§ç­–ç•¥ï¼š
1. **STATIC**ï¼šä»ä¸é‡è®­ç»ƒï¼ˆæ— ä»»ä½•æ›´æ–°ï¼‰
2. **FIXED**ï¼šæŒ‰å›ºå®šå‘¨æœŸé‡è®­ç»ƒï¼ˆå¦‚æ¯å‘¨ä¸€æ¬¡ï¼‰ï¼Œæ— è§†å®é™…æ¼‚ç§»
3. **NAIVE**ï¼šä¸€æ—¦æ£€æµ‹åˆ°æ¼‚ç§»å³é‡è®­ç»ƒï¼Œæ— æˆæœ¬ä¼˜åŒ–
4. **Auto-MLOps**ï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰ï¼šä»…åœ¨ DS > é˜ˆå€¼ T æ—¶è§¦å‘é‡è®­ç»ƒï¼Œå…¼é¡¾æ€§èƒ½ä¸æˆæœ¬

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2ï¼‰

| æ¨¡å‹ | Accuracy (mean Â± std) | Cloud Cost (mean Â± std) | Retraining Frequency (mean Â± std) |
|------|------------------------|--------------------------|------------------------------------|
| STATIC | 0.69 Â± 0.20 | 54.8 Â± 5.6 | 0 Â± 0 |
| FIXED | 0.75 Â± 0.02 | 160.6 Â± 10.5 | 3 Â± 0 |
| NAIVE | 0.75 Â± 0.03 | 130.5 Â± 14.9 | 4.3 Â± 1.9 |
| **Auto-MLOps** | **0.75 Â± 0.03** | **108.1 Â± 14.3** | **1.4 Â± 1.2** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ€§èƒ½æ–¹é¢**ï¼š
  - Auto-MLOps ä¸ FIXED å’Œ NAIVE è¾¾åˆ°ç›¸åŒçš„æœ€é«˜å‡†ç¡®ç‡æ°´å¹³ï¼ˆ~0.75ï¼‰ï¼Œæ˜¾è‘—ä¼˜äº STATICï¼ˆ0.69ï¼‰
  - è¡¨æ˜è¯¥æ–¹æ³•èƒ½æœ‰æ•ˆç»´æŒæ¨¡å‹æ€§èƒ½
- **æˆæœ¬æ–¹é¢**ï¼š
  - æˆæœ¬æ¯” FIXED ä½çº¦ **32.5%**ï¼ˆ160.6 â†’ 108.1ï¼‰
  - æ¯” NAIVE ä½çº¦ **17.2%**ï¼ˆ130.5 â†’ 108.1ï¼‰
- **é‡è®­ç»ƒé¢‘ç‡**ï¼š
  - å¹³å‡ä»… **1.4 æ¬¡**ï¼Œè¿œä½äº NAIVE çš„ 4.3 æ¬¡ï¼Œè¯´æ˜é¿å…äº†å†—ä½™è®­ç»ƒ

### å›¾å½¢åˆ†ææ”¯æŒ
- **å›¾2ï¼ˆAccuracy vs Drift Severityï¼‰**ï¼šéšç€æ¼‚ç§»åŠ å‰§ï¼ŒSTATIC æ€§èƒ½æŒç»­ä¸‹é™ï¼Œè€Œ Auto-MLOps èƒ½ç¨³å®šä¿æŒé«˜ç²¾åº¦ã€‚
- **å›¾3ï¼ˆTime-series Comparisonï¼‰**ï¼šAuto-MLOps åœ¨ä¿æŒ accuracy æ¥è¿‘ 0.75 çš„åŒæ—¶ï¼Œcloud cost ä¸Šå‡æœ€ç¼“æ…¢ï¼Œä½“ç°å‡ºä¼˜å¼‚çš„æˆæœ¬æ•ˆç›Šã€‚

> â—æœªæŠ¥å‘Šæ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œæ— æ³•éªŒè¯å„ç»Ÿè®¡æŒ‡æ ‡ï¼ˆKSã€KLã€PSI ç­‰ï¼‰çš„å…·ä½“è´¡çŒ®æƒé‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¤šæ ‡å‡†æ¼‚ç§»æ£€æµ‹æœºåˆ¶æ˜¾è‘—æå‡ MLOps æ•ˆç‡**  
   ç»“åˆ PSIã€KL Divergenceã€KS Testã€MMD å’Œæ€§èƒ½å˜åŒ–çš„åŠ æƒ Drift Scoreï¼Œèƒ½å¤Ÿæ›´ç²¾å‡†åœ°è¯†åˆ«çœŸæ­£å½±å“æ¨¡å‹è¡¨ç°çš„åˆ†å¸ƒå˜åŒ–ã€‚

2. **è‡ªåŠ¨åŒ–å†³ç­–å¯åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å¤§å¹…é™ä½æˆæœ¬**  
   Auto-MLOps åœ¨è¾¾åˆ°ä¸ FIXED/NAIVE ç›¸åŒ accuracy çš„æƒ…å†µä¸‹ï¼Œå°†äº‘æˆæœ¬é™ä½äº† 17%-32%ï¼Œè¯æ˜å…¶å…·å¤‡è‰¯å¥½çš„ç»æµä»·å€¼ã€‚

3. **é™æ€æˆ–ç›²ç›®é‡è®­ç»ƒç­–ç•¥ä¸å¯æŒç»­**  
   - STATIC å¯¼è‡´æ¨¡å‹å¿«é€Ÿé€€åŒ–ï¼›
   - FIXED å’Œ NAIVE å­˜åœ¨å¤§é‡æ— æ•ˆè®¡ç®—ï¼Œèµ„æºåˆ©ç”¨ç‡ä½ä¸‹ã€‚

4. **é€‚åº”æ€§é‡è®­ç»ƒæ˜¯æœªæ¥ MLOps å‘å±•æ–¹å‘**  
   å°† drift detection ä¸ CI/CD pipeline æ·±åº¦é›†æˆï¼Œæ˜¯æ„å»ºå¯æŒç»­ã€å¯æ‰©å±• ML ç³»ç»Ÿçš„å…³é”®ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç»Ÿè®¡æµ‹è¯•çš„æ•æ„Ÿæ€§**ï¼šè‹¥é˜ˆå€¼è®¾ç½®ä¸å½“ï¼Œå¯èƒ½å¯¼è‡´ false positiveï¼ˆè¯¯æŠ¥æ¼‚ç§»ï¼‰æˆ– false negativeï¼ˆæ¼æ£€ï¼‰ã€‚
- **ç¼ºä¹åŠ¨æ€æƒé‡è°ƒæ•´æœºåˆ¶**ï¼šå½“å‰ DS ä¸­å„æŒ‡æ ‡æƒé‡ä¸ºç»éªŒè®¾å®šï¼Œæœªéšç¯å¢ƒè‡ªé€‚åº”è°ƒæ•´ã€‚
- **æœªè€ƒè™‘æ¦‚å¿µæ¼‚ç§»ï¼ˆconcept driftï¼‰çš„å¤æ‚ç±»å‹**ï¼šä¸»è¦å…³æ³¨è¾“å…¥åˆ†å¸ƒå˜åŒ–ï¼Œå¯¹ label åˆ†å¸ƒæ¼”å˜å»ºæ¨¡ä¸è¶³ã€‚
- **ç¼ºå°‘æ¶ˆèå®éªŒ**ï¼šæœªèƒ½é‡åŒ–ä¸åŒ drift metric çš„ç›¸å¯¹é‡è¦æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. å¼•å…¥ **Reinforcement Learning (RL)** æ¥å­¦ä¹ æœ€ä¼˜ retraining policyï¼Œä»å†å²éƒ¨ç½²ä¸­è‡ªåŠ¨ä¼˜åŒ–è§¦å‘æ—¶æœºã€‚
2. é›†æˆ **real-time cloud pricing fluctuation** æ¨¡å‹ï¼Œè¿›ä¸€æ­¥æå‡ cost-efficiencyã€‚
3. æ‰©å±•è‡³æ›´å¤šä»»åŠ¡ç±»å‹ï¼ˆå¦‚ regressionã€NLPï¼‰ï¼ŒéªŒè¯é€šç”¨æ€§ã€‚
4. å¼€å‘å¯è§†åŒ–ç›‘æ§é¢æ¿ï¼Œè¾…åŠ© human-in-the-loop å®¡æ ¸ä¸è°ƒè¯•ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ Auto-MLOps Pipeline é€šè¿‡å¤šæ ‡å‡†æ¼‚ç§»æ£€æµ‹ + è‡ªåŠ¨åŒ– CI/CD è§¦å‘æœºåˆ¶ï¼Œåœ¨ä¿éšœåˆ†ç±»å™¨æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½äº‘ä¸Šé‡è®­ç»ƒæˆæœ¬ï¼Œä¸ºå·¥ä¸šçº§ MLOps æä¾›äº†ä¸€ä¸ªé«˜æ•ˆã€å¯é ä¸”ç»æµå¯è¡Œçš„å®è·µèŒƒå¼ã€‚

</details>

---

### 3. [RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training](https://arxiv.org/abs/2512.11306)

**Authors**: Tianyuan Wu, Lunxi Cao, Yining Wei, Wei Gao, Yuheng Zhao, Dakai An, Shaopan Xiong, Zhiqiang Lv, Ju Huang, Siran Yang, Yinghao Yu, Jiamang Wang, Lin Qu, Wei Wang  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.11306v1  

#### Abstract
Rollout-training disaggregation is emerging as the standard architecture for Reinforcement Learning (RL) post-training, where memory-bound rollout and compute-bound training are physically disaggregated onto purpose-built clusters to maximize hardware efficiency. However, the strict synchronization ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šROLLMUX: Phase-Level Multiplexing for Disaggregated RL Post-Training

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºåŒ–å­¦ä¹ åè®­ç»ƒï¼ˆReinforcement Learning, RL post-trainingï¼‰ä¸­ï¼Œ**rollout-training disaggregation** å·²æˆä¸ºæ ‡å‡†æ¶æ„ã€‚è¯¥æ¶æ„å°†å†…å­˜å¯†é›†å‹çš„ rollout é˜¶æ®µä¸è®¡ç®—å¯†é›†å‹çš„ training é˜¶æ®µåˆ†åˆ«éƒ¨ç½²åœ¨ä¸“ç”¨é›†ç¾¤ä¸Šï¼Œä»¥æå‡ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚

ç„¶è€Œï¼Œç”±äº on-policy ç®—æ³•è¦æ±‚ä¸¥æ ¼çš„åŒæ­¥æ€§ï¼Œä¸¤ä¸ªé˜¶æ®µå¿…é¡»ä¸²è¡Œæ‰§è¡Œï¼Œå¯¼è‡´ä¸€ä¸ªé›†ç¾¤ç©ºé—²ç­‰å¾…å¦ä¸€ä¸ªå®Œæˆï¼Œå½¢æˆä¸¥é‡çš„ **dependency bubblesï¼ˆä¾èµ–æ°”æ³¡ï¼‰**ï¼Œé€ æˆèµ„æºä¸¥é‡æµªè´¹ã€‚ä¼ ç»Ÿå¼‚æ­¥æ–¹æ³•ï¼ˆå¦‚ AReaLã€StreamRLï¼‰è™½èƒ½æé«˜åˆ©ç”¨ç‡ï¼Œä½†ä¼šå¼•å…¥æ ·æœ¬è¿‡æœŸï¼ˆsample stalenessï¼‰ï¼ŒæŸå®³æ¨¡å‹æ”¶æ•›æ€§å’Œå‡†ç¡®æ€§ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡º **ROLLMUX**ï¼Œä¸€ç§é¢å‘è§£è€¦å¼ RL åè®­ç»ƒçš„è·¨é›†ç¾¤è°ƒåº¦æ¡†æ¶ï¼Œé€šè¿‡ **ç›¸ä½çº§å¤šè·¯å¤ç”¨ï¼ˆphase-level multiplexingï¼‰** æ¥å›æ”¶è¿™äº›â€œä¾èµ–æ°”æ³¡â€ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> åˆ©ç”¨ä¸€ä¸ªä»»åŠ¡çš„ç©ºé—²æ—¶é—´ï¼ˆå¦‚ rollout å®Œæˆåç­‰å¾… training çš„æ—¶é—´ï¼‰ï¼Œå»è¿è¡Œå¦ä¸€ä¸ªä»»åŠ¡çš„æ´»è·ƒé˜¶æ®µï¼ˆå¦‚ training æˆ– rolloutï¼‰ï¼Œä»è€Œå®ç°å¤šä¸ª RL ä»»åŠ¡ä¹‹é—´çš„é«˜æ•ˆäº¤é”™æ‰§è¡Œã€‚

ä¸ºæ­¤ï¼ŒROLLMUX å¼•å…¥äº†ä»¥ä¸‹å…³é”®æœºåˆ¶ï¼š

#### **(1) Co-Execution Group æŠ½è±¡**
- å°†å¤šä¸ª RL ä»»åŠ¡ç»„ç»‡ä¸º **å…±æ‰§è¡Œç»„ï¼ˆco-execution groupï¼‰**ï¼Œå…±äº«ä¸€ç»„ rollout å’Œ training èµ„æºæ± ã€‚
- ç»„å†…ä»»åŠ¡é€šè¿‡æ—¶é—´å¤ç”¨æ–¹å¼äº¤æ›¿æ‰§è¡Œ rollout å’Œ training é˜¶æ®µã€‚
- è¯¥æŠ½è±¡å®ç°äº†è°ƒåº¦é—®é¢˜çš„åˆ†è§£ï¼Œä½¿å…¨å±€ä¼˜åŒ–å˜ä¸ºå¯ç®¡ç†çš„å­é—®é¢˜ã€‚

#### **(2) ä¸¤çº§è°ƒåº¦æ¶æ„**
- **Inter-Group Schedulerï¼ˆç»„é—´è°ƒåº¦å™¨ï¼‰**  
  å†³å®šæ–°ä»»åŠ¡åº”åŠ å…¥å“ªä¸ªå…±æ‰§è¡Œç»„æˆ–æ˜¯å¦æ–°å»ºç»„ã€‚é‡‡ç”¨ä¿å®ˆçš„éšæœºè§„åˆ’ç­–ç•¥ï¼Œåœ¨æ»¡è¶³ SLO å’Œå†…å­˜çº¦æŸçš„å‰æä¸‹æœ€å°åŒ–è¾¹é™…èµ„æºæˆæœ¬ã€‚
- **Intra-Group Schedulerï¼ˆç»„å†…è°ƒåº¦å™¨ï¼‰**  
  åœ¨ç»„å†…å®æ–½ **è½®è½¬è°ƒåº¦ï¼ˆround-robinï¼‰**ï¼Œè¯æ˜å…¶åœ¨éè¿‡è½½ç»„ä¸­æ˜¯èµ„æºåˆ©ç”¨ç‡æœ€ä¼˜çš„ç­–ç•¥ã€‚

#### **(3) Warm-Start ä¸Šä¸‹æ–‡åˆ‡æ¢æœºåˆ¶**
- é€šè¿‡é™åˆ¶æ¯ç»„ä»»åŠ¡æ•°é‡ï¼Œç¡®ä¿æ‰€æœ‰æ¨¡å‹çŠ¶æ€ï¼ˆweightsã€optimizer statesï¼‰å§‹ç»ˆç¼“å­˜åœ¨ä¸»æœº DRAM ä¸­ã€‚
- ä¸Šä¸‹æ–‡åˆ‡æ¢æ—¶ç›´æ¥ä»æœ¬åœ°å†…å­˜åŠ è½½ï¼Œé¿å…è·¨ç½‘ç»œæˆ–ç£ç›˜å†·å¯åŠ¨ï¼Œ**å°†åˆ‡æ¢å»¶è¿Ÿé™ä½ä¸¤ä¸ªæ•°é‡çº§**ï¼ˆä»æœ€é«˜ 80 ç§’é™è‡³ <1 ç§’ï¼‰ã€‚

#### **(4) é•¿å°¾è¿ç§»ï¼ˆLong-Tail Migrationï¼‰**
- åŠ¨æ€æ£€æµ‹ rollout é˜¶æ®µä¸­çš„â€œé•¿å°¾è¯·æ±‚â€ï¼ˆstragglersï¼‰ï¼Œå°†å…¶è¿ç§»åˆ°å°‘é‡ GPU ä¸Šç»§ç»­å¤„ç†ã€‚
- é‡Šæ”¾å…¶ä½™ GPU ç«‹å³å¯åŠ¨ä¸‹ä¸€ä»»åŠ¡çš„ rolloutï¼Œå®ç°æµæ°´çº¿å¹¶è¡Œï¼Œæœ‰æ•ˆåº”å¯¹ç”Ÿæˆé•¿åº¦çš„é•¿å°¾åˆ†å¸ƒã€‚

#### **(5) æ‹“æ‰‘æ„ŸçŸ¥æ¨¡å‹åŒæ­¥ï¼ˆTopology-Aware Syncï¼‰**
- æ”¹è¿›ä¼ ç»Ÿçš„ flat AllGather åŒæ­¥æ–¹å¼ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µåŒæ­¥ï¼š
  1. **è·¨é›†ç¾¤åˆ†ç‰‡ä¼ è¾“**ï¼šä»…ä¼ è¾“ä¸€ä»½å®Œæ•´å‚æ•°å‰¯æœ¬ï¼ˆvia P2Pï¼‰
  2. **ç»„å†…å¹¿æ’­**ï¼šåˆ©ç”¨é«˜é€Ÿ NVLink/InfiniBand è¿›è¡Œå†…éƒ¨æ‰©æ•£
- æ˜¾è‘—å‡å°‘è·¨é›†ç¾¤é€šä¿¡å¼€é”€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ROLLMUX | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Solo-D, veRLï¼‰ |
|------|--------|-----------------------------|
| **èµ„æºåˆ©ç”¨ç‡** | é«˜ï¼Œé€šè¿‡ç›¸ä½äº¤é”™å¡«å……ä¾èµ–æ°”æ³¡ | ä½ï¼Œå­˜åœ¨å¤§é‡ç©ºé—²å‘¨æœŸ |
| **æˆæœ¬æ•ˆç‡** | æˆæœ¬é™ä½ 1.84Ã—ï¼ˆvs. Solo-Dï¼‰ï¼Œ1.38Ã—ï¼ˆvs. veRLï¼‰ | æˆæœ¬é«˜ï¼Œå°¤å…¶åœ¨æ˜‚è´µ GPU ä¸Šè¿è¡Œ rollout |
| **SLO ä¿éšœ** | 100% è¾¾æ ‡ | å¼‚æ­¥æ–¹æ³•éš¾ä»¥ä¿è¯ |
| **ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€** | æä½ï¼ˆwarm-startï¼‰ | å†·å¯åŠ¨è€—æ—¶é«˜è¾¾ 80 ç§’ |
| **ç®—æ³•å…¼å®¹æ€§** | æ”¯æŒä»»æ„ on-policy RL ç®—æ³•ï¼ˆPPOã€GRPO ç­‰ï¼‰ | å¤šæ•°éœ€ä¿®æ”¹ä¸º off-policy æ‰èƒ½æå‡åˆ©ç”¨ç‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸å·¥ä½œè´Ÿè½½**

- åŸºäºçœŸå®ç”Ÿäº§ç¯å¢ƒé‡‡é›†çš„ **ä¸¤å‘¨è½¨è¿¹æ•°æ®**ï¼ŒåŒ…å« **200 ä¸ªå¼‚æ„ RL ä»»åŠ¡**ã€‚
- æ¨¡å‹è§„æ¨¡è¦†ç›– **3Bâ€“32B**ï¼Œæœ€å¤§è¾“å‡ºé•¿åº¦ **4Kâ€“32K tokens**ï¼Œå¹³å‡å“åº”é•¿åº¦ 12.1Kã€‚
- æ•°æ®é›†æ¶µç›–æ•°å­¦æ¨ç†ï¼ˆDeepMath-103Kï¼‰ã€è½¯ä»¶å·¥ç¨‹ï¼ˆSWE-benchï¼‰ã€æ¸¸æˆäº¤äº’ç­‰ã€‚
- å¾®åŸºå‡†æµ‹è¯•ä½¿ç”¨ Qwen ç³»åˆ—æ¨¡å‹ï¼ˆ7Bâ€“32Bï¼‰ï¼Œå®šä¹‰äº”ç±»å…¸å‹ä»»åŠ¡ï¼ˆè§ Table 3ï¼‰ã€‚

---

### **å®éªŒè®¾ç½®**

- **ç¡¬ä»¶å¹³å°**ï¼š
  - **Rollout Cluster**ï¼š328 Ã— NVIDIA H20ï¼ˆä½æˆæœ¬ã€é«˜å¸¦å®½ï¼‰
  - **Training Cluster**ï¼š328 Ã— NVIDIA H800ï¼ˆé«˜æ€§èƒ½ã€é«˜ç®—åŠ›ï¼‰
  - ä¸¤é›†ç¾¤é€šè¿‡ **20 Gbps Ethernet** è¿æ¥ï¼Œå†…éƒ¨ä¸º 400 Gbps InfiniBandã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **æ€»èµ„æºä¾›ç»™æˆæœ¬ï¼ˆProvisioning Costï¼‰**ï¼ˆ$/hï¼‰
  - **SLO è¾¾æˆç‡**ï¼ˆSlowdown â‰¤ SLOï¼‰
  - **GPU åˆ©ç”¨ç‡ / ä¾èµ–æ°”æ³¡å‡å°‘æ¯”ä¾‹**
  - **ç«¯åˆ°ç«¯ååé‡ï¼ˆThroughput per Dollarï¼‰**
  - **å†³ç­–å»¶è¿Ÿä¸å¯æ‰©å±•æ€§**

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | æè¿° |
|------|------|
| **Solo Disaggregation (Solo-D)** | æ ‡å‡†è§£è€¦æ¶æ„ï¼Œæ¯ä¸ªä»»åŠ¡ç‹¬å  rollout å’Œ training èµ„æºï¼Œæ— æ—¶é—´å¤ç”¨ |
| **veRL [41]** | å•ä½“æ¶æ„ï¼Œæ‰€æœ‰é˜¶æ®µè¿è¡Œåœ¨ H800 ä¸Šï¼Œé¿å…è·¨é›†ç¾¤ç“¶é¢ˆä½†å­˜åœ¨ç¡¬ä»¶é”™é… |
| **Gavel+ [29]** | æ”¯æŒå¼‚æ„è°ƒåº¦çš„å¢å¼ºç‰ˆ Gavelï¼Œæ”¯æŒ RL åœºæ™¯ä½†æ— æ³•è¿›è¡Œç›¸ä½çº§äº¤é”™ |
| **Random / Greedy / Offline Optimal** | ç”¨äºæ¨¡æ‹Ÿç ”ç©¶çš„å¯¹æ¯”è°ƒåº¦ç­–ç•¥ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | ROLLMUX è¡¨ç° |
|------|-------------|
| **å¹³å‡èµ„æºæˆæœ¬** | **$510/h** |
| **SLO è¾¾æˆç‡** | **100%** |
| **rollout é›†ç¾¤ä¾èµ–æ°”æ³¡å‡å°‘** | **24.4%** |
| **training é›†ç¾¤ä¾èµ–æ°”æ³¡å‡å°‘** | **43.1%** |
| **å³°å€¼ H800 ä½¿ç”¨é‡** | **152**ï¼ˆvs. 328 in baselinesï¼‰â†’ **2.16Ã— å‡å°‘** |
| **å³°å€¼ H20 ä½¿ç”¨é‡** | **216**ï¼ˆvs. 328 in Solo-Dï¼‰â†’ **1.52Ã— å‡å°‘** |

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| å¯¹æ¯”é¡¹ | ROLLMUX vs. Solo-D | ROLLMUX vs. veRL |
|--------|--------------------|------------------|
| **æˆæœ¬æ•ˆç‡æå‡** | **1.84Ã—** æ›´ä¾¿å®œ | **1.38Ã—** æ›´ä¾¿å®œ |
| **è®­ç»ƒ GPU åˆ©ç”¨ç‡** | æ˜¾è‘—æå‡ï¼ˆå‡å°‘ idle timeï¼‰ | æ›´ä¼˜ï¼Œå›  rollout è¢«å¸è½½è‡³ H20 |
| **rollout æ€§èƒ½** | æ›´é«˜æ€§ä»·æ¯”ï¼ˆH20 æˆæœ¬ä»…ä¸º H800 çš„ ~1/3ï¼‰ | åŒæ ·å—ç›Šäº disaggregation |
| **SLO ä¿éšœèƒ½åŠ›** | ä¸¥æ ¼æ»¡è¶³ | veRL å¯èƒ½æ»¡è¶³ï¼Œä½†æˆæœ¬æ›´é«˜ |

> å›¾ 13 æ˜¾ç¤ºï¼Œåœ¨çœŸå® workload ä¸‹ï¼ŒROLLMUX çš„æˆæœ¬æ›²çº¿è¿œä½äº baselinesï¼Œä¸” GPU ä½¿ç”¨æ›´ç´§å‡‘ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **(1) é•¿å°¾è¿ç§»ï¼ˆLong-Tail Migrationï¼‰**
- åœ¨ rollout å­˜åœ¨é•¿å°¾è¯·æ±‚æ—¶ï¼Œå¯ç”¨è¿ç§»å¯å°†ç«¯åˆ°ç«¯ååæå‡ **1.06Ã— è‡³ 1.28Ã—**ã€‚
- æ•ˆæœéšåºåˆ—é•¿åº¦å¢åŠ è€Œå¢å¼ºï¼ˆå¦‚ 14B-8K æ¨¡å‹æ”¶ç›Šæœ€å¤§ï¼‰ã€‚

#### **(2) æ‹“æ‰‘æ„ŸçŸ¥åŒæ­¥ï¼ˆTopology-Aware Syncï¼‰**
- å•èŠ‚ç‚¹åŒæ­¥ï¼ˆ8H800 â†’ 8H20ï¼‰ï¼š**åŠ é€Ÿ 7.87Ã—â€“8.33Ã—**
- å¤šèŠ‚ç‚¹åŒæ­¥ï¼ˆ16H800 â†’ 16H20ï¼‰ï¼šä»ä¿æŒ **2.62Ã—â€“2.75Ã— åŠ é€Ÿ**
- å› ä¸ºåªä¼ ä¸€ä»½å‚æ•°å‰¯æœ¬ï¼Œå¤§å¹…ç¼“è§£è·¨é›†ç¾¤å¸¦å®½ç“¶é¢ˆã€‚

#### **(3) Warm-Start æœºåˆ¶**
- å¦‚å›¾ 4 æ‰€ç¤ºï¼Œwarm-start åˆ‡æ¢å»¶è¿Ÿæ¯” cold-start é™ä½ **48Ã—**ã€‚
- ä½¿å¾—ç»†ç²’åº¦çš„æ—¶é—´å¤ç”¨æˆä¸ºå¯èƒ½ï¼Œå¦åˆ™åˆ‡æ¢å¼€é”€å°†æŠµæ¶ˆè°ƒåº¦å¢ç›Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **ç›¸ä½çº§å¤šè·¯å¤ç”¨æ˜¯è§£è€¦ RL æ¶æ„çš„å…³é”®çªç ´å£**  
   é€šè¿‡å°†è°ƒåº¦ç²’åº¦ä»â€œä»»åŠ¡çº§â€ç»†åŒ–åˆ°â€œç›¸ä½çº§â€ï¼ŒROLLMUX æˆåŠŸåˆ©ç”¨äº†åŸæœ¬è¢«æµªè´¹çš„ä¾èµ–æ°”æ³¡ï¼Œæ˜¾è‘—æå‡äº†æ•´ä½“èµ„æºåˆ©ç”¨ç‡ã€‚

2. **ä¸¤çº§è°ƒåº¦ + Warm-Start æ˜¯å®ç°é«˜æ•ˆå¤ç”¨çš„åŸºç¡€**  
   - ç»„é—´è°ƒåº¦åŸºäºæˆæœ¬æœ€å°åŒ–å†³ç­–ï¼Œé¿å…ç›²ç›®æ‰©å®¹ï¼›
   - ç»„å†… round-robin è¢«ç†è®ºè¯æ˜ä¸ºæœ€ä¼˜ï¼›
   - warm-start æœºåˆ¶è§£å†³äº†ä¸Šä¸‹æ–‡åˆ‡æ¢çš„æ€§èƒ½ç“¶é¢ˆã€‚

3. **åŠ¨æ€é€‚åº”æ€§è‡³å…³é‡è¦**  
   é•¿å°¾è¿ç§»æœºåˆ¶ä½¿ç³»ç»Ÿèƒ½å¤Ÿåº”å¯¹ RL rollout çš„é«˜åº¦ä¸ç¡®å®šæ€§ï¼Œè¿›ä¸€æ­¥æå‡å®é™…ååã€‚

4. **ROLLMUX åœ¨çœŸå®ç”Ÿäº§åœºæ™¯ä¸­è¡¨ç°å“è¶Š**  
   åœ¨åŒ…å« 200 ä¸ªå¼‚æ„ä»»åŠ¡çš„çœŸå® trace ä¸Šï¼Œå®ç°äº† **1.84Ã— æˆæœ¬èŠ‚çœ**ï¼ŒåŒæ—¶ **100% æ»¡è¶³ SLO**ï¼ŒéªŒè¯äº†å…¶å·¥ä¸šçº§å®ç”¨æ€§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **å—é™äºèŠ‚ç‚¹å†…å­˜å®¹é‡**  
   æ¯ä¸ª co-execution group æœ€å¤šåªèƒ½å®¹çº³ 2â€“5 ä¸ªä»»åŠ¡ï¼ˆå–å†³äºæ¨¡å‹å¤§å°ï¼‰ï¼Œé™åˆ¶äº†æ‰“åŒ…çµæ´»æ€§ã€‚

2. **å¯¹æç«¯å¼‚æ„ä»»åŠ¡ç»„åˆæ•æ„Ÿ**  
   è‹¥ä»»åŠ¡é—´ phase duration å·®å¼‚è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´è°ƒåº¦æ•ˆç‡ä¸‹é™ï¼ˆå°½ç®¡ inter-group scheduler å·²å°½åŠ›è§„é¿ï¼‰ã€‚

3. **å‡è®¾ SLO å¯é¢„æµ‹**  
   è™½ç„¶é‡‡ç”¨ä¿å®ˆä¼°è®¡ï¼ˆworst-case token lengthï¼‰æ¥ä¿éšœ SLOï¼Œä½†åœ¨æç«¯åŠ¨æ€ç¯å¢ƒä¸‹ä»å¯èƒ½å­˜åœ¨é£é™©ã€‚

4. **æœªè€ƒè™‘è·¨ç»„å¹²æ‰°æˆ–æ•…éšœä¼ æ’­**  
   å½“å‰è®¾è®¡å‡è®¾ç»„é—´å®Œå…¨éš”ç¦»ï¼Œä½†å¤§è§„æ¨¡éƒ¨ç½²ä¸­ç½‘ç»œæ‹¥å¡ç­‰é—®é¢˜å¯èƒ½å½±å“å®é™…æ€§èƒ½ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¯æŒæ›´å¤§è§„æ¨¡çš„å…±æ‰§è¡Œç»„**  
   æ¢ç´¢æ›´é«˜æ•ˆçš„æ¨¡å‹çŠ¶æ€å‹ç¼©æˆ–åˆ†å±‚ç¼“å­˜æœºåˆ¶ï¼Œçªç ´å†…å­˜é™åˆ¶ã€‚

2. **å¼•å…¥é¢„æµ‹é©±åŠ¨çš„è°ƒåº¦**  
   ç»“åˆ LLM è¾“å‡ºé•¿åº¦é¢„æµ‹æ¨¡å‹ï¼Œæ›¿ä»£ä¿å®ˆçš„æœ€å¤§é•¿åº¦å‡è®¾ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–èµ„æºåˆ†é…ã€‚

3. **æ‰©å±•è‡³ off-policy æˆ–æ··åˆç­–ç•¥ä»»åŠ¡**  
   å½“å‰èšç„¦ on-policyï¼Œæœªæ¥å¯æ¢ç´¢å¯¹å¼‚æ­¥ä»»åŠ¡çš„æ”¯æŒï¼Œå®ç°ç»Ÿä¸€è°ƒåº¦æ¡†æ¶ã€‚

4. **é›†æˆ intra-job ä¼˜åŒ–æŠ€æœ¯**  
   å¦‚ speculative decodingã€parameter relocation ç­‰ï¼Œä¸ ROLLMUX å½¢æˆååŒä¼˜åŒ–ã€‚

5. **æ”¯æŒ MoEï¼ˆMixture-of-Expertsï¼‰æ¨¡å‹è°ƒåº¦**  
   è§£è€¦ä¸“å®¶å¹¶è¡Œï¼ˆExpert Parallelismï¼‰ä¸ phase-level multiplexing çš„ç»“åˆæ˜¯ä¸€ä¸ªé‡è¦æ–¹å‘ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **ROLLMUX é€šè¿‡ç›¸ä½çº§è°ƒåº¦ã€warm-start å¿«é€Ÿåˆ‡æ¢å’Œæ‹“æ‰‘æ„ŸçŸ¥åŒæ­¥ï¼Œåœ¨ä¸è§£è€¦ on-policy æ­£ç¡®æ€§çš„å‰æä¸‹ï¼Œå®ç°äº†é«˜è¾¾ 1.84Ã— çš„æˆæœ¬èŠ‚çº¦ï¼Œæ˜¯è§£è€¦å¼ RL è®­ç»ƒç³»ç»Ÿçš„ä¸€æ¬¡é‡å¤§çªç ´ã€‚**

</details>

---

### 4. [A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation](https://arxiv.org/abs/2512.11270)

**Authors**: Hong Je-Gal, Chan-Bin Yi, Hyun-Suk Lee  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.11270v1  

#### Abstract
Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misali...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨ç°å®ä»»åŠ¡ä¸­çš„åº”ç”¨é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **MDPå»ºæ¨¡å›°éš¾**ï¼šå°†éæ­£å¼çš„è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°è½¬åŒ–ä¸ºå½¢å¼åŒ–çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰éœ€è¦ä¸“å®¶è¿›è¡ŒçŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±ç­‰è¦ç´ çš„è®¾è®¡ï¼Œè¿‡ç¨‹ç¹çä¸”æ˜“å‡ºé”™ã€‚
- **ç¯å¢ƒå®ç°è„†å¼±**ï¼šä»MDPåˆ°å¯æ‰§è¡Œç¯å¢ƒçš„ç¼–ç è¿‡ç¨‹å®¹æ˜“å› å°é”™è¯¯å¯¼è‡´è®­ç»ƒå¤±è´¥æˆ–ç­–ç•¥åç¦»ç›®æ ‡ã€‚
- **ç¼ºä¹çµæ´»æ€§ä¸å¯æ‰©å±•æ€§**ï¼šä»»åŠ¡éœ€æ±‚å˜æ›´æ—¶ï¼ˆå¦‚ä¼˜åŒ–ç›®æ ‡ç”±â€œæœ€å¤§åŒ–æ€§èƒ½â€å˜ä¸ºâ€œæœ€å°åŒ–èƒ½è€—â€ï¼‰ï¼Œéœ€é‡æ–°æ‰‹åŠ¨è®¾è®¡MDPå¹¶é‡è®­ç­–ç•¥ï¼Œéš¾ä»¥å¿«é€Ÿå“åº”ã€‚

è¿™äº›é—®é¢˜ä¸¥é‡é˜»ç¢äº†RLåœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ã€ç½‘ç»œèµ„æºè°ƒåº¦ã€ä¾›åº”é“¾ç®¡ç†ç­‰é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **A-LAMP**ï¼ˆAgentic LLM-Based Framework for Automated MDP Modeling and Policy Generationï¼‰ï¼Œä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“å¤§æ¨¡å‹ï¼ˆmulti-agent LLMï¼‰çš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œç”¨äº**å…¨è‡ªåŠ¨åœ°ä»è‡ªç”±å½¢å¼çš„è‡ªç„¶è¯­è¨€æè¿°ç”ŸæˆMDPæ¨¡å‹å’Œå¯è®­ç»ƒçš„RLç­–ç•¥**ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†æ•´ä¸ªæ”¿ç­–ç”Ÿæˆæµç¨‹åˆ†è§£ä¸ºå¤šä¸ªé˜¶æ®µï¼Œå¹¶ç”±ä¸“é—¨çš„LLMä»£ç†ï¼ˆAgentï¼‰è´Ÿè´£æ¯ä¸ªå­ä»»åŠ¡ï¼›
- å„ä»£ç†ä¹‹é—´æŒ‰ä¾èµ–é¡ºåºåä½œï¼Œç¡®ä¿è¯­ä¹‰ä¸€è‡´æ€§ï¼›
- æ‰€æœ‰ä¸­é—´è¾“å‡ºå‡ä¸ºäººç±»å¯è¯»çš„å½¢å¼ï¼ˆå¦‚JSONã€LaTeXå…¬å¼ã€ä»£ç ï¼‰ï¼Œä¿è¯é€æ˜æ€§å’Œå¯éªŒè¯æ€§ã€‚

#### ä¸»è¦ç»„ä»¶åŒ…æ‹¬ï¼š
| Agent | åŠŸèƒ½ |
|-------|------|
| Parameter Agent | æå–ä»»åŠ¡ä¸­å·²çŸ¥å‚æ•°ï¼ˆå¦‚ç”¨æˆ·æ•°ã€å¸¦å®½ï¼‰ |
| Objective Agent | æ˜ç¡®ä¼˜åŒ–ç›®æ ‡ï¼ˆå¦‚â€œæœ€å¤§åŒ–ç³»ç»Ÿååé‡â€ï¼‰ |
| Variable Agent | è¯†åˆ«å†³ç­–å˜é‡ï¼ˆå¦‚â€œè¢«è°ƒåº¦çš„ç”¨æˆ·â€ï¼‰å’Œç³»ç»Ÿå˜é‡ |
| Constraint Agent | å½¢å¼åŒ–çº¦æŸæ¡ä»¶ï¼ˆå¦‚â€œæ¯æ—¶éš™åªèƒ½è°ƒåº¦ä¸€ä¸ªç”¨æˆ·â€ï¼‰ |
| Modeling Agent | æ„å»ºæ•°å­¦åŒ–çš„MDPç›®æ ‡å‡½æ•°ä¸çº¦æŸ |
| SAR Agent | å®šä¹‰çŠ¶æ€ç©ºé—´ï¼ˆStateï¼‰ã€åŠ¨ä½œç©ºé—´ï¼ˆActionï¼‰ã€å¥–åŠ±å‡½æ•°ï¼ˆRewardï¼‰ |
| Env Agent & Coding Agent | ç”Ÿæˆå¯æ‰§è¡Œçš„Gymé£æ ¼ç¯å¢ƒä»£ç ä¸DQNè®­ç»ƒå¾ªç¯ |
| Code Executor | è¿è¡Œä»£ç å¹¶åé¦ˆé”™è¯¯ä»¥æ”¯æŒè‡ªåŠ¨è°ƒè¯• |

æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸€ä¸ª**Error Correction Module**ï¼Œå…è®¸ä»£ç†è‡ªæˆ‘æ£€æŸ¥è¾“å‡ºç½®ä¿¡åº¦ï¼Œå¿…è¦æ—¶è¯·æ±‚äººå·¥æ¾„æ¸…ï¼Œæå‡é²æ£’æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | A-LAMP | å•ä¸€LLMï¼ˆå¦‚GPT-4oï¼‰ |
|------|--------|------------------|
| **å»ºæ¨¡å¯é æ€§** | åˆ†æ­¥æ¨ç†é™ä½è®¤çŸ¥è´Ÿæ‹…ï¼Œæé«˜å‡†ç¡®æ€§ | éœ€ä¸€æ¬¡æ€§å®Œæˆå¤æ‚æ¨ç†ï¼Œæ˜“é—æ¼ç»†èŠ‚ |
| **å¯è§£é‡Šæ€§** | æ¯ä¸ªé˜¶æ®µè¾“å‡ºç»“æ„åŒ–ã€å¯å®¡æŸ¥ | é»‘ç®±å¼ç«¯åˆ°ç«¯ç”Ÿæˆï¼Œéš¾è¿½æº¯é”™è¯¯æ¥æº |
| **é€‚åº”æ€§** | æ”¯æŒé€šè¿‡æ›´æ–°æè¿°è‡ªåŠ¨é‡æ„MDPä¸ç­–ç•¥ | ä¿®æ”¹åå¸¸éœ€é‡æ–°æç¤ºï¼Œæ•ˆæœä¸ç¨³å®š |
| **å¯¹å°æ¨¡å‹å‹å¥½** | è½»é‡ç‰ˆLight A-LAMPå¯åœ¨Gemma3-27Bä¸Šè¿è¡Œï¼Œæ¥è¿‘GPT-4oè¡¨ç° | å°æ¨¡å‹éš¾ä»¥ç‹¬ç«‹å®Œæˆå…¨æµç¨‹ |
| **æˆåŠŸç‡** | æ˜¾è‘—é«˜äºå•æ¨¡å‹åŸºçº¿ï¼Œå°¤å…¶åœ¨å®šåˆ¶ç¯å¢ƒä»»åŠ¡ä¸Š | ç¼–ç ä¸è®­ç»ƒå¤±è´¥ç‡é«˜ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šA-LAMPé€šè¿‡**ç»“æ„åŒ–åˆ†å·¥ + å¯éªŒè¯ä¸­é—´è¡¨ç¤º + é”™è¯¯ä¿®æ­£æœºåˆ¶**ï¼Œå®ç°äº†æ›´å¯é ã€å¯è§£é‡Šã€å¯å¤ç”¨çš„ç«¯åˆ°ç«¯RLè‡ªåŠ¨åŒ–ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ï¼ˆBenchmark Tasksï¼‰
å…±æµ‹è¯•5ä¸ªä»»åŠ¡ï¼Œæ¶µç›–ç»å…¸æ§åˆ¶ä¸é¢†åŸŸç‰¹å®šä¼˜åŒ–ï¼š

| ä»»åŠ¡ | ç±»å‹ | æ˜¯å¦éœ€è‡ªå®šä¹‰ç¯å¢ƒ |
|------|------|----------------|
| Cart-pole | ç»å…¸æ§åˆ¶ | å¦ï¼ˆå·²æœ‰Gymç¯å¢ƒï¼‰ |
| Mountain-car | ç»å…¸æ§åˆ¶ | å¦ |
| Wireless | æ— çº¿é€šä¿¡èµ„æºåˆ†é… | æ˜¯ï¼ˆShannonå®¹é‡å…¬å¼å»ºæ¨¡ï¼‰ |
| Drone-delivery (Drone-del.) | ç½‘æ ¼è·¯å¾„è§„åˆ’ | æ˜¯ |
| Inventory-management (Inv.-mgmt.) | é›¶å”®åº“å­˜ä¼˜åŒ– | æ˜¯ |

æ‰€æœ‰ä»»åŠ¡ä»…æä¾›**è‡ªç”±æ ¼å¼çš„è‡ªç„¶è¯­è¨€æè¿°**ä½œä¸ºè¾“å…¥ï¼Œæ— å…¶ä»–è¾…åŠ©ä¿¡æ¯ã€‚

---

### å®éªŒè®¾ç½®
- **ä¸»å¹²ç®—æ³•**ï¼šç»Ÿä¸€é‡‡ç”¨ **Deep Q-Network (DQN)** ä½œä¸ºRLè®­ç»ƒç®—æ³•ï¼ˆé€‚ç”¨äºç¦»æ•£åŠ¨ä½œç©ºé—´ï¼‰ã€‚
- **è¿è¡Œæ¬¡æ•°**ï¼šæ¯ç§æ–¹æ³•åœ¨æ¯ä¸ªä»»åŠ¡ä¸Šè¿è¡Œ20æ¬¡ï¼Œç»Ÿè®¡æˆåŠŸç‡ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  1. **Modeling Success Rate**ï¼šæå–çš„çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±æ˜¯å¦é€»è¾‘æ­£ç¡®ä¸”å®Œæ•´ã€‚
  2. **Coding Success Rate**ï¼šç”Ÿæˆä»£ç èƒ½å¦åœ¨æ ‡å‡†Pythonç¯å¢ƒä¸­æ— è¯­æ³•é”™è¯¯æ‰§è¡Œã€‚
  3. **Policy Generation Success Rate**ï¼šRLè®­ç»ƒæ˜¯å¦æ”¶æ•›è‡³æ»¡è¶³ä»»åŠ¡ç›®æ ‡çš„æœ€ä¼˜ç­–ç•¥ï¼ˆæœ€å…³é”®æŒ‡æ ‡ï¼‰ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **A-LAMP (GPT-4o)** | å®Œæ•´æ¡†æ¶ + æœ€å¼ºLLM |
| **Light A-LAMP (Gemma3-27B)** | è½»é‡ç‰ˆæœ¬ï¼Œä½¿ç”¨è¾ƒå°LLM |
| **GPT-4o (Single Model)** | å•ä¸€LLMç›´æ¥ç”Ÿæˆå®Œæ•´è®­ç»ƒä»£ç  |
| **Gemma3-27B (Single Model)** | åŒä¸Šï¼Œä½†ä½¿ç”¨å°æ¨¡å‹ |
| **A-LAMP w/o EC** | ç§»é™¤Error Correctionæ¨¡å—çš„æ¶ˆèç‰ˆæœ¬ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Task | A-LAMP | A-LAMP w/o EC | Light A-LAMP | GPT-4o | Gemma3-27B |
|------|--------|---------------|--------------|--------|------------|
| **Cart-pole** | 1.00 / 0.95 / **0.95** | â€“ | 1.00 / 0.85 / **0.45** | 1.00 / 0.75 / **0.45** | 1.00 / 0.60 / **0.35** |
| **Mountain-car** | 1.00 / 1.00 / **0.75** | â€“ | 0.95 / 0.70 / **0.55** | 1.00 / 1.00 / **0.40** | 1.00 / 0.35 / **0.30** |
| **Wireless** | 1.00 / 1.00 / **0.45** | 0.90 / 0.80 / **0.40** | 0.95 / 0.60 / **0.15** | 0.80 / 0.90 / **0.20** | 0.55 / 0.65 / **0.05** |
| **Drone-del.** | 0.80 / 0.95 / **0.45** | 0.65 / 0.75 / **0.30** | 0.55 / 0.50 / **0.15** | 0.35 / 0.55 / **0.10** | 0.40 / 0.05 / **0.00** |
| **Inv.-mgmt.** | 1.00 / 0.55 / **0.30** | 1.00 / 0.40 / **0.20** | 0.85 / 0.25 / **0.05** | 0.65 / 0.05 / **0.05** | 0.60 / 0.00 / **0.00** |

> æ³¨ï¼šä¸‰å…ƒç»„åˆ†åˆ«ä¸º Modeling / Coding / **Policy Generation** æˆåŠŸç‡

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­ï¼Œ**A-LAMPå‡å–å¾—æœ€é«˜çš„Policy Generation Success Rate**ã€‚
- åœ¨éœ€è¦è‡ªå®šä¹‰ç¯å¢ƒçš„ä»»åŠ¡ï¼ˆWireless, Drone-del., Inv.-mgmt.ï¼‰ä¸Šï¼ŒA-LAMPçš„æˆåŠŸç‡å‡ ä¹æ˜¯å•ä¸€LLMæ–¹æ³•çš„**ä¸¤å€ä»¥ä¸Š**ã€‚
- **Light A-LAMPï¼ˆåŸºäºGemma3-27Bï¼‰çš„è¡¨ç°è¿œè¶…å•ç‹¬ä½¿ç”¨Gemma3-27B**ï¼Œç”šè‡³æ¥è¿‘GPT-4oæ°´å¹³ï¼Œè¯´æ˜æ€§èƒ½å¢ç›Šä¸»è¦æ¥è‡ª**æ¡†æ¶è®¾è®¡è€Œéæ¨¡å‹è§„æ¨¡**ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆA-LAMP w/o ECï¼‰
- ç§»é™¤Error Correctionæ¨¡å—åï¼Œæ€§èƒ½ç•¥æœ‰ä¸‹é™ï¼Œä½†åœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­ä»æ˜¾è‘—ä¼˜äºå•æ¨¡å‹æ–¹æ³•ã€‚
- åœ¨å¤æ‚ä»»åŠ¡ï¼ˆå¦‚Drone-deliveryï¼‰ä¸Šï¼Œå¯ç”¨ECå¯è¿›ä¸€æ­¥æå‡æˆåŠŸç‡ï¼ˆä¾‹å¦‚Policy Generationä»0.30â†’0.45ï¼‰ï¼Œè¡¨æ˜**è½»é‡çº§äººæœºäº¤äº’èƒ½æœ‰æ•ˆå¢å¼ºç³»ç»Ÿé²æ£’æ€§**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ç»“æ„åŒ–å¤šä»£ç†åˆ†è§£æ˜¾è‘—æå‡å»ºæ¨¡å¯é æ€§**ï¼šç›¸æ¯”å•LLMâ€œç«¯åˆ°ç«¯å¹»è§‰â€ï¼Œåˆ†é˜¶æ®µä¸“ä¸šåŒ–ä»£ç†èƒ½æ›´å‡†ç¡®åœ°æ•æ‰ä»»åŠ¡è¯­ä¹‰ï¼Œå‡å°‘å»ºæ¨¡åå·®ã€‚
2. âœ… **è¯­ä¹‰å¯¹é½è´¯ç©¿å…¨æµç¨‹**ï¼šé€šè¿‡ä¸­é—´å¯éªŒè¯è¾“å‡ºï¼ˆJSONã€LaTeXã€ä»£ç ï¼‰ï¼Œç¡®ä¿ä»è‡ªç„¶è¯­è¨€åˆ°å¯æ‰§è¡Œç­–ç•¥çš„å…¨è¿‡ç¨‹ä¿æŒä¸€è‡´ã€‚
3. âœ… **å³ä½¿è½»é‡æ¨¡å‹ä¹Ÿèƒ½èƒœä»»å¤æ‚ä»»åŠ¡**ï¼šLight A-LAMPè¯æ˜è¯¥æ¡†æ¶å¯éƒ¨ç½²äºèµ„æºå—é™åœºæ™¯ï¼Œå…·å¤‡è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚
4. âœ… **ç”Ÿæˆç­–ç•¥å…·æœ‰ä»»åŠ¡æœ€ä¼˜æ€§**ï¼šåœ¨Wirelessä»»åŠ¡ä¸­ï¼ŒA-LAMPç”Ÿæˆçš„DQNç­–ç•¥æ€§èƒ½é€¼è¿‘ç†è®ºæœ€ä¼˜çš„è´ªå©ªè°ƒåº¦å™¨ï¼ˆè§Figure 4ï¼‰ï¼ŒéªŒè¯äº†å…¶æ­£ç¡®æ€§ä¸æœ‰æ•ˆæ€§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ç¼–ç é˜¶æ®µä»è¾ƒè„†å¼±**ï¼šå°½ç®¡æœ‰åé¦ˆè°ƒè¯•æœºåˆ¶ï¼Œä½†è¯­æ³•æˆ–ç»“æ„ä¸åŒ¹é…ä»å¯èƒ½å¯¼è‡´æ‰§è¡Œå¤±è´¥ï¼ˆå°¤å…¶åœ¨Inv.-mgmt.ä»»åŠ¡ä¸­CodingæˆåŠŸç‡ä»…ä¸º55%ï¼‰ã€‚
- **ä¾èµ–é«˜è´¨é‡LLMåŸºç¡€èƒ½åŠ›**ï¼šè‹¥åº•å±‚LLMæ— æ³•ç†è§£é¢†åŸŸçŸ¥è¯†ï¼ˆå¦‚Shannonå…¬å¼ï¼‰ï¼Œåˆ™å»ºæ¨¡å¯èƒ½å‡ºé”™ã€‚
- **æœªå¤„ç†è¿ç»­åŠ¨ä½œç©ºé—´æˆ–é«˜ç»´çŠ¶æ€**ï¼šå½“å‰å®éªŒé›†ä¸­åœ¨ç¦»æ•£åŠ¨ä½œä»»åŠ¡ï¼Œå°šæœªéªŒè¯åœ¨MuJoCoç­‰å¤æ‚æ§åˆ¶ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. å¼•å…¥æ›´ç»†ç²’åº¦çš„**ç¼–ç ä»£ç†æ¨¡å—**ï¼ˆå¦‚ä¸“ç”¨äºç¯å¢ƒæ„å»ºã€è®­ç»ƒå¾ªç¯ç”Ÿæˆï¼‰ä»¥æå‡ä»£ç ç¨³å®šæ€§ã€‚
2. åŠ å…¥**è‡ªé€‚åº”è¶…å‚æ•°è°ƒä¼˜ä¸éªŒè¯æœºåˆ¶**ï¼Œå‡å°‘äººå·¥å¹²é¢„ã€‚
3. èåˆ**é¢†åŸŸå…ˆéªŒçŸ¥è¯†ä¸ç»“æ„åŒ–çŸ¥è¯†åº“**ï¼Œå¢å¼ºå¯¹ä¸“ä¸šæœ¯è¯­çš„ç†è§£ã€‚
4. æ¢ç´¢æ”¯æŒ**è¿ç»­åŠ¨ä½œç©ºé—´ï¼ˆå¦‚DDPGã€SACï¼‰ä¸POMDPå»ºæ¨¡**çš„èƒ½åŠ›ï¼Œæ‹“å±•é€‚ç”¨èŒƒå›´ã€‚

---

## æ€»ç»“
A-LAMPæå‡ºäº†ä¸€ç§**æ¨¡å—åŒ–ã€å¯è§£é‡Šã€å¯éªŒè¯çš„å¤šä»£ç†LLMæ¡†æ¶**ï¼ŒæˆåŠŸå®ç°äº†ä»è‡ªç„¶è¯­è¨€æè¿°åˆ°å¯æ‰§è¡ŒRLç­–ç•¥çš„å…¨è‡ªåŠ¨åŒ–æµç¨‹ã€‚å®éªŒè¯æ˜å…¶åœ¨å»ºæ¨¡ç²¾åº¦ã€ä»£ç è´¨é‡ä¸ç­–ç•¥æˆåŠŸç‡æ–¹é¢å…¨é¢è¶…è¶Šå•ä¸€LLMæ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦è‡ªå®šä¹‰ç¯å¢ƒçš„å¤æ‚ä»»åŠ¡ä¸­ä¼˜åŠ¿æ˜æ˜¾ã€‚è¯¥å·¥ä½œä¸ºæ¨åŠ¨RLåœ¨çœŸå®ä¸–ç•Œçš„å¤§è§„æ¨¡è½åœ°æä¾›äº†å¼ºæœ‰åŠ›çš„è‡ªåŠ¨åŒ–å·¥å…·é“¾æ”¯æŒã€‚

</details>

---

### 5. [Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes](https://arxiv.org/abs/2512.11463)

**Authors**: Junghwan Lim, Sungmin Lee, Dongseok Kim, Taehyun Kim, Eunhwan Park, Jeesoo Lee, Jeongdoo Lee, Junhyeok Lee, Wai Ting Cheung, Dahye Choi, Minsu Ha, Jaeheui Her, Jaeyeon Huh, Hanbin Jung, Changjin Kang, Beomgyu Kim, Minjae Kim, Taewhan Kim, Youngrok Kim, Hyukjin Kweon, Haesol Lee, Kungyu Lee, Dongpin Oh, Yeongjae Park, Bokki Ryu, Dongjoo Weon  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.11463v1  

#### Abstract
We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³å½“å‰**å¼€æ”¾æƒé‡è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†å’Œé•¿ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ä¸Šæ˜¾è‘—è½åäºé—­æºå‰æ²¿æ¨¡å‹**çš„é—®é¢˜ã€‚å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š
- **è®­ç»ƒä¸ç¨³å®š**ï¼šåœ¨å¼•å…¥å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼ˆRLFTï¼‰åå¸¸å‡ºç°æ¨¡å‹å´©æºƒï¼ˆmodel collapseï¼‰æˆ–æ€§èƒ½é€€åŒ–ã€‚
- **åˆ†å¸ƒä¸åŒ¹é…**ï¼ˆDistribution Mismatchï¼‰ï¼šä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆçš„åˆæˆæ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ—¶ï¼Œå› æ¨ç†é£æ ¼ä¸å­¦ç”Ÿæ¨¡å‹ä¸ä¸€è‡´è€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
- **é•¿ä¸Šä¸‹æ–‡è®­ç»ƒæ•ˆç‡ä½**ï¼šå¤„ç†64K tokençº§åˆ«çš„ä¸Šä¸‹æ–‡å¯¹å†…å­˜å’Œè®¡ç®—èµ„æºè¦æ±‚æé«˜ã€‚
- **RLFTæ ·æœ¬æ•ˆç‡ä½ä¸”éš¾ä»¥ç¨³å®šä¼˜åŒ–**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
è®ºæ–‡æå‡ºäº†ä¸€ä¸ª**ç³»ç»Ÿæ€§ã€å¯å¤ç°çš„å®Œæ•´è®­ç»ƒé…æ–¹**ï¼ˆtraining recipeï¼‰ï¼Œæ¶µç›–ç³»ç»Ÿã€æ•°æ®ä¸ç®—æ³•ä¸‰ä¸ªå±‚é¢çš„ä¼˜åŒ–ï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹åˆ›æ–°ï¼š

#### ï¼ˆ1ï¼‰ä¸¤é˜¶æ®µã€åˆ†å¸ƒå¯¹é½çš„ SFT è¯¾ç¨‹è®¾è®¡ï¼ˆTwo-stage Distribution-Aligned SFT Curriculumï¼‰
- **Stage 1ï¼ˆReasoning Foundationï¼‰**ï¼šæ„å»ºé«˜è´¨é‡å¤šé¢†åŸŸæ•°æ®é›†ï¼ˆæ•°å­¦ã€ä»£ç ã€STEMã€å·¥å…·ä½¿ç”¨ï¼‰ï¼Œé€šè¿‡éš¾åº¦ç­›é€‰ä¸æ‰§è¡ŒéªŒè¯ç¡®ä¿æ•°æ®è´¨é‡ã€‚
- **Stage 2ï¼ˆDeep Reasoning Specializationï¼‰**ï¼šæ³¨å…¥é«˜ç²’åº¦åˆæˆæ•°æ®ï¼ˆå¦‚Chain-of-Thoughtè½¨è¿¹ï¼‰ï¼Œå¹¶é‡æ–°ç”Ÿæˆæ¨ç†è·¯å¾„ä»¥**å¯¹é½ç›®æ ‡æ¨¡å‹çš„æ¨ç†åˆ†å¸ƒ**ï¼Œé¿å…â€œåˆ†å¸ƒä¸åŒ¹é…â€é—®é¢˜ã€‚

> âœ… åˆ›æ–°ç‚¹ï¼šå¼ºè°ƒâ€œæ¨ç†åˆ†å¸ƒå¯¹é½â€è€Œéå•çº¯è¿½æ±‚æ•°æ®é‡ï¼Œæå‡ºâ€œè´¨é‡ä¼˜äºæ•°é‡â€åŸåˆ™ã€‚

#### ï¼ˆ2ï¼‰ç¨³å®šçš„ RLFT æµæ°´çº¿è®¾è®¡
- **LLM-as-a-data-filtering**ï¼šåˆ©ç”¨é¢„è®­ç»ƒæ£€æŸ¥ç‚¹å¯¹åˆå§‹é—®é¢˜æ± è¿›è¡Œé‡‡æ ·ä¸ pass rate ç»Ÿè®¡ï¼Œä»…ä¿ç•™ä¸­ç­‰éš¾åº¦æ ·æœ¬ï¼ˆÎ± â‰¤ p(x) â‰¤ Î²ï¼‰ï¼Œé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±ã€‚
- **Mixed-Policy Trajectory Reuse**ï¼šå›ºå®šä¸€æ‰¹rolloutè½¨è¿¹ç”¨äºå¤šä¸ªæ¢¯åº¦æ›´æ–°æ­¥éª¤ï¼Œæå‡è®­ç»ƒæ•ˆç‡å¹¶å¢å¼ºç¨³å®šæ€§ã€‚
- **Multi-task RLFT**ï¼šè”åˆä¼˜åŒ–æ•°å­¦ã€ç¼–ç ä¸æŒ‡ä»¤éµå¾ªä»»åŠ¡ï¼Œç¼“è§£å•ä»»åŠ¡RLå¯¼è‡´çš„è·¨ä»»åŠ¡æ€§èƒ½é€€åŒ–ï¼ˆcatastrophic forgettingï¼‰ã€‚
- **å–æ¶ˆé•¿åº¦æƒ©ç½š**ï¼ˆLength Penaltyï¼‰ï¼šé¼“åŠ±æ¨¡å‹ç”Ÿæˆæ›´é•¿çš„æ¨ç†é“¾ï¼Œæå‡å¤æ‚ä»»åŠ¡è¡¨ç°ã€‚

#### ï¼ˆ3ï¼‰é«˜æ•ˆçš„ç³»ç»Ÿçº§ä¼˜åŒ–
- **Hybrid Parallelism æ¶æ„**ï¼šç»“åˆ DeepSpeed-Ulysses çš„ Sequence Parallelism å’Œå¤šç§ DP/TP é…ç½®ï¼Œæ”¯æŒ64Kä¸Šä¸‹æ–‡è®­ç»ƒã€‚
- **Liger Kernel Loss Function**ï¼šå°† logits æ²¿ context dimension åˆ†ç‰‡è®¡ç®—æŸå¤±ï¼Œæ˜¾è‘—é™ä½ RL è®­ç»ƒä¸­çš„å³°å€¼æ˜¾å­˜å ç”¨ã€‚
- **ç»†ç²’åº¦æ¿€æ´»æ£€æŸ¥ç‚¹**ï¼ˆFine-grained Activation Checkpointingï¼‰ï¼šæ‰‹åŠ¨è°ƒä¼˜æ¯å±‚é‡è®¡ç®—ç­–ç•¥ï¼Œå¹³è¡¡å†…å­˜ä¸è®¡ç®—å¼€é”€ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿåšæ³• | Motif-2-12.7B æ–¹æ³• |
|------|--------|------------------|
| SFT æ•°æ® | ç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆçš„åˆæˆæ•°æ® | å¼ºè°ƒ**åˆ†å¸ƒå¯¹é½**ï¼Œè¿‡æ»¤ä¸å…¼å®¹è½¨è¿¹ |
| RLFT ç¨³å®šæ€§ | æ˜“å‘ç”Ÿæ¨¡å‹å´©æºƒæˆ–æ€§èƒ½ä¸‹é™ | é€šè¿‡éš¾åº¦è¿‡æ»¤ + è½¨è¿¹å¤ç”¨å®ç°ç¨³å®šæ”¶æ•› |
| ä¸Šä¸‹æ–‡æ‰©å±• | çªç„¶æ‹‰é•¿è‡³é•¿ä¸Šä¸‹æ–‡ | æ¸è¿›å¼ curriculumï¼ˆ16K â†’ 32K â†’ 64Kï¼‰ |
| è®¡ç®—æ•ˆç‡ | å…¨é‡ on-policy rollout æˆæœ¬é«˜ | Mixed-policy + trajectory reuse æå‡æ ·æœ¬æ•ˆç‡ |
| ç³»ç»Ÿæ”¯æŒ | ç¼ºä¹é’ˆå¯¹é•¿åºåˆ—çš„ä¼˜åŒ– | Liger Kernel + Hybrid Parallelism æ”¯æŒé«˜æ•ˆ64Kè®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| ç±»å‹ | æ•°æ®æ¥æº | æè¿° |
|------|---------|------|
| **SFT é˜¶æ®µ** | Nemotron-Post-Training-Dataset, OpenReasoningDataset, Mixture-of-Thoughts, rstar-coder | å¤šé¢†åŸŸæ¨ç†æ•°æ®ï¼Œç»ä¸¥æ ¼æ¸…æ´—ä¸éªŒè¯ |
| **æ•°å­¦æ¨ç†** | GURU-92K | åŒ…å«ç»„åˆã€ä»£æ•°ã€å‡ ä½•ç­‰å­é¢†åŸŸï¼Œç»åˆ†å±‚æŠ½æ ·å¹³è¡¡åˆ†å¸ƒ |
| **ä»£ç ç”Ÿæˆ** | GURU-92K ä¸­çš„ç¼–ç¨‹é¢˜ | åŒæ ·ç»è¿‡ pass rate è¿‡æ»¤ä¸éš¾åº¦æ§åˆ¶ |
| **æŒ‡ä»¤éµå¾ª** | è‡ªå»ºåˆæˆæ•°æ®é›†ï¼ˆ10Kæ ·æœ¬ï¼‰ | ä¸“ä¸ºæŒ‘æˆ˜å½“å‰èƒ½åŠ›è¾¹ç•Œè®¾è®¡ |
| **è¯„ä¼°åŸºå‡†** | MMLU-Pro, GPOA Diamond, Humanity's Last Exam, LiveCodeBench, SciCode, AIME 2025, IFBench, AA-LCR, Terminal-Bench Hard, Telecom Bench | æ„æˆç»¼åˆæŒ‡æ ‡ AAII |

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šMotif-2-12.7B-Instruct
- **å‚æ•°è§„æ¨¡**ï¼š12.7B
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šæœ€ç»ˆæ”¯æŒ **64K tokens**
- **ç¡¬ä»¶å¹³å°**ï¼šH100 GPU é›†ç¾¤ï¼Œä½¿ç”¨ SkyPilot è¿›è¡Œèµ„æºè°ƒåº¦
- **å¹¶è¡Œç­–ç•¥**ï¼šHybrid Parallelismï¼ˆSequence Parallelism + DP-shard + DP-replicateï¼‰
- **RLç®—æ³•**ï¼šGSPOï¼ˆGroup Sequence Policy Optimizationï¼‰ï¼Œcritic-free çš„ PPO å˜ä½“
- **è®­ç»ƒæµç¨‹**ï¼š
  1. ä¸¤é˜¶æ®µ SFTï¼ˆé€æ­¥æ‰©å±•ä¸Šä¸‹æ–‡ï¼‰
  2. RLFT å‰å…ˆè¿›è¡Œæ•°æ®éš¾åº¦è¿‡æ»¤
  3. å¤šä»»åŠ¡æ··åˆè®­ç»ƒï¼Œè½¨è¿¹å¤ç”¨ S=3 æ­¥

### è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**Artificial Analysis Intelligence Index (AAII)** â€”â€” ç”±10é¡¹å¤šæ ·åŒ– benchmark çš„å¹³å‡å¾—åˆ†æ„æˆã€‚
- å…¶ä»–å…³é”®æŒ‡æ ‡ï¼š
  - æ•°å­¦ï¼šAIME 2025 Pass@1
  - ç¼–ç¨‹ï¼šLiveCodeBench v5 Pass@1
  - æ¨ç†ä¸€è‡´æ€§ã€é•¿ä¸Šä¸‹æ–‡è¿è´¯æ€§ã€å·¥å…·è°ƒç”¨æˆåŠŸç‡ç­‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **é—­æºæ¨¡å‹**ï¼šGPT-5.1ï¼ˆæ–‡ä¸­ç§° Motif è¶…è¶Šå…¶è¡¨ç°ï¼‰
- **å¼€æºæ¨¡å‹**ï¼šå„ç±» 30â€“40B å‚æ•°çº§ reasoning æ¨¡å‹ï¼ˆå¦‚ DeepSeek-Math, Qwen-Max ç­‰ï¼‰
- å¯¹æ¯”é‡ç‚¹ï¼šåœ¨è¿œå°äºå¯¹æ‰‹å‚æ•°é‡çš„æƒ…å†µä¸‹ï¼Œæ˜¯å¦èƒ½è¾¾åˆ°ç”šè‡³è¶…è¶Šå…¶æ¨ç†æ€§èƒ½ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | å‚æ•°é‡ | AAII å¾—åˆ† | å¤‡æ³¨ |
|------|--------|----------|------|
| **Motif-2-12.7B-Reasoning** | **12.7B** | **78.4** | è¶…è¿‡ GPT-5.1 |
| GPT-5.1 | ~æœªçŸ¥ | 76.2 | å½“å‰æœ€å¼ºé—­æºä¹‹ä¸€ |
| å…¶ä»–é¢†å…ˆå¼€æºæ¨¡å‹ | â‰¥30B | <78.0 | æ— ä¸€ä½äº12.7Bä»è¾¾æ­¤æ°´å¹³ |

#### ç»†é¡¹æ€§èƒ½äº®ç‚¹ï¼š
- **LiveCodeBench v5 Pass@1**ï¼š
  - Baseline: 51.78
  - + seed-oss-36b æ•°æ®: **63.69** (+11.91)
  - + gpt-oss-120b æ•°æ®: **33.92** (â†“17.86) â†’ è¯æ˜åˆ†å¸ƒä¸åŒ¹é…çš„å±å®³
- **AIME 2025**ï¼šç›¸æ¯” base model æ˜¾è‘—æå‡ï¼Œåœ¨ä¸­ç­‰éš¾åº¦é—®é¢˜ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚
- **é•¿ä¸Šä¸‹æ–‡æµ‹è¯•**ï¼šåœ¨ 32Kâ€“64K token è¾“å…¥ä¸‹ä¿æŒæ¨ç†ä¸€è‡´æ€§ï¼Œä¼˜äºå¤šæ•°åŒç±»æ¨¡å‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **AAII æ€»åˆ†ä¸Šè¶…è¿‡ GPT-5.1**ï¼Œæˆä¸ºç›®å‰å”¯ä¸€ä¸€ä¸ªåœ¨è¯¥ç»¼åˆæŒ‡æ•°ä¸Šé¢†å…ˆçš„ **<13B å‚æ•°æ¨¡å‹**ã€‚
- æ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶Šå¤šä¸ª **30â€“40B å‚æ•°çš„é—­æºä¸å¼€æºæ¨¡å‹**ã€‚
- åœ¨æ•°å­¦ä¸ç¼–ç¨‹ä»»åŠ¡ä¸Šçš„å¢ç›Šå°¤ä¸ºæ˜¾è‘—ï¼Œè¡¨æ˜å…¶æ¨ç†èƒ½åŠ›çœŸæ­£å¾—åˆ°å¢å¼ºï¼Œè€Œéæ³›åŒ–åå·®ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰
è™½ç„¶æœªæä¾›å®Œæ•´è¡¨æ ¼ï¼Œä½†ä»æ–‡ä¸­åˆ†æå¯æç‚¼å‡ºä»¥ä¸‹å…³é”®æ¶ˆèå‘ç°ï¼š

| ç»„ä»¶ | ç§»é™¤åçš„åæœ | ç»“è®º |
|------|-------------|------|
| åˆ†å¸ƒå¯¹é½çš„åˆæˆæ•°æ® | ä½¿ç”¨ gpt-oss-120b æ•°æ®å¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™ï¼ˆâ†“17.86ï¼‰ | æ•°æ®æ¥æºå¿…é¡»ä¸å­¦ç”Ÿæ¨¡å‹èƒ½åŠ›åŒ¹é… |
| éš¾åº¦è¿‡æ»¤æœºåˆ¶ï¼ˆLLM-as-a-filterï¼‰ | å‡ºç°é›¶ä¼˜åŠ¿ï¼ˆzero advantageï¼‰ç°è±¡ï¼Œæ¢¯åº¦æ¶ˆå¤± | ä¸­ç­‰éš¾åº¦æ ·æœ¬æ˜¯æœ‰æ•ˆå­¦ä¹ çš„å‰æ |
| è½¨è¿¹å¤ç”¨ï¼ˆTrajectory Reuseï¼‰ | è®­ç»ƒæ³¢åŠ¨å‰§çƒˆï¼Œæ”¶æ•›å›°éš¾ | æ˜¾è‘—æé«˜è®­ç»ƒç¨³å®šæ€§ä¸æ•ˆç‡ |
| å¤šä»»åŠ¡ RL | å•ä»»åŠ¡ RL å¯¼è‡´å…¶ä»–ä»»åŠ¡æ€§èƒ½é€€åŒ– | Multi-task æ˜¯é˜²æ­¢ç¾éš¾æ€§é—å¿˜çš„å…³é”® |
| å–æ¶ˆé•¿åº¦æƒ©ç½š | æ¨¡å‹å€¾å‘äºç”Ÿæˆæ›´å®Œæ•´çš„ä¸­é—´æ¨ç†æ­¥éª¤ | æœ‰åˆ©äºå¤æ‚æ¨ç†ï¼Œä¸åº”ç›²ç›®å¥—ç”¨é€šç”¨æ–‡æœ¬ç”Ÿæˆè§„åˆ™ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å‚æ•°è§„æ¨¡å¹¶éå†³å®šæ¨ç†èƒ½åŠ›çš„å”¯ä¸€å› ç´ **ï¼šé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„è®­ç»ƒæµç¨‹ï¼Œ12.7B æ¨¡å‹ä¹Ÿèƒ½è¾¾åˆ°ç”šè‡³è¶…è¶Šæ›´å¤§æ¨¡å‹çš„è¡¨ç°ã€‚
2. **SFT é˜¶æ®µçš„æ•°æ®è´¨é‡ä¸åˆ†å¸ƒå¯¹é½è‡³å…³é‡è¦**ï¼šç›²ç›®ä½¿ç”¨â€œæ›´å¼ºæ•™å¸ˆæ¨¡å‹â€çš„è¾“å‡ºåè€Œæœ‰å®³ã€‚
3. **RLFT å¯ä»¥ç¨³å®šä¸”æœ‰ç›Šåœ°åº”ç”¨äºå°æ¨¡å‹**ï¼šå‰ææ˜¯é‡‡ç”¨éš¾åº¦è¿‡æ»¤ã€è½¨è¿¹å¤ç”¨ã€å¤šä»»åŠ¡æ­£åˆ™ç­‰å·¥ç¨‹æŠ€å·§ã€‚
4. **ç³»ç»Ÿä¼˜åŒ–æ˜¯æ”¯æ’‘é•¿ä¸Šä¸‹æ–‡è®­ç»ƒçš„åŸºç¡€**ï¼šLiger Kernel ä¸ Hybrid Parallelism ä½¿å¾— 64K ä¸Šä¸‹æ–‡ä¸‹çš„ RLFT æˆä¸ºå¯èƒ½ã€‚
5. **test-time scalingï¼ˆå¦‚æ€ç»´é“¾å»¶é•¿ï¼‰ä¸ RLFT ç›¸è¾…ç›¸æˆ**ï¼šRL è®­ç»ƒå¢å¼ºäº†æ¨¡å‹æ¢ç´¢æ·±å±‚æ¨ç†çš„èƒ½åŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„éªŒè¯æœºåˆ¶**ï¼šå¦‚ä»£ç æ‰§è¡Œã€æ•°å­¦ç­”æ¡ˆæ ¡éªŒç­‰ï¼Œé™åˆ¶äº†å¯æ‰©å±•åˆ°æ›´å¤šéå½¢å¼åŒ–ä»»åŠ¡çš„èƒ½åŠ›ã€‚
- **æ•°æ®è¿‡æ»¤æˆæœ¬è¾ƒé«˜**ï¼šéœ€è¦é¢å¤–è¿è¡Œ rollouts æ¥ä¼°è®¡ pass rateï¼Œå¢åŠ é¢„å¤„ç†å¼€é”€ã€‚
- **å¯¹åŸºç¡€è®¾æ–½è¦æ±‚é«˜**ï¼šå°½ç®¡å¼ºè°ƒâ€œç°å®é¢„ç®—â€ï¼Œä½†ä»éœ€ H100 çº§åˆ«é›†ç¾¤ä¸é«˜çº§å¹¶è¡ŒæŠ€æœ¯æ”¯æŒã€‚
- **æœªå…¬å¼€æ‰€æœ‰è®­ç»ƒç»†èŠ‚**ï¼šä¾‹å¦‚ç¡®åˆ‡çš„å­¦ä¹ ç‡è°ƒåº¦ã€batch sizeã€æ€»è®­ç»ƒæ­¥æ•°ç­‰ä»ä¸å¤Ÿé€æ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†è¯¥è®­ç»ƒèŒƒå¼è¿ç§»åˆ°æ›´å¤§æˆ–æ›´å°è§„æ¨¡æ¨¡å‹ï¼ŒéªŒè¯å…¶å¯æ‰©å±•æ€§ã€‚
- æ¢ç´¢è‡ªåŠ¨åŒ–çš„ curriculum è®¾è®¡ä¸åŠ¨æ€éš¾åº¦è°ƒæ•´æœºåˆ¶ã€‚
- æ‰©å±•åˆ°æ›´å¤šéç»“æ„åŒ–æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ç¤¾ä¼šç§‘å­¦ã€ä¼¦ç†åˆ¤æ–­ç­‰ï¼‰ã€‚
- å¼€å‘æ›´ä½æ˜¾å­˜æ¶ˆè€—çš„ RLFT å®ç°æ–¹æ¡ˆï¼Œè¿›ä¸€æ­¥é™ä½è®­ç»ƒé—¨æ§›ã€‚
- æ¨åŠ¨ç¤¾åŒºå…±å»ºâ€œåˆ†å¸ƒå¯¹é½â€çš„åˆæˆæ•°æ®æ ‡å‡†ä¸å…±äº«ç”Ÿæ€ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> *Motif-2-12.7B-Reasoning* è¯æ˜äº†**é€šè¿‡ç³»ç»Ÿæ€§çš„å·¥ç¨‹ä¼˜åŒ–ä¸è®­ç»ƒè®¾è®¡ï¼Œå°å‹å¼€æ”¾æ¨¡å‹ä¹Ÿèƒ½åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šåª²ç¾ç”šè‡³è¶…è¶Šå¤§å‹é—­æºæ¨¡å‹**ï¼Œä¸ºç¤¾åŒºæä¾›äº†æå…·å®è·µä»·å€¼çš„ RL è®­ç»ƒè“å›¾ã€‚

</details>

---

### 6. [AdaSD: Adaptive Speculative Decoding for Efficient Language Model Inference](https://arxiv.org/abs/2512.11280)

**Authors**: Kuan-Wei Lu, Ding-Yong Hong, Pangfeng Liu  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.11280v1  

#### Abstract
Large language models (LLMs) have achieved remarkable performance across a wide range of tasks, but their increasing parameter sizes significantly slow down inference. Speculative decoding mitigates this issue by leveraging a smaller draft model to predict candidate tokens, which are then verified b...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# AdaSD: Adaptive Speculative Decoding for Efficient Language Model Inference â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ç„¶åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºå‚æ•°é‡å·¨å¤§ï¼Œæ¨ç†è¿‡ç¨‹å˜å¾—**å†…å­˜å—é™ä¸”è®¡ç®—ç¼“æ…¢**ã€‚ä¼ ç»Ÿçš„ **Speculative Decoding** è™½èƒ½é€šè¿‡å°æ¨¡å‹ï¼ˆdraft modelï¼‰ç”Ÿæˆå€™é€‰ token å¹¶ç”±å¤§æ¨¡å‹ï¼ˆtarget modelï¼‰å¹¶è¡ŒéªŒè¯æ¥åŠ é€Ÿæ¨ç†ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- éœ€è¦é¢å¤–è®­ç»ƒ draft modelï¼›
- ä¾èµ–å¤§é‡è¶…å‚æ•°è°ƒä¼˜ï¼ˆå¦‚å€™é€‰é•¿åº¦ã€æ¥å—é˜ˆå€¼ï¼‰ï¼›
- æ¥å—æ ‡å‡†è¿‡äºä¸¥æ ¼æˆ–å›ºå®šï¼Œéš¾ä»¥é€‚åº”ä¸åŒä¸Šä¸‹æ–‡ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†å…¶é€šç”¨æ€§å’Œéƒ¨ç½²æ•ˆç‡ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šAdaSDï¼ˆAdaptive Speculative Decodingï¼‰
ä½œè€…æå‡º **AdaSD**ï¼Œä¸€ç§æ— éœ€è¶…å‚æ•°è°ƒä¼˜çš„è‡ªé€‚åº”æ¨æµ‹è§£ç æ–¹æ¡ˆï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰åŒè‡ªé€‚åº”é˜ˆå€¼æœºåˆ¶
- **Generation Thresholdï¼ˆç”Ÿæˆé˜ˆå€¼ï¼‰**ï¼šåŸºäº draft model è¾“å‡º token çš„ **Entropy** åŠ¨æ€å†³å®šä½•æ—¶åœæ­¢ç”Ÿæˆå€™é€‰åºåˆ—ã€‚
  - è‹¥å½“å‰ token çš„ç†µè¶…è¿‡å†å²æ‹’ç» token çš„å¹³å‡ç†µï¼Œåˆ™ç»ˆæ­¢ç”Ÿæˆã€‚
- **Verification Thresholdï¼ˆéªŒè¯é˜ˆå€¼ï¼‰**ï¼šåŸºäº draft å’Œ target æ¨¡å‹è¾“å‡ºåˆ†å¸ƒä¹‹é—´çš„ **Jensen-Shannon Distance (JS Distance)** å†³å®šæ˜¯å¦æ¥å—å€™é€‰ tokenã€‚
  - æ¥å—æ¡ä»¶æ”¾å®½ä¸ºâ€œåˆ†å¸ƒç›¸ä¼¼â€è€Œéâ€œtoken å®Œå…¨åŒ¹é…â€ï¼Œæå‡çµæ´»æ€§ã€‚

#### ï¼ˆ2ï¼‰å®æ—¶åŠ¨æ€æ›´æ–°æœºåˆ¶
ä¸¤ä¸ªé˜ˆå€¼å‡åœ¨æ¨ç†è¿‡ç¨‹ä¸­**åœ¨çº¿æ›´æ–°**ï¼Œåˆ©ç”¨å·²ç”Ÿæˆ token çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆç†µä¸ JS è·ç¦»ï¼‰ï¼Œæ— éœ€é¢„åˆ†ææ¨¡å‹æˆ–ä»»åŠ¡ç‰¹æ€§ã€‚

#### ï¼ˆ3ï¼‰å®Œå…¨å…è®­ç»ƒã€å…è°ƒå‚
- ä¸éœ€è¦å¯¹ draft æˆ– target æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼›
- æ‰€æœ‰å†³ç­–è‡ªåŠ¨é€‚åº”è¾“å…¥å†…å®¹å’Œæ¨¡å‹è¡Œä¸ºï¼Œé€‚ç”¨äºä»»æ„ç°æˆï¼ˆoff-the-shelfï¼‰æ¨¡å‹ç»„åˆã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | Vanilla SD | AssistedGen | BiLD/FSD | AdaSD |
|------|------------|-------------|----------|--------|
| æ˜¯å¦éœ€è®­ç»ƒ | å¦ | å¦ | å¦ | âŒ å¦ |
| æ˜¯å¦éœ€è°ƒå‚ | æ˜¯ï¼ˆå›ºå®šé•¿åº¦/é˜ˆå€¼ï¼‰ | æ˜¯ï¼ˆROC æ›²çº¿ï¼‰ | æ˜¯ï¼ˆå›ºå®šé˜ˆå€¼ï¼‰ | âœ… **å¦ï¼ˆå…¨è‡ªåŠ¨ï¼‰** |
| æ˜¯å¦åŠ¨æ€è°ƒæ•´é•¿åº¦ | å¦ | æ˜¯ | å¦ | âœ… æ˜¯ |
| æ˜¯å¦åŠ¨æ€è°ƒæ•´æ¥å—æ ‡å‡† | å¦ | å¦ | æ˜¯ï¼ˆä½†éœ€é¢„è®¾ï¼‰ | âœ… æ˜¯ |
| å…¼å®¹æ€§ | é«˜ | ä¸­ | ä¸­ | é«˜ |

> AdaSD åœ¨ä¿æŒé«˜å…¼å®¹æ€§çš„åŒæ—¶ï¼Œå®ç°äº†æ›´å…¨é¢çš„è‡ªé€‚åº”æ§åˆ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
ä½¿ç”¨ä¸‰ä¸ªä»£è¡¨æ€§åŸºå‡†æ•°æ®é›†ï¼Œè¦†ç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼š
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼ˆæ¨ç†å¯†é›†å‹ï¼‰
- **HumanEval**ï¼šç¼–ç¨‹ä¸ä»£ç ç”Ÿæˆï¼ˆé€»è¾‘æ€§å¼ºï¼‰
- **MMLU**ï¼šå¤šå­¦ç§‘é€‰æ‹©é¢˜ï¼ˆçŸ­è¾“å‡ºã€åˆ†ç±»ä»»åŠ¡ï¼‰

---

### âš™ï¸ å®éªŒè®¾ç½®
#### æ¨¡å‹é…ç½®
æµ‹è¯•ä¸‰ç»„ draft-target æ¨¡å‹å¯¹ï¼š
1. `Llama 3.1 70B`ï¼ˆtargetï¼‰ + `Llama 3.1 8B`ï¼ˆdraftï¼‰
2. `Llama 3.1 70B` + `Llama 3.2 1B`
3. `Qwen 2.5 72B` + `Qwen 2.5 7B`

æ‰€æœ‰æ¨¡å‹æ¥è‡ªåŒä¸€æ—ä»¥ç¡®ä¿å…±äº«è¯æ±‡è¡¨ï¼ˆvocabulary alignmentï¼‰ã€‚

#### åŸºçº¿æ–¹æ³•ï¼ˆBaselineï¼‰
- **Vanilla Speculative Decoding**ï¼šå›ºå®šå€™é€‰é•¿åº¦ä¸º 5ã€‚
- **AssistedGen**ï¼ˆHugging Face å†…ç½®ï¼‰ï¼šåŸºäº DISCO çš„æ— ç›‘ç£å˜ä½“ï¼ŒåŠ¨æ€åˆ¤æ–­ç”Ÿæˆåœæ­¢æ—¶æœºã€‚

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **tks/sec** | è§£ç ååé‡ï¼ˆtokens per secondï¼‰ï¼Œè¡¡é‡é€Ÿåº¦ |
| **Speedup** | ç›¸å¯¹äº Vanilla çš„åŠ é€Ÿæ¯” |
| **Accuracy** | ä»»åŠ¡æ­£ç¡®ç‡ï¼ˆexact matchï¼‰ |
| **JSDist @ threshold** | éªŒè¯æ—¶ä½¿ç”¨çš„ JS Distance é˜ˆå€¼æ°´å¹³ |
| **#cand / #match / AccRate** | ç”Ÿæˆæ•°ã€æ¥å—æ•°ã€æ¥å—ç‡ |

#### å®ç°ç»†èŠ‚
- ä½¿ç”¨ Hugging Face Transformersï¼ˆv4.55ï¼‰
- è¿è¡Œäº 4Ã—NVIDIA A6000 GPU
- é‡‡ç”¨ sampling ç­–ç•¥ï¼ˆé greedyï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š æ€§èƒ½æ±‡æ€»ï¼ˆä»¥ Llama ä¸ºä¾‹ï¼‰

| æ–¹æ³• | GSM8K (speedup) | HumanEval (speedup) | MMLU (speedup) | Accuracy Drop |
|------|------------------|----------------------|----------------|---------------|
| **Vanilla** | 1.00Ã— | 1.00Ã— | 1.00Ã— | â€” |
| **AssistedGen** | 1.16Ã— | 1.27Ã— | 1.01Ã— | <0.5% |
| **AdaSD** | **1.26Ã—** | **1.32Ã—** | **1.09Ã—** | <2% |

> åœ¨ Llama æ¨¡å‹ä¸Šï¼ŒAdaSD å®ç°æœ€é«˜è¾¾ **49% çš„åŠ é€Ÿ**ï¼ˆè§æ¶ˆèå®éªŒï¼‰ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚

---

### ğŸ”¬ å…³é”®æ€§èƒ½æ•°æ®äº®ç‚¹

#### ï¼ˆ1ï¼‰æ˜¾è‘—æé€Ÿ
- åœ¨ `Llama 3.1 70B/8B` ä¸Šï¼š
  - GSM8Kï¼š**1.26Ã— speedup**
  - HumanEvalï¼š**1.32Ã— speedup**
- åœ¨ `Llama 3.1 70B/1B` ä¸Šï¼š
  - æœ€é«˜è¾¾ **1.49Ã— speedup**ï¼ˆHumanEvalï¼‰

#### ï¼ˆ2ï¼‰ç²¾åº¦æŸå¤±æå°
- æ‰€æœ‰ä»»åŠ¡ä¸­ accuracy ä¸‹é™å‡ **< 2%**
- å°¤å…¶åœ¨ HumanEval ä¸Šä»ä¿æŒ >73% å‡†ç¡®ç‡

#### ï¼ˆ3ï¼‰MMLU åŠ é€Ÿæœ‰é™çš„åŸå› åˆ†æ
- MMLU è¾“å‡ºæçŸ­ï¼ˆé€šå¸¸ä»…å‡ ä¸ª tokenï¼‰ï¼Œæ¨æµ‹ç©ºé—´å° â†’ åŠ é€Ÿä¸Šé™ä½ï¼ˆçº¦ 8â€“10%ï¼‰
- ç¬¦åˆé¢„æœŸï¼Œè¯´æ˜ AdaSD æ›´é€‚åˆé•¿åºåˆ—ç”Ÿæˆåœºæ™¯

#### ï¼ˆ4ï¼‰Qwen æ¨¡å‹ä¸Šçš„è¡¨ç°å·®å¼‚
- AdaSD åœ¨ Qwen ä¸Šç•¥é€Šäº AssistedGenï¼ˆ1.28 vs 1.29 speedupï¼‰
- åŸå› ï¼šAdaSD ç”Ÿæˆæ›´é•¿å€™é€‰åºåˆ—ï¼ˆ~14.5 tokensï¼‰ï¼Œå¯¼è‡´ draft å¼€é”€å¢åŠ 
- ä½†æ¥å—ç‡æ›´é«˜ï¼ˆ72% vs 83%ï¼‰ï¼Œè¡¨æ˜å…¶éªŒè¯ç­–ç•¥æœ‰æ•ˆ

---

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰

| å˜ä½“ | æ–¹æ³•æè¿° | Speedup (GSM8K) | AccRate |
|------|---------|------------------|--------|
| **Gen-Only** | ä»…å¯ç”¨ç”Ÿæˆé˜ˆå€¼ï¼ˆç†µæ§åˆ¶ï¼‰ | 1.17â€“1.29Ã— | â†“ æ¥å—ç‡ |
| **Verify-Only** | ä»…å¯ç”¨éªŒè¯é˜ˆå€¼ï¼ˆJS è·ç¦»ï¼‰ | â‰¤1.08Ã— | â†‘ å‡†ç¡®æ€§ |
| **AdaSD (Full)** | ä¸¤è€…ç»“åˆ | **1.26â€“1.41Ã—** | å¹³è¡¡æœ€ä½³ |

> ç»“è®ºï¼š**ç”Ÿæˆé•¿åº¦æ§åˆ¶æ˜¯ä¸»è¦åŠ é€Ÿæ¥æº**ï¼Œè€ŒéªŒè¯é˜ˆå€¼ä¼˜åŒ–è¿›ä¸€æ­¥æå‡äº†é²æ£’æ€§å’Œç¨³å®šæ€§ã€‚

æ­¤å¤–ï¼Œä½œè€…å°è¯•äº†ä¸‰ç§æ›´å¤æ‚çš„éªŒè¯é˜ˆå€¼å¯å‘å¼ï¼ˆAppendix Bï¼‰ï¼Œä½†å‘ç°ç®€å•å–â€œæ¥å—ä¸æ‹’ç» JS è·ç¦»å‡å€¼â€çš„ç­–ç•¥æ•ˆæœæœ€å¥½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç†µå’Œ JS Distance æ˜¯æœ‰æ•ˆçš„ä¸ç¡®å®šæ€§åº¦é‡æŒ‡æ ‡**
   - è¢«æ‹’ token æ˜¾è‘—å…·æœ‰æ›´é«˜çš„ entropy å’Œ JS distanceï¼ˆå›¾2ã€å›¾3ï¼‰
   - æ”¯æŒå°†å…¶ä½œä¸ºè‡ªé€‚åº”å†³ç­–ä¾æ®

2. **åŒé˜ˆå€¼ååŒä½œç”¨æœ€ä¼˜**
   - å•ç‹¬ä½¿ç”¨ä»»ä¸€æœºåˆ¶å·²æœ‰å¢ç›Šï¼Œè”åˆä½¿ç”¨å®ç°æœ€å¤§åŠ é€Ÿ

3. **AdaSD æ˜¯çœŸæ­£â€œå³æ’å³ç”¨â€çš„é«˜æ•ˆæ–¹æ¡ˆ**
   - æ— éœ€è®­ç»ƒã€æ— éœ€è°ƒå‚ã€æ— éœ€å…ˆéªŒçŸ¥è¯†
   - å¯ç›´æ¥åº”ç”¨äº Hugging Face ç”Ÿæ€ä¸­çš„ä¸»æµæ¨¡å‹

4. **é€‚ç”¨äºé•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡**
   - åœ¨ GSM8K å’Œ HumanEval ä¸Šè¡¨ç°ä¼˜å¼‚
   - åœ¨çŸ­è¾“å‡ºä»»åŠ¡ï¼ˆå¦‚ MMLUï¼‰ä¸­æ”¶ç›Šè¾ƒå°

---

### âš ï¸ å±€é™æ€§ï¼ˆLimitationsï¼‰
1. **è¦æ±‚ draft ä¸ target æ¨¡å‹å…±äº« vocabulary**
   - å¦åˆ™æ— æ³•è®¡ç®— token-level entropy å’Œ JS distance
   - å½“å‰è®¸å¤šå°æ¨¡å‹ï¼ˆ<1Bï¼‰ä½¿ç”¨ä¸åŒ tokenizerï¼Œé™åˆ¶é€‚ç”¨èŒƒå›´

2. **ç¼ºä¹é«˜æ•ˆçš„ draft-target æ¨¡å‹é…å¯¹**
   - ç†æƒ³æ¯”ä¾‹çº¦ä¸º 50â€“100Ã— å‚æ•°å·®è·
   - ä½†ç°å®ä¸­å¾ˆå°‘æœ‰åŒç³»åˆ—çš„å¤§/å°æ¨¡å‹åŒæ—¶æ»¡è¶³æ­¤æ¯”ä¾‹ä¸”å…±äº« vocab

3. **ç”Ÿæˆè¿‡é•¿å¯èƒ½å¯¼è‡´å¼€é”€ä¸Šå‡**
   - å¦‚åœ¨ Qwen å®éªŒä¸­è§‚å¯Ÿåˆ°ï¼Œè¾ƒé•¿çš„å€™é€‰åºåˆ—å¢åŠ äº† draft æ¨¡å‹è´Ÿæ‹…

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥æ›´å¤šä¿¡å·ï¼ˆå¦‚ attention varianceã€feature normï¼‰æ”¹è¿› generation æ§åˆ¶
- è®¾è®¡æ›´æ™ºèƒ½çš„ verification threshold æ›´æ–°ç­–ç•¥ï¼ˆå¦‚åŠ æƒç§»åŠ¨å¹³å‡ï¼‰
- æ¢ç´¢è·¨ vocabulary çš„é€‚é…æ–¹æ³•ï¼ˆä¾‹å¦‚é€šè¿‡ embedding å¯¹é½ï¼‰
- æ‰©å±•è‡³ vision-language æˆ– speech æ¨¡å‹çš„ speculative inference

---

## âœ… æ€»ç»“
**AdaSD** æå‡ºäº†ä¸€ç§æ–°é¢–ã€å®ç”¨ä¸”é«˜æ•ˆçš„è‡ªé€‚åº”æ¨æµ‹è§£ç æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥åŸºäº **entropy** å’Œ **JS Distance** çš„åŒåŠ¨æ€é˜ˆå€¼æœºåˆ¶ï¼Œåœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹æ˜¾è‘—æå‡äº† LLM æ¨ç†é€Ÿåº¦ã€‚å…¶å®éªŒå……åˆ†éªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºæœªæ¥å…è°ƒå‚ã€è‡ªé€‚åº”æ¨ç†ç³»ç»Ÿæä¾›äº†é‡è¦æ€è·¯ã€‚å°½ç®¡å­˜åœ¨ vocabulary å¯¹é½ç­‰ç°å®çº¦æŸï¼Œä½†åœ¨åˆé€‚åœºæ™¯ä¸‹ï¼ŒAdaSD æ˜¯å½“å‰æœ€å…ˆè¿›çš„ speculative decoding æ–¹æ¡ˆä¹‹ä¸€ã€‚

</details>

---

### 7. [Speculative Decoding Speed-of-Light: Optimal Lower Bounds via Branching Random Walks](https://arxiv.org/abs/2512.11718)

**Authors**: Sergey Pankratov, Dan Alistarh  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.11718v1  

#### Abstract
Speculative generation has emerged as a promising technique to accelerate inference in large language models (LLMs) by leveraging parallelism to verify multiple draft tokens simultaneously. However, the fundamental limits on the achievable speedup remain poorly understood. In this work, we establish...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Speculative Decoding Speed-of-Light: Optimal Lower Bounds via Branching Random Walks*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äº **Speculative Decoding**ï¼ˆæ¨æµ‹è§£ç ï¼‰æŠ€æœ¯åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†åŠ é€Ÿä¸­çš„**ç†è®ºæé™é—®é¢˜**ã€‚å°½ç®¡è¯¥æŠ€æœ¯å·²è¢«å¹¿æ³›é‡‡ç”¨å¹¶å–å¾—æ˜¾è‘—ç»éªŒæˆåŠŸï¼ˆå¦‚ EAGLEã€Medusaï¼‰ï¼Œä½†å…¶**å¯å®ç°çš„æœ€å¤§åŠ é€Ÿæ¯”ï¼ˆspeedupï¼‰ä»ç¼ºä¹ä¸¥æ ¼çš„ç†è®ºåˆ†æ**ã€‚ç°æœ‰ç ”ç©¶å¤šåŸºäºç®€åŒ–å‡è®¾ï¼ˆå¦‚å¹³å‡æ¥å—ç‡ï¼‰ï¼Œæœªèƒ½æ­ç¤ºç³»ç»Ÿå®¹é‡ $P$ å’Œæ¨¡å‹å†…åœ¨å±æ€§ï¼ˆå¦‚ç†µï¼‰å¯¹æ€§èƒ½çš„æ ¹æœ¬é™åˆ¶ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„ç†è®ºæ¡†æ¶ï¼Œé€šè¿‡å°†æ¨æµ‹ç”Ÿæˆè¿‡ç¨‹å»ºæ¨¡ä¸º **Branching Random Walks (BRW)** æ¥åˆ†ææœ€ä¼˜æ€§èƒ½è¾¹ç•Œï¼š

- **æ ¸å¿ƒæ´å¯Ÿ**ï¼šå°† token çš„ç”Ÿæˆæ ‘ï¼ˆtoken treeï¼‰è§†ä¸ºä¸€ä¸ªä»¥ log-probability ä¸ºæƒé‡çš„ BRWï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªå¯èƒ½çš„ token åºåˆ—è·¯å¾„ã€‚
- **ç†è®ºå·¥å…·å¼•å…¥**ï¼šåˆ©ç”¨æ¦‚ç‡è®ºä¸­æˆç†Ÿçš„ BRW å·¥å…·ï¼ˆå¦‚ **Many-to-One Lemma** å’Œ **Renewal Theory**ï¼‰æ¥åˆ†æåœ¨éªŒè¯é¢„ç®— $P$ ä¸‹é«˜æ¦‚ç‡è·¯å¾„çš„åˆ†å¸ƒã€‚
- **æœ€ä¼˜ç­–ç•¥åˆ»ç”»**ï¼šè¯æ˜æœ€ä¼˜çš„ç¡®å®šæ€§æ¨æµ‹ç­–ç•¥æ˜¯è´ªå¿ƒåœ°é€‰æ‹©å…·æœ‰æœ€é«˜æ¥å—æ¦‚ç‡çš„ $P$ ä¸ª token è·¯å¾„ï¼ˆå³æœ€å°åŒ– log-probability å’Œçš„å­æ ‘ï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é¦–æ¬¡â€œç´§â€ä¸‹ç•Œ**ï¼šæä¾›äº†é¦–ä¸ªå…³äºä»»ä½•ç¡®å®šæ€§æ¨æµ‹ç®—æ³•çš„**ç´§è‡´è¿è¡Œæ—¶é—´ä¸‹ç•Œ**ï¼ˆç­‰ä»·äºé€Ÿåº¦ä¸Šç•Œï¼‰ï¼Œè€Œéå¯å‘å¼ä¼°è®¡ã€‚
- **æ­ç¤ºæ ¹æœ¬æƒè¡¡**ï¼šæ˜ç¡®æŒ‡å‡ºåŠ é€Ÿæ¯”çš„å¢é•¿å—é™äºæ¨¡å‹è¾“å‡ºçš„**æœŸæœ›ç†µ $\mu$** å’Œ**äºŒé˜¶ log-çŸ© $\mu^{(2)}$**ï¼Œæ­ç¤ºäº†å¹¶è¡Œåº¦ $P$ å¸¦æ¥çš„æ”¶ç›Šé€’å‡è§„å¾‹ã€‚
- **é€šç”¨æ€§å¼º**ï¼šæ‰€å»ºç«‹çš„æ¡†æ¶ä¸ä»…é€‚ç”¨äºåŸºç¡€çº¿æ€§æ¨æµ‹ï¼Œä¹Ÿå¯ç”¨äºåˆ†æ EAGLE-3 ç­‰å…ˆè¿›åŠ¨æ€æ ‘æ¨æµ‹ç³»ç»Ÿçš„æ•ˆç‡ä¸Šé™ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨å¤šä¸ªæ ‡å‡†åŸºå‡†ä»»åŠ¡ä¸Šè¿›è¡Œï¼Œæ¶µç›–ä¸åŒé¢†åŸŸï¼š
- **ä»£ç ç”Ÿæˆ**ï¼šHumanEval
- **å¯¹è¯èƒ½åŠ›**ï¼šMT-bench
- **æ•°å­¦æ¨ç†**ï¼šGSM8K
- **æ‘˜è¦ç”Ÿæˆ**ï¼šCNN/DM
- **é—®ç­”ä»»åŠ¡**ï¼šNatural Questions (NQ)

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ç›®æ ‡æ¨¡å‹**ï¼šLlama 3.1 8B Instruct (L3-8B), Llama 3.3 70B Instruct (L3-70B), DeepSeek R1 Distill Llama 8B (DS-8B), Qwen3 8B (Q3-8B)
- **æ¸©åº¦è®¾ç½®**ï¼šæ‰€æœ‰è¿è¡Œå‡ä½¿ç”¨ temperature = 1.0
- **æ ·æœ¬æ•°é‡**ï¼šæ¯æ•°æ®é›† 80 ä¸ªæ ·æœ¬ç”¨äºè®¡ç®—ç»Ÿè®¡é‡
- **å…³é”®å‚æ•°æµ‹é‡**ï¼š
  - $\mu$ï¼šç›®æ ‡æ¨¡å‹è¾“å‡ºåˆ†å¸ƒçš„**æœŸæœ›ç†µ**
  - $\mu^{(2)}$ï¼š**æœŸæœ›äºŒé˜¶ log-çŸ©**ï¼ˆå³ $-\log p$ çš„æ–¹å·®ç›¸å…³é¡¹ï¼‰
- **è¯„ä¼°æ–¹å¼**ï¼š
  - éªŒè¯ç†è®ºé¢„æµ‹çš„æ¥å— token æ•° $E[X]$ ä¸Šç•Œæ˜¯å¦ä¸å®é™…ç³»ç»Ÿï¼ˆå¦‚ EAGLE-3ï¼‰è¡¨ç°ä¸€è‡´ã€‚
  - ç»˜åˆ¶ç†è®ºè¾¹ç•Œä¸ EAGLE-3 åœ¨ä¸åŒ $P$ï¼ˆæ¨æµ‹å¤§å°ï¼‰ä¸‹çš„æ€§èƒ½æ›²çº¿å¯¹æ¯”å›¾ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- ä¸»è¦å¯¹æ¯”å¯¹è±¡æ˜¯å½“å‰æœ€å…ˆè¿›çš„æ¨æµ‹è§£ç ç³»ç»Ÿ **EAGLE-3**ã€‚
- å°†å…¶å®æµ‹çš„å¹³å‡æ¯è½®æ¥å— token æ•°ä¸ä»¥ä¸‹ç†è®ºè¾¹ç•Œæ¯”è¾ƒï¼š
  - **Theorem 1 æä¾›çš„ç²¾ç¡®ä¸Šç•Œ**ï¼ˆè“è‰²è™šçº¿ï¼‰
  - **Corollary 1 æä¾›çš„æ¸è¿‘æé™**ï¼ˆæ©™è‰²è™šçº¿ï¼Œ$P \to \infty$ï¼‰
  - **Lemma 7 æä¾›çš„çŸ¥è¯†ä¸å®Œç¾æƒ…å†µä¸‹çš„ä¸‹ç•Œ**ï¼ˆç»¿è‰²è™šçº¿ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
#### è¡¨1ï¼šå„æ¨¡å‹ä¸ä»»åŠ¡ä¸‹çš„ $\mu$ å’Œ $\mu^{(2)}$ æµ‹é‡å€¼ï¼ˆéƒ¨åˆ†æ‘˜å½•ï¼‰

| Model       | Task        | $\mu$   | $\mu^{(2)}$ |
|-------------|-------------|---------|-------------|
| L3-8B       | HumanEval   | 0.279   | 0.777       |
| L3-8B       | MT-bench    | 1.088   | 6.654       |
| L3-70B      | HumanEval   | 0.136   | 0.238       |
| L3-70B      | MT-bench    | 0.179   | 0.383       |
| DS-8B       | HumanEval   | 0.530   | 1.252       |
| Q3-8B       | HumanEval   | 0.178   | 0.313       |

> è§‚å¯Ÿï¼šæ›´å¤§æ›´å‡†ç¡®çš„æ¨¡å‹ï¼ˆå¦‚ L3-70Bï¼‰é€šå¸¸å…·æœ‰æ›´ä½ä¸”æ›´ç¨³å®šçš„ $\mu$ï¼Œæ„å‘³ç€æ›´é«˜çš„æ¨æµ‹æ½œåŠ›ï¼›Qwen3 åœ¨å¤šæ•°ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè¾ƒä½çš„ $\mu$ï¼Œç†è®ºä¸Šæ›´é€‚åˆæ¨æµ‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Figure 1** æ˜¾ç¤ºï¼Œåœ¨å›ºå®š $P=60$ æ—¶ï¼ŒEAGLE-3 çš„å®æµ‹æ€§èƒ½ä¸ Lemma 7 çš„ä¸‹ç•Œå‘ˆ**è¿‘ä¼¼çº¿æ€§å…³ç³»**ï¼Œè¡¨æ˜ç†è®ºè¾¹ç•Œèƒ½æœ‰æ•ˆé¢„æµ‹å®é™…ç³»ç»Ÿçš„è¡Œä¸ºè¶‹åŠ¿ã€‚
- **Figure 2** å±•ç¤ºäº†éšç€ $P$ å¢åŠ ï¼ŒEAGLE-3 çš„æ€§èƒ½å˜åŒ–ï¼š
  - å®é™…æ€§èƒ½ï¼ˆæ˜Ÿå·æ ‡è®°ï¼‰æ¥è¿‘â€œæ½œåœ¨ä¸Šé™â€ï¼ˆé»‘è‰²å®çº¿ï¼Œè€ƒè™‘å®é™…æ¥å—ç‡ä½†å¿½ç•¥èµ·è‰å¼€é”€ï¼‰ã€‚
  - ä½†ä»æ˜¾è‘—ä½äºç†è®ºæœ€å¤§ä¸Šç•Œï¼ˆè“è‰²è™šçº¿ï¼‰ï¼Œè¯´æ˜å½“å‰ç®—æ³•å°šæœªè¾¾åˆ°æœ€ä¼˜ã€‚
  - ä¸åŒä»»åŠ¡é—´å·®è·æ˜æ˜¾ï¼Œé«˜ç†µä»»åŠ¡ï¼ˆå¦‚ MT-benchï¼‰æå‡ç©ºé—´æ›´å°ã€‚

### æ¶ˆèå®éªŒç»“æœ
è™½ç„¶æœªè¿›è¡Œä¼ ç»Ÿæ„ä¹‰ä¸Šçš„æ¶ˆèå®éªŒï¼Œä½†é€šè¿‡å¯¹æ¯”ä¸åŒå‡è®¾ä¸‹çš„è¾¹ç•Œæ­ç¤ºäº†å…³é”®å› ç´ å½±å“ï¼š
- **å®Œç¾çŸ¥è¯† vs ä¸å®Œç¾çŸ¥è¯†**ï¼šä» Lemma 7 å¯è§ï¼Œå½“æ¨æµ‹å™¨æ— æ³•å®Œå…¨æŒæ¡ç›®æ ‡æ¨¡å‹åˆ†å¸ƒæ—¶ï¼ˆå­˜åœ¨ $q(x)=0$ ä½† $p(x)>0$ çš„æƒ…å†µï¼‰ï¼Œæ€§èƒ½ä¸‹ç•Œæ˜¾è‘—é™ä½ï¼Œçªæ˜¾äº†è®­ç»ƒé«˜è´¨é‡ draft model çš„é‡è¦æ€§ã€‚
- **æ¸è¿‘åˆ†æ**ï¼šTheorem 3 å’Œ Corollary 1 è¡¨æ˜ï¼Œå½“ $P \to \infty$ æ—¶ï¼Œæœ€ä¼˜ $E[X] \sim \frac{\log P}{\mu}$ï¼Œè¿›ä¸€æ­¥ç¡®è®¤äº†å¯¹æ•°å¢é•¿è§„å¾‹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åŠ é€Ÿæ¯”å­˜åœ¨æ ¹æœ¬ä¸Šé™**ï¼šä»»ä½•ç¡®å®šæ€§æ¨æµ‹ç®—æ³•çš„æœŸæœ›æ¯è½®æ¥å— token æ•°æ»¡è¶³ï¼š
   $$
   E[X] \leq \frac{\mu + \mu^{(2)}}{\mu^2} \log P + O(1)
   $$
   å³åŠ é€Ÿæ¯”éšå¹¶è¡Œå®¹é‡ $P$ **å¯¹æ•°å¢é•¿**ï¼Œå­˜åœ¨ä¸¥é‡æ”¶ç›Šé€’å‡ã€‚
   
2. **æ¨¡å‹ä¸ç¡®å®šæ€§æ˜¯ç“¶é¢ˆ**ï¼šåŠ é€Ÿæ½œåŠ›ä¸»è¦ç”±ç›®æ ‡æ¨¡å‹çš„**æœŸæœ›ç†µ $\mu$** å†³å®šâ€”â€”$\mu$ è¶Šä½ï¼ˆè¾“å‡ºè¶Šç¡®å®šï¼‰ï¼Œæ¨æµ‹è¶Šé«˜æ•ˆï¼›åä¹‹åˆ™éš¾ä»¥å¹¶è¡ŒåŒ–ã€‚

3. **åˆ†å¸ƒå˜å¼‚æ€§æœ‰é¢å¤–å½±å“**ï¼šé™¤äº†å¹³å‡ç†µå¤–ï¼Œ**äºŒé˜¶çŸ© $\mu^{(2)}$** ä¹Ÿå½±å“å¸¸æ•°å› å­ï¼Œè¡¨æ˜ log-prob åˆ†å¸ƒçš„æ³¢åŠ¨æ€§ä¼šè¿›ä¸€æ­¥é™åˆ¶æ€§èƒ½ã€‚

4. **å½“å‰ç³»ç»Ÿä»æœ‰æ”¹è¿›ç©ºé—´**ï¼šEAGLE-3 ç­‰å…ˆè¿›ç³»ç»Ÿè™½å·²æ¥è¿‘å…¶è®¾è®¡ä¸‹çš„æ€§èƒ½æé™ï¼Œä½†è·ç¦»ç†è®ºæœ€ä¼˜ä»æœ‰çº¦ **Ã—2 çš„å·®è·**ï¼Œä¸»è¦æºäºæ¨æµ‹è¯¯å·®ï¼ˆspeculation errorï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **i.i.d. å‡è®¾ä¸ç°å®**ï¼šå‡è®¾ä¸åŒå‰ç¼€ä¸‹çš„æ¥å—æ¦‚ç‡ç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆAssumption 2ï¼‰ï¼Œå¿½ç•¥äº†è¯­è¨€çš„ä¸Šä¸‹æ–‡ä¾èµ–æ€§ã€‚
- **ç®€åŒ–æ—¶åºæ¨¡å‹**ï¼šå‡è®¾ verifier å»¶è¿Ÿæ’å®šã€drafting å¼€é”€å¯å¿½ç•¥ï¼Œæœªè€ƒè™‘ KV Cache å¢é•¿ç­‰å®é™…å·¥ç¨‹å› ç´ ã€‚
- **ä»…é™ç¡®å®šæ€§ç®—æ³•**ï¼šåˆ†æé›†ä¸­äºç¡®å®šæ€§æ¨æµ‹ç­–ç•¥ï¼Œæœªæ¶µç›–éšæœºæ€§æ–¹æ³•ã€‚
- **å®Œç¾çŸ¥è¯†å‡è®¾**ï¼šä¸Šç•Œæ¨å¯¼å‡è®¾ draft model å®Œå…¨çŸ¥æ™“ç›®æ ‡æ¨¡å‹åˆ†å¸ƒï¼Œç°å®ä¸­ä¸å¯è¾¾ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ”¾å®½ i.i.d. å‡è®¾ï¼Œæ‰©å±•è‡³å¹³ç¨³æˆ–éå†è¿‡ç¨‹ä»¥æ›´å¥½å»ºæ¨¡è¯­è¨€åŠ¨æ€ã€‚
- å¼•å…¥æ›´çœŸå®çš„æ—¶åºå’Œèµ„æºæ¶ˆè€—æ¨¡å‹ï¼ˆå¦‚è€ƒè™‘ drafting æˆæœ¬ï¼‰ã€‚
- æ¢ç´¢éç¡®å®šæ€§æˆ–è‡ªé€‚åº”æ¨æµ‹ç­–ç•¥çš„ç†è®ºè¾¹ç•Œã€‚
- è®¾è®¡æ›´æ¥è¿‘ç†è®ºæé™çš„å®ç”¨ç®—æ³•ï¼Œä¾‹å¦‚ä¼˜åŒ– cross-entropy æŸå¤±ä»¥å‡å°‘ speculation errorã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡é€šè¿‡å¼•å…¥ **Branching Random Walks** æ¡†æ¶ï¼Œé¦–æ¬¡ä¸º Speculative Decoding å»ºç«‹äº†**ç´§è‡´çš„ç†è®ºæ€§èƒ½ä¸Šç•Œ**ï¼Œæ­ç¤ºäº†åŠ é€Ÿæ¯”å—æ¨¡å‹ç†µåˆ¶çº¦çš„æœ¬è´¨è§„å¾‹ï¼Œå¹¶éªŒè¯äº†å½“å‰ç³»ç»Ÿä¸ç†è®ºæé™ä¹‹é—´çš„å·®è·ï¼Œä¸ºæœªæ¥é«˜æ•ˆ LLM æ¨ç†ç³»ç»Ÿçš„è®¾è®¡æä¾›äº†åšå®çš„ç†è®ºæŒ‡å¯¼ã€‚

</details>

---

### 8. [Evaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems](https://arxiv.org/abs/2512.10987)

**Authors**: Sumit Chongder  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.10987v1  

#### Abstract
In recent years, the landscape of federated learning has witnessed significant advancements, particularly in decentralized methodologies. This research paper presents a comprehensive comparison of Centralized Hierarchical Federated Learning (HFL) with Decentralized Aggregated Federated Learning (AFL...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEvaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶èšç„¦äº **Centralized Hierarchical Federated Learning (HFL)** æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œä¸»è¦åŒ…æ‹¬ï¼š
- **é€šä¿¡ç“¶é¢ˆ**ï¼šæ‰€æœ‰å®¢æˆ·ç«¯éœ€ä¸ä¸­å¤®æœåŠ¡å™¨é¢‘ç¹é€šä¿¡ï¼Œå¯¼è‡´å»¶è¿Ÿé«˜ã€å¸¦å®½å‹åŠ›å¤§ã€‚
- **éšç§é£é™©**ï¼šå°½ç®¡åŸå§‹æ•°æ®ä¸ä¸Šä¼ ï¼Œä½†æ¨¡å‹æ›´æ–°é›†ä¸­èšåˆä»å¯èƒ½æ³„éœ²æ•æ„Ÿä¿¡æ¯ã€‚
- **å•ç‚¹æ•…éšœ**ï¼šä¾èµ–ä¸­å¿ƒåŒ–æœåŠ¡å™¨ï¼Œç³»ç»Ÿé²æ£’æ€§å·®ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº† HFL åœ¨å¤§è§„æ¨¡ã€è¾¹ç¼˜è®¾å¤‡åˆ†å¸ƒå¹¿æ³›åœºæ™¯ä¸‹çš„å¯æ‰©å±•æ€§å’Œå®‰å…¨æ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
è®ºæ–‡æå‡ºå¹¶ç³»ç»Ÿæ¯”è¾ƒäº†ä¸¤ç§å»ä¸­å¿ƒåŒ–çš„è”é‚¦å­¦ä¹ èŒƒå¼ï¼š
- **Decentralized Aggregated Federated Learning (AFL)**  
- **Decentralized Continual Federated Learning (CFL)**

å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- å¼•å…¥ **å®Œå…¨å»ä¸­å¿ƒåŒ–çš„èšåˆæœºåˆ¶**ï¼Œæ— éœ€ä¸­å¤®æœåŠ¡å™¨å‚ä¸æ¨¡å‹èšåˆï¼Œé€šè¿‡å®¢æˆ·ç«¯ä¹‹é—´çš„ç›´æ¥é€šä¿¡å®Œæˆåä½œè®­ç»ƒã€‚
- å¯¹æ¯”åˆ†æäº† HFLã€AFL å’Œ CFL åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼Œæ„å»ºäº†ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œæ¶µç›–ç²¾åº¦ã€æ•ˆç‡ã€é€šä¿¡å¼€é”€ç­‰å¤šä¸ªç»´åº¦ã€‚
- ç‰¹åˆ«å¼ºè°ƒäº† **Decentralized Aggregation** åœ¨æå‡æ¨¡å‹æ€§èƒ½å’Œä¿æŠ¤éšç§æ–¹é¢çš„æ½œåŠ›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ä¼˜åŠ¿ |
|------|------|
| **AFL** | å‡å°‘å¯¹ä¸­å¿ƒèŠ‚ç‚¹çš„ä¾èµ–ï¼Œé™ä½é€šä¿¡å»¶è¿Ÿï¼›æ”¯æŒå±€éƒ¨æ¨¡å‹èšåˆï¼Œæé«˜è®­ç»ƒæ•ˆç‡ |
| **CFL** | æ”¯æŒæŒç»­å­¦ä¹ èƒ½åŠ›ï¼Œåœ¨åŠ¨æ€ç¯å¢ƒä¸­ä¸æ–­é€‚åº”æ–°ä»»åŠ¡ï¼›è¡¨ç°å‡ºæœ€é«˜çš„å‡†ç¡®ç‡å’Œç¨³å®šæ€§ |
| æ•´ä½“æ¡†æ¶ | é¦–æ¬¡åœ¨åŒä¸€å®éªŒæ¡ä»¶ä¸‹å¯¹ HFLã€AFLã€CFL è¿›è¡Œæ¨ªå‘å¯¹æ¯”ï¼Œæä¾›å¯å¤ç°çš„åŸºå‡†ç»“æœ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **MNIST**ï¼šæ‰‹å†™æ•°å­—å›¾åƒæ•°æ®é›†ï¼ˆ10ç±»ï¼Œ28Ã—28ç°åº¦å›¾ï¼‰
- **Fashion-MNIST**ï¼šæœè£…å“ç±»å›¾åƒæ•°æ®é›†ï¼ˆ10ç±»ï¼Œ28Ã—28ç°åº¦å›¾ï¼‰

ä¸¤ä¸ªå‡ä¸ºæ ‡å‡†å›¾åƒåˆ†ç±» benchmark æ•°æ®é›†ï¼Œç”¨äºéªŒè¯ä¸åŒ FL èŒƒå¼çš„æ³›åŒ–èƒ½åŠ›ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ•°æ®åˆ†å¸ƒ**ï¼šé‡‡ç”¨ IIDï¼ˆIndependent and Identically Distributedï¼‰åˆ†å¸ƒæ¨¡æ‹Ÿç†æƒ³ç¯å¢ƒã€‚
- **æ¨¡å‹æ¶æ„**ï¼šç»Ÿä¸€ä½¿ç”¨ CNN æ¶æ„ï¼ŒåŒ…å«ä¸‰ä¸ªå·ç§¯å±‚ï¼ˆ16@3x3, 12@3x3, 10@3x3ï¼‰ã€ReLU æ¿€æ´»å‡½æ•°ã€ä¸¤ä¸ª Max-Pooling å±‚åŠå…¨è¿æ¥è¾“å‡ºå±‚ã€‚
- **è®­ç»ƒè½®æ•°**ï¼šå¤šè½®è¿­ä»£è®­ç»ƒï¼Œæ¯è½®é€‰æ‹©éƒ¨åˆ†å®¢æˆ·ç«¯å‚ä¸ã€‚
- **å®ç°å·¥å…·**ï¼š
  - Python 3.11.4
  - TensorFlow 2.16.1 / Keras 3.1.1
  - Jupyter Notebook + Anaconda ç¯å¢ƒ

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Accuracy** | æ­£ç¡®é¢„æµ‹æ ·æœ¬å æ¯” |
| **Precision** | æ‰€æœ‰æ­£ç±»é¢„æµ‹ä¸­çœŸæ­£ä¾‹çš„æ¯”ä¾‹ |
| **Recall** | æ‰€æœ‰å®é™…æ­£ä¾‹ä¸­è¢«æ­£ç¡®è¯†åˆ«çš„æ¯”ä¾‹ |
| **F1 Score** | Precision ä¸ Recall çš„è°ƒå’Œå¹³å‡å€¼ |
| **Build Time (s)** | æ¨¡å‹è®­ç»ƒæ€»è€—æ—¶ï¼ˆä»å¼€å§‹åˆ°æ”¶æ•›ï¼‰ |
| **Classification Time (s)** | æ¨ç†é˜¶æ®µè€—æ—¶ï¼ˆå•æ¬¡å‰å‘ä¼ æ’­æ—¶é—´ï¼‰ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Hierarchical FL (HFL)**ï¼šä¼ ç»Ÿä¸­å¿ƒåŒ–åˆ†å±‚è”é‚¦å­¦ä¹ ï¼Œä½œä¸ºä¸»è¦ baseline
- **Aggregated FL (AFL)**ï¼šå»ä¸­å¿ƒåŒ–èšåˆè”é‚¦å­¦ä¹ 
- **Continual FL (CFL)**ï¼šæ”¯æŒæŒç»­å­¦ä¹ çš„å»ä¸­å¿ƒåŒ–è”é‚¦å­¦ä¹ 

ä¸‰è€…åœ¨ç›¸åŒç½‘ç»œç»“æ„ã€ä¼˜åŒ–å™¨ï¼ˆSGDï¼‰ã€å­¦ä¹ ç‡ç­‰è¶…å‚æ•°ä¸‹è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 2ï¼‰

#### åœ¨ **Fashion-MNIST** ä¸Šçš„è¡¨ç°ï¼š

| Environment | Testing Acc | Precision | Recall | F1 Score | Build Time (s) | Class. Time (s) |
|------------|-------------|-----------|--------|----------|----------------|------------------|
| HFL        | 0.41        | 0.41      | 0.33   | 0.40     | 86.11          | 0.57             |
| AFL        | 0.70        | 0.71      | 0.68   | 0.68     | 55.33          | 0.47             |
| CFL        | **0.88**    | **0.88**  | **0.87**| **0.86**| 80.07          | **0.31**         |

#### åœ¨ **MNIST** ä¸Šçš„è¡¨ç°ï¼š

| Environment | Testing Acc | Precision | Recall | F1 Score | Build Time (s) | Class. Time (s) |
|------------|-------------|-----------|--------|----------|----------------|------------------|
| HFL        | 0.60        | 0.75      | 0.60   | 0.59     | 88.26          | 0.55             |
| AFL        | 0.72        | 0.76      | 0.72   | 0.72     | **54.02**      | 0.52             |
| CFL        | **0.98**    | **0.98**  | **0.98**| **0.98**| 79.02          | **0.29**         |

> æ³¨ï¼šæœ€ä½³ç»“æœåŠ ç²—æ˜¾ç¤º

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å‡†ç¡®æ€§æ–¹é¢**ï¼š
  - CFL æ˜¾è‘—ä¼˜äº HFL å’Œ AFLï¼Œå°¤å…¶åœ¨ Fashion-MNIST ä¸Šæµ‹è¯•å‡†ç¡®ç‡é«˜å‡ºè¿‘ **47ä¸ªç™¾åˆ†ç‚¹**ï¼ˆ0.41 â†’ 0.88ï¼‰ã€‚
  - AFL ç›¸è¾ƒ HFL æå‡æ˜æ˜¾ï¼Œè¯´æ˜å»ä¸­å¿ƒåŒ–èšåˆæœ¬èº«å³å¯å¸¦æ¥æ€§èƒ½å¢ç›Šã€‚
- **æ•ˆç‡æ–¹é¢**ï¼š
  - **AFL å…·æœ‰æœ€çŸ­çš„ Build Time**ï¼Œè¡¨æ˜å…¶åœ¨å¿«é€Ÿæ”¶æ•›æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚
  - **CFL æ‹¥æœ‰æœ€ä½çš„ Classification Time**ï¼Œé€‚åˆä½å»¶è¿Ÿæ¨ç†åœºæ™¯ã€‚
- **ç»¼åˆæ€§èƒ½**ï¼š
  - CFL åœ¨å‡ ä¹æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡å–å¾—æœ€ä¼˜ï¼Œå°¤å…¶æ˜¯åœ¨ Precisionã€Recallã€F1 Score ä¸Šæ¥è¿‘å®Œç¾è¡¨ç°ï¼ˆMNIST ä¸Šè¾¾ 0.98ï¼‰ã€‚

### âŒ æ˜¯å¦æœ‰æ¶ˆèå®éªŒï¼Ÿ
è®ºæ–‡æœªæ˜ç¡®å¼€å±•æ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œä¾‹å¦‚ï¼š
- ä¸åŒèšåˆç­–ç•¥çš„å½±å“ï¼ˆå¦‚ FedAvg vs. Gossipï¼‰
- é IID æ•°æ®ä¸‹çš„æ€§èƒ½å˜åŒ–
- ç½‘ç»œæ‹“æ‰‘ç»“æ„å¯¹å»ä¸­å¿ƒåŒ–é€šä¿¡çš„å½±å“

å› æ­¤æ— æ³•åˆ¤æ–­å„ç»„ä»¶çš„å…·ä½“è´¡çŒ®åº¦ï¼Œè¿™æ˜¯æœ¬ç ”ç©¶çš„ä¸€ä¸ªå±€é™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å»ä¸­å¿ƒåŒ–è”é‚¦å­¦ä¹ æ˜¾è‘—ä¼˜äºä¸­å¿ƒåŒ–æ¶æ„**ï¼š
   - AFL å’Œ CFL åœ¨ **accuracyã€precisionã€recallã€F1 score** ä¸Šå…¨é¢è¶…è¶Š HFLã€‚
   - å°¤å…¶æ˜¯ **CFL è¡¨ç°å‡ºæœ€å¼ºçš„å»ºæ¨¡èƒ½åŠ›å’Œæ³›åŒ–æ€§èƒ½**ã€‚

2. **Decentralized Aggregation æ˜¯å…³é”®é©±åŠ¨åŠ›**ï¼š
   - åˆ†å¸ƒå¼èšåˆæœºåˆ¶æœ‰æ•ˆç¼“è§£äº†é€šä¿¡ç“¶é¢ˆï¼Œæå‡äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œé²æ£’æ€§ã€‚
   - å®¢æˆ·ç«¯é—´ç›´æ¥äº¤æ¢æ¨¡å‹æ›´æ–°å¢å¼ºäº†éšç§ä¿æŠ¤èƒ½åŠ›ã€‚

3. **CFL åœ¨æ¨ç†æ•ˆç‡ä¸Šå…·å¤‡æ˜¾è‘—ä¼˜åŠ¿**ï¼š
   - æœ€ä½çš„ **classification time** ä½¿å…¶é€‚ç”¨äºå®æ—¶åº”ç”¨ï¼ˆå¦‚ç§»åŠ¨ç«¯ã€IoT è®¾å¤‡ï¼‰ã€‚

4. **AFL å¹³è¡¡äº†é€Ÿåº¦ä¸æ€§èƒ½**ï¼š
   - è™½ç„¶ç²¾åº¦ç•¥ä½äº CFLï¼Œä½†æ‹¥æœ‰æœ€å¿«çš„ **build time**ï¼Œé€‚åˆéœ€è¦å¿«é€Ÿéƒ¨ç½²çš„åœºæ™¯ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å®éªŒåŸºäº **IID æ•°æ®å‡è®¾**ï¼Œæœªè€ƒè™‘ç°å®ä¸–ç•Œä¸­å¸¸è§çš„ non-iid æ•°æ®åˆ†å¸ƒé—®é¢˜ã€‚
- ç¼ºä¹å¯¹ **é€šä¿¡å¼€é”€ã€èƒ½è€—ã€ç½‘ç»œæ‹“æ‰‘ç¨³å®šæ€§** çš„é‡åŒ–åˆ†æã€‚
- æœªæ¶‰åŠå®‰å…¨æ”»å‡»ï¼ˆå¦‚æ‹œå åº­æ”»å‡»ï¼‰æˆ–å·®åˆ†éšç§æœºåˆ¶ä¸‹çš„é²æ£’æ€§æµ‹è¯•ã€‚
- æ‰€æœ‰å®éªŒåœ¨ä»¿çœŸç¯å¢ƒä¸­å®Œæˆï¼Œç¼ºä¹çœŸå®åˆ†å¸ƒå¼ç½‘ç»œä¸­çš„éªŒè¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…å»ºè®®ï¼‰
1. **æ¢ç´¢å¤šæ ·åŒ–çš„æ•°æ®åˆ†å¸ƒç»„åˆ**ï¼šç ”ç©¶ non-IIDã€åæ–œåˆ†å¸ƒã€è·¨åŸŸè¿ç§»ç­‰å¤æ‚åœºæ™¯ä¸‹çš„ DFL æ€§èƒ½ã€‚
2. **è§£å†³å¼‚æ„æ€§ä¸å¯æ‰©å±•æ€§é—®é¢˜**ï¼šé’ˆå¯¹è®¾å¤‡è®¡ç®—èƒ½åŠ›ã€å­˜å‚¨ã€ç½‘ç»œå¸¦å®½å·®å¼‚è®¾è®¡æ›´çµæ´»çš„è°ƒåº¦æœºåˆ¶ã€‚
3. **å¢å¼ºéšç§ä¸å®‰å…¨æ€§ä¿éšœ**ï¼šç»“åˆ Secure Multi-Party Computationï¼ˆSMPCï¼‰æˆ– Differential Privacy æŠ€æœ¯è¿›ä¸€æ­¥å¼ºåŒ–å»ä¸­å¿ƒåŒ–ç³»ç»Ÿçš„æŠ—æ”»å‡»èƒ½åŠ›ã€‚
4. **æ‹“å±•è‡³æ›´å¤šåº”ç”¨åœºæ™¯**ï¼šå¦‚åŒ»ç–—ã€è‡ªåŠ¨é©¾é©¶ã€å¤šæœºå™¨äººååŒç­‰é«˜éšç§éœ€æ±‚é¢†åŸŸã€‚

---

## âœ… æ€»ç»“
è¯¥è®ºæ–‡ç³»ç»Ÿåœ°è¯„ä¼°äº†ä¸‰ç§ä¸»æµè”é‚¦å­¦ä¹ æ¶æ„ï¼ˆHFLã€AFLã€CFLï¼‰ï¼Œå®éªŒè¯æ˜ **Decentralized FL èŒƒå¼åœ¨æ€§èƒ½ã€æ•ˆç‡å’Œéšç§ä¿æŠ¤æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„ Centralized HFL**ã€‚å…¶ä¸­ï¼Œ**CFL åœ¨æ•´ä½“æ€§èƒ½ä¸Šè¡¨ç°æœ€ä¸ºçªå‡º**ï¼Œè€Œ **AFL åœ¨è®­ç»ƒæ•ˆç‡ä¸Šæœ‰æ˜æ˜¾ä¼˜åŠ¿**ã€‚ç ”ç©¶æˆæœä¸ºæœªæ¥è”é‚¦å­¦ä¹ ç³»ç»Ÿçš„è®¾è®¡æä¾›äº†é‡è¦å‚è€ƒï¼Œæ¨åŠ¨äº†ä»â€œä¸­å¿ƒåŒ–èšåˆâ€å‘â€œå»ä¸­å¿ƒåŒ–åä½œâ€çš„æ¼”è¿›è¶‹åŠ¿ã€‚

</details>

---

### 9. [ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning](https://arxiv.org/abs/2512.11727)

**Authors**: Yuze He, Ferdi Kossmann, Srinivasan Seshan, Peter Steenkiste  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.11727v1  

#### Abstract
Recent advances in video analytics address real-time data drift by continuously retraining specialized, lightweight DNN models for individual cameras. However, the current practice of retraining a separate model for each camera suffers from high compute and communication costs, making it unscalable....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäºè¾¹ç¼˜æœåŠ¡å™¨çš„**å®æ—¶è§†é¢‘è¿ç»­å­¦ä¹ ç³»ç»Ÿ**ï¼ˆlive video continuous learningï¼‰é¢ä¸´ä¸¥é‡çš„èµ„æºæ•ˆç‡ç“¶é¢ˆã€‚ä¸»æµæ–¹æ³•ï¼ˆå¦‚ Ekyaã€RECLï¼‰é‡‡ç”¨â€œç‹¬ç«‹é‡è®­ç»ƒâ€ï¼ˆindependent retrainingï¼‰ï¼Œå³ä¸ºæ¯ä¸ªæ‘„åƒå¤´å•ç‹¬é‡è®­ç»ƒä¸€ä¸ªè½»é‡çº§ DNN æ¨¡å‹ä»¥åº”å¯¹æ•°æ®æ¼‚ç§»ï¼ˆdata driftï¼‰ã€‚è¿™ç§ç­–ç•¥å¯¼è‡´ï¼š
- **è®¡ç®—å†—ä½™**ï¼šå¤šä¸ªæ‘„åƒå¤´ç»å†ç›¸ä¼¼çš„æ•°æ®æ¼‚ç§»æ—¶ï¼Œé‡å¤è®­ç»ƒé«˜åº¦ç›¸ä¼¼çš„æ¨¡å‹ã€‚
- **é€šä¿¡å¼€é”€å¤§**ï¼šæ¯ä¸ªæ‘„åƒå¤´éœ€æŒç»­ä¸Šä¼ å¸§æ•°æ®ï¼Œå ç”¨å¤§é‡å¸¦å®½ã€‚
- **æ‰©å±•æ€§å·®**ï¼šéšç€æ‘„åƒå¤´æ•°é‡å¢åŠ ï¼ŒGPU å’Œç½‘ç»œèµ„æºå‹åŠ›çº¿æ€§å¢é•¿ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šECCO ä¸ Group Retraining
è®ºæ–‡æå‡º **ECCO**ï¼Œä¸€ç§å…¨æ–°çš„é«˜æ•ˆè¿ç»­å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ **Group Retrainingï¼ˆåˆ†ç»„é‡è®­ç»ƒï¼‰**ï¼š
> å°†ç»å†**ç›¸ä¼¼æ•°æ®æ¼‚ç§»**çš„æ‘„åƒå¤´åŠ¨æ€èšåˆæˆç»„ï¼Œå¹¶ä½¿ç”¨å®ƒä»¬çš„**è”åˆæ•°æ®**å…±åŒè®­ç»ƒä¸€ä¸ªå…±äº«æ¨¡å‹ã€‚

#### åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **è½»é‡çº§åŠ¨æ€åˆ†ç»„ç®—æ³•**  
   - åŸºäºå…ƒæ•°æ®ï¼ˆæ—¶é—´ã€ä½ç½®ï¼‰å¿«é€Ÿç­›é€‰å€™é€‰ç»„ï¼Œå†é€šè¿‡ç²¾åº¦å¢ç›Šè¯„ä¼°æ˜¯å¦åˆå¹¶ï¼Œé¿å…é«˜ç»´è§†é¢‘æµç›´æ¥æ¯”è¾ƒã€‚
   - æ”¯æŒå‘¨æœŸæ€§â€œé‡æ–°åˆ†ç»„â€ï¼ˆregroupingï¼‰ï¼Œé€‚åº”åŠ¨æ€å˜åŒ–çš„åœºæ™¯åˆ†å¸ƒã€‚

2. **é¢å‘åˆ†ç»„é‡è®­ç»ƒçš„ GPU åˆ†é…å™¨**  
   - æå‡ºæ–°çš„ä¼˜åŒ–ç›®æ ‡ï¼š`max âˆ‘nâ±¼^Î²Â·Aâ±¼ + min Aâ±¼`ï¼Œå…¼é¡¾æ•´ä½“ç²¾åº¦ä¸ç»„é—´å…¬å¹³æ€§ã€‚
   - è®¾è®¡è´ªå¿ƒç®—æ³•ï¼ˆAlgorithm 1ï¼‰åœ¨å¾®çª—å£ï¼ˆmicro-windowï¼‰ç²’åº¦ä¸ŠåŠ¨æ€åˆ†é… GPU æ—¶é—´ï¼Œé˜²æ­¢å°è§„æ¨¡ç»„è¢«â€œé¥¿æ­»â€ã€‚

3. **èµ„æºæ„ŸçŸ¥çš„ä¼ è¾“æ§åˆ¶å™¨ï¼ˆTransmission Controllerï¼‰**  
   - åœ¨æ¯å°æ‘„åƒå¤´ç«¯å®ç°ï¼š
     - **é‡‡æ ·é…ç½®è‡ªé€‚åº”**ï¼šæ ¹æ®åˆ†é…çš„ GPU èµ„æºé€‰æ‹©æœ€ä¼˜å¸§ç‡ä¸åˆ†è¾¨ç‡ç»„åˆã€‚
     - **å®šåˆ¶åŒ– GAIMD æ‹¥å¡æ§åˆ¶**ï¼šä½¿å„ç»„çš„å¸¦å®½åˆ†é…ä¸å…¶ GPU é…é¢æˆæ­£æ¯”ï¼Œå®ç° compute-aware bandwidth sharingã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆEkya, RECLï¼‰ | ECCO |
|------|------------------------|------|
| æ¨¡å‹è®­ç»ƒæ–¹å¼ | ç‹¬ç«‹é‡è®­ç»ƒï¼ˆper-cameraï¼‰ | åˆ†ç»„å…±äº«è®­ç»ƒï¼ˆgroup retrainingï¼‰ |
| GPU åˆ†é…ç›®æ ‡ | æœ€å¤§åŒ–æ€»ç²¾åº¦æå‡ | å¹³è¡¡ç²¾åº¦ä¸å…¬å¹³æ€§ |
| å¸¦å®½åˆ©ç”¨ | é»˜è®¤å‡ç­‰åˆ†é…ï¼ˆAIMDï¼‰ | GPU-æ¯”ä¾‹åŠ æƒåˆ†é…ï¼ˆGAIMDï¼‰ |
| æ•°æ®æ•ˆç‡ | ä½ï¼ˆé‡å¤è®­ç»ƒï¼‰ | é«˜ï¼ˆèšåˆæ•°æ® + è‡ªç„¶æ¨¡å‹å¤ç”¨ï¼‰ |

> **æ ¹æœ¬ä¼˜åŠ¿**ï¼šECCO ä»â€œè·¨æ‘„åƒå¤´ç›¸å…³æ€§â€ä¸­æŒ–æ˜èµ„æºæ•ˆç‡çº¢åˆ©ï¼Œåœ¨ä¸ç‰ºç‰²ç”šè‡³æå‡ç²¾åº¦çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½è®¡ç®—ä¸é€šä¿¡æˆæœ¬ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | æè¿° |
|-------|------|------|
| **CityFlow** | é™æ€äº¤é€šæ‘„åƒå¤´ | 40 å°ç›¸æœºæ‹æ‘„åŸå¸‚è·¯å£ï¼Œ3+å°æ—¶åŒæ­¥è§†é¢‘ |
| **MDOT** | ç§»åŠ¨æ— äººæœºæ‘„åƒå¤´ | 5 æ¶æ— äººæœºç¼–é˜Ÿé£è¡Œï¼Œå…± 155 ç»„è§†é¢‘ç‰‡æ®µï¼ˆ>259k å¸§ï¼‰ |
| **CARLA Simulated Datasets** | æ¨¡æ‹Ÿè‡ªåŠ¨é©¾é©¶åœºæ™¯ | ä½¿ç”¨ CARLA æ¨¡æ‹Ÿå™¨ç”Ÿæˆä¸åŒç›¸ä¼¼åº¦çº§åˆ«çš„å¤šæ‘„åƒå¤´è§†é¢‘æµï¼Œç”¨äºå¯æ§å®éªŒ |

### âš™ï¸ å®éªŒè®¾ç½®
- **ä»»åŠ¡ç±»å‹**ï¼šObject Detection ä¸ Instance Segmentation
- **æ¨¡å‹æ¶æ„**ï¼š
  - Student Model: YOLOv11n / YOLOv11n-Seg
  - Teacher Model: YOLOv11x / YOLOv11x-Seg
- **ç¡¬ä»¶å¹³å°**ï¼šæœåŠ¡å™¨é…å¤‡ 5Ã— NVIDIA RTX 4090 GPU
- **ä»¿çœŸç¯å¢ƒ**ï¼šDocker å®¹å™¨æ¨¡æ‹Ÿæ‘„åƒå¤´ + NS-3 ç½‘ç»œä»¿çœŸï¼ˆæ”¯æŒ GAIMDï¼‰
- **é‡è®­ç»ƒçª—å£**ï¼šå›ºå®šé•¿åº¦çš„æ—¶é—´ç‰‡ï¼Œå†…å«å¤šä¸ª micro-windows

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **mAP**ï¼ˆmean Average Precisionï¼‰ | æ£€æµ‹ä¸åˆ†å‰²ä»»åŠ¡çš„æ ‡å‡†ç²¾åº¦æŒ‡æ ‡ |
| **Response Time** | è§¦å‘é‡è®­ç»ƒåè¾¾åˆ°ç›®æ ‡ mAP æ‰€éœ€æ—¶é—´ |
| **Scalability** | åœ¨ç›¸åŒèµ„æºä¸‹æ”¯æŒçš„æœ€å¤§æ‘„åƒå¤´æ•° |
| **Fairness** | ä¸åŒç»„ä¹‹é—´çš„ç²¾åº¦å·®å¼‚ï¼ˆå°¤å…¶æ˜¯å¤§å°ç»„ä¹‹é—´ï¼‰ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç‰¹ç‚¹ |
|------|------|
| **Naive Baseline** | å‡åŒ€ GPU åˆ†é… + å›ºå®šé‡‡æ · + å‡ç­‰å¸¦å®½ |
| **Ekya** | å…ˆè¿› GPU è°ƒåº¦ï¼Œä½†ä»ä¸ºç‹¬ç«‹é‡è®­ç»ƒ |
| **RECL** | ä½¿ç”¨å†å²æ¨¡å‹åˆå§‹åŒ–ï¼ˆmodel zooï¼‰åŠ é€Ÿæ”¶æ•›ï¼Œç‹¬ç«‹é‡è®­ç»ƒ |

> æ‰€æœ‰åŸºçº¿å‡æœªåˆ©ç”¨è·¨æ‘„åƒå¤´ç›¸å…³æ€§è¿›è¡Œæ¨¡å‹å…±äº«ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Figure 6 & Section 5.1ï¼‰
| æŒ‡æ ‡ | æå‡å¹…åº¦ |
|------|----------|
| **Object Detection mAP** | æå‡ **6.7% â€“ 16.6%** |
| **Instance Segmentation mAP** | æå‡ **9.3% â€“ 18.1%** |
| **åŒç­‰ç²¾åº¦ä¸‹æ”¯æŒæ‘„åƒå¤´æ•°** | æå‡ **3.3Ã—** |
| **è¾¾åˆ°ç›¸åŒç²¾åº¦æ‰€éœ€ GPU æ•°é‡** | å‡å°‘ **1.8Ã— â€“ 2.4Ã—** |
| **è¾¾åˆ°ç›¸åŒç²¾åº¦æ‰€éœ€å¸¦å®½** | ä»…éœ€åŸºçº¿çš„ **25% â€“ 33%** |
| **ä½å¸¦å®½ä¸‹å“åº”æ—¶é—´** | ç¼©çŸ­ **>5Ã—** |

> ğŸ’¡ å³ä¾¿åœ¨æç«¯æ¡ä»¶ä¸‹ï¼ˆå¦‚ä»… 1 GPUï¼‰ï¼ŒGroup Retraining æ€§èƒ½æ¥è¿‘ä½¿ç”¨ 3 GPU çš„ç‹¬ç«‹è®­ç»ƒï¼ˆè§ Figure 2cï¼‰ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰åŠ¨æ€åˆ†ç»„æœ‰æ•ˆæ€§ï¼ˆFigure 9ï¼‰
- å½“ç§»åŠ¨æ‘„åƒå¤´è¿›å…¥éš§é“å¯¼è‡´åœºæ™¯çªå˜æ—¶ï¼ŒECCO æˆåŠŸæ£€æµ‹åˆ°å…¶ä¸åŸç»„ç²¾åº¦ä¸‹é™ï¼Œå°†å…¶ç§»å‡ºå¹¶å¯åŠ¨æ–°ç»„ã€‚
- éªŒè¯äº† **regrouping æœºåˆ¶èƒ½æœ‰æ•ˆç»´æŠ¤ç»„å†…ä¸€è‡´æ€§**ã€‚

#### ï¼ˆ2ï¼‰GPU åˆ†é…å™¨å¯¹æ¯”ï¼ˆFigure 10ï¼‰
| åˆ†é…å™¨ | è¡¨ç° |
|--------|------|
| **RECL Allocator** | å¤§ç»„ï¼ˆ3 camï¼‰ä¼˜å…ˆè·å¾—èµ„æºï¼Œå°ç»„ï¼ˆ1 camï¼‰é•¿æœŸé¥¥é¥¿ï¼Œç²¾åº¦å·®è·è¾¾ **23% mAP** |
| **ECCO Allocator** | å®ç°è¿‘ä¼¼åŒæ­¥ç²¾åº¦ä¸Šå‡ï¼Œæ˜¾è‘—æå‡å…¬å¹³æ€§ |

> ç»“è®ºï¼šä¼ ç»Ÿä»¥â€œæ€»ç²¾åº¦æœ€å¤§åŒ–â€ä¸ºç›®æ ‡çš„åˆ†é…å™¨ä¸é€‚åˆ group retraining åœºæ™¯ã€‚

#### ï¼ˆ3ï¼‰ä¼ è¾“æ§åˆ¶å™¨æ¶ˆèï¼ˆFigure 11ï¼‰
- **æ— æ§åˆ¶å™¨**ï¼šå›ºå®šé‡‡æ · + æ ‡å‡† AIMD â†’ å¸¦å®½åˆ†é…åç¦»ç†æƒ³æ¯”ä¾‹ï¼Œç²¾åº¦ä½ã€‚
- **ECCO æ§åˆ¶å™¨**ï¼š
  - åœ¨ 9 Mbps å…±äº«å¸¦å®½ä¸‹ï¼Œå¸¦å®½åˆ†é…é€¼è¿‘ GPU-proportional ç›®æ ‡ã€‚
  - åœ¨ 3 Mbps ä½å¸¦å®½ä¸‹ï¼Œç²¾åº¦é«˜å‡ºåŸºçº¿ **4.7%**ã€‚
  - è¾¾åˆ°å³°å€¼ç²¾åº¦æ‰€éœ€å¸¦å®½ä»…ä¸ºåŸºçº¿çš„ **1/3**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **è·¨æ‘„åƒå¤´æ•°æ®æ¼‚ç§»å­˜åœ¨å¼ºæ—¶ç©ºç›¸å…³æ€§**  
   - é™æ€æ‘„åƒå¤´ï¼ˆå¦‚å¹¿åœºç›‘æ§ï¼‰ã€ç§»åŠ¨è®¾å¤‡ï¼ˆå¦‚æ— äººæœºç¼–é˜Ÿï¼‰å¸¸ç»å†ç›¸ä¼¼ç¯å¢ƒå˜åŒ–ï¼Œé€‚åˆåˆ†ç»„å¤„ç†ã€‚

2. **Group Retraining æ˜¾è‘—æå‡èµ„æºæ•ˆç‡**  
   - é€šè¿‡å…±äº«æ¨¡å‹å‡å°‘å†—ä½™è®­ç»ƒï¼Œé™ä½ GPU ä¸å¸¦å®½éœ€æ±‚ã€‚
   - åœ¨ç›¸åŒèµ„æºä¸‹å¯æ”¯æŒ **3.3Ã— æ›´å¤šæ‘„åƒå¤´**ï¼Œæˆ–æå‡ç²¾åº¦ **>15%**ã€‚

3. **compute-aware é€šä¿¡è®¾è®¡è‡³å…³é‡è¦**  
   - ä»…ä¼˜åŒ– GPU æˆ–ä»…ä¼˜åŒ–å¸¦å®½éƒ½ä¸å¤Ÿï¼›å¿…é¡»è”åˆè°ƒåº¦ã€‚
   - å®šåˆ¶åŒ–çš„ GAIMD å¯åœ¨å¼‚æ„ç½‘ç»œä¸­é€¼è¿‘ GPU-proportional å¸¦å®½åˆ†é…ã€‚

4. **è‡ªç„¶æ¨¡å‹å¤ç”¨å¢å¼ºå“åº”é€Ÿåº¦**  
   - ååŠ å…¥ç»„çš„æ‘„åƒå¤´å¯ç»§æ‰¿å·²éƒ¨åˆ†æ›´æ–°çš„æ¨¡å‹ï¼Œèµ·å§‹ç²¾åº¦æ›´é«˜ï¼ˆFigure 12ï¼‰ã€‚
   - æ•°æ®èšåˆåŠ å¿«è®­ç»ƒæ”¶æ•›ï¼Œå°¤å…¶åœ¨ä½å¸¦å®½ä¸‹å“åº”æ—¶é—´ç¼©çŸ­ **>5Ã—**ï¼ˆFigure 13ï¼‰ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡çš„æ¼‚ç§»æ£€æµ‹æœºåˆ¶**  
   - è‹¥æ¼‚ç§»æ£€æµ‹ä¸å‡†ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯åˆ†ç»„æˆ–å»¶è¿Ÿå“åº”ã€‚
2. **åˆ†ç»„æ”¶ç›Šä¾èµ–æ‘„åƒå¤´ç›¸ä¼¼åº¦**  
   - å¦‚ Figure 8 æ‰€ç¤ºï¼Œåœ¨ä½ç›¸ä¼¼åº¦ç»„ä¸­ï¼Œgroup retraining æ”¶ç›Šæœ‰é™ï¼ˆä»… +1.2% mAPï¼‰ã€‚
3. **ä¸­å¿ƒåŒ–æœåŠ¡å™¨å‡è®¾**  
   - æ‰€æœ‰é‡è®­ç»ƒé›†ä¸­åœ¨è¾¹ç¼˜æœåŠ¡å™¨å®Œæˆï¼Œæœªè€ƒè™‘å®Œå…¨å»ä¸­å¿ƒåŒ–éƒ¨ç½²ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ›´æ™ºèƒ½çš„è‡ªåŠ¨åˆ†ç»„ç­–ç•¥**  
   - æ¢ç´¢åŸºäº embedding similarity æˆ– clustering çš„è½»é‡çº§åœ¨çº¿åˆ†ç»„ç®—æ³•ã€‚
2. **è”é‚¦å­¦ä¹ èåˆ**  
   - åœ¨ä¿æŠ¤éšç§å‰æä¸‹å®ç°åˆ†å¸ƒå¼ group retrainingã€‚
3. **ç«¯åˆ°ç«¯è”åˆä¼˜åŒ–**  
   - å°†åˆ†ç»„å†³ç­–ã€GPU åˆ†é…ã€å¸¦å®½æ§åˆ¶ç»Ÿä¸€å»ºæ¨¡ä¸ºå¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚
4. **æ‰©å±•è‡³æ›´å¤šè§†è§‰ä»»åŠ¡**  
   - å¦‚ multi-object trackingã€action recognition ç­‰ã€‚

---

## æ€»ç»“
ECCO æ˜¯é¦–ä¸ªç³»ç»Ÿæ€§åˆ©ç”¨ **cross-camera correlations** æ¥ä¼˜åŒ– **continuous learning** æ•ˆç‡çš„å·¥ä½œã€‚å®ƒé€šè¿‡ **group retraining** èŒƒå¼ï¼Œå®ç°äº†è®¡ç®—ã€é€šä¿¡ä¸å“åº”æ€§çš„å…¨é¢ä¼˜åŒ–ï¼Œåœ¨çœŸå®ä¸æ¨¡æ‹Ÿæ•°æ®é›†ä¸Šå‡å±•ç°å‡ºæ˜¾è‘—ä¼˜äº Ekyaã€RECL ç­‰å…ˆè¿›ç³»ç»Ÿçš„æ€§èƒ½ã€‚è¯¥å·¥ä½œä¸ºå¤§è§„æ¨¡å®æ—¶è§†é¢‘åˆ†æç³»ç»Ÿçš„å¯æŒç»­æ¼”è¿›æä¾›äº†é‡è¦æ€è·¯ã€‚

</details>

---

### 10. [Softmax as Linear Attention in the Large-Prompt Regime: a Measure-based Perspective](https://arxiv.org/abs/2512.11784)

**Authors**: Etienne Boursier, Claire Boyer  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.11784v1  

#### Abstract
Softmax attention is a central component of transformer architectures, yet its nonlinear structure poses significant challenges for theoretical analysis. We develop a unified, measure-based framework for studying single-layer softmax attention under both finite and infinite prompts. For i.i.d. Gauss...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Softmax as Linear Attention in the Large-Prompt Regime: a Measure-based Perspective*

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡æ—¨åœ¨è§£å†³ **softmax attention** åœ¨ç†è®ºåˆ†æä¸Šçš„å›°éš¾ã€‚å°½ç®¡ softmax æ˜¯ Transformer æ¶æ„çš„æ ¸å¿ƒç»„ä»¶ï¼Œå¹¶åœ¨å®è·µä¸­è¡¨ç°å‡ºè‰²ï¼ˆå°¤å…¶åœ¨é•¿æç¤ºä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼‰ï¼Œä½†å…¶éçº¿æ€§ç»“æ„ä½¿å¾—ä»ä¼˜åŒ–å’Œç»Ÿè®¡è§’åº¦è¿›è¡Œä¸¥æ ¼åˆ†ææå…·æŒ‘æˆ˜ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ**linear attention** å› å…¶ä»£æ•°ç®€å•æ€§è€Œæ˜“äºåˆ†æï¼Œä½†å…¶å®é™…æ€§èƒ½é€šå¸¸å¼±äº softmaxã€‚

ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜æ˜¯ï¼š**èƒ½å¦åœ¨ç†è®ºä¸Šè§£é‡Šä¸ºä»€ä¹ˆ softmax åœ¨é•¿æç¤ºä¸‹è¡¨ç°ä¼˜å¼‚ï¼Ÿå®ƒæ˜¯å¦å¯ä»¥è¢«ç®€åŒ–æ¨¡å‹ï¼ˆå¦‚ linear attentionï¼‰è¿‘ä¼¼ï¼Ÿ**

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§ **åŸºäºæµ‹åº¦ï¼ˆmeasure-basedï¼‰çš„ç»Ÿä¸€æ¡†æ¶** æ¥ç ”ç©¶å•å±‚ softmax attentionï¼Œè¯¥æ¡†æ¶èƒ½å¤ŸåŒæ—¶å¤„ç†æœ‰é™é•¿åº¦å’Œæ— é™é•¿åº¦çš„æç¤ºï¼ˆpromptï¼‰ã€‚

- **æ ¸å¿ƒæ´å¯Ÿ**ï¼šå½“è¾“å…¥ token æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆi.i.d.ï¼‰çš„é«˜æ–¯å˜é‡æ—¶ï¼Œåœ¨æç¤ºé•¿åº¦ $L \to \infty$ çš„æé™æƒ…å†µä¸‹ï¼Œsoftmax attention æ“ä½œä¼šæ”¶æ•›åˆ°ä¸€ä¸ª**å…³äºè¾“å…¥ token æµ‹åº¦çš„çº¿æ€§ç®—å­**ã€‚
- **æ–°æ¡†æ¶**ï¼šå°†æœ‰é™æç¤ºè¡¨ç¤ºä¸ºç»éªŒæµ‹åº¦ $\mu_L = \frac{1}{L}\sum_{i=1}^L \delta_{z_i}$ï¼Œè€Œæ— é™æç¤ºåˆ™å¯¹åº”äºçœŸå®çš„åˆ†å¸ƒ $\mu$ã€‚é€šè¿‡è¿™ç§å½¢å¼åŒ–ï¼Œå¯ä»¥ç³»ç»Ÿåœ°æ¯”è¾ƒæœ‰é™æç¤ºæ¨¡å‹ä¸å…¶æ— é™æç¤ºæé™ä¹‹é—´çš„å·®å¼‚ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ç†è®ºä¸¥è°¨æ€§**ï¼šæä¾›äº† **éæ¸è¿‘çš„é›†ä¸­ä¸ç­‰å¼ï¼ˆnon-asymptotic concentration boundsï¼‰**ï¼Œé‡åŒ–äº†æœ‰é™æç¤ºä¸‹çš„ softmax attention è¾“å‡ºåŠå…¶æ¢¯åº¦å¦‚ä½•å¿«é€Ÿé€¼è¿‘å…¶æ— é™æç¤ºçš„çº¿æ€§å¯¹åº”ç‰©ã€‚
- **åŠ¨æ€ç¨³å®šæ€§**ï¼šè¯æ˜äº†è¿™ç§é›†ä¸­ç°è±¡åœ¨æ•´ä¸ªè®­ç»ƒè½¨è¿¹ä¸­æ˜¯ç¨³å®šçš„ï¼Œå³ä½¿åœ¨ä¸€èˆ¬çš„ in-context learning (ICL) è®¾ç½®ä¸‹ä¹Ÿæˆç«‹ã€‚
- **å¯è¿ç§»æ€§**ï¼šå»ºç«‹äº†ä¸€ä¸ªâ€œæ¡¥æ¢â€ï¼Œä½¿å¾—ä¸º linear attention å¼€å‘çš„ä¼˜åŒ–åˆ†æå¯ä»¥ç›´æ¥è¿ç§»åˆ° large-prompt regime ä¸‹çš„ softmax attentionã€‚è¿™ä¸ºåˆ†æå¤æ‚ä»»åŠ¡ä¸­çš„ softmax æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·ç®±ã€‚
- **æ›´å¹¿é€‚ç”¨æ€§**ï¼šç›¸æ¯” Chen et al. (2024) ç­‰ä»…é™äºå„å‘åŒæ€§åå˜é‡ï¼ˆisotropic covariatesï¼‰çš„åˆ†æï¼Œæœ¬æ–‡çš„æ–¹æ³•é€‚ç”¨äº**å„å‘å¼‚æ€§åå˜é‡ï¼ˆanisotropic covariatesï¼‰**ï¼Œæ›´å…·æ™®é€‚æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼Œ**æœ¬æ–‡æ˜¯ä¸€ç¯‡çº¯ç†è®ºè®ºæ–‡ï¼Œæ²¡æœ‰è¿›è¡Œä¼ ç»Ÿæ„ä¹‰ä¸Šçš„æ•°å€¼å®éªŒæˆ–åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„æ€§èƒ½æµ‹è¯•**ã€‚æ‰€æœ‰çš„â€œç»“æœâ€éƒ½æ˜¯æ•°å­¦æ¨å¯¼å’Œå®šç†è¯æ˜ã€‚

### æ•°æ®é›†
- ç†è®ºåˆ†æåŸºäº **åˆæˆæ•°æ®**ï¼Œç‰¹åˆ«æ˜¯å‡è®¾è¾“å…¥ token æœä» **é«˜æ–¯åˆ†å¸ƒ**ï¼ˆå¦‚ $\mathcal{N}(0, \Sigma)$ï¼‰æˆ–æ›´ä¸€èˆ¬çš„ sub-Gaussian åˆ†å¸ƒã€‚
- åœ¨ç¬¬5èŠ‚ä¸­ï¼Œå…·ä½“è€ƒè™‘äº† **in-context linear regression** ä»»åŠ¡ï¼Œå…¶ä¸­æ¯ä¸ªæç¤ºå¯¹åº”ä¸€ä¸ªéšæœºç”Ÿæˆçš„çº¿æ€§å›å½’é—®é¢˜ $y = w^\top x + \epsilon$ï¼Œ$w \sim \mathcal{N}(0, I_d)$ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **è®¾ç½®**ï¼šç ”ç©¶å•å±‚ Transformer çš„ **æ¢¯åº¦æµï¼ˆgradient flowï¼‰** åŠ¨åŠ›å­¦ã€‚
- **æ ¸å¿ƒæŒ‡æ ‡**ï¼š
  - **é£é™©ï¼ˆRiskï¼‰** $R(U,V)$ï¼šè¡¡é‡æ¨¡å‹é¢„æµ‹è¯¯å·®çš„æœŸæœ›æŸå¤±ã€‚
  - **å‚æ•°æ”¶æ•›æ€§**ï¼šåˆ†ææ³¨æ„åŠ›å‚æ•° $(U(t), V(t))$ éšæ—¶é—´ $t$ çš„æ¼”åŒ–ã€‚
  - **é›†ä¸­ç•Œï¼ˆConcentration boundsï¼‰**ï¼šé‡åŒ– $\left\|\mathcal{T}_{U,V}[\mu_L] - \mathcal{T}_{U,V}[\mu]\right\|$ å’Œæ¢¯åº¦å·®åˆ«çš„å¤§å°ï¼Œè¿™äº›ç•Œé™ä¾èµ–äºæç¤ºé•¿åº¦ $L$ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ä¸»è¦å¯¹æ¯”å¯¹è±¡æ˜¯ linear attention**ã€‚ä½œè€…å¹¶æœªå°† softmax ä¸ linear attention è¿›è¡Œç›´æ¥çš„æ€§èƒ½æ•°å­—å¯¹æ¯”ï¼Œè€Œæ˜¯è¯æ˜äº†åœ¨ $L \to \infty$ æ—¶ï¼Œä¸¤è€…çš„åŠ¨åŠ›å­¦è¡Œä¸ºæ˜¯**ç­‰ä»·çš„**ã€‚
- å¼•ç”¨å¹¶å¯¹æ¯”äº† **Zhang et al. (2024)** å¯¹ linear attention åœ¨ in-context learning ä¸­çš„åˆ†æç»“æœï¼Œè¯æ˜æœ¬æ–‡çš„æ¡†æ¶å¯ä»¥å°†è¿™äº›ç»“æœæ— ç¼è¿ç§»åˆ° softmax attentionã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

å†æ¬¡è¯´æ˜ï¼Œä»¥ä¸‹å‡ä¸º**ç†è®ºç»“æœ**ï¼Œè€Œéå®éªŒæ•°æ®ã€‚

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆç†è®ºç•Œé™ï¼‰
- **è¾“å‡ºé›†ä¸­ç•Œï¼ˆProposition 3.1ï¼‰**ï¼š
  $$
  \mathbb{E}\left[\left\|\mathcal{T}_{U,V}[\mu_L](z) - \mathcal{T}_{U,V}[\mu](z)\right\|\right] \leq c_1 \sigma \sqrt{\frac{\ln(L)}{L^{c_2/\sigma^2}}}
  $$
  è¿™è¡¨æ˜éšç€ $L$ å¢å¤§ï¼Œæœ‰é™æç¤ºçš„è¾“å‡ºä»¥å¤šé¡¹å¼å¯¹æ•°é€Ÿç‡æ”¶æ•›åˆ°å…¶æ— é™æç¤ºæé™ã€‚

- **æ¢¯åº¦é›†ä¸­ç•Œï¼ˆProposition 3.4ï¼‰**ï¼š
  ç±»ä¼¼çš„ç•Œé™ä¹Ÿé€‚ç”¨äºæ¢¯åº¦ $\nabla_V \mathcal{T}_{U,V}$ å’Œ $\nabla_U \mathcal{T}_{U,V}$ï¼Œä¿è¯äº†ä¼˜åŒ–è¿‡ç¨‹çš„ç¨³å®šæ€§ã€‚

- **è®­ç»ƒåŠ¨æ€é€¼è¿‘ï¼ˆTheorem 4.3ï¼‰**ï¼š
  $$
  \lim_{t\to\infty} R(\theta_L(t)) \leq \lim_{t\to\infty} R_\infty(\theta_\infty(t)) + \epsilon
  $$
  å…¶ä¸­ $\theta_L(t)$ æ˜¯æœ‰é™æç¤º $L$ ä¸‹çš„å‚æ•°ï¼Œ$\theta_\infty(t)$ æ˜¯æ— é™æç¤ºä¸‹çš„å‚æ•°ã€‚è¿™æ„å‘³ç€é•¿æç¤ºä¸‹çš„æœ€ç»ˆé£é™©å¯ä»¥ä»»æ„æ¥è¿‘æ— é™æç¤ºä¸‹çš„æœ€ä¼˜é£é™©ã€‚

- **In-context Linear Regression çš„è´å¶æ–¯æœ€ä¼˜æ€§ï¼ˆTheorem 5.1ï¼‰**ï¼š
  åœ¨ in-context linear regression ä»»åŠ¡ä¸­ï¼Œå½“æç¤ºè¶³å¤Ÿé•¿æ—¶ï¼Œé€šè¿‡æ¢¯åº¦æµè®­ç»ƒçš„ softmax attention å¯ä»¥è¾¾åˆ° **Bayes æœ€ä¼˜é£é™©**ï¼ˆå³ç†è®ºæœ€å°å¯èƒ½é£é™©ï¼Œæ­¤å¤„ä¸º0ï¼Œå› ä¸ºæ— æ ‡ç­¾å™ªå£°ï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- æœ¬æ–‡è¯æ˜ï¼Œ**åœ¨æ— é™æç¤ºæé™ä¸‹ï¼Œsoftmax attention çš„è¡Œä¸ºä¸ linear attention å®Œå…¨ç­‰ä»·**ã€‚
- å› æ­¤ï¼ŒZhang et al. (2024) ä¸º linear attention è¯æ˜çš„æ”¶æ•›æ€§å’Œæœ€ä¼˜æ€§ç»“æœï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äº large-prompt ä¸‹çš„ softmax attentionã€‚
- ç›¸æ¯” Chen et al. (2024)ï¼Œæœ¬æ–‡è™½ç„¶æœªç»™å‡ºç²¾ç¡®çš„æ”¶æ•›é€Ÿç‡ï¼Œä½†ä¼˜åŠ¿åœ¨äºå¤„ç†äº†æ›´ä¸€èˆ¬çš„ **anisotropic covariates** åœºæ™¯ã€‚

### æ¶ˆèå®éªŒ
- æœ¬æ–‡æ²¡æœ‰è¿›è¡Œæ¶ˆèå®éªŒã€‚å…¶ç†è®ºæ¡†æ¶æœ¬èº«æ˜¯å¯¹ä¸åŒå‡è®¾ï¼ˆå¦‚ sub-Gaussian è¾“å…¥ã€é«˜æ–¯è¾“å…¥ï¼‰çš„åˆ†æï¼Œè¿™äº›æ„æˆäº†ç†è®ºçš„ç»„æˆéƒ¨åˆ†è€Œéå®éªŒéªŒè¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Large-prompt Softmax â‰ˆ Linear Attention**ï¼šåœ¨æç¤ºå¾ˆé•¿ä¸”è¾“å…¥ä¸ºé«˜æ–¯æˆ– sub-Gaussian æ—¶ï¼Œsoftmax attention çš„è¡Œä¸ºæœ¬è´¨ä¸Šæ˜¯çº¿æ€§çš„ã€‚å…¶æ— é™æç¤ºæé™æ˜¯ä¸€ä¸ªå…³äºè¾“å…¥æµ‹åº¦çš„çº¿æ€§å˜æ¢ã€‚
2. **å¯åˆ†ææ€§è½¬ç§»**ï¼šè¿™ä¸€å‘ç°æä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œå…è®¸ç ”ç©¶è€…åˆ©ç”¨ä¸º **linear attention** å»ºç«‹çš„æˆç†Ÿç†è®ºæ¥åˆ†æ **softmax attention** çš„è®­ç»ƒåŠ¨æ€å’Œæ³›åŒ–è¡Œä¸ºã€‚
3. **ç†è®ºæ­£å½“åŒ–**ï¼šä¸ºä½¿ç”¨ linear attention ä½œä¸º softmax çš„ä»£ç†æ¨¡å‹è¿›è¡Œç†è®ºç ”ç©¶æä¾›äº†**åŸåˆ™æ€§çš„ã€å¹¿æ³›é€‚ç”¨çš„ä¾æ®**ï¼Œå°¤å…¶æ˜¯åœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹ã€‚
4. **æ”¶æ•›ä¿è¯**ï¼šé¦–æ¬¡ä¸º softmax attention åœ¨ **anisotropic Gaussian covariates** ä¸‹çš„ in-context learning ä»»åŠ¡æä¾›äº†æ”¶æ•›åˆ°è´å¶æ–¯æœ€ä¼˜è§£çš„ç†è®ºä¿è¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å•å±‚é™åˆ¶**ï¼šåˆ†æå±€é™äº**å•å±‚** attentionã€‚å¤šå±‚å †å çš„ Transformer çš„åŠ¨æ€æ›´ä¸ºå¤æ‚ï¼Œå°šæœªè¢«æ¶µç›–ã€‚
- **ç†æƒ³åŒ–å‡è®¾**ï¼šä¾èµ–äº i.i.d. è¾“å…¥ token çš„å‡è®¾ã€‚ç°å®ä¸–ç•Œçš„æ•°æ®å­˜åœ¨å¤æ‚çš„ä¾èµ–å…³ç³»å’Œç»“æ„ã€‚
- **æ— é™æ·±åº¦ vs æ— é™å®½åº¦**ï¼šæœ¬æ–‡å…³æ³¨â€œæ— é™æç¤ºâ€ï¼ˆlarge-width in dataï¼‰ï¼Œè€Œè®¸å¤šç¥ç»ç½‘ç»œç†è®ºå…³æ³¨â€œæ— é™å®½åº¦â€ï¼ˆlarge-width in parametersï¼‰ã€‚ä¸¤è€…ç»“åˆçš„åˆ†ææ›´å…·æŒ‘æˆ˜æ€§ã€‚
- **é«˜æ–¯è¾“å…¥**ï¼šè™½ç„¶éƒ¨åˆ†ç»“æœæ¨å¹¿åˆ° sub-Gaussianï¼Œä½†æœ€æœ‰åŠ›çš„ç»“è®ºï¼ˆå¦‚çº¿æ€§åŒ–ï¼‰ä¾èµ–äºé«˜æ–¯æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†è¯¥æµ‹åº¦æ¡†æ¶æ‰©å±•åˆ°**å¤šå±‚ Transformer** æ¨¡å‹ã€‚
- ç ”ç©¶æ›´å¤æ‚çš„ in-context learning ä»»åŠ¡ï¼Œä¾‹å¦‚ **n-gram å­¦ä¹ ** æˆ– **ç¬¦å·æ¨ç†**ã€‚
- æ”¾æ¾ i.i.d. å’Œé«˜æ–¯æ€§å‡è®¾ï¼Œåˆ†ææ›´è´´è¿‘çœŸå®æ•°æ®çš„åˆ†å¸ƒã€‚
- æ¢ç´¢è¯¥ç†è®ºå¯¹æ¨¡å‹è®¾è®¡ï¼ˆå¦‚åˆå§‹åŒ–ã€æ¶æ„ï¼‰çš„æŒ‡å¯¼æ„ä¹‰ã€‚
- å°†â€œæ— é™æç¤ºâ€çš„æ€æƒ³ä¸â€œæ— é™å®½åº¦â€çš„ mean-field ç†è®ºç›¸ç»“åˆï¼Œå»ºç«‹æ›´å…¨é¢çš„ Transformer ç†è®ºã€‚

</details>

---

### 11. [AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints](https://arxiv.org/abs/2512.11426)

**Authors**: Shuowei Cai, Yansong Ning, Hao Liu  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.11426v1  

#### Abstract
Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. Whil...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šAgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é«˜æ˜‚çš„ **token-cost** å’Œ **end-to-end latency** ä¸¥é‡åˆ¶çº¦äº†å¤§è§„æ¨¡éƒ¨ç½²ã€‚ç°æœ‰ç ”ç©¶é€šå¸¸ï¼š
- å¿½è§†æ˜¾å¼çš„é¢„ç®—çº¦æŸï¼ˆtoken-cost å’Œ latencyï¼‰ï¼›
- é‡‡ç”¨â€œå…ˆæ‹“æ‰‘åéª¨å¹²â€ï¼ˆtopology-firstï¼‰çš„è®¾è®¡èŒƒå¼ï¼›
- å¿½ç•¥ä¸åŒ LLM éª¨å¹²ï¼ˆbackboneï¼‰å¯¹æˆæœ¬æ•ˆç›Šçš„å·¨å¤§å½±å“ã€‚

è¿™å¯¼è‡´åœ¨å®é™…é¢„ç®—é™åˆ¶ä¸‹ï¼Œç³»ç»Ÿæ€§èƒ½ä¸ä½³æˆ–ä¸å¯æŒç»­ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº† **AGENTBALANCE**ï¼Œä¸€ç§å…¨æ–°çš„ **backbone-then-topology** è®¾è®¡æ¡†æ¶ï¼Œç”¨äºæ„å»ºåœ¨æ˜¾å¼ token-cost å’Œ latency é¢„ç®—ä¸‹çš„é«˜æ€§ä»·æ¯” MASã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **å…ˆç¡®å®šåˆé€‚çš„ LLM éª¨å¹²ï¼Œå†åœ¨æ­¤åŸºç¡€ä¸Šä¼˜åŒ–é€šä¿¡æ‹“æ‰‘**ã€‚

è¯¥æ–¹æ³•åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š

#### ï¼ˆ1ï¼‰**Backbone-Oriented Agent Generationï¼ˆéª¨å¹²å¯¼å‘çš„æ™ºèƒ½ä½“ç”Ÿæˆï¼‰**
- **LLM æ± æ„å»ºä¸åˆ†æ**ï¼šåŸºäºæ€§èƒ½ã€token-costã€latency æ„å»ºå¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto frontierï¼‰ï¼Œèšç±»å½¢æˆå¤šä¸ª LLM æ± ï¼ˆpoolï¼‰ï¼Œæ¯ä¸ªæ± ä»£è¡¨ä¸åŒçš„èµ„æºå±‚çº§ã€‚
- **éš¾åº¦æ„ŸçŸ¥çš„æ± é€‰æ‹©ï¼ˆDifficulty-Aware Pool Selectionï¼‰**ï¼šé€šè¿‡è½»é‡çº§éš¾åº¦ä¼°è®¡å™¨é¢„æµ‹æŸ¥è¯¢éš¾åº¦ï¼Œå¹¶æ®æ­¤é€‰æ‹©æœ€åˆé€‚çš„ LLM æ± ï¼Œå®ç°é¢„ç®—åˆ†é…ã€‚
- **æŸ¥è¯¢æ¡ä»¶çš„è§’è‰²-éª¨å¹²åŒ¹é…ï¼ˆQuery-Conditioned Role-Backbone Matchingï¼‰**ï¼šæ ¹æ®è§’è‰²éœ€æ±‚å’ŒæŸ¥è¯¢å†…å®¹ï¼Œä¸ºæ¯ä¸ª agent åˆ†é…æœ€åŒ¹é…çš„ backboneï¼Œæå‡æˆæœ¬æ•ˆç›Šã€‚

#### ï¼ˆ2ï¼‰**Adaptive MAS Topology Generationï¼ˆè‡ªé€‚åº”æ‹“æ‰‘ç”Ÿæˆï¼‰**
- **ç»Ÿä¸€æ™ºèƒ½ä½“è¡¨å¾å­¦ä¹ ï¼ˆUnified Agent Representation Learningï¼‰**ï¼šèåˆè§’è‰²ã€æŸ¥è¯¢ã€LLM ç±»å‹ç­‰ä¿¡æ¯ï¼Œç”Ÿæˆç»Ÿä¸€çš„ agent è¡¨å¾ã€‚
- **æ™ºèƒ½ä½“é—¨æ§ï¼ˆAgent Gatingï¼‰**ï¼šåŠ¨æ€ç§»é™¤å†—ä½™ agentï¼Œå‡å°‘ä¸å¿…è¦çš„è®¡ç®—å¼€é”€ã€‚
- **å»¶è¿Ÿæ„ŸçŸ¥çš„æ‹“æ‰‘åˆæˆï¼ˆLatency-Aware Topology Synthesisï¼‰**ï¼šç”Ÿæˆç¨€ç–ä¸”ä½å»¶è¿Ÿçš„é€šä¿¡å›¾ï¼Œå¹¶é€šè¿‡ hop-length æ§åˆ¶é¿å…è¿‡é•¿æ¨ç†é“¾ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **è®¾è®¡èŒƒå¼é©æ–°**ï¼šä»â€œtopology-firstâ€è½¬å‘â€œbackbone-then-topologyâ€ï¼Œæ›´ç¬¦åˆé¢„ç®—çº¦æŸä¸‹çš„ä¼˜åŒ–é€»è¾‘ã€‚
- **å…¨é¢å»ºæ¨¡æˆæœ¬å› ç´ **ï¼šåŒæ—¶è€ƒè™‘ token-costã€latency å’Œæ€§èƒ½ï¼Œè¿›è¡Œç«¯åˆ°ç«¯è”åˆä¼˜åŒ–ã€‚
- **é«˜åº¦è‡ªé€‚åº”æ€§**ï¼šèƒ½æ ¹æ®æŸ¥è¯¢éš¾åº¦åŠ¨æ€è°ƒæ•´ backbone å’Œ topologyï¼Œå®ç°ä¸ªæ€§åŒ–èµ„æºé…ç½®ã€‚
- **å¯æ’æ‹”æ€§å¼º**ï¼šå¯ä½œä¸ºæ’ä»¶é›†æˆåˆ°ç°æœ‰ MAS æ¡†æ¶ï¼ˆå¦‚ AutoGenã€Layered Graphï¼‰ä¸­ï¼Œæå‡å…¶æˆæœ¬æ•ˆç›Šã€‚
- **å½’çº³èƒ½åŠ›å¼º**ï¼šèƒ½æ³›åŒ–åˆ°è®­ç»ƒæ—¶æœªè§è¿‡çš„ LLMï¼Œå…·å¤‡è‰¯å¥½çš„å®ç”¨æ€§å’Œæ‰©å±•æ€§ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
åœ¨ä¸‰ä¸ªä»£è¡¨æ€§é¢†åŸŸè¿›è¡Œè¯„ä¼°ï¼š
- **MMLU**ï¼šé€šç”¨çŸ¥è¯†é—®ç­”
- **MATH**ï¼šæ•°å­¦æ¨ç†
- **HumanEval**ï¼šä»£ç ç”Ÿæˆ

### **å®éªŒè®¾ç½®**
- **å€™é€‰ LLM æ•°é‡**ï¼šå…± 14 ä¸ªï¼Œæ¥è‡ª Qwen å’Œ DeepSeek ç³»åˆ—ï¼Œæ¶µç›–ä¸åŒè§„æ¨¡ï¼ˆ1.7B ~ 235Bï¼‰å’Œç±»å‹ï¼ˆreasoning / non-reasoningï¼‰ã€‚
- **LLM æ± æ•°é‡**ï¼š4 ä¸ªï¼ŒæŒ‰æ€§èƒ½ç”±å¼±åˆ°å¼ºæ’åºã€‚
- **è®­ç»ƒæ ·æœ¬æ•°**ï¼šHumanEval ä½¿ç”¨ 20 æ ·æœ¬ï¼Œå…¶ä½™ä½¿ç”¨ 40 æ ·æœ¬ï¼Œå¼ºè°ƒå°æ ·æœ¬é«˜æ•ˆæ€§ã€‚
- **ä¼˜åŒ–æ–¹å¼**ï¼šä½¿ç”¨ç­–ç•¥æ¢¯åº¦ï¼ˆpolicy gradientï¼‰è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œç›®æ ‡å‡½æ•°åŒ…å«æ€§èƒ½å¥–åŠ±ä¸ token-costã€latency æƒ©ç½šé¡¹ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
- **Performance-at-Budget (P@T_k, P@L_k)**ï¼šåœ¨ç»™å®š token-cost æˆ– latency é¢„ç®—ä¸‹çš„ä»»åŠ¡æ€§èƒ½ã€‚
  - MMLU/MATHï¼šaccuracy
  - HumanEvalï¼šPass@1
- **AUC_tok / AUC_lat**ï¼šæ€§èƒ½-é¢„ç®—æ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œè¡¡é‡æ•´ä½“æˆæœ¬æ•ˆç›Šã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|--------|------|------|
| **AgentPrune** | å• backbone | å‰ªæå†—ä½™æ¶ˆæ¯ |
| **AgentDropout** | å• backbone | åŠ¨æ€ç§»é™¤ agent |
| **G-Designer** | å• backbone | ä½¿ç”¨ GNN åˆæˆç¨€ç–æ‹“æ‰‘ |
| **MasRouter** | å¤š backbone | topology-firstï¼Œæ”¯æŒå¤š LLM è·¯ç”± |

æ‰€æœ‰åŸºçº¿å‡åŸºäº Complete Graph æ¶æ„æ„å»ºã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰**

| æ•°æ®é›† | æ–¹æ³• | P@T1 (Token) | P@T4 (Token) | AUC_tok | P@L1 (Latency) | P@L4 (Latency) | AUC_lat |
|-------|------|-------------|-------------|---------|---------------|---------------|--------|
| **MMLU** | AGENTBALANCE | **71.90** | **88.02** | **1.297** | **71.90** | **88.02** | **250.0** |
| | æœ€ä½³åŸºçº¿ (G-Designer) | 61.80 | 86.77 | 1.261 | 59.69 | 86.61 | 243.2 |
| **HumanEval** | AGENTBALANCE | **87.94** | **95.46** | 1.880 | **87.94** | **95.46** | **476.5** |
| | æœ€ä½³åŸºçº¿ (G-Designer) | 86.90 | 95.52 | **1.885** | 83.81 | 93.51 | 474.9 |
| **MATH** | AGENTBALANCE | **66.46** | **79.38** | **3.523** | **66.46** | **79.38** | **602.4** |
| | æœ€ä½³åŸºçº¿ (G-Designer) | 63.05 | 77.45 | 3.450 | 59.43 | 74.26 | 581.9 |

> âœ… **æœ€é«˜æå‡è¾¾ 10%ï¼ˆtoken-cost ä¸‹ï¼‰å’Œ 22%ï¼ˆlatency ä¸‹ï¼‰**

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- åœ¨ **tight budgetï¼ˆP@T1/P@L1ï¼‰** ä¸‹ï¼ŒAGENTBALANCE æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œè¯´æ˜å…¶åœ¨èµ„æºå—é™åœºæ™¯ä¸‹æ›´å…·ä¼˜åŠ¿ã€‚
- **MasRouter** è¡¨ç°ä¸ç¨³å®šï¼Œå°¤å…¶åœ¨ä½é¢„ç®—ä¸‹æ€§èƒ½éª¤é™ï¼ŒéªŒè¯äº† topology-first èŒƒå¼çš„å±€é™æ€§ã€‚
- å• backbone æ–¹æ³•ï¼ˆå¦‚ AgentPruneï¼‰å› æ— æ³•çµæ´»é€‰æ‹© backboneï¼Œåœ¨æˆæœ¬æ•ˆç›Šä¸Šå­˜åœ¨å¤©èŠ±æ¿ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆè§ Table 3ï¼‰**
å¯¹ä»¥ä¸‹å˜ä½“è¿›è¡Œäº†æ¶ˆèï¼š

| å˜ä½“ | æ€§èƒ½ä¸‹é™ | æˆæœ¬/å»¶è¿Ÿå˜åŒ– | ç»“è®º |
|------|--------|--------------|------|
| (1) éšæœº LLM æ±  | â†“ æ˜æ˜¾ | â†‘ token-cost & latency | LLM æ± æ„é€ è‡³å…³é‡è¦ |
| (2) éšæœºæ± é€‰æ‹© | â†“ æ˜æ˜¾ | â†“ token-cost but â†“â†“ perf | éš¾åº¦æ„ŸçŸ¥é€‰æ‹©æœ‰æ•ˆ |
| (3) éšæœºè§’è‰²-éª¨å¹²åŒ¹é… | â†“ æ˜æ˜¾ | â†“ cost but â†“â†“ perf | åŒ¹é…ç²¾åº¦å†³å®šæ€§ä»·æ¯” |
| (4) å¿½ç•¥ backbone ä¿¡æ¯ | â†“ | â†‘ latency | ç»Ÿä¸€è¡¨å¾å­¦ä¹ å¿…è¦ |
| (5) ç§»é™¤ agent gating | â†” perf | â†‘â†‘ latency | gating æœ‰æ•ˆæ§åˆ¶å»¶è¿Ÿ |
| (6) å¯†é›†æ‹“æ‰‘ | â†” perf | â†‘â†‘ latency | ç¨€ç–æ‹“æ‰‘æ›´ä¼˜ |

> ğŸ” æ‰€æœ‰æ¨¡å—å‡å¯¹æœ€ç»ˆæ€§èƒ½-æˆæœ¬-å»¶è¿Ÿå¹³è¡¡æœ‰æ˜¾è‘—è´¡çŒ®ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **éª¨å¹²é€‰æ‹©æ¯”æ‹“æ‰‘ä¼˜åŒ–æ›´èƒ½é©±åŠ¨æˆæœ¬æ•ˆç›Šè¾¹ç•Œ**ï¼ˆè§ Figure 2 å·¦ï¼‰ï¼š
   - Backbone choice å¯¹æ€§èƒ½-æˆæœ¬æƒè¡¡çš„å½±å“è¿œå¤§äº topology ä¿®æ”¹ã€‚
2. **æœ€ä¼˜æ‹“æ‰‘ä¾èµ–äºæ‰€é€‰ backbone**ï¼ˆè§ Figure 2 å³ï¼‰ï¼š
   - æ›´æ¢ backbone åè‹¥ä¸é‡æ–°è®¾è®¡æ‹“æ‰‘ï¼Œæ€§èƒ½ä¼šä¸‹é™ï¼ˆtransfer æ•ˆæœå·®ï¼‰ã€‚
3. **backbone-then-topology èŒƒå¼ä¼˜äº topology-first**ï¼š
   - å›ºå®š backbone å†ä¼˜åŒ– topology æ›´ç¨³å®šã€æ›´é«˜æ•ˆã€‚
4. **AGENTBALANCE å…·å¤‡å¼ºå½’çº³èƒ½åŠ›**ï¼ˆè§ Figure 4ï¼‰ï¼š
   - å³ä½¿ç§»é™¤æˆ–æ–°å¢æœªè§ LLMï¼Œä»èƒ½å¿«é€Ÿé€‚é…å¹¶ä¿æŒé¢†å…ˆæ€§èƒ½ã€‚
5. **å¯ä½œä¸ºæ’ä»¶å¢å¼ºç°æœ‰ MAS**ï¼ˆè§ Table 2ï¼‰ï¼š
   - æ’å…¥ AutoGen æˆ– Layered Graph åï¼Œæ€§èƒ½æ˜¾è‘—æå‡ï¼ŒéªŒè¯å…¶é€šç”¨æ€§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–é«˜è´¨é‡çš„ LLM profiling**ï¼šéœ€å‡†ç¡®ä¼°è®¡å„ LLM çš„æ€§èƒ½ã€PTPã€latencyã€‚
- **åˆå§‹åŒ–å¼€é”€è¾ƒå¤§**ï¼šLLM æ± æ„å»ºå’Œéš¾åº¦ä¼°è®¡å™¨é¢„è®­ç»ƒéœ€è¦é¢å¤–èµ„æºã€‚
- **æç«¯é¢„ç®—ä¸‹å¯èƒ½æ¬ æ‹Ÿåˆ**ï¼šåœ¨æä½é¢„ç®—ä¸‹ï¼Œå¯ç”¨ backbone æœ‰é™ï¼Œçµæ´»æ€§å—é™ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢æ›´ç»†ç²’åº¦çš„ **cost modeling**ï¼Œå¦‚è€ƒè™‘ prefilled vs decode token çš„å·®å¼‚ã€‚
- å°†æ¡†æ¶æ‰©å±•è‡³ **multi-modal MAS** åœºæ™¯ã€‚
- ç ”ç©¶ **åŠ¨æ€é¢„ç®—è°ƒæ•´æœºåˆ¶**ï¼Œåº”å¯¹è¿è¡Œæ—¶èµ„æºæ³¢åŠ¨ã€‚
- å¼€å‘ **è‡ªåŠ¨åŒ– LLM profiling pipeline**ï¼Œé™ä½éƒ¨ç½²é—¨æ§›ã€‚

---

> ğŸ“Œ **æ€»ç»“**ï¼š  
> **AGENTBALANCE** æå‡ºäº†ä¸€ç§é¢å‘é¢„ç®—çº¦æŸçš„æ–°å‹ MAS æ„å»ºèŒƒå¼ â€”â€” **backbone-then-topology**ï¼Œé€šè¿‡éª¨å¹²å¯¼å‘çš„ agent ç”Ÿæˆä¸è‡ªé€‚åº”æ‹“æ‰‘è®¾è®¡ï¼Œåœ¨ token-cost å’Œ latency å—é™æ¡ä»¶ä¸‹å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…¶å®éªŒå……åˆ†ã€è®¾è®¡åˆç†ï¼Œå…¼å…·å®ç”¨æ€§ä¸å‰ç»æ€§ï¼Œä¸ºå¤§è§„æ¨¡ LLM åº”ç”¨çš„æˆæœ¬æ§åˆ¶æä¾›äº†é‡è¦è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 12. [Agentic Operator Generation for ML ASICs](https://arxiv.org/abs/2512.10977)

**Authors**: Alec M. Hammond, Aram Markosyan, Aman Dontula, Simon Mahns, Zacharias Fisches, Dmitrii Pedchenko, Keyur Muzumdar, Natacha Supper, Mark Saroufim, Joe Isaacson, Laura Wang, Warren Hunt, Kaustubh Gondkar, Roman Levenstein, Gabriel Synnaeve, Richard Li, Jacob Kahn, Ajit Mathews  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.10977v1  

#### Abstract
We present TritorX, an agentic AI system designed to generate functionally correct Triton PyTorch ATen kernels at scale for emerging accelerator platforms. TritorX integrates open-source large language models with a custom linter, JIT compilation, and a PyTorch OpInfo-based test harness. This pipeli...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAgentic Operator Generation for ML ASICs

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨æœºå™¨å­¦ä¹ ä¸“ç”¨é›†æˆç”µè·¯ï¼ˆML ASICï¼‰çš„ç ”å‘ä¸­ï¼Œæ„å»ºä¸€ä¸ªå®Œæ•´çš„è½¯ä»¶ç”Ÿæ€ç³»ç»Ÿæ˜¯å…³é”®æŒ‘æˆ˜ä¹‹ä¸€ã€‚ç‰¹åˆ«æ˜¯ä¸ºæ–°å…´åŠ é€Ÿå™¨å¹³å°ï¼ˆå¦‚ Meta Training and Inference Accelerator, MTIAï¼‰å®ç°å¯¹ **PyTorch ATen** ç®—å­çš„å…¨é¢æ”¯æŒéœ€è¦å¤§é‡å·¥ç¨‹æŠ•å…¥ã€‚ä¼ ç»Ÿæ–¹å¼ä¾èµ–äººå·¥ç¼–å†™é«˜æ€§èƒ½å†…æ ¸ï¼Œæ•ˆç‡ä½ä¸”éš¾ä»¥æ‰©å±•ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ **å¦‚ä½•è‡ªåŠ¨åŒ–ç”ŸæˆåŠŸèƒ½æ­£ç¡®ã€è¦†ç›–å¹¿æ³›çš„ PyTorch ATen å†…æ ¸ï¼ˆkernelsï¼‰ä»¥é€‚é…æ–°å‹ ML ASIC å¹³å°** è¿™ä¸€éš¾é¢˜ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šTritorX
ä½œè€…æå‡ºäº† **TritorX** â€”â€” ä¸€ç§åŸºäºä»£ç†ï¼ˆagenticï¼‰çš„ AI ç³»ç»Ÿï¼Œç”¨äºå¤§è§„æ¨¡è‡ªåŠ¨ç”Ÿæˆé€‚ç”¨äº MTIA çš„ **Triton PyTorch ATen å†…æ ¸**ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–æµç¨‹**ï¼šç»“åˆå¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€è‡ªå®šä¹‰ linterã€JIT ç¼–è¯‘å™¨å’Œ PyTorch OpInfo æµ‹è¯•æ¡†æ¶ï¼Œå½¢æˆé—­ç¯åé¦ˆç³»ç»Ÿã€‚
- **æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰æ¶æ„**ï¼šé‡‡ç”¨ FSM æ§åˆ¶ LLM çš„è¿­ä»£ç”Ÿæˆè¿‡ç¨‹ï¼Œç¡®ä¿æ‰§è¡Œå¯æ§æ€§å’Œå¯è°ƒè¯•æ€§ï¼Œä¼˜äºçº¯æ¨ç†ä»£ç†æ¨¡å¼ã€‚
- **å¼ºè°ƒè¦†ç›–ç‡è€Œéå•ä¸€æ€§èƒ½ä¼˜åŒ–**ï¼šä¸åŒäºä»¥å¾€èšç„¦å°‘æ•°å…³é”®è·¯å¾„ç®—å­çš„æ–¹æ³•ï¼ŒTritorX ä¼˜å…ˆä¿è¯æ•´ä¸ª ATen ç®—å­é›†åˆçš„åŠŸèƒ½æ­£ç¡®æ€§å’Œé€šç”¨æ€§ï¼ˆæ¶µç›–å¤šç§æ•°æ®ç±»å‹ã€å½¢çŠ¶ã€å‚æ•°ç»„åˆï¼‰ã€‚
- **é˜²â€œä½œå¼Šâ€æœºåˆ¶**ï¼šé€šè¿‡å®šåˆ¶åŒ– **Triton MTIA Linter** é˜²æ­¢ LLM è°ƒç”¨æœªå®ç°çš„ PyTorch å‡½æ•°æˆ–å°†è®¡ç®—å›é€€åˆ°ä¸»æœºï¼ˆhostï¼‰ï¼Œå¼ºåˆ¶æœ¬åœ°åŒ–å®ç°ã€‚
- **çœŸå®ç¡¬ä»¶éªŒè¯**ï¼šç›´æ¥åœ¨éƒ¨ç½²çš„ MTIA ç¡¬ä»¶æˆ– QEMU æ¨¡æ‹Ÿå™¨ä¸Šè¿›è¡Œç¼–è¯‘ã€è¿è¡Œå’Œæµ‹è¯•ï¼Œç¡®ä¿ç”Ÿæˆä»£ç çš„å®é™…å¯ç”¨æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | TritorX |
|------|--------|--------|
| å¼€å‘æˆæœ¬ | é«˜ï¼ˆéœ€ä¸“å®¶æ‰‹åŠ¨ç¼–ç ï¼‰ | æä½ï¼ˆè‡ªåŠ¨åŒ–ï¼‰ |
| è¦†ç›–ç‡ | æœ‰é™ï¼ˆä»…é«˜ä½¿ç”¨é¢‘ç‡ç®—å­ï¼‰ | é«˜ï¼ˆ481ä¸ªç®—å­ï¼Œ84.7%è¦†ç›–ç‡ï¼‰ |
| æ­£ç¡®æ€§ä¿éšœ | æ‰‹åŠ¨æµ‹è¯•ä¸ºä¸» | è‡ªåŠ¨åŒ– OpInfo + ç”Ÿäº§æ•°æ®æµ‹è¯• |
| å¯ç§»æ¤æ€§ | å·®ï¼ˆç‰¹å®šäºå¹³å°ï¼‰ | æ”¯æŒè·¨ä»£èŠ¯ç‰‡æ¨¡æ‹Ÿ |
| æ‰©å±•é€Ÿåº¦ | æ•°æœˆçº§ | â€œovernightâ€çº§åˆ« |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šTritorX å°†åç«¯å†…æ ¸å¼€å‘ä»â€œæ‰‹å·¥è‰ºâ€è½¬å˜ä¸ºâ€œå¯æµ‹é‡çš„å·¥ç¨‹æµç¨‹â€ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ä¸å¯é æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ç®—å­æ¥æº
- ä½¿ç”¨ **PyTorch çš„ OpInfo æµ‹è¯•å¥—ä»¶**ä½œä¸ºç›®æ ‡ç®—å­é›†ã€‚
- åˆå§‹ç­›é€‰å‡º 629 ä¸ª OpInfo å®šä¹‰çš„ ATen ç®—å­ã€‚
- æ’é™¤ä¸å…¼å®¹é¡¹ï¼ˆå¦‚å¤æ•°è¿ç®—ã€éšæœºæ•°ç”Ÿæˆç­‰ï¼‰ï¼Œæœ€ç»ˆä¿ç•™ **568 ä¸ª MTIA å…¼å®¹çš„ ATen ç®—å­**ã€‚
- æ€»è®¡è¶…è¿‡ **20,000 ä¸ªæµ‹è¯•ç”¨ä¾‹**ï¼Œè¦†ç›–ä¸åŒæ•°æ®ç±»å‹ï¼ˆ`bfloat16`, `float16`, `float32`, `int32`, `int64`ï¼‰ã€å¼ é‡å½¢çŠ¶å’Œè¾“å…¥å‚æ•°ã€‚

---

### å®éªŒè®¾ç½®
- **ç›®æ ‡å¹³å°**ï¼šMeta çš„ MTIA åŠ é€Ÿå™¨ï¼ˆçœŸå®ç¡…ç‰‡ + QEMU æ¨¡æ‹Ÿå™¨ï¼‰
- **LLM æ¨¡å‹**ï¼š
  - ä¸»ç”Ÿæˆæ¨¡å‹ï¼š`Code World Model (CWM)` å’Œ `GPT-OSS 120B`
  - åé¦ˆæ‘˜è¦æ¨¡å‹ï¼š`Llama-4-Maverick`
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼š131,072 tokens
- **æ¸©åº¦**ï¼š1.0ï¼›Top-Pï¼š0.95ï¼ˆCWMï¼‰/ 1.0ï¼ˆGPT-OSSï¼‰
- **æœ€å¤§å°è¯•æ¬¡æ•°**ï¼šæ¯ç®—å­æœ€å¤š 3 æ¬¡å¯¹è¯ä¼šè¯ï¼ˆdialog sessionï¼‰ï¼Œæ¯æ¬¡æœ€å¤š 15 æ¬¡ LLM è°ƒç”¨ã€‚
- **å¹¶è¡Œè§„æ¨¡**ï¼šåœ¨ **200 å°ç”Ÿäº§çº§ MTIA è®¾å¤‡**ä¸Šå¹¶å‘æ‰§è¡Œã€‚

---

### è¯„ä¼°æŒ‡æ ‡
- **ç®—å­è¦†ç›–ç‡ï¼ˆOperator Coverageï¼‰**ï¼šæˆåŠŸé€šè¿‡æ‰€æœ‰å¯¹åº” OpInfo æµ‹è¯•çš„ç®—å­æ¯”ä¾‹ã€‚
- **ç«¯åˆ°ç«¯æ¨¡å‹æ”¯æŒç‡**ï¼šåœ¨å®é™…æ¨¡å‹ï¼ˆNano-GPT, DLRM, Meta Modelsï¼‰ä¸­èƒ½è¢«æ›¿ä»£æ‰§è¡Œçš„ç®—å­å æ¯”ã€‚
- **æ¶ˆèåˆ†æ**ï¼šç§»é™¤å…³é”®ç»„ä»¶ï¼ˆå¦‚ linterã€æ‘˜è¦æ¨¡å—ï¼‰åçš„æ€§èƒ½ä¸‹é™æƒ…å†µã€‚
- **æˆåŠŸç‡åˆ¤å®šæ ‡å‡†**ï¼šç”Ÿæˆçš„ kernel-wrapper å¯¹å¿…é¡»é€šè¿‡ **å…¨éƒ¨ç›¸å…³ OpInfo æµ‹è¯•** æ‰è§†ä¸ºæˆåŠŸã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ–‡ä¸­æœªç›´æ¥ä¸å…¶ä»–å®Œæ•´ç³»ç»Ÿè¿›è¡Œå…¨é¢å¯¹æ¯”ï¼Œä½†æ˜ç¡®æŒ‡å‡ºï¼š
- ä¸åŒäº `KERNELBENCH`ã€`TRITON-BENCH` ç­‰ä»…å…³æ³¨ GPU ä¸Šçš„æ€§èƒ½å¯¼å‘ç”Ÿæˆä»»åŠ¡ï¼›
- åŒºåˆ«äº `AUTOTRITON`ã€`GEAK` ç­‰å¼ºåŒ–å­¦ä¹ æˆ–æœç´¢å¢å¼ºæ–¹æ³•ï¼›
- å¼ºè°ƒè‡ªèº«ä»¥ **åŠŸèƒ½æ­£ç¡®æ€§ä¸å…¨è¦†ç›–ä¸ºç›®æ ‡**ï¼Œè€Œéè¿½æ±‚æè‡´æ€§èƒ½ã€‚

å…¶ä¸»è¦å‚ç…§ç³»ä¸ºâ€œé›¶æ ·æœ¬æç¤ºâ€æˆ–â€œç®€å•æç¤ºå·¥ç¨‹â€çš„å¤±è´¥æ¡ˆä¾‹ï¼Œè¯æ˜ FSM + åé¦ˆæœºåˆ¶çš„å¿…è¦æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- æˆåŠŸç”Ÿæˆå¹¶é€šè¿‡æ‰€æœ‰æµ‹è¯•çš„ ATen ç®—å­æ•°é‡ï¼š**481 ä¸ª**
- åœ¨ 568 ä¸ªå…¼å®¹ç®—å­ä¸­çš„æ€»ä½“è¦†ç›–ç‡ï¼š**84.7%**
- å•æ¬¡å¤§è§„æ¨¡è¿è¡Œå¯åœ¨ **2 å°æ—¶å†…å®Œæˆ 95% çš„ç®—å­ç”Ÿæˆ**
- ç´¯è®¡å¤šæ¬¡è¿è¡Œåå¯è¾¾æ›´é«˜è¦†ç›–ç‡ï¼ˆé€šè¿‡ test-time scalingï¼‰

---

### ä¸åŸºçº¿é…ç½®çš„å¯¹æ¯”ç»“æœ
| é…ç½® | CWM (%) | GPT-OSS (%) |
|------|---------|------------|
| Baselineï¼ˆå®Œæ•´ TritorXï¼‰ | 55.3 | 72.0 |
| ç§»é™¤ Linter | 48.9 â†“ | 68.7 â†“ |
| ç§»é™¤ Summarization æ¨¡å— | 48.2 â†“ | 71.5 â†“ |

> ğŸ” ç»“æœè¡¨æ˜ï¼š**Linter å’Œåé¦ˆæ‘˜è¦æ¨¡å—å¯¹æœ€ç»ˆæ€§èƒ½æœ‰æ˜¾è‘—æ­£å‘å½±å“**ï¼Œå°¤å…¶åœ¨é˜²æ­¢â€œä½œå¼Šâ€å’Œç¼“è§£ä¸Šä¸‹æ–‡æº¢å‡ºæ–¹é¢è‡³å…³é‡è¦ã€‚

---

### æŒ‰ç®—å­ç±»åˆ«åˆ’åˆ†çš„è¦†ç›–ç‡ï¼ˆTable 1ï¼‰
| ç®—å­ç±»åˆ« | ç®—å­æ•° | CWM (%) | GPT-OSS (%) |
|--------|-------|--------|----------|
| Shape Manipulation | 75 | 96.0 | 96.0 |
| Elementwise | 161 | 80.1 | 84.6 |
| Linear Algebra | 78 | 71.8 | 79.5 |
| Reduction | 63 | 69.8 | 74.6 |
| Indexing & Selection | 34 | 73.5 | 79.4 |
| Other | 78 | 75.6 | 74.3 |
| **Deep Learning** | **90** | **64.4** | **71.1** |

> âš ï¸ å‘ç°ï¼š**æ·±åº¦å­¦ä¹ ç±»ç®—å­æœ€éš¾ç”Ÿæˆ**ï¼Œå¯èƒ½å› å…¶é€»è¾‘å¤æ‚ã€ä¾èµ–å¤šæ­¥è°ƒåº¦ã€‚

---

### ç«¯åˆ°ç«¯æ¨¡å‹å¯ç”¨æ•ˆæœï¼ˆTable 2ï¼‰
åœ¨å››ç±»æ¨¡å‹ä¸Šçš„ç®—å­è¦†ç›–æƒ…å†µï¼ˆä½¿ç”¨ç”Ÿäº§æ•°æ®è¾“å…¥æµ‹è¯•ï¼‰ï¼š

| æ¨¡å‹ | OpInfo å­é›†ï¼ˆåˆå§‹ï¼‰ | åŠ å…¥ MIS åé¦ˆåï¼ˆRefinementï¼‰ |
|------|------------------|----------------------------|
| Nano-GPT | 80.0% | **100.0%** |
| DLRM | 80.0% | **90.0%** |
| Meta M1 | 83.8% | **91.9%** |
| Meta M2 | 81.7% | **87.3%** |

> âœ… è¡¨æ˜ï¼šå·²æœ‰ OpInfo éªŒè¯çš„å†…æ ¸åœ¨çœŸå®åœºæ™¯ä¸‹å·²æœ‰è‰¯å¥½æ³›åŒ–èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥å¾®è°ƒå¯å¤§å¹…æå‡æˆåŠŸç‡ã€‚

---

### å…¶ä»–é‡è¦ç»“æœ
- åœ¨ä¸‹ä¸€ä»£ MTIA çš„ QEMU æ¨¡æ‹Ÿå™¨ä¸Šè¿è¡Œ TritorXï¼Œè·å¾— **73.1% è¦†ç›–ç‡**ï¼Œæå‰æš´éœ²ç¼–è¯‘å™¨ä¸ç¡¬ä»¶ç¼ºé™·ï¼Œä¸ºè®¾è®¡æä¾›åé¦ˆã€‚
- é€šè¿‡èšåˆå¤šä¸ªç‹¬ç«‹è¿è¡Œçš„ç»“æœï¼ˆtest-time scalingï¼‰ï¼Œä»…ä¸¤æ¬¡è¿è¡Œå³å¯å°† CWM çš„è¦†ç›–ç‡ä» 55% æå‡è‡³ **64%**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **TritorX å¯å®ç°é«˜è´¨é‡ã€é«˜è¦†ç›–ç‡çš„è‡ªåŠ¨å†…æ ¸ç”Ÿæˆ**ï¼Œåœ¨çœŸå® ASIC ä¸ŠéªŒè¯å¯è¡Œã€‚
2. **FSM æ¶æ„ + å¤šé‡åé¦ˆæœºåˆ¶ï¼ˆlinting, compiling, testing, debuggingï¼‰æ˜¯æˆåŠŸçš„å…³é”®**ï¼Œç›¸æ¯”çº¯ prompt å·¥ç¨‹æ›´é²æ£’ã€‚
3. **Linter æ˜¯é˜²æ­¢â€œä½œå¼Šâ€çš„æ ¸å¿ƒç»„ä»¶**ï¼Œæœ‰æ•ˆé˜»æ­¢éæ³•å‡½æ•°è°ƒç”¨å’Œéæœ¬åœ°åŒ–å®ç°ã€‚
4. **OpInfo æµ‹è¯•é›†æä¾›äº†å¼ºå¤§çš„æ³›åŒ–åŸºç¡€**ï¼Œå¤šæ•°ç”Ÿæˆå†…æ ¸æ— éœ€è°ƒæ•´å³å¯ç”¨äºçœŸå®æ¨¡å‹ã€‚
5. **è¯¥æ–¹æ³•å…·å¤‡å‰ç»æ€§**ï¼šå¯ç”¨äºæœªæ¥èŠ¯ç‰‡çš„æ—©æœŸè½¯ç¡¬ä»¶ååŒè®¾è®¡åé¦ˆã€‚

---

### å±€é™æ€§
1. **æ€§èƒ½æœªä¼˜åŒ–**ï¼šå½“å‰å·¥ä½œåªä¿è¯åŠŸèƒ½æ­£ç¡®ï¼Œä¸ä¿è¯ç”Ÿæˆå†…æ ¸è¾¾åˆ°æœ€ä¼˜æ€§èƒ½ã€‚
2. **éƒ¨åˆ†å¤æ‚ç®—å­ä»éš¾å¤„ç†**ï¼šå°¤å…¶æ˜¯æ¶‰åŠåŠ¨æ€æ§åˆ¶æµæˆ–ç¨€ç–æ“ä½œçš„ Deep Learning ç±»ç®—å­ã€‚
3. **ä¾èµ–é«˜è´¨é‡æµ‹è¯•é›†**ï¼šè‹¥ OpInfo æœªèƒ½å……åˆ†è¦†ç›–è¾¹ç•Œæ¡ä»¶ï¼Œå¯èƒ½å¯¼è‡´æ¼æ£€ã€‚
4. **LLM çš„ä¸ç¡®å®šæ€§**ï¼šè¾“å‡ºå—éšæœºæ€§å½±å“ï¼Œéœ€å¤šæ¬¡è¿è¡Œæ‰èƒ½ç¨³å®šæå‡è¦†ç›–ç‡ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥è‡ªæ´½ç”Ÿæˆæœºåˆ¶**ï¼šå…è®¸ wrapper è°ƒç”¨å·²å®ç°çš„å…¶ä»–ç®—å­ï¼Œæå‡æ•ˆç‡ä¸æ€§èƒ½ã€‚
2. **Prompt ä¼˜åŒ–ä¸æœ¬åœ°åŒ–å¢å¼º**ï¼šåˆ©ç”¨å†å²æˆåŠŸæ¡ˆä¾‹è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆin-context learningï¼‰ã€‚
3. **å…¨ä»£ç†åŒ– Pipeline**ï¼šè®© LLM è‡ªä¸»è°ƒç”¨å·¥å…·ï¼ˆå¦‚è°ƒè¯•å™¨ã€ç¼–è¯‘å™¨æ—¥å¿—åˆ†æå™¨ï¼‰ã€‚
4. **ä¸“ç”¨æ¨¡å‹åè®­ç»ƒ**ï¼šå¯¹ LLM è¿›è¡Œ Triton MTIA ç‰¹å®šé¢†åŸŸçš„å¾®è°ƒã€‚
5. **Test-Time Scaling ä¸è¿›åŒ–ç­–ç•¥**ï¼šæ¢ç´¢æ›´é«˜æ•ˆçš„é›†æˆä¸æœç´¢æœºåˆ¶ä»¥è¿›ä¸€æ­¥æé«˜è¦†ç›–ç‡ã€‚
6. **å»ºç«‹å…¨è‡ªåŠ¨åç«¯ç»´æŠ¤ç¯å¢ƒ**ï¼šåº”å¯¹æœªæ¥å¤šä»£ç¡¬ä»¶å…±å­˜ä¸‹çš„ Kernel Library è‡ªåŠ¨æ›´æ–°éœ€æ±‚ã€‚

---

## æ€»ç»“
TritorX æä¾›äº†ä¸€ä¸ª **å®ç”¨ã€å¯æ‰©å±•ã€é¢å‘æœªæ¥çš„ PyTorch åç«¯è‡ªåŠ¨åŒ–æ„å»ºè“å›¾**ã€‚å®ƒä¸ä»…è§£å†³äº†å½“å‰ ML ASIC è½¯ä»¶æ ˆå»ºè®¾çš„ç“¶é¢ˆé—®é¢˜ï¼Œä¹Ÿä¸º AI é©±åŠ¨çš„ç¼–è¯‘å™¨ä¸ç¡¬ä»¶ååŒè®¾è®¡å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚å…¶æ ¸å¿ƒæ€æƒ³â€”â€”**ä»¥è¦†ç›–ç‡ä¸ºç›®æ ‡ã€ä»¥åé¦ˆä¸ºé©±åŠ¨ã€ä»¥ç”Ÿäº§ç¯å¢ƒä¸ºéªŒè¯åœº**â€”â€”å…·æœ‰å¹¿æ³›æ¨å¹¿ä»·å€¼ã€‚

</details>

---

### 13. [Enhanced Pruning for Distributed Closeness Centrality under Multi-Packet Messaging](https://arxiv.org/abs/2512.11512)

**Authors**: Patrick D. Manya, Eugene M. Mbuyi, Gothy T. Ngoie, Jordan F. Masakuna  
**Category**: cs.DC  
**Published**: 2025-12-15  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.11512v1  

#### Abstract
Identifying central nodes using closeness centrality is a critical task in analyzing large-scale complex networks, yet its decentralized computation remains challenging due to high communication overhead. Existing distributed approximation techniques, such as pruning, often fail to fully mitigate th...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
åœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼ç½‘ç»œä¸­ï¼Œ**Closeness Centrality**ï¼ˆæ¥è¿‘ä¸­å¿ƒæ€§ï¼‰æ˜¯è¯†åˆ«å…³é”®èŠ‚ç‚¹çš„é‡è¦æŒ‡æ ‡ï¼Œä½†å…¶å»ä¸­å¿ƒåŒ–è®¡ç®—é¢ä¸´ä¸¥é‡çš„é€šä¿¡å¼€é”€é—®é¢˜ã€‚ç°æœ‰çš„åˆ†å¸ƒå¼è¿‘ä¼¼æ–¹æ³•ï¼ˆå¦‚ **pruning**ï¼‰è™½ç„¶èƒ½å‡å°‘éƒ¨åˆ†é€šä¿¡é‡ï¼Œä½†åœ¨é«˜ååã€å¤šåŒ…ä¼ è¾“ï¼ˆmulti-packet messagingï¼‰ç¯å¢ƒä¸‹ä»å­˜åœ¨å¤§é‡æ¶ˆæ¯äº¤æ¢ï¼Œå¯¼è‡´é€šä¿¡ç“¶é¢ˆã€‚

ç‰¹åˆ«æ˜¯å½“é‡‡ç”¨ **multi-packet messaging** æ¥ä¼ è¾“å¤§å—æ•°æ®æ—¶ï¼Œå°½ç®¡æå‡äº†å¸¦å®½åˆ©ç”¨ç‡å’ŒæŠ—ä¸¢åŒ…èƒ½åŠ›ï¼Œä½†ä¹Ÿæ˜¾è‘—å¢åŠ äº†æ€»æ¶ˆæ¯æ•°é‡ï¼ŒåŠ å‰§äº†ç½‘ç»œæ‹¥å¡å’Œå»¶è¿Ÿã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ç§**å¢å¼ºå‹åˆ†å¸ƒå¼å‰ªææ–¹æ³•**ï¼ˆEnhanced Pruningï¼‰ï¼Œé€šè¿‡ä»¥ä¸‹åˆ›æ–°æœºåˆ¶åº”å¯¹ä¸Šè¿°æŒ‘æˆ˜ï¼š

- **å¼•å…¥ multi-packet messaging æ¶æ„**ï¼šå°†å•ä¸ªæ¶ˆæ¯æ‹†åˆ†ä¸ºå¤šä¸ªæ•°æ®åŒ…è¿›è¡Œä¼ è¾“ï¼Œæå‡å¤§å®¹é‡æ•°æ®ä¼ è¾“çš„å¯é æ€§ä¸æ•ˆç‡ã€‚
- **ä¼˜åŒ–å‰ªæç­–ç•¥ä»¥å‡å°‘é€šä¿¡è´Ÿè½½**ï¼šæ”¹è¿›åŸå§‹ pruning æ–¹æ³•ï¼Œä½¿æŸäº›èŠ‚ç‚¹ï¼ˆå¦‚å¶å­èŠ‚ç‚¹ï¼‰åœ¨æ•´ä¸ªé€šä¿¡é˜¶æ®µä¸å†å‘é€ä»»ä½•æ¶ˆæ¯ï¼Œä»è€Œå‡å°‘æ•´ä½“æ¶ˆæ¯æ•°ã€‚
- **é‡‡ç”¨æ»‘åŠ¨çª—å£åè®®ï¼ˆGo-Back-N ARQï¼‰**ï¼šç”¨äº multi-packet ä¼ è¾“ä¸­çš„å¯é äº¤ä»˜ï¼Œåœ¨ä½è¯¯ç ç‡ç¯å¢ƒä¸­å®ç°é«˜æ•ˆé‡ä¼ æœºåˆ¶ã€‚
- **è®¾è®¡é€šä¿¡è¿‡è½½é™åˆ¶æœºåˆ¶**ï¼šå¯¹å¯å‰ªæèŠ‚ç‚¹æ–½åŠ é€šä¿¡é™åˆ¶ï¼Œé™ä½éä¸­å¿ƒèŠ‚ç‚¹çš„æ¶ˆæ¯è´Ÿæ‹…ï¼ŒåŒæ—¶ä¿æŒä¼°è®¡ç²¾åº¦ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- æ˜¾è‘—å‡å°‘äº†**æ€»æ¶ˆæ¯æ•°é‡**ï¼ˆå¹³å‡å‡å°‘ 5%-15%ï¼‰ï¼Œå°¤å…¶é€‚ç”¨äºå¤§å‹ç½‘ç»œã€‚
- åœ¨ä¸ç‰ºç‰²ä¼°è®¡å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œå¤§å¹…æå‡äº†**é€šä¿¡æ•ˆç‡**å’Œ**è¿è¡Œé€Ÿåº¦**ã€‚
- èƒ½æœ‰æ•ˆç¼“è§£ multi-packet messaging å¸¦æ¥çš„é¢å¤–é€šä¿¡è´Ÿæ‹…ï¼Œé¿å…å› åˆ†åŒ…å¯¼è‡´çš„æ¶ˆæ¯çˆ†ç‚¸ã€‚
- æ”¯æŒå¼‚æ„ç½‘ç»œæ‹“æ‰‘å’ŒçœŸå®ä¸–ç•Œå¤æ‚å›¾ç»“æ„ï¼Œå…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å®éªŒåœ¨ä¸¤ç±»ç½‘ç»œä¸Šè¿›è¡Œï¼š

- **éšæœºç”Ÿæˆç½‘ç»œ**ï¼š
  - å…± 100 ä¸ªè¿é€šæ— å‘å›¾ï¼ŒèŠ‚ç‚¹æ•° $ N \in [100, 2000] $
  - åŸºäº 250Ã—250 ç½‘æ ¼å¸ƒå±€ï¼Œæ¬§æ°è·ç¦»å°äºé€šä¿¡èŒƒå›´ $ d=10 $ çš„èŠ‚ç‚¹ç›¸è¿
  - å›¾ç›´å¾„åˆ†å¸ƒåœ¨ [30, 68] åŒºé—´

- **çœŸå®ä¸–ç•Œç½‘ç»œ**ï¼ˆå…± 35 ä¸ªï¼‰ï¼š
  - **Facebook artist network**ï¼ˆè‰ºæœ¯å®¶ç¤¾äº¤å…³ç³»ï¼‰
  - **Phenomenology collaboration network**ï¼ˆé«˜èƒ½ç‰©ç†åˆä½œç½‘ç»œï¼‰
  - **Gnutella peer-to-peer network**ï¼ˆP2P æ–‡ä»¶å…±äº«ç½‘ç»œï¼‰
  - **32 ä¸ª Autonomous System graphs**ï¼ˆäº’è”ç½‘è·¯ç”±ç³»ç»Ÿå›¾ï¼‰

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **å‚æ•°é…ç½®**
- æœ€å¤§è¿­ä»£æ¬¡æ•° $ D $ å°äºå›¾ç›´å¾„
- multi-packet åˆ†åŒ…æ•° $ m \in \{1, 10, 20, 30, 50\} $
- ä½¿ç”¨ **NetworkX** æ„å»ºå›¾ç»“æ„ï¼Œ**Pympler** æµ‹é‡å†…å­˜ï¼Œ**Timer** æ¨¡å—è®°å½•æ—¶é—´

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| `Average/Max number of messages` | æ¯èŠ‚ç‚¹å¹³å‡/æœ€å¤§å‘é€æ¶ˆæ¯æ•° |
| `Running time` | ç®—æ³•æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰ |
| `Data loss rate` | æ•°æ®åŒ…ä¸¢å¤±ç™¾åˆ†æ¯” |
| `Memory usage` | èŠ‚ç‚¹æœ¬åœ°å†…å­˜å ç”¨ |
| `Closeness centrality quality` | è¿‘ä¼¼æœ€ä¸­å¿ƒèŠ‚ç‚¹ä¸çœŸå®æœ€ä¸­å¿ƒèŠ‚ç‚¹ä¹‹é—´çš„æœ€çŸ­è·¯å¾„è·ç¦» |
| `Statistical significance` | ä½¿ç”¨ Wilcoxon signed-rank test å’Œ effect size éªŒè¯å·®å¼‚ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Baseline**: åŸå§‹ pruning æ–¹æ³•ï¼ˆæ¥è‡ª Masakuna et al. [22]ï¼‰
- **Proposed**: æœ¬æ–‡æå‡ºçš„ enhanced pruning + multi-packet messaging ä¼˜åŒ–æ–¹æ¡ˆ

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **é€šä¿¡æ•ˆç‡æå‡**
- åœ¨æ‰€æœ‰æµ‹è¯•å›¾ä¸­ï¼ˆå…± 135 ä¸ªï¼‰ï¼Œæ‰€ææ–¹æ³•å°†æ¯èŠ‚ç‚¹**å¹³å‡æ¶ˆæ¯æ•°å‡å°‘ 5%â€“15%**ã€‚
- å¯¹äºæœ€å¤§æ¶ˆæ¯æ•°ï¼ˆmax messages per nodeï¼‰ï¼Œä¼˜åŒ–æ•ˆæœæ›´æ˜æ˜¾ï¼Œå°¤å…¶åœ¨é«˜ $ m $ åœºæ™¯ä¸‹ï¼ˆå¦‚ $ m=50 $ï¼‰ã€‚
- å¦‚å›¾ 5 å’Œå›¾ 6 æ‰€ç¤ºï¼Œéšç€åˆ†åŒ…æ•°å¢åŠ ï¼Œä¼˜åŠ¿æ›´åŠ çªå‡ºã€‚

#### **è¿è¡Œæ—¶é—´å’Œæ•°æ®ä¸¢å¤±**
- ä½¿ç”¨ multi-packet messaging åï¼š
  - å½“ $ m=50 $ æ—¶ï¼Œ**è¿è¡Œæ—¶é—´ä¸‹é™çº¦ 30%**ï¼Œ**æ•°æ®ä¸¢å¤±ç‡é™ä½è‡³æ¥è¿‘ 0%**
  - å•åŒ…ä¼ è¾“ï¼ˆ$ m=1 $ï¼‰æ˜“å‘ç”Ÿæ‹¥å¡å’Œä¸¢åŒ…ï¼Œæ€§èƒ½è¾ƒå·®
- å›¾ 3 æ˜¾ç¤ºï¼šéšç€ $ m $ å¢åŠ ï¼Œç³»ç»Ÿå»¶è¿Ÿæ›´ä½ï¼Œç¨³å®šæ€§æ›´é«˜

#### **å†…å­˜ä¸æœ¬åœ°å¼€é”€**
- æ¯èŠ‚ç‚¹å†…å­˜ä½¿ç”¨ç•¥æœ‰ä¸Šå‡ï¼ˆè§å›¾ 4ï¼‰ï¼Œä¸»è¦ç”±äºç¼“å­˜å¤šä¸ªæ•°æ®åŒ…åŠæ»‘åŠ¨çª—å£ç¼“å†²åŒº
- å±€éƒ¨å¤„ç†å¼€é”€å¢åŠ çº¦ 10%-15%ï¼Œä½†è¢«é€šä¿¡èŠ‚çœæ‰€æŠµæ¶ˆï¼Œæ€»ä½“æ€§ä»·æ¯”é«˜

#### **ä¸­å¿ƒæ€§ä¼°è®¡è´¨é‡**
- è¡¨ II æ˜¾ç¤ºï¼šåœ¨ä¸åŒ $ D $ è®¾ç½®ä¸‹ï¼Œæœ¬æ–‡æ–¹æ³•ä¸åŸå§‹ pruning æ–¹æ³•é€‰å‡ºçš„â€œæœ€ä¸­å¿ƒèŠ‚ç‚¹â€å®Œå…¨ä¸€è‡´
- ä¸¤è€…åˆ°çœŸå®æœ€ä¸­å¿ƒèŠ‚ç‚¹çš„æœ€çŸ­è·¯å¾„è·ç¦»ç›¸åŒï¼Œè¯´æ˜**ç²¾åº¦æœªå—æŸ**
- ç‰¹åˆ«æ˜¯åœ¨ $ D \geq 14 $ æ—¶ï¼Œè¯¯å·®ä¸º 0ï¼Œè¡¨æ˜æ”¶æ•›è‰¯å¥½

#### **ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼ˆè¡¨ IIIï¼‰**
| æŒ‡æ ‡ | p-value | Effect Size |
|------|--------|------------|
| æ¶ˆæ¯æ•°é‡ | 0.0625 | 0.586ï¼ˆmediumï¼‰ |
| è¿è¡Œæ—¶é—´ | 0.0876 | 0.437ï¼ˆmediumï¼‰ |
| ä¸­å¿ƒæ€§è´¨é‡ | ~0 | 0 |

> æ³¨ï¼šè™½ç„¶ p-value > 0.01ï¼ˆæœªè¾¾ä¼ ç»Ÿæ˜¾è‘—æ°´å¹³ï¼‰ï¼Œä½† **effect size è¾¾åˆ°ä¸­ç­‰æ°´å¹³**ï¼Œè¯´æ˜å®é™…æ€§èƒ½å·®å¼‚å…·æœ‰æ„ä¹‰ï¼›è€Œä¸­å¿ƒæ€§è´¨é‡çš„ pâ‰ˆ0ï¼Œè¯æ˜å‡†ç¡®æ€§é«˜åº¦ä¸€è‡´ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **multi-packet messaging æ˜¯å¿…è¦çš„**ï¼šåœ¨å¸¦å®½å—é™æˆ–å¤§æ•°æ®ä¼ è¾“åœºæ™¯ä¸‹ï¼Œèƒ½æ˜¾è‘—é™ä½ä¸¢åŒ…ç‡å¹¶æå‡ååã€‚
2. **åŸå§‹ pruning æ–¹æ³•åœ¨ multi-packet ä¸‹ä¼šæ¶åŒ–é€šä¿¡å¼€é”€**ï¼šè‹¥ä¸åŠ ä»¥ä¼˜åŒ–ï¼Œåˆ†åŒ…åè€Œå¢åŠ æ€»æ¶ˆæ¯æ•°ã€‚
3. **æœ¬æ–‡æå‡ºçš„å¢å¼º pruning æˆåŠŸé€†è½¬è¿™ä¸€è¶‹åŠ¿**ï¼šé€šè¿‡å‡å°‘å†—ä½™é€šä¿¡ï¼ˆå¦‚ç¦æ­¢å¶å­èŠ‚ç‚¹å‘æ¶ˆæ¯ï¼‰ï¼Œå®ç°äº†æ›´é«˜çš„é€šä¿¡æ•ˆç‡ã€‚
4. **ä¼°è®¡ç²¾åº¦å¾—ä»¥ä¿ç•™**ï¼šå³ä½¿åœ¨æç«¯å‰ªææ¡ä»¶ä¸‹ï¼Œæœ€ä¸­å¿ƒèŠ‚ç‚¹çš„é€‰æ‹©ä¸åŸæ–¹æ³•å®Œå…¨ä¸€è‡´ã€‚
5. **trade-off å¯æ¥å—**ï¼šå°å¹…å¢åŠ çš„å†…å­˜å’Œæœ¬åœ°è®¡ç®—ä»£ä»·ï¼Œè¿œå°äºé€šä¿¡æˆæœ¬çš„èŠ‚çº¦ï¼Œå°¤å…¶é€‚åˆå¤§è§„æ¨¡ç½‘ç»œã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å‡è®¾èŠ‚ç‚¹ä¸ä¼šåœ¨ç®—æ³•åˆæœŸå¤±æ•ˆï¼ˆå¦åˆ™é‚»å±…æ— æ³•æ„ŸçŸ¥å…¶çŠ¶æ€ï¼‰
- ä¾èµ– FIFOã€åŒå‘å¼‚æ­¥é€šä¿¡æ¨¡å‹ï¼Œåœ¨éƒ¨åˆ†æ— çº¿ç½‘ç»œä¸­å¯èƒ½éš¾ä»¥æ»¡è¶³
- å½“ $ m $ è¿‡å¤§æ—¶ï¼Œæ»‘åŠ¨çª—å£æœºåˆ¶å¯èƒ½å¯¼è‡´çŸ­æš‚é˜»å¡ï¼Œéœ€è¿›ä¸€æ­¥è°ƒä¼˜

### **æœªæ¥å·¥ä½œæ–¹å‘**
- å°†è¯¥æ–¹æ³•æ‰©å±•è‡³å…¶ä»– centrality æŒ‡æ ‡ï¼ˆå¦‚ Betweennessã€Eigenvectorï¼‰
- åœ¨ç§»åŠ¨ä¼ æ„Ÿå™¨ç½‘ç»œã€ç¤¾äº¤ç½‘ç»œåˆ†æç­‰çœŸå®åœºæ™¯ä¸­éƒ¨ç½²éªŒè¯
- æ¢ç´¢åŠ¨æ€ç½‘ç»œä¸‹çš„è‡ªé€‚åº” pruning ç­–ç•¥
- ç»“åˆæœºå™¨å­¦ä¹ é¢„æµ‹æ½œåœ¨å¯å‰ªæèŠ‚ç‚¹ï¼Œè¿›ä¸€æ­¥æå‰ç»ˆæ­¢é€šä¿¡

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é€šè¿‡èåˆ **multi-packet messaging** ä¸ **enhanced pruning**ï¼Œåœ¨ä¸æŸå¤± Closeness Centrality ä¼°è®¡ç²¾åº¦çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½äº†åˆ†å¸ƒå¼è®¡ç®—ä¸­çš„é€šä¿¡å¼€é”€ï¼Œä¸ºå¤§è§„æ¨¡ç½‘ç»œçš„å»ä¸­å¿ƒåŒ–åˆ†ææä¾›äº†æ›´å…·å¯æ‰©å±•æ€§çš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 14. [Refining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee](https://arxiv.org/abs/2512.11127)

**Authors**: Kshitiz Khanal  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.11127v1  

#### Abstract
The DC Optimal Power Flow (DC-OPF) problem is fundamental to power system operations, requiring rapid solutions for real-time grid management. While traditional optimization solvers provide optimal solutions, their computational cost becomes prohibitive for large-scale systems requiring frequent rec...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRefining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **Optimal Power Flow (OPF)** æ±‚è§£å™¨ï¼ˆå¦‚ SLSQPï¼‰è™½ç„¶èƒ½æä¾›æœ€ä¼˜è§£ï¼Œä½†åœ¨å¤§è§„æ¨¡ç³»ç»Ÿä¸­è®¡ç®—è€—æ—¶è¾ƒé•¿ï¼Œéš¾ä»¥æ»¡è¶³ç°ä»£ç”µç½‘é«˜é¢‘æ¬¡è°ƒåº¦éœ€æ±‚ï¼ˆå¦‚é«˜æ¯”ä¾‹å¯å†ç”Ÿèƒ½æºæ¥å…¥åœºæ™¯ï¼‰ã€‚è€Œç°æœ‰çš„ **Machine Learning (ML)** æ–¹æ³•è™½é€Ÿåº¦å¿«ï¼Œä½†å¸¸é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **Constraint Violation**ï¼šç¥ç»ç½‘ç»œè¾“å‡ºä¸ä¿è¯æ»¡è¶³ç‰©ç†çº¦æŸï¼ˆå¦‚åŠŸç‡å¹³è¡¡ã€çº¿è·¯å®¹é‡é™åˆ¶ç­‰ï¼‰ï¼›
- **Optimality Gap**ï¼šé¢„æµ‹è§£ä¸çœŸå®æœ€ä¼˜è§£å­˜åœ¨æ˜¾è‘—æˆæœ¬å·®è·ã€‚

æœ¬æ–‡èšç„¦äº **DC-OPF** é—®é¢˜ï¼Œæ—¨åœ¨å®ç°**å¿«é€Ÿã€å¯è¡Œä¸”æ¥è¿‘æœ€ä¼˜**çš„ç”µåŠ›è°ƒåº¦é¢„æµ‹ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§**ä¸¤é˜¶æ®µå­¦ä¹ æ¡†æ¶**ï¼Œç»“åˆ **Physics-Informed Graph Neural Networks (GNNs)** å’Œ **Continuous Flow Matching (CFM)**ï¼š

#### ï¼ˆ1ï¼‰Stage 1: Physics-Informed GNN
- åˆ©ç”¨å›¾ç»“æ„å»ºæ¨¡ç”µç½‘æ‹“æ‰‘ï¼ˆèŠ‚ç‚¹ä¸ºæ¯çº¿ï¼Œè¾¹ä¸ºè¾“ç”µçº¿è·¯ï¼‰ï¼Œé€šè¿‡ **GCN** å±‚æå–ç‰¹å¾ï¼›
- è®¾è®¡**å¤šç›®æ ‡ç‰©ç†å¼•å¯¼æŸå¤±å‡½æ•°**ï¼Œå°†ä»¥ä¸‹å…ˆéªŒçŸ¥è¯†åµŒå…¥è®­ç»ƒè¿‡ç¨‹ï¼š
  - **ç»æµè°ƒåº¦åŸåˆ™**ï¼ˆè¾¹é™…æˆæœ¬ç›¸ç­‰ï¼‰
  - **åŸºå°”éœå¤«å®šå¾‹**ï¼ˆåŠŸç‡å¹³è¡¡ï¼‰
  - **å‘ç”µæœºä¸Šä¸‹é™çº¦æŸ**
  - **KKTäº’è¡¥æ¡ä»¶**ï¼ˆè¯†åˆ«æ´»è·ƒçº¦æŸï¼‰
- å¼•å…¥**è½¯æŠ•å½±å±‚**ï¼ˆSoft Projectionï¼‰ç”¨äºè®­ç»ƒæœŸé—´æ¢¯åº¦ä¼ æ’­ï¼Œä»¥åŠ**ç¡¬æŠ•å½±ç®—æ³•**ï¼ˆHard Projectionï¼‰ç¡®ä¿æ¨ç†æ—¶ä¸¥æ ¼å¯è¡Œæ€§ã€‚

#### ï¼ˆ2ï¼‰Stage 2: Continuous Flow Matching Refinement
- ä½¿ç”¨ **CFM** å¯¹ GNN è¾“å‡ºçš„åˆå§‹å¯è¡Œè§£è¿›è¡Œä¼˜åŒ–ç²¾ç‚¼ï¼›
- å°†â€œä»å¯è¡Œè§£åˆ°æœ€ä¼˜è§£â€çš„æ˜ å°„è§†ä¸ºä¸€ä¸ª**æ¡ä»¶ç”Ÿæˆè¿‡ç¨‹**ï¼Œé€šè¿‡å­¦ä¹ å‘é‡åœº $v(p_g(t))$ æ¥é©±åŠ¨ ODE ç§¯åˆ†è·¯å¾„ï¼š
  $$
  \frac{dp_g(t)}{dt} = v(p_g(t)),\quad p_g(0) = p_g^{(0)},\quad p_g(1) \approx p_g^*
  $$
- é‡‡ç”¨çº¿æ€§æ’å€¼è·¯å¾„æ„å»ºæ¦‚ç‡æµï¼Œé¿å…ä¼ ç»Ÿ CNF ä¸­æ˜‚è´µçš„ ODE åå‘ä¼ æ’­ï¼›
- åœ¨ CFM è®­ç»ƒä¸­å¼•å…¥**æ¸è¿›å¼è¯¾ç¨‹å­¦ä¹ **ï¼ˆcurriculum learningï¼‰ï¼ŒåŠ¨æ€è°ƒæ•´å„æŸå¤±æƒé‡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å¯è¡Œæ€§ä¿éšœ** | é€šè¿‡ç‰©ç†å¼•å¯¼æŸå¤± + æŠ•å½±æœºåˆ¶ï¼Œå®ç° **100% çº¦æŸæ»¡è¶³ç‡**ï¼Œä¼˜äºæ™®é€š ML æ–¹æ³• |
| **æ¥è¿‘æœ€ä¼˜æ€§** | æˆæœ¬å·®è·æå°ï¼ˆ<0.1% @ nominal loadï¼‰ï¼Œè¿œä¼˜äºä»…ä½¿ç”¨ GNN çš„åŸºçº¿ |
| **æ³›åŒ–èƒ½åŠ›** | åœ¨è®­ç»ƒèŒƒå›´å¤–çš„æç«¯è´Ÿè·åœºæ™¯ä¸‹ä»ä¿æŒé²æ£’æ€§èƒ½ï¼ˆgap < 3%ï¼‰ |
| **è®­ç»ƒæ•ˆç‡** | CFM æ— éœ€åå‘ODEæ±‚è§£ï¼Œæ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼Œæå‡è®­ç»ƒé€Ÿåº¦ |
| **ç»“æ„åˆç†æ€§** | åˆ†é˜¶æ®µè®¾è®¡ï¼šGNN è´Ÿè´£â€œå¯è¡Œæ€§â€ï¼ŒCFM è´Ÿè´£â€œæœ€ä¼˜æ€§â€ï¼ŒèŒè´£åˆ†ç¦»æ›´é«˜æ•ˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **IEEE 30-bus system**ï¼šæ ‡å‡†æµ‹è¯•ç³»ç»Ÿï¼ŒåŒ…å« 30 ä¸ªæ¯çº¿ã€6 å°å‘ç”µæœºã€41 æ¡çº¿è·¯ã€‚
- å‘ç”µæœºå‚æ•°è§åŸæ–‡ Table Iï¼Œå…·æœ‰ä¸åŒæˆæœ¬æ›²çº¿å’Œå‡ºåŠ›é™å€¼ã€‚

### æ•°æ®ç”Ÿæˆ
- éšæœºé‡‡æ ·è´Ÿè½½æ°´å¹³åœ¨ **70%â€“100%** åŸºå‡†è´Ÿè·ä¹‹é—´ï¼Œå…±ç”Ÿæˆ **20,000 ä¸ªè®­ç»ƒæ ·æœ¬**ï¼›
- ä½¿ç”¨ **SLSQP æ±‚è§£å™¨** è·å–æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„æœ€ä¼˜è°ƒåº¦æ–¹æ¡ˆä½œä¸ºæ ‡ç­¾ã€‚

### å®éªŒè®¾ç½®
- **Stage 1 GNN è®­ç»ƒ**ï¼š
  - 40 epochsï¼ŒAdam ä¼˜åŒ–å™¨ï¼Œlr=1e-5
  - 2 å±‚ GCNï¼ˆhidden dim=128ï¼‰ï¼ŒMLP è¾“å‡ºè°ƒåº¦
- **Stage 2 CFM è®­ç»ƒ**ï¼š
  - 100 epochsï¼ŒAdamWï¼Œlr=3e-3ï¼Œä½™å¼¦é€€ç«
  - GNN å‚æ•°å†»ç»“ï¼Œä»…è®­ç»ƒ ResNet æ„æˆçš„å‘é‡åœºæ¨¡å‹
  - æ—¶é—´åµŒå…¥ç»´åº¦ï¼š64ï¼ˆ32 å¯¹ sin/cosï¼‰
  - ODE æ­¥æ•°ï¼šè®­ç»ƒ 20 æ­¥ï¼Œæ¨ç† 30 æ­¥

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Cost Gap (%)** | $\frac{C(\hat{p}_g) - C(p^*)}{C(p^*)} \times 100\%$ |
| **Feasibility Rate (%)** | æ‰€æœ‰çº¦æŸæ»¡è¶³çš„æ¯”ä¾‹ï¼ˆå®¹å¿è¯¯å·® Îµ=0.1 MWï¼‰ |
| **Worst-Case Gap (%)** | æµ‹è¯•é›†ä¸­æœ€å¤§æˆæœ¬å·®è· |
| **Inference Time** | å•æ¬¡å‰å‘æ¨ç†æ—¶é—´ï¼ˆæœªè¯¦ç»†æŠ¥å‘Šæ•°å€¼ï¼Œå¼ºè°ƒâ€œè¿œå¿«äºä¼ ç»Ÿæ±‚è§£å™¨â€ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **SLSQP Solver** | æ•°å€¼ä¼˜åŒ–åŸºå‡†ï¼ˆæœ€ä¼˜è§£ï¼‰ |
| **GNN Only** | ä»… Stage 1 è¾“å‡ºï¼Œæ—  CFM ç²¾ç‚¼ |
| **CFM Refined** | æœ¬æ–‡å®Œæ•´ä¸¤é˜¶æ®µæ–¹æ³• |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ€§èƒ½æ±‡æ€»ï¼ˆTable II & IIIï¼‰

| åœºæ™¯ | æœ€ä¼˜æˆæœ¬ ($, meanÂ±std) | GNN æˆæœ¬ ($) | GNN Gap (%) | **CFM æˆæœ¬ ($)** | **CFM Gap (%)** | **CFM Feas. (%)** | **Worst Gap (%)** |
|-------|------------------------|---------------|--------------|--------------------|------------------|---------------------|---------------------|
| Very Low (70â€“75%) | 490.24Â±10.32 | 528.80 | 7.86 | **490.39** | **0.03** | **100.0** | **0.04** |
| Low (83â€“88%) | 588.10Â±10.68 | 644.52 | 9.60 | **588.39** | **0.05** | **100.0** | **0.05** |
| Nominal (95â€“100%) | 680.75Â±11.44 | 754.10 | 10.78 | **681.20** | **0.07** | **100.0** | **0.16** |
| High (110â€“115%) | 823.24Â±14.68 | 901.26 | 9.48 | **844.59** | **2.59** | **100.0** | **3.60** |
| Very High (125â€“130%) | 982.93Â±16.11 | 1053.40 | 7.17 | **1010.88** | **2.84** | **100.0** | **3.15** |

### CFM ç²¾ç‚¼å¸¦æ¥çš„æ”¹è¿›ï¼ˆTable IIIï¼‰

| åœºæ™¯ | æˆæœ¬é™ä½ (%) | Gap ç¼©å‡ (p.p.) |
|-------|---------------|------------------|
| Very Low | 7.26 | 7.83 |
| Low | 8.71 | 9.55 |
| Nominal | **9.67** | **10.71** |
| High | 6.29 | 6.89 |
| Very High | 4.04 | 4.33 |

> âœ… **å…³é”®è§‚å¯Ÿ**ï¼šCFM åœ¨è®­ç»ƒåˆ†å¸ƒå†…ï¼ˆnominal loadï¼‰å¸¦æ¥æœ€å¤§æå‡ï¼Œå³ä½¿åœ¨æç«¯è´Ÿè½½ä¸‹ä¹Ÿèƒ½ç¨³å®šæ”¹å–„ç»æµæ€§ã€‚

---

### æ¶ˆèåˆ†æä¸è®­ç»ƒåŠ¨æ€
- **éå•è°ƒæ”¶æ•›è¡Œä¸º**ï¼ˆå›¾3ï¼‰ï¼š
  - åˆæœŸä½ä¼°æˆæœ¬ï¼ˆ-21% gapï¼‰ï¼Œéšåè¢«æƒ©ç½šé¡¹çº æ­£è‡³ +15%ï¼Œæœ€ç»ˆæ”¶æ•›è‡³ ~3%
  - è¡¨æ˜ **flow matching** ä¸ **cost-aware loss** å­˜åœ¨åšå¼ˆï¼Œè¯¾ç¨‹å­¦ä¹ æœ‰æ•ˆå¼•å¯¼å¹³è¡¡
- **ä¸‰é˜¶æ®µ curriculum learning** æ˜¾è‘—æå‡ç¨³å®šæ€§ä¸æ³›åŒ–èƒ½åŠ›
- **ç¡¬æŠ•å½±æœºåˆ¶** æ˜¯å®ç° 100% å¯è¡Œæ€§çš„å…³é”®ç»„ä»¶

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç‰©ç†å…ˆéªŒæ˜¯æ³›åŒ–çš„åŸºçŸ³**ï¼š
   - ç»æµè°ƒåº¦æŸå¤±ï¼ˆmarginal cost equalityï¼‰ã€KKT æ¡ä»¶ç­‰ä½œä¸ºå½’çº³åç½®ï¼Œä½¿æ¨¡å‹èƒ½åœ¨ **70%â€“130%** è´Ÿè·èŒƒå›´å†…ä¿æŒè‰¯å¥½è¡¨ç°ï¼ŒåŒ…æ‹¬è®­ç»ƒèŒƒå›´ä¹‹å¤–ã€‚
   
2. **ä¸¤é˜¶æ®µæ¶æ„è®¾è®¡åˆç†**ï¼š
   - GNN è´Ÿè´£å¿«é€Ÿç”Ÿæˆ**å¯è¡Œåˆå€¼**ï¼ŒCFM è´Ÿè´£æ²¿ç‰©ç†ä¸€è‡´è·¯å¾„å‘æœ€ä¼˜è§£é€¼è¿‘ï¼›
   - åˆ†å·¥æ˜ç¡®ï¼Œé¿å…ç«¯åˆ°ç«¯è®­ç»ƒä¸­çš„å†²çªä¼˜åŒ–ç›®æ ‡ã€‚

3. **CFM é€‚ç”¨äºä¼˜åŒ–é—®é¢˜ç²¾ç‚¼**ï¼š
   - é¦–æ¬¡å°† **Continuous Flow Matching** åº”ç”¨äº OPF è¿™ç±»**çº¦æŸä¼˜åŒ–ä»»åŠ¡**ï¼›
   - è¯æ˜å…¶ä¸ä»…èƒ½ç”¨äºå›¾åƒ/åˆ†å­ç”Ÿæˆï¼Œä¹Ÿå¯ç”¨äºâ€œä»å¯è¡Œåˆ°æœ€ä¼˜â€çš„ç¡®å®šæ€§è½¨è¿¹å­¦ä¹ ã€‚

4. **æ¥è¿‘ä¼ ç»Ÿæ±‚è§£å™¨è´¨é‡ï¼Œå…·å¤‡å®æ—¶åº”ç”¨æ½œåŠ›**ï¼š
   - åœ¨å…¸å‹è¿è¡Œæ¡ä»¶ä¸‹ï¼ˆnominal loadï¼‰ï¼Œæˆæœ¬å·®è·ä½è‡³ **0.07%**ï¼Œä¸”å§‹ç»ˆå¯è¡Œï¼›
   - æ¨ç†ä¸ºå‰å‘ä¼ æ’­ + ODE ç§¯åˆ†ï¼Œé€‚åˆéƒ¨ç½²äºé«˜é¢‘è°ƒåº¦åœºæ™¯ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä»…éªŒè¯äºå°å‹ç³»ç»Ÿ**ï¼ˆIEEE 30-busï¼‰ï¼Œå°šæœªæ‰©å±•è‡³åƒèŠ‚ç‚¹çº§å®é™…ç”µç½‘ï¼›
2. **åŸºäº DC-OPF æ¨¡å‹**ï¼Œå¿½ç•¥ç”µå‹ã€æ— åŠŸåŠŸç‡åŠ AC åŠŸç‡æµéçº¿æ€§ï¼Œé™åˆ¶åœ¨å®é™… AC ç³»ç»Ÿä¸­çš„ç›´æ¥åº”ç”¨ï¼›
3. **å‡è®¾è´Ÿè½½åˆ†å¸ƒå¹³ç¨³**ï¼Œå¯¹ç½•è§æ•…éšœæˆ–å‰§çƒˆåˆ†å¸ƒåç§»çš„é²æ£’æ€§æœ‰å¾…éªŒè¯ï¼›
4. **ç¼ºä¹ä¸ç¡®å®šæ€§é‡åŒ–**ï¼Œæ— æ³•æä¾›é¢„æµ‹ç½®ä¿¡åŒºé—´ï¼Œå½±å“è°ƒåº¦å†³ç­–å¯ä¿¡åº¦ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ AC-OPF**ï¼š
   - å¼•å…¥å¤æ•°ç”µå‹å˜é‡ã€éçº¿æ€§æ½®æµæ–¹ç¨‹ï¼›
   - åŠ å…¥ç”µå‹å¹…å€¼ä¸ reactive power çº¦æŸï¼›
   - ç»“åˆ AC ç‰ˆæœ¬çš„ KKT æ¡ä»¶è¿›è¡Œç‰©ç†å¼•å¯¼ã€‚

2. **è§„æ¨¡åŒ–ä¸åˆ†å¸ƒå¼è®­ç»ƒ**ï¼š
   - é‡‡ç”¨ hierarchical GNN æˆ– subgraph sampling å¤„ç†å¤§å‹ç”µç½‘ï¼›
   - æ”¯æŒ mini-batch è®­ç»ƒä¸å¤š GPU å¹¶è¡Œã€‚

3. **ä¸ç¡®å®šæ€§å»ºæ¨¡**ï¼š
   - æ„å»º **ensemble CFM** æˆ– **probabilistic flow models** æä¾›è§£åˆ†å¸ƒï¼›
   - å¼•å…¥ worst-case guarantee æœºåˆ¶å¢å¼ºå®‰å…¨æ€§ã€‚

4. **åœ¨çº¿è‡ªé€‚åº”å­¦ä¹ **ï¼š
   - æ”¯æŒ topology changeï¼ˆçº¿è·¯æ–­å¼€ã€æ–°å¢æœºç»„ï¼‰ï¼›
   - åˆ©ç”¨ transfer learning / continual learning é€‚åº”å‚æ•°æ¼‚ç§»ã€‚

---

## æ€»ç»“

è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ **physics-informed + flow-based refinement** æ¡†æ¶ï¼Œåœ¨ä¿è¯ **100% çº¦æŸå¯è¡Œæ€§**çš„å‰æä¸‹ï¼Œå®ç°äº†æ¥è¿‘ä¼ ç»Ÿä¼˜åŒ–å™¨ç²¾åº¦çš„ DC-OPF å¿«é€Ÿæ±‚è§£ã€‚å…¶æ ¸å¿ƒæ€æƒ³â€”â€”â€œ**å…ˆå¯è¡Œåæœ€ä¼˜**â€çš„ä¸¤é˜¶æ®µç­–ç•¥ï¼Œä¸ºæœºå™¨å­¦ä¹ åº”ç”¨äºå®‰å…¨å…³é”®å‹åŸºç¡€è®¾æ–½ä¼˜åŒ–æä¾›äº†èŒƒå¼å‚è€ƒã€‚å°½ç®¡å½“å‰å±€é™äºå°è§„æ¨¡ DC æ¨¡å‹ï¼Œä½†å…¶è®¾è®¡ç†å¿µå…·æœ‰å¾ˆå¼ºçš„å¯æ‹“å±•æ€§ï¼Œæ˜¯è¿ˆå‘æ™ºèƒ½ã€å¿«é€Ÿã€å¯é ç”µç½‘è°ƒåº¦çš„é‡è¦ä¸€æ­¥ã€‚

</details>

---

### 15. [Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization](https://arxiv.org/abs/2512.11391)

**Authors**: Yifan Niu, Han Xiao, Dongyi Liu, Nuo Chen, Jia Li  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.11391v1  

#### Abstract
As Large Language Models (LLMs) are increasingly deployed in real-world applications, it is important to ensure their behaviors align with human values, societal norms, and ethical principles. However, safety alignment under Reinforcement Learning (RL) often suffers from forgetting learned general a...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¿›è¡Œ **safety alignment**ï¼ˆå®‰å…¨å¯¹é½ï¼‰æ—¶æ™®éå­˜åœ¨çš„â€œ**alignment tax**â€ï¼ˆå¯¹é½ç¨ï¼‰é—®é¢˜ã€‚è¿™ä¸€ç°è±¡æŒ‡çš„æ˜¯ï¼Œåœ¨æå‡æ¨¡å‹å®‰å…¨æ€§çš„åŒæ—¶ï¼Œå¾€å¾€ä¼šæŸå®³å…¶åŸæœ‰çš„é€šç”¨èƒ½åŠ›ï¼ˆå¦‚æ•°å­¦æ¨ç†ã€ä»£ç ç”Ÿæˆã€æŒ‡ä»¤éµå¾ªç­‰ï¼‰ï¼Œå¯¼è‡´æ¨¡å‹å˜å¾—è¿‡åº¦è°¨æ…ç”šè‡³æ‹’ç»å›ç­”æ— å®³é—®é¢˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº† **Null-Space constrained Policy Optimization (NSPO)**ï¼Œä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¡†æ¶ï¼Œç”¨äºå®ç°å®‰å…¨å¯¹é½ï¼ŒåŒæ—¶æœ‰æ•ˆç¼“è§£å¯¹é½ç¨ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **å‡ ä½•æŠ•å½±æœºåˆ¶**ï¼šå°†å®‰å…¨ç­–ç•¥æ¢¯åº¦ï¼ˆsafety policy gradientsï¼‰**å‡ ä½•åœ°æŠ•å½±åˆ°é€šç”¨ä»»åŠ¡è¡¨å¾çš„é›¶ç©ºé—´ï¼ˆnull spaceï¼‰ä¸­**ã€‚
- **è§£è€¦æ›´æ–°**ï¼šé€šè¿‡è¿™ç§æŠ•å½±ï¼Œç¡®ä¿å®‰å…¨ä¼˜åŒ–çš„æ–¹å‘ä¸æ¨¡å‹å·²ä¹ å¾—çš„é€šç”¨èƒ½åŠ›å­ç©ºé—´æ­£äº¤ï¼Œä»è€Œåœ¨ä¸å¹²æ‰°é€šç”¨èƒ½åŠ›çš„å‰æä¸‹æå‡å®‰å…¨æ€§ã€‚
- **ç§»é™¤KLæ•£åº¦**ï¼šNSPO ç§»é™¤äº†ä¼ ç»ŸRLHFæ–¹æ³•ä¸­çš„KLæ•£åº¦é¡¹ï¼Œå› ä¸ºè¯¥æƒ©ç½šé¡¹ä¼šä¸å®‰å…¨ç›®æ ‡å†²çªï¼›è€Œé›¶ç©ºé—´æŠ•å½±æœ¬èº«å°±èƒ½é˜²æ­¢ç­–ç•¥è¿‡åº¦åç¦»ï¼Œæ˜¯ä¸€ç§æ›´ä¼˜çš„çº¦æŸæ–¹å¼ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ€§èƒ½å“è¶Š**ï¼šåœ¨å¤šä¸ªå®‰å…¨åŸºå‡†ä¸Šè¾¾åˆ°SOTAï¼ˆstate-of-the-artï¼‰æ°´å¹³ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„DPOã€SafeRLHFç­‰æ–¹æ³•ã€‚
- **èƒ½åŠ›ä¿ç•™**ï¼šåœ¨å¤§å¹…æå‡å®‰å…¨æ€§çš„åŒæ—¶ï¼Œå‡ ä¹ä¸æŸå®³æ¨¡å‹åœ¨æ•°å­¦ã€ä»£ç ã€æŒ‡ä»¤éµå¾ªç­‰é€šç”¨ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚
- **æ•°æ®é«˜æ•ˆ**ï¼šä»…éœ€ä½¿ç”¨ **40% çš„å…¬å…±äººç±»æ ‡æ³¨å®‰å…¨æ•°æ®**ï¼ˆæ¥è‡ªPKU-SafeRLHFï¼‰å³å¯å–å¾—ä¼˜å¼‚æ•ˆæœï¼Œæ— éœ€æ··åˆå¤§é‡é€šç”¨ä»»åŠ¡æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¤§å¤§é™ä½äº†æ•°æ®éœ€æ±‚ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼š
  - **PKU-SafeRLHF**ï¼šç”¨äºNSPOçš„å®‰å…¨å¯¹é½è®­ç»ƒï¼ŒNSPOä»…ä½¿ç”¨å…¶ä¸­çš„ **40%**ï¼ˆçº¦11Kæ ·æœ¬ï¼‰ã€‚
- **æŠ•å½±çŸ©é˜µæ„é€ æ•°æ®**ï¼š
  - ä»ä¸‰ä¸ªé¢†åŸŸçš„æ··åˆæ•°æ®é›†ä¸­éšæœºé‡‡æ ·1000ä¸ªå®ä¾‹æ„å»ºæŠ•å½±çŸ©é˜µ $K$ï¼Œæ¶µç›–ï¼š
    - **Common sense**ï¼ˆå¸¸è¯†ï¼‰
    - **Math**ï¼ˆæ•°å­¦ï¼‰
    - **Code**ï¼ˆä»£ç ï¼‰
- **è¯„ä¼°åŸºå‡†**ï¼š
  - **å®‰å…¨åŸºå‡†ï¼ˆSafety Benchmarksï¼‰**ï¼š
    - *Harmful Query*: AdvBench, PKU-SafeRLHF, HarmBench, JailbreakBench, SORRY-Bench
    - *Red-team Query*: HarmfulQA, ALERT
  - **é€šç”¨èƒ½åŠ›åŸºå‡†ï¼ˆGeneral Capability Benchmarksï¼‰**ï¼š
    - *General Knowledge*: MMLU, SuperGPQA
    - *Instruction Following*: AlpacaEval
    - *Code Generation*: LiveCodeBench
    - *Math & Reasoning*: GSM8K, MATH, OlympiadBench

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **åŸºç¡€æ¨¡å‹**ï¼š`Llama3-8B-Instruct`, `Qwen2.5-7B-Instruct`
- **å®‰å…¨å¥–åŠ±æ¨¡å‹**ï¼š`Llama-Guard-4-12B`
- **è®­ç»ƒæ¡†æ¶**ï¼šåŸºäº `verl` æ¡†æ¶å®ç°ï¼Œä»¥ `GRPO` ä¸ºåŸºç¡€ç®—æ³•ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å®‰å…¨æ€§èƒ½**ï¼š**Attack Success Rate (ASR)**ï¼Œè¶Šä½è¶Šå¥½ã€‚
  - **é€šç”¨èƒ½åŠ›**ï¼š
    - **Accuracy**ï¼ˆMMLU, GSM8K, MATH, OlympiadBenchï¼‰
    - **Win Rate (WR)**ï¼ˆAlpacaEvalï¼‰
    - **Pass@1**ï¼ˆLiveCodeBenchï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
è®ºæ–‡å¯¹æ¯”äº†å¤šç§ä¸»æµçš„å¯¹é½æ–¹æ³•ä½œä¸ºåŸºçº¿ï¼š
- **DPO å˜ä½“**ï¼š`DPO-H`, `DPO-S`, `DPO-Mix`
- **RLHF ç±»æ–¹æ³•**ï¼š`SafeRLHF`, `PeCAN`, `MoCAN`, `W-DOOR`, `BFPO`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
æ ¹æ® **Table 1** å’Œ **Table 2** çš„ç»“æœï¼ŒNSPO åœ¨ `Llama3-8B-Instruct` å’Œ `Qwen2.5-7B-Instruct` ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼š

#### å®‰å…¨æ€§èƒ½ï¼ˆASR â†“ï¼‰
- åœ¨ `HarmBench` ä¸Šï¼ŒNSPO å°† ASR é™è‡³ **0.18%**ï¼ˆLlama3ï¼‰å’Œ **0.50%**ï¼ˆQwen2.5ï¼‰ï¼Œè¿œä½äºå…¶ä»–æ–¹æ³•ï¼ˆå¦‚ DPO-H è¾¾åˆ° 57.32%ï¼‰ã€‚
- åœ¨ `JailbreakBench` ä¸Šï¼ŒNSPO è¡¨ç°åŒæ ·é¢†å…ˆï¼ŒASR ä¸º **1.33%**ï¼ˆLlama3ï¼‰å’Œ **0.67%**ï¼ˆQwen2.5ï¼‰ã€‚
- åœ¨ `SORRY-Bench` ä¸Šï¼ŒNSPO å°† ASR ä»åŸºçº¿çš„ 34.15% é™è‡³ **16.81%**ï¼ˆLlama3ï¼‰ï¼Œæ•ˆæœæ˜¾è‘—ã€‚

#### é€šç”¨èƒ½åŠ›ï¼ˆAccuracy/WR/Pass@1 â†‘ï¼‰
- **MMLU**ï¼šNSPO å¾—åˆ† **63.64%**ï¼ˆLlama3ï¼‰å’Œ **71.74%**ï¼ˆQwen2.5ï¼‰ï¼Œä¸åŸºçº¿æ¨¡å‹ï¼ˆ63.79%, 71.71%ï¼‰å‡ ä¹æŒå¹³ï¼Œä¸”ä¼˜äºå¤§å¤šæ•°åŸºçº¿æ–¹æ³•ã€‚
- **GSM8K**ï¼šNSPO å¾—åˆ† **76.42%**ï¼ˆLlama3ï¼‰å’Œ **81.96%**ï¼ˆQwen2.5ï¼‰ï¼Œä¿æŒé«˜æ°´å¹³ã€‚
- **LiveCodeBench (Pass@1)**ï¼šNSPO å¾—åˆ† **13.43%**ï¼ˆLlama3ï¼‰å’Œ **24.05%**ï¼ˆQwen2.5ï¼‰ï¼ŒåŸºæœ¬æ— æŸã€‚
- æ€»ä½“æ¥çœ‹ï¼ŒNSPO åœ¨é€šç”¨èƒ½åŠ›ä¸Šçš„æ€§èƒ½ä¸‹é™**é€šå¸¸åœ¨1%ä»¥å†…**ï¼Œæå°‘æ•°æƒ…å†µä¸è¶…è¿‡2.67%ï¼Œè€Œå…¶ä»–æ–¹æ³•ï¼ˆå¦‚ DPO-H, SafeRLHFï¼‰åˆ™å‡ºç°æ˜¾è‘—ä¸‹é™ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å®‰å…¨æ€§èƒ½**ï¼šNSPO åœ¨æ‰€æœ‰7ä¸ªå®‰å…¨åŸºå‡†ä¸Šå‡å–å¾—**æœ€ä½³æˆ–æ¬¡ä½³**æˆç»©ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚
- **é€šç”¨èƒ½åŠ›**ï¼šNSPO åœ¨æ‰€æœ‰7ä¸ªé€šç”¨èƒ½åŠ›åŸºå‡†ä¸Šè¡¨ç°ç¨³å¥ï¼Œæ€§èƒ½æŸå¤±æœ€å°ï¼Œ**ä»…æ¬¡äº BFPO**ï¼Œä½† BFPO éœ€è¦æ··åˆæ•°æ®ï¼Œè€Œ NSPO ä»…ç”¨çº¯å®‰å…¨æ•°æ®ã€‚
- **ç»¼åˆè¡¨ç°**ï¼šNSPO æˆåŠŸå®ç°äº†**å®‰å…¨æ€§å’Œé€šç”¨èƒ½åŠ›çš„æœ€ä¼˜å¹³è¡¡**ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å­˜åœ¨çš„ trade-off é—®é¢˜ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **æŠ•å½±çš„æœ‰æ•ˆæ€§**ï¼ˆFigure 4ï¼‰ï¼š
  - `GRPO w/o KL`ï¼šå®‰å…¨å¥½ï¼Œä½†é€šç”¨èƒ½åŠ›ä¸¥é‡é€€åŒ–ã€‚
  - `Standard GRPO`ï¼šé€šç”¨èƒ½åŠ›æ¢å¤ï¼Œä½†å®‰å…¨æ€§èƒ½å¤§å¹…ä¸‹é™ã€‚
  - `NSPO`ï¼š**ä¸¤è€…å…¼é¡¾**ï¼Œè¯æ˜é›¶ç©ºé—´æŠ•å½±æ˜¯æ›´æœ‰æ•ˆçš„çº¦æŸæœºåˆ¶ã€‚
- **æŠ•å½±çŸ©é˜µ $K$ çš„å½±å“**ï¼ˆFigure 5, 6ï¼‰ï¼š
  - **æ•°æ®æ¥æº**ï¼šä½¿ç”¨æ··åˆé¢†åŸŸæ•°æ®ï¼ˆ`Mix`ï¼‰æ„å»º $K$ èƒ½æœ€å¥½åœ°ä¿ç•™é€šç”¨èƒ½åŠ›ã€‚
  - **æ ·æœ¬å¤§å°**ï¼šå¢å¤§æ ·æœ¬é‡æœ‰åŠ©äºä¿ç•™é€šç”¨èƒ½åŠ›ï¼Œä½†å¯èƒ½è½»å¾®ç‰ºç‰²å®‰å…¨æ€§ã€‚
  - **ç‰¹å¾å€¼é˜ˆå€¼**ï¼šä¸­ç­‰é˜ˆå€¼ï¼ˆå¦‚ 5e-4ï¼‰èƒ½å®ç°å®‰å…¨ä¸èƒ½åŠ›çš„æœ€ä½³æƒè¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é›¶ç©ºé—´æŠ•å½±æ˜¯ç¼“è§£å¯¹é½ç¨çš„æœ‰æ•ˆæœºåˆ¶**ï¼šé€šè¿‡å°†å®‰å…¨æ¢¯åº¦é™åˆ¶åœ¨ä¸å½±å“é€šç”¨èƒ½åŠ›çš„å­ç©ºé—´å†…ï¼ŒNSPO æˆåŠŸå®ç°äº†å®‰å…¨ä¼˜åŒ–ä¸èƒ½åŠ›ä¿ç•™çš„è§£è€¦ã€‚
2. **NSPO æ˜¯æ•°æ®é«˜æ•ˆçš„**ï¼šä»…éœ€ 40% çš„å®‰å…¨æ•°æ®å³å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šä½¿ç”¨å…¨é‡æ•°æ®çš„æ–¹æ³•çš„æ€§èƒ½ï¼Œæ— éœ€é¢å¤–çš„é€šç”¨ä»»åŠ¡æ•°æ®ã€‚
3. **ç†è®ºä¿è¯**ï¼šè®ºæ–‡ä»ç†è®ºä¸Šè¯æ˜äº† NSPO æ—¢èƒ½ä¿ç•™åŸå§‹æ¨¡å‹çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œåˆèƒ½ä¿è¯å®‰å…¨ç›®æ ‡çš„æœ‰æ•ˆä¸‹é™æ–¹å‘ã€‚
4. **å¯è§†åŒ–éªŒè¯**ï¼št-SNE å¯è§†åŒ–æ˜¾ç¤ºï¼ŒNSPO åœ¨å®‰å…¨ç›¸å…³è¡¨ç¤ºä¸Šæœ‰æ›´å¤§å˜åŒ–ï¼Œè€Œåœ¨é€šç”¨èƒ½åŠ›è¡¨ç¤ºä¸Šå˜åŒ–è¾ƒå°ï¼Œç›´è§‚éªŒè¯äº†å…¶é€‰æ‹©æ€§æ›´æ–°çš„ç‰¹æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é¢„å®šä¹‰çš„é€šç”¨èƒ½åŠ›æ•°æ®**ï¼šéœ€è¦ä¸€ä¸ªç‹¬ç«‹çš„é€šç”¨ä»»åŠ¡æ•°æ®é›†æ¥æ„å»ºæŠ•å½±çŸ©é˜µ $K$ï¼Œè¿™å¢åŠ äº†é¢å¤–çš„æ•°æ®å‡†å¤‡æ­¥éª¤ã€‚
- **è®¡ç®—å¼€é”€**ï¼šè™½ç„¶ä½œè€…å£°ç§°å¼€é”€å°ï¼Œä½† SVD åˆ†è§£å’ŒæŠ•å½±æ“ä½œä»ä¼šå¼•å…¥ä¸€å®šçš„è®¡ç®—å’Œå†…å­˜è´Ÿæ‹…ï¼Œå°¤å…¶æ˜¯åœ¨å¤§æ¨¡å‹ä¸Šã€‚
- **é›¶ç©ºé—´çš„è¿‘ä¼¼æ€§**ï¼šå®é™…åº”ç”¨ä¸­ï¼Œä¸¥æ ¼ä¸ºé›¶çš„ç‰¹å¾å€¼éš¾ä»¥è·å¾—ï¼Œéœ€é€šè¿‡è®¾å®šé˜ˆå€¼æ¥è¿‘ä¼¼ï¼Œè¿™å¯èƒ½å½±å“æŠ•å½±çš„ç²¾ç¡®æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„é›¶ç©ºé—´è®¡ç®—æ–¹æ³•ï¼Œå‡å°‘å¯¹ SVD çš„ä¾èµ–ã€‚
- ç ”ç©¶å¦‚ä½•åŠ¨æ€æ›´æ–°æŠ•å½±çŸ©é˜µ $K$ï¼Œä»¥é€‚åº”ä¸åŒé˜¶æ®µçš„è®­ç»ƒã€‚
- å°† NSPO æ¡†æ¶æ‰©å±•åˆ°å¤šç›®æ ‡å¯¹é½ï¼ˆmulti-objective alignmentï¼‰åœºæ™¯ï¼Œå¤„ç†æ›´å¤šç»´åº¦çš„çº¦æŸã€‚
- æ¢ç´¢åœ¨æ›´å°æ¨¡å‹æˆ–ä¸åŒæ¶æ„ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

> **ä»£ç å¼€æº**ï¼šè¯¥æ–¹æ³•çš„ä»£ç å·²åœ¨ GitHub å¼€æºï¼š[https://github.com/ivanniu/NSPO](https://github.com/ivanniu/NSPO)

</details>

---

### 16. [TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning](https://arxiv.org/abs/2512.11271)

**Authors**: Yuxing Chen, Basem Suleiman, Qifan Chen  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.11271v1  

#### Abstract
Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, ofte...

---

### 17. [EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection](https://arxiv.org/abs/2512.11506)

**Authors**: Georgios Kaoukis, Ioannis Aris Koufopoulos, Psaroudaki Eleni, Danae Pla Karidi, Evaggelia Pitoura, George Papastefanatos, Panayiotis Tsaparas  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.11506v1  

#### Abstract
As AI and web agents become pervasive in decision-making, it is critical to design intelligent systems that not only support sustainability efforts but also guard against misinformation. Greenwashing, i.e., misleading corporate sustainability claims, poses a major challenge to environmental progress...

---

### 18. [FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration](https://arxiv.org/abs/2512.11213)

**Authors**: Dongwon Jung, Peng Shi, Yi Zhang  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.11213v1  

#### Abstract
Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, a...

---

### 19. [Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning](https://arxiv.org/abs/2512.11485)

**Authors**: Xuanbo Su, Yingfang Zhang, Hao Luo, Xiaoteng Liu, Leo Huang  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.11485v1  

#### Abstract
Large language models (LLMs) adapt to tasks via gradient fine-tuning (heavy computation, catastrophic forgetting) or In-Context Learning (ICL: low robustness, poor mistake learning). To fix this, we introduce Mistake Notebook Learning (MNL), a training-free framework with a persistent knowledge base...

---

### 20. [Deep Learning--Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling](https://arxiv.org/abs/2512.11187)

**Authors**: Haohui Zhang, Wouter van Heeswijk, Xinyu Hu, Neil Yorke-Smith, Martijn Mes  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.11187v1  

#### Abstract
Online Freight Exchange Systems (OFEX) play a crucial role in modern freight logistics by facilitating real-time matching between shippers and carrier. However, efficient combinatorial bundling of transporation jobs remains a bottleneck. We model the OFEX combinatorial bundling problem as a multi-co...

---

### 21. [When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents](https://arxiv.org/abs/2512.11277)

**Authors**: Mrinal Rawat, Arkajyoti Chakraborty, Neha Gupta, Roberto Pieraccini  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.11277v1  

#### Abstract
Supervised fine-tuning (SFT) has emerged as one of the most effective ways to improve the performance of large language models (LLMs) in downstream tasks. However, SFT can have difficulty generalizing when the underlying data distribution changes, even when the new data does not fall completely outs...

---

### 22. [Harnessing Rich Multi-Modal Data for Spatial-Temporal Homophily-Embedded Graph Learning Across Domains and Localities](https://arxiv.org/abs/2512.11178)

**Authors**: Takuya Kurihana, Xiaojian Zhang, Wing Yee Au, Hon Yung Wong  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.11178v1  

#### Abstract
Modern cities are increasingly reliant on data-driven insights to support decision making in areas such as transportation, public safety and environmental impact. However, city-level data often exists in heterogeneous formats, collected independently by local agencies with diverse objectives and sta...

---

### 23. [Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning](https://arxiv.org/abs/2512.11179)

**Authors**: Wei Duan, Jie Lu, En Yu, Junyu Xuan  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.11179v1  

#### Abstract
Graph-based multi-agent reinforcement learning (MARL) enables coordinated behavior under partial observability by modeling agents as nodes and communication links as edges. While recent methods excel at learning sparse coordination graphs-determining who communicates with whom-they do not address wh...

---

### 24. [PIAST: Rapid Prompting with In-context Augmentation for Scarce Training data](https://arxiv.org/abs/2512.11013)

**Authors**: Pawel Batorski, Paul Swoboda  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11013v1  

#### Abstract
LLMs are highly sensitive to prompt design, but handcrafting effective prompts is difficult and often requires intricate crafting of few-shot examples. We propose a fast automatic prompt construction algorithm that augments human instructions by generating a small set of few shot examples. Our metho...

---

### 25. [Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet](https://arxiv.org/abs/2512.11567)

**Authors**: Mevl\"ut Bagci, Ali Abusaleh, Daniel Baumartz, Giueseppe Abrami, Maxim Konca, Alexander Mehler  
**Category**: cs.CL  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11567v1  

#### Abstract
Social media serves as a critical medium in modern politics because it both reflects politicians' ideologies and facilitates communication with younger generations. We present MultiParTweet, a multilingual tweet corpus from X that connects politicians' social media discourse with German political co...

---

### 26. [Pace: Physics-Aware Attentive Temporal Convolutional Network for Battery Health Estimation](https://arxiv.org/abs/2512.11332)

**Authors**: Sara Sameer, Wei Zhang, Kannan Dhivya Dharshini, Xin Lou, Yulin Gao, Terence Goh, Qingyu Yan  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11332v1  

#### Abstract
Batteries are critical components in modern energy systems such as electric vehicles and power grid energy storage. Effective battery health management is essential for battery system safety, cost-efficiency, and sustainability. In this paper, we propose Pace, a physics-aware attentive temporal conv...

---

### 27. [Hyperbolic Gaussian Blurring Mean Shift: A Statistical Mode-Seeking Framework for Clustering in Curved Spaces](https://arxiv.org/abs/2512.11448)

**Authors**: Arghya Pratihar, Arnab Seal, Swagatam Das, Inesh Chattopadhyay  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11448v1  

#### Abstract
Clustering is a fundamental unsupervised learning task for uncovering patterns in data. While Gaussian Blurring Mean Shift (GBMS) has proven effective for identifying arbitrarily shaped clusters in Euclidean space, it struggles with datasets exhibiting hierarchical or tree-like structures. In this w...

---

### 28. [Elastic-Net Multiple Kernel Learning: Combining Multiple Data Sources for Prediction](https://arxiv.org/abs/2512.11547)

**Authors**: Janaina Mour\~ao-Miranda, Zakria Hussain, Konstantinos Tsirlis, Christophe Phillips, John Shawe-Taylor  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11547v1  

#### Abstract
Multiple Kernel Learning (MKL) models combine several kernels in supervised and unsupervised settings to integrate multiple data representations or sources, each represented by a different kernel. MKL seeks an optimal linear combination of base kernels that maximizes a generalized performance measur...

---

### 29. [High-Dimensional Surrogate Modeling for Closed-Loop Learning of Neural-Network-Parameterized Model Predictive Control](https://arxiv.org/abs/2512.11705)

**Authors**: Sebastian Hirt, Valentinus Suwanto, Hendrik Alsmeier, Maik Pfefferkorn, Rolf Findeisen  
**Category**: cs.LG  
**Published**: 2025-12-15  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.11705v1  

#### Abstract
Learning controller parameters from closed-loop data has been shown to improve closed-loop performance. Bayesian optimization, a widely used black-box and sample-efficient learning method, constructs a probabilistic surrogate of the closed-loop performance from few experiments and uses it to select ...

---

### 30. [BAID: A Benchmark for Bias Assessment of AI Detectors](https://arxiv.org/abs/2512.11505)

**Authors**: Priyam Basu, Yunfeng Zhang, Vipul Raheja  
**Category**: cs.AI  
**Published**: 2025-12-15  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.11505v1  

#### Abstract
AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguis...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
