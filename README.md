# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-12 05:57:54 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [GoodSpeed: Optimizing Fair Goodput with Adaptive Speculative Decoding in Distributed Edge Inference](https://arxiv.org/abs/2512.09963)

**Authors**: Phuong Tran, Tzu-Hao Liu, Long Tan Le, Tung-Anh Nguyen, Van Quan La, Eason Yu, Han Shu, Choong Seon Hong, Nguyen H. Tran  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 14.0  
**Type**: new  
**ArXiv ID**: 2512.09963v1  

#### Abstract
Large language models (LLMs) have revolutionized natural language processing, yet their high computational demands pose significant challenges for real-time inference, especially in multi-user server speculative decoding and resource-constrained environments. Speculative decoding has emerged as a pr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**GooDSPEED: Optimizing Fair Goodput with Adaptive Speculative Decoding in Distributed Edge Inference**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **åˆ†å¸ƒå¼è¾¹ç¼˜æ¨ç†ä¸­çš„å»¶è¿Ÿä¸ååç“¶é¢ˆ**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²é¢ä¸´é«˜å»¶è¿Ÿã€ä½ååçš„é—®é¢˜ã€‚
- **å¤šæœåŠ¡å™¨åä½œä¸‹çš„å…¬å¹³æ€§æŒ‘æˆ˜**ï¼šä¼ ç»Ÿ speculative decoding å¤šå‡è®¾å•ä¸€å®¢æˆ·ç«¯æˆ–ç†æƒ³åŒ–ç¯å¢ƒï¼Œå¿½è§†äº†å¤šä¸ªå¼‚æ„ draft server åœ¨å…±äº«ä¸­å¤®éªŒè¯æœåŠ¡å™¨æ—¶çš„èµ„æºç«äº‰ä¸å…¬å¹³åˆ†é…é—®é¢˜ã€‚
- **åŠ¨æ€æç¤ºå¯¼è‡´çš„éå¹³ç¨³æ€§**ï¼šç”¨æˆ·è¾“å…¥ï¼ˆå¦‚å¯¹è¯ä¸»é¢˜çªå˜ï¼‰ä¼šå¯¼è‡´ token æ¥å—ç‡ï¼ˆacceptance rateï¼‰å‰§çƒˆæ³¢åŠ¨ï¼Œå½±å“ç³»ç»Ÿç¨³å®šæ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
- **GooDSPEED æ¡†æ¶**ï¼šæå‡ºä¸€ç§åŸºäº**è‡ªé€‚åº” speculative decoding** çš„åˆ†å¸ƒå¼è¾¹ç¼˜æ¨ç†æ¡†æ¶ï¼Œç»“åˆè½»é‡çº§ draft æ¨¡å‹ä¸é›†ä¸­å¼å¤§æ¨¡å‹éªŒè¯æœºåˆ¶ã€‚
  - å¤šä¸ªè¾¹ç¼˜ draft server å¹¶è¡Œç”Ÿæˆ speculative tokensï¼›
  - ä¸­å¤® verification server æ‰¹é‡å¹¶è¡ŒéªŒè¯è¿™äº› tokensï¼Œå¹¶åé¦ˆæ¥å—ç»“æœã€‚
- **æ¢¯åº¦è°ƒåº¦ç®—æ³•ï¼ˆGradient Scheduling Algorithmï¼‰**ï¼š
  - åŠ¨æ€è°ƒæ•´æ¯ä¸ª draft server çš„ draft é•¿åº¦ $ S_i(t) $ï¼Œä»¥æœ€å¤§åŒ–å¯¹æ•°æ•ˆç”¨å‡½æ•° $ \sum \log x_i $ï¼Œå®ç°**æ¯”ä¾‹å…¬å¹³æ€§ï¼ˆproportional fairnessï¼‰**ï¼›
  - åˆ©ç”¨å¹³æ»‘ä¼°è®¡çš„ acceptance rate $ \hat{\alpha}_i(t) $ å’Œ goodput $ \hat{x}_i(t) $ è¿›è¡Œåœ¨çº¿å†³ç­–ï¼Œé€‚åº”éå¹³ç¨³è´Ÿè½½ã€‚
- **ç†è®ºæ”¶æ•›æ€§åˆ†æ**ï¼š
  - åŸºäº fluid sample path åˆ†æï¼Œè¯æ˜è¯¥ç®—æ³•åœ¨ç¨³æ€ä¸‹æ”¶æ•›åˆ°æœ€ä¼˜ goodput åˆ†é…ï¼›
  - åœ¨åŠ¨æ€è´Ÿè½½ä¸‹å…·æœ‰æœ‰ç•Œè¯¯å·®ï¼Œå…·å¤‡æ¸è¿‘æœ€ä¼˜æ€§ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | GooDSPEED | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Fixed-S, Random-Sï¼‰ |
|------|-----------|-------------------------------|
| èµ„æºåˆ©ç”¨ç‡ | é«˜ï¼ŒåŠ¨æ€é€‚é…å„ client çš„æ¥å—ç‡ | å›ºå®šåˆ†é…ï¼Œæ˜“é€ æˆèµ„æºæµªè´¹æˆ–æ‹¥å¡ |
| å…¬å¹³æ€§ | æ˜¾å¼ä¼˜åŒ– log utilityï¼Œä¿éšœå¼±æ¨¡å‹ä¹Ÿèƒ½è·å¾—åˆç†å¸¦å®½ | å¿½è§†å…¬å¹³æ€§ï¼Œå¼ºè€…æ’å¼º |
| ååæ•ˆç‡ | æ›´é«˜çš„ç³»ç»Ÿçº§ goodputï¼ˆæœ‰æ•ˆæ¥å— token æ•°ï¼‰ | å—é™äºæœ€æ…¢ client æˆ–ä½æ¥å—ç‡æ¨¡å‹ |
| é€‚ç”¨åœºæ™¯ | æ”¯æŒå¼‚æ„è®¾å¤‡ã€åŠ¨æ€æç¤ºã€å¤šç”¨æˆ·å¹¶å‘ | å¤šä¸ºå•å®¢æˆ·ç«¯æˆ–é™æ€é…ç½® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å…±ä½¿ç”¨ **8 ä¸ªå…¬å¼€æ•°æ®é›†**ï¼Œè¦†ç›–å¤šç§å…¸å‹åº”ç”¨åœºæ™¯ï¼š
- **æŒ‡ä»¤å¾®è°ƒ / å¯¹è¯ä»»åŠ¡**ï¼šAlpaca, Awesome-ChatGPT-Prompts
- **é•¿æ–‡æœ¬æ‘˜è¦**ï¼šCNN/DailyMail
- **æ¨ç†ä¸é—®ç­”**ï¼šOpenOrca, Chatbot Arena
- **æ•°å­¦è§£é¢˜**ï¼šGSM8K
- **Text-to-SQL**ï¼šSPIDER
- **é«˜éš¾åº¦é•¿å°¾æŸ¥è¯¢**ï¼šHLE

> æ•°æ®åˆ†å¸ƒäº 4â€“8 ä¸ª draft servers ä¸Šï¼Œæ¨¡æ‹ŸçœŸå®å¼‚æ„ã€å¤šæ ·åŒ–è´Ÿè½½ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
| ç»„ä»¶ | é…ç½® |
|------|------|
| **Verification Server** | NVIDIA H100 GPUï¼Œè¿è¡Œ Qwen3-14B æˆ– Llama3.1-70B-Instruct-AWQ-INT4 |
| **Draft Servers** | NVIDIA L4 GPUï¼Œè¿è¡Œ Qwen3-0.6B ~ 3B æˆ– Llama3-1B/3B ç­‰å°å‹æ¨¡å‹ |
| **Token Budget C** | è®¾ä¸º 6, 16, 20, 24, 28ï¼ˆä¾æ®å†…å­˜å ç”¨ <75% HBM3 å’Œå»¶è¿Ÿå®¹å¿åº¦ç¡®å®šï¼‰ |
| **æœ€å¤§è¾“å‡ºé•¿åº¦** | 50 æˆ– 150 tokens |
| **å®¢æˆ·ç«¯æ•°é‡** | 4 æˆ– 8 ä¸ª draft servers |

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **Goodput**ï¼šå•ä½æ—¶é—´å†…è¢«ç›®æ ‡æ¨¡å‹æ¥å—çš„æœ‰æ•ˆ token æ•°é‡ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
- **End-to-end Latency**ï¼šä»è¯·æ±‚å‘å‡ºåˆ°å“åº”å®Œæˆçš„æ—¶é—´
- **Utility Function**ï¼š$ U(x) = \sum_{i=1}^N \log x_i $ï¼Œè¡¡é‡ç³»ç»Ÿæ•´ä½“å…¬å¹³ä¸æ•ˆç‡
- **Wall Time Components**ï¼š
  - Receiving Timeï¼ˆç­‰å¾…æ‰€æœ‰ draft åˆ°è¾¾ï¼‰
  - Verification Timeï¼ˆå¹¶è¡ŒéªŒè¯è€—æ—¶ï¼‰
  - Sending Timeï¼ˆè¿”å›ç»“æœæ—¶é—´ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Fixed-S**ï¼šæ¯ä¸ª draft server å›ºå®šç”Ÿæˆ $ S_i = C/N $ ä¸ª tokens
- **Random-S**ï¼šéšæœºåˆ†é… $ S_i $ï¼Œæ€»å’Œä¸è¶…è¿‡ $ C $

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®
#### ï¼ˆ1ï¼‰Goodput ä¼°è®¡å‡†ç¡®æ€§ï¼ˆFigure 2ï¼‰
- GooDSPEED çš„å¹³æ»‘ä¼°è®¡ goodput æ›²çº¿ä¸å®é™…æµ‹é‡å€¼é«˜åº¦ä¸€è‡´ï¼ˆMA æ»¤æ³¢åï¼‰ï¼Œæ ‡å‡†å·®å°ï¼Œè¯´æ˜ä¼°è®¡ç¨³å®šå¯é ã€‚
- åœ¨ Qwen3 å’Œ Llama3 è®¾ç½®ä¸‹å‡è¡¨ç°è‰¯å¥½ï¼Œé€‚ç”¨äºä¸åŒè§„æ¨¡ LLMã€‚

#### ï¼ˆ2ï¼‰ç«¯åˆ°ç«¯å»¶è¿Ÿåˆ†è§£ï¼ˆFigure 3ï¼‰
- æ€»ä½“ wall time ä¸ Fixed-S ç›¸å½“ï¼Œä¼˜äº Random-Sï¼ˆä½ 5â€“25%ï¼‰ï¼›
- **Verification Time æ¯” Fixed-S ä½çº¦ 5%**ï¼Œè¡¨æ˜æ›´ä¼˜çš„å·¥ä½œè´Ÿè½½å¹³è¡¡ï¼›
- Receiving Time ç•¥é«˜ï¼ˆå› åŠ¨æ€é•¿åº¦éœ€ç­‰æœ€æ…¢ clientï¼‰ï¼Œä½†å¯é€šè¿‡å¼‚æ­¥æœºåˆ¶ç¼“è§£ã€‚

#### ï¼ˆ3ï¼‰æ•ˆç”¨å‡½æ•°æ”¶æ•›æ€§ï¼ˆFigure 4ï¼‰
- GooDSPEED åœ¨çº¦ **400â€“600 è½®è¿­ä»£å†…æ”¶æ•›**ï¼›
- æœ€ç»ˆ utility æ˜¾è‘—é«˜äº Fixed-S å’Œ Random-Sï¼ˆæå‡å¯è¾¾ 20â€“40%ï¼‰ï¼›
- æ”¶æ•›é€Ÿåº¦ç¬¦åˆç†è®ºé¢„æµ‹ï¼ˆ$ T/\beta \approx 400â€“600 $ï¼Œå– $ \beta=0.5 $ï¼‰ã€‚

#### ï¼ˆ4ï¼‰ç³»ç»Ÿååå¢ç›Š
- åœ¨å¤šç§æ¨¡å‹ç»„åˆï¼ˆQwen/Llamaï¼‰ã€å®¢æˆ·ç«¯æ•°é‡ï¼ˆ4/8ï¼‰ã€token budget ä¸‹ï¼ŒGooDSPEED å‡å®ç°ï¼š
  - **æ›´é«˜çš„ç³»ç»Ÿçº§ goodput**
  - **æ›´å‡è¡¡çš„ per-client åååˆ†é…**
  - **æ›´å¼ºçš„æŠ—æ³¢åŠ¨èƒ½åŠ›**

### ğŸ” æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»è®¾è®¡å¯æ¨æ–­ä»¥ä¸‹å…³é”®ç»„ä»¶ä½œç”¨ï¼š
- **æŒ‡æ•°å¹³æ»‘ï¼ˆexponential smoothingï¼‰**ï¼šæ˜¾è‘—é™ä½ acceptance rate æ³¢åŠ¨å¸¦æ¥çš„æ§åˆ¶éœ‡è¡ï¼›
- **æ¢¯åº¦è°ƒåº¦æœºåˆ¶**ï¼šç›¸æ¯”å›ºå®šç­–ç•¥ï¼Œåœ¨éå¹³ç¨³ç¯å¢ƒä¸‹ä»èƒ½é€¼è¿‘æœ€ä¼˜è§£ï¼›
- **å¹¶è¡Œæ‰¹å¤„ç†éªŒè¯**ï¼šå……åˆ†åˆ©ç”¨ GPU å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼Œç¼©çŸ­éªŒè¯æ—¶é—´ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **GooDSPEED èƒ½æœ‰æ•ˆæå‡åˆ†å¸ƒå¼è¾¹ç¼˜ LLM æ¨ç†çš„ goodput ä¸å…¬å¹³æ€§**ï¼š
   - é€šè¿‡åŠ¨æ€è°ƒåº¦é€‚åº”ä¸åŒ draft server çš„æ¥å—ç‡å˜åŒ–ï¼›
   - å®ç°æ¥è¿‘æœ€ä¼˜çš„èµ„æºåˆ†é…ï¼Œé¿å…â€œæœ¨æ¡¶æ•ˆåº”â€ã€‚

2. **æ¢¯åº¦è°ƒåº¦ç®—æ³•å…·å¤‡ç†è®ºä¿è¯ä¸å®è·µæœ‰æ•ˆæ€§**ï¼š
   - åœ¨ fluid limit ä¸‹æ”¶æ•›è‡³å…¨å±€æœ€ä¼˜ï¼›
   - å³ä½¿åœ¨éå¹³ç¨³ prompt æ¡ä»¶ä¸‹ä¹Ÿä¿æŒç¨³å®šæ€§èƒ½ã€‚

3. **ç³»ç»Ÿå¯åœ¨æ•°ç™¾è½®å†…å¿«é€Ÿæ”¶æ•›**ï¼š
   - å®é™…éƒ¨ç½²ä¸­æ— éœ€é•¿æ—¶é—´è®­ç»ƒå³å¯è¾¾åˆ°é«˜æ•ˆçŠ¶æ€ï¼›
   - é€‚åˆå®æ—¶äº¤äº’åº”ç”¨ã€‚

4. **éªŒè¯äº† speculative decoding åœ¨è¾¹ç¼˜ååŒåœºæ™¯çš„å¯è¡Œæ€§**ï¼š
   - è¾¹ç¼˜è®¾å¤‡è´Ÿè´£å¿«é€Ÿèµ·è‰ï¼Œäº‘ç«¯/ä¸­å¿ƒèŠ‚ç‚¹è´Ÿè´£ç²¾ç¡®éªŒè¯ï¼›
   - æ¶æ„çµæ´»ï¼Œæ”¯æŒå¼‚æ„ç¡¬ä»¶ä¸æ¨¡å‹ã€‚

### âš ï¸ å±€é™æ€§
- **ä¾èµ–å‡†ç¡®çš„ acceptance rate ä¼°è®¡**ï¼šè‹¥ prompt å˜åŒ–è¿‡äºå‰§çƒˆæˆ– draft model è´¨é‡æå·®ï¼Œå¯èƒ½å¯¼è‡´ä¼°è®¡åå·®ï¼›
- **æ¥æ”¶æ—¶é—´å—æœ€æ…¢ client å½±å“**ï¼šåŠ¨æ€ draft é•¿åº¦å¼•å…¥åŒæ­¥ç­‰å¾…å¼€é”€ï¼›
- **æœªè€ƒè™‘ç½‘ç»œå¸¦å®½é™åˆ¶**ï¼šå½“å‰å®éªŒå‡è®¾å±€åŸŸç½‘ç¯å¢ƒï¼Œå¹¿åŸŸç½‘éƒ¨ç½²å¯èƒ½å¢åŠ é€šä¿¡å»¶è¿Ÿï¼›
- **ä»…æ”¯æŒå•ä¸ª verification server**ï¼šæ‰©å±•è‡³å¤šéªŒè¯èŠ‚ç‚¹å°šæœªè®¨è®ºã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥**å¼‚æ­¥è°ƒåº¦æœºåˆ¶**ä»¥å‡å°‘æ¥æ”¶ç­‰å¾…æ—¶é—´ï¼›
- æ¢ç´¢**è‡ªé€‚åº” smoothing å‚æ•°**ï¼ˆå¦‚æ ¹æ®æ–¹å·®è‡ªåŠ¨è°ƒèŠ‚ $ \eta, \beta $ï¼‰ï¼›
- æ‰©å±•è‡³**å¤š verification server æ¶æ„**ï¼Œè¿›ä¸€æ­¥æå‡å¯æ‰©å±•æ€§ï¼›
- ç»“åˆ **quantizationã€distillation** æŠ€æœ¯ä¼˜åŒ– draft model è´¨é‡ä¸é€Ÿåº¦ï¼›
- å°†æ¡†æ¶åº”ç”¨äº **video generationã€autonomous agents** ç­‰å¤šæ¨¡æ€æ¨ç†ä»»åŠ¡ã€‚

---

## æ€»ç»“

âœ… **GooDSPEED æ˜¯é¦–ä¸ªå°† speculative decoding ä¸æ¢¯åº¦èµ„æºè°ƒåº¦ç›¸ç»“åˆï¼Œç”¨äºè§£å†³åˆ†å¸ƒå¼è¾¹ç¼˜ LLM æ¨ç†ä¸­ goodput ä¸å…¬å¹³æ€§æƒè¡¡é—®é¢˜çš„ç³»ç»Ÿæ€§æ¡†æ¶**ã€‚  
ğŸ“Š å®éªŒè¡¨æ˜å…¶åœ¨çœŸå®æ¨¡å‹ä¸å¤šæ ·åŒ–è´Ÿè½½ä¸‹ï¼Œç›¸æ¯”å›ºå®šæˆ–éšæœºè°ƒåº¦ç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿååã€é™ä½äº†å»¶è¿Ÿï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„ç†è®ºæ”¶æ•›æ€§å’Œå®ç”¨æ€§ï¼Œä¸ºæœªæ¥è¾¹ç¼˜æ™ºèƒ½æœåŠ¡æä¾›äº†é‡è¦æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 2. [Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning](https://arxiv.org/abs/2512.10054)

**Authors**: Logan Robbins  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2512.10054v1  

#### Abstract
Autoregressive decoding in Large Language Models (LLMs) is inherently sequential, creating a latency bottleneck that scales linearly with output length. While ``Decomposition-and-Fill'' methods like Skeleton-of-Thought attempt to parallelize generation via external orchestration, they suffer from \t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªå›å½’è§£ç æ˜¯**é¡ºåºæ‰§è¡Œ**çš„ï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿéšè¾“å‡ºé•¿åº¦çº¿æ€§å¢é•¿ï¼Œä¸¥é‡åˆ¶çº¦é•¿æ–‡æœ¬ç”Ÿæˆæ•ˆç‡ã€‚è™½ç„¶å·²æœ‰â€œåˆ†è§£-å¡«å……â€ç±»æ–¹æ³•ï¼ˆå¦‚ **Skeleton-of-Thought (SoT)**ï¼‰å°è¯•é€šè¿‡å¤–éƒ¨å¹¶è¡ŒåŒ–æå‡é€Ÿåº¦ï¼Œä½†è¿™äº›æ–¹æ³•å°†æ¨¡å‹è§†ä¸ºé»‘ç®±ï¼Œç¼ºä¹è·¨æµé€šä¿¡æœºåˆ¶ï¼Œå®¹æ˜“äº§ç”Ÿ**Coherence Drift**ï¼ˆè¿è´¯æ€§æ¼‚ç§»ï¼‰ï¼Œå³å¹¶è¡Œæµä¹‹é—´å‡ºç°äº‹å®å†²çªæˆ–å†—ä½™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **Parallel Decoder Transformer (PDT)**ï¼Œä¸€ç§å°†å¹¶è¡ŒåŒ–æœºåˆ¶å†…åµŒäºæ¨¡å‹å†…éƒ¨çš„æ–°å‹æ¶æ„ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **Speculative Note Conditioning (SNC)**ï¼šåœ¨å†»ç»“çš„é¢„è®­ç»ƒä¸»å¹²æ¨¡å‹ä¸Šå¼•å…¥è½»é‡çº§é€‚é…å™¨ï¼Œä½¿å¤šä¸ªå¹¶è¡Œè§£ç æµå¯é€šè¿‡å…±äº«çš„åŠ¨æ€æ½œåœ¨ç©ºé—´ï¼ˆNote Busï¼‰è¿›è¡Œè¯­ä¹‰åŒæ­¥ã€‚æ¯ä¸ªæµå¯å¹¿æ’­å‹ç¼©åçš„è¯­ä¹‰â€œç¬”è®°â€ï¼ˆnotesï¼‰ï¼Œå…¶ä»–æµé€šè¿‡äº¤å‰æ³¨æ„åŠ›è¯»å–ï¼Œå¹¶ç”±å­¦ä¹ åˆ°çš„éªŒè¯å¤´æ§åˆ¶ä¿¡ä»»ç¨‹åº¦ã€‚
- **æ¨¡å‹å†…éƒ¨åè°ƒæœºåˆ¶**ï¼šä¸åŒäº SoT ç­‰â€œç»•æ¨¡å‹â€ï¼ˆaround-the-modelï¼‰æ–¹æ³•ï¼ŒPDT å°†åè°ƒé€»è¾‘ç›´æ¥é›†æˆè¿›è§£ç è¿‡ç¨‹ï¼Œå®ç°**æ¨¡å‹å†…éƒ¨å¹¶è¡Œè§£ç **ï¼ˆmodel-internal parallel decodingï¼‰ã€‚
- **å‚æ•°é«˜æ•ˆè®­ç»ƒç­–ç•¥**ï¼šä»…è®­ç»ƒå æ€»å‚æ•° <5% çš„è½»é‡å­æ¨¡å—ï¼ˆStream Adaptersã€SNC Heads ç­‰ï¼‰ï¼Œä¸»å¹²æ¨¡å‹æƒé‡ä¿æŒå†»ç»“ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¼€é”€ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ SoTï¼‰ | PDT |
|------|------------------|-----|
| å¹¶è¡Œç²’åº¦ | Prompt-level åˆ†è§£ | Prompt-level + Token-level åè°ƒ |
| é€šä¿¡æœºåˆ¶ | æ— ï¼ˆé»‘ç›’è°ƒç”¨ï¼‰ | å†…å»º Note Bus ä¸ SNC è·¨æµåŒæ­¥ |
| è¿è´¯æ€§ä¿éšœ | å¼±ï¼ˆæ˜“å‘ç”Ÿ Coherence Driftï¼‰ | å¼ºï¼ˆé€šè¿‡ Agreement Head è§¦å‘ Rollback è‡ªæˆ‘çº æ­£ï¼‰ |
| å‚æ•°æ•ˆç‡ | é«˜ï¼ˆæ— éœ€è®­ç»ƒï¼‰ | æé«˜ï¼ˆä»…è®­ç»ƒ <5% æ–°å¢å‚æ•°ï¼‰ |
| æ¨ç†ä¸€è‡´æ€§ | å·® | å¯æ¢å¤è¿‘ä¼¼ä¸²è¡Œè¯­ä¹‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- æ„é€ äº†ä¸€ä¸ªåŒ…å« **10,000 ä¸ªå¤šæ®µè½æ¨ç†ä»»åŠ¡**çš„æ•°æ®é›†ï¼Œç”± GPT-4 è’¸é¦ç”Ÿæˆã€‚
- æ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
  - â€œTeacher Planâ€ï¼šæ•™å¸ˆæ¨¡å‹çš„å®Œæ•´æ¨ç†è·¯å¾„ï¼›
  - â€œNotes Contractâ€ï¼šç»“æ„åŒ–çš„è¯­ä¹‰æ‰¿è¯ºé›†åˆï¼Œç”¨äºç›‘ç£å¹¶è¡Œæµæ˜¯å¦æ»¡è¶³è®¡åˆ’é¡¹ã€‚

### å®éªŒè®¾ç½®
- **ä¸»å¹²æ¨¡å‹**ï¼šå†»ç»“çš„ **20B å‚æ•° GPT-OSS** æ¨¡å‹ã€‚
- **ç¡¬ä»¶å¹³å°**ï¼š8Ã—NVIDIA B200 GPUï¼ˆæ¯å¡ 180GB VRAMï¼‰ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - å…¨å±€ batch size ä¸º 16ï¼ˆmicro-batch 1ï¼‰ï¼›
  - å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆgradient checkpointingï¼‰ï¼›
  - ä½¿ç”¨ **å››é˜¶æ®µè¯¾ç¨‹å­¦ä¹ **ï¼ˆcurriculum learningï¼‰é€æ­¥è§£é”æ¨¡å—è®­ç»ƒã€‚
- **å¹¶è¡Œæµæ•°**ï¼šé»˜è®¤ K=3~6ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Coverage Precision** | å½“ç³»ç»Ÿæ ‡è®°æŸè®¡åˆ’é¡¹ä¸ºâ€œå·²è¦†ç›–â€æ—¶ï¼Œå®é™…æ­£ç¡®çš„æ¯”ä¾‹ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ |
| **Coverage Recall** | æ‰€æœ‰æ­£ç¡®å®Œæˆçš„è®¡åˆ’é¡¹ä¸­ï¼Œè¢«ç³»ç»Ÿè¯†åˆ«çš„æ¯”ä¾‹ï¼ˆè¶Šä½è¡¨ç¤ºä¿å®ˆï¼‰ |
| **Validation Loss** | éªŒè¯é›†ä¸Šçš„æŸå¤±å€¼ |
| **Rollback Rate** | å› ä¸ä¸€è‡´è§¦å‘å›æ»šæ“ä½œçš„é¢‘ç‡ |
| **Memory Utilization** | GPU æ˜¾å­˜å ç”¨æƒ…å†µï¼Œç”¨äºéªŒè¯å‚æ•°æ•ˆç‡å‡è®¾ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Skeleton-of-Thought (SoT)**ï¼šä½œä¸ºä¸»è¦å¤–éƒ¨å¹¶è¡ŒåŒ–åŸºçº¿ï¼Œå­˜åœ¨æ˜æ˜¾çš„ Coherence Driftã€‚
- **Full Fine-tuning**ï¼šä½œä¸ºå‚æ•°æ•ˆç‡çš„å¯¹æ¯”æç«¯ï¼Œç”¨äºæ­ç¤ºâ€œMemory Cliffâ€ç°è±¡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | PDT ç»“æœ |
|------|---------|
| **Coverage Precision** | **77.8%**ï¼ˆæœ€ç»ˆé˜¶æ®µï¼‰ |
| **Coverage Recall** | 4.91%ï¼ˆè¡¨æ˜ç­–ç•¥ä¿å®ˆï¼‰ |
| **Validation Loss** | 0.00ï¼ˆå®Œç¾æ‹ŸåˆéªŒè¯é›†ï¼‰ |
| **SNC æ”¶æ•›æ­¥æ•°** | ~20k æ­¥åå‡ºç°ç›¸å˜å¼ä¸‹é™ï¼Œ40k+ æ­¥è¶‹äºç¨³å®š |
| **å‚æ•°å æ¯”** | å¯è®­ç»ƒå‚æ•° < æ€»å‚æ•°çš„ 5% |

> æ³¨ï¼šæ–‡ä¸­è¿˜æåˆ°åœ¨ç¬¬ 50,000 æ­¥æ—¶è¾¾åˆ° **71.6% çš„ self-correction precision**ï¼Œä½“ç°è‡ªæˆ‘çº é”™èƒ½åŠ›ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **vs SoT**ï¼š
  - PDT æ˜¾è‘—å‡å°‘ Coherence Drift å’Œå†—ä½™ç”Ÿæˆï¼›
  - åœ¨å¤šæµä¸€è‡´æ€§æ–¹é¢è¡¨ç°æ›´ä¼˜ï¼Œå¾—ç›Šäº Agreement Head çš„æ˜¾å¼éªŒè¯æœºåˆ¶ï¼›
  - å°½ç®¡ SoT æ›´ç®€å•ï¼Œä½† PDT åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¯­ä¹‰å®Œæ•´æ€§æ›´é«˜ã€‚
- **vs Full Fine-tuning**ï¼š
  - å…¨å¾®è°ƒç«‹å³å¯¼è‡´ **OOMï¼ˆOut-of-Memoryï¼‰**ï¼Œå› éœ€é¢å¤– ~115GB å­˜å‚¨ä¼˜åŒ–å™¨çŠ¶æ€ï¼›
  - å®éªŒç¡®è®¤äº†â€œ**Memory Cliff**â€çš„å­˜åœ¨â€”â€”å¯¹äº 20B+ æ¨¡å‹ï¼Œå…¨å¾®è°ƒä¸å¯è¡Œäºå•èŠ‚ç‚¹éƒ¨ç½²ï¼›
  - éªŒè¯äº† PDT çš„å‚æ•°é«˜æ•ˆè®¾è®¡ä¸ä»…æ˜¯ä¼˜åŒ–ï¼Œæ›´æ˜¯**å¿…è¦æ¡ä»¶**ã€‚

### æ¶ˆèå®éªŒä¸åˆ†æï¼ˆæ¥è‡ªé™„å½•ï¼‰
- **Zero-Initialization Gating**ï¼šè‹¥ä¸åˆå§‹åŒ–é—¨æ§ä¸ºé›¶ï¼Œåˆ™ SNC æ³¨å…¥ä¼šç ´åé¢„è®­ç»ƒç‰¹å¾åˆ†å¸ƒï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚
- **Agreement Head çš„ä½œç”¨**ï¼šç§»é™¤è¯¥æ¨¡å—åï¼Œrollback æœºåˆ¶å¤±æ•ˆï¼ŒCoherence Drift æ˜¾è‘—ä¸Šå‡ã€‚
- **Note Bus å®¹é‡æ§åˆ¶**ï¼šè¿‡å¤§çš„ Note Buffer å¯¼è‡´å†…å­˜å‹åŠ›å¢åŠ ï¼Œä¸”è¾¹é™…æ”¶ç›Šé€’å‡ï¼›å»ºè®®ç»“åˆ summarization æ§åˆ¶ `Cbus`ã€‚
- **Stochastic Cadence æ¨¡æ‹Ÿ**ï¼ˆé™„å½• Eï¼‰ï¼š
  - é”™è¯¯å‘ˆâ€œçªå‘æ€§â€ï¼ˆclusteredï¼‰åè€Œé™ä½ rollback é¢‘ç‡ï¼ˆä» 9.87% â†’ 5.45%ï¼‰ï¼Œè¯´æ˜ PDT å¯¹çœŸå®åœºæ™¯ä¸­çš„ bursty inconsistency å…·æœ‰é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ¨¡å‹å†…éƒ¨å¹¶è¡Œè§£ç å¯è¡Œ**ï¼šé€šè¿‡ SNC æœºåˆ¶ï¼Œå¯åœ¨å†»ç»“ä¸»å¹²ä¸Šå®ç°å¤šæµååŒç”Ÿæˆï¼Œçªç ´ä¼ ç»Ÿè‡ªå›å½’ç“¶é¢ˆã€‚
2. âœ… **æ— éœ€å…¨æ¨¡å‹å¾®è°ƒå³å¯å®ç°è¯­ä¹‰åŒæ­¥**ï¼šè½»é‡çº§é€‚é…å™¨è¶³ä»¥å­¦ä¼šè·¨æµåè°ƒï¼Œä¿ç•™åŸå§‹æ¨¡å‹èƒ½åŠ›çš„åŒæ—¶å¢å¼ºç»“æ„åŒ–è¾“å‡ºã€‚
3. âœ… **é«˜ç²¾åº¦è‡ªæˆ‘çº æ­£æœºåˆ¶æœ‰æ•ˆ**ï¼šCoverage Precision è¾¾ 77.8%ï¼Œè¯æ˜ç³»ç»Ÿèƒ½å¯é åˆ¤æ–­ç”Ÿæˆå†…å®¹æ˜¯å¦ç¬¦åˆé¢„æœŸè¯­ä¹‰ã€‚
4. âœ… **å‚æ•°æ•ˆç‡æ˜¯å¤§è§„æ¨¡æ¨¡å‹éƒ¨ç½²çš„å…³é”®**ï¼šå®éªŒè¯æ˜ï¼Œ20B çº§æ¨¡å‹æ— æ³•æ‰¿å—å…¨å¾®è°ƒå¸¦æ¥çš„æ˜¾å­˜å¼€é”€ï¼Œâ€œMemory Cliffâ€çœŸå®å­˜åœ¨ã€‚
5. âœ… **ä¿å®ˆç­–ç•¥ä¼˜äºæ¿€è¿›è¦†ç›–**ï¼šä½ Recall + é«˜ Precision çš„ç»„åˆæå‡äº†ç³»ç»Ÿå®‰å…¨æ€§ï¼Œé¿å…è™šå‡è¿›åº¦å£°æ˜ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **é™æ€æµæ•°é‡**ï¼šå½“å‰å¹¶è¡Œæµæ•°å›ºå®šï¼Œä¸èƒ½æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´ã€‚
- **Note Schema è®¾è®¡ä¾èµ–å…ˆéªŒ**ï¼šNotes Contract éœ€äººå·¥æˆ–å¼º Teacher æ¨¡å‹æ„é€ ï¼Œå°šæœªå®Œå…¨è‡ªåŠ¨åŒ–ã€‚
- **æ¨ç†å¼€é”€ç•¥æœ‰å¢åŠ **ï¼šSNC æ³¨æ„åŠ›ä¸ Agreement åˆ¤æ–­å¸¦æ¥ä¸€å®šè®¡ç®—è´Ÿæ‹…ï¼Œè™½è¿œå°äºå…¨å¾®è°ƒï¼Œä½†ä»é«˜äºçº¯è‡ªå›å½’ã€‚
- **æ‰©å±•æ€§å—é™äºå…±äº«æ€»çº¿**ï¼šå½“å‰ Note Bus é‡‡ç”¨å…¨è¿æ¥æ¨¡å¼ï¼Œå½“æµæ•° N > 6 æ—¶åŒæ­¥å¼€é”€çº¿æ€§å¢é•¿ï¼Œå½±å“å¯æ‰©å±•æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…æå‡ºï¼‰
1. **Dynamic Stream Allocation**ï¼šPlanner Head åŠ¨æ€å†³å®šå¹¶è¡Œæµæ•°é‡ã€‚
2. **Hierarchical Note Schemas**ï¼šæ”¯æŒåµŒå¥—å‘½åç©ºé—´ï¼Œå®ç°é€’å½’ä»»åŠ¡åˆ†è§£ã€‚
3. **Hardware-aware SNC Kernels**ï¼šè¿›ä¸€æ­¥ä¼˜åŒ– Note Read æ“ä½œçš„å»¶è¿Ÿï¼Œé€¼è¿‘æ‰¹é‡è§£ç é€Ÿåº¦ã€‚
4. **Security Analysis**ï¼šç ”ç©¶ç±»ä¼¼ speculative execution çš„ä¾§ä¿¡é“æ”»å‡»é£é™©ï¼ˆå¦‚ä¿¡æ¯æ³„éœ²ï¼‰ã€‚
5. **å¼€æ”¾èµ„æº**ï¼šä½œè€…å·²å¼€æºä»£ç ã€æ•°æ®é›†ä¸é€‚é…å™¨æƒé‡ï¼Œæ¨åŠ¨ model-internal parallelism ç ”ç©¶ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> PDT æå‡ºäº†ä¸€ç§**å‚æ•°é«˜æ•ˆçš„æ¨¡å‹å†…å¹¶è¡Œè§£ç æ¡†æ¶**ï¼Œé€šè¿‡ **Speculative Note Conditioning** å®ç°å¤šæµè¯­ä¹‰åŒæ­¥ï¼Œåœ¨ä¸ä¿®æ”¹ä¸»å¹²æƒé‡çš„å‰æä¸‹ï¼Œä»¥ <5% çš„é¢å¤–å‚æ•°å®ç°äº†é«˜è¾¾ **77.8% çš„ coverage precision**ï¼Œè§£å†³äº† SoT ç±»æ–¹æ³•çš„ Coherence Drift é—®é¢˜ï¼Œå¹¶åœ¨ç¡¬ä»¶å±‚é¢éªŒè¯äº†å…¶å¯¹â€œMemory Cliffâ€çš„è§„é¿èƒ½åŠ›ï¼Œä¸ºä¸‹ä¸€ä»£ç™¾Bçº§æ¨¡å‹çš„é«˜æ•ˆæ¨ç†æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 3. [Design Space Exploration of DMA based Finer-Grain Compute Communication Overlap](https://arxiv.org/abs/2512.10236)

**Authors**: Shagnik Pal, Shaizeen Aga, Suchita Pati, Mahzabeen Islam, Lizy K. John  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.10236v1  

#### Abstract
As both ML training and inference are increasingly distributed, parallelization techniques that shard (divide) ML model across GPUs of a distributed system, are often deployed. With such techniques, there is a high prevalence of data-dependent communication and computation operations where communica...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDesign Space Exploration of DMA based Finer-Grain Compute Communication Overlap

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰è®­ç»ƒå’Œæ¨ç†ä¸­ï¼Œ**é€šä¿¡ä¸è®¡ç®—çš„ä¾èµ–å…³ç³»**å¯¼è‡´é€šä¿¡æ“ä½œæš´éœ²åœ¨å…³é”®è·¯å¾„ä¸Šï¼ˆon-critical-path data-dependent communicationï¼‰ï¼Œæ— æ³•è¢«æœ‰æ•ˆéšè—ã€‚å°¤å…¶æ˜¯åœ¨ **tensor-sequence parallelismã€context-parallelism å’Œ expert-parallelism** ç­‰å¹¶è¡Œç­–ç•¥ä¸­ï¼Œé€šä¿¡ç›´æ¥ä½œä¸ºåç»­è®¡ç®—çš„è¾“å…¥ï¼Œé€ æˆä¸¥é‡çš„æ€§èƒ½ç“¶é¢ˆã€‚

ç°æœ‰åŸºäº **shard-level overlap** çš„æ–¹æ³•è™½ç„¶å°è¯•é‡å é€šä¿¡ä¸è®¡ç®—ï¼Œä½†åœ¨ä»¥ä¸‹æ–¹é¢å­˜åœ¨å±€é™ï¼š
- ä»…æ”¯æŒ **peer-to-peer (P2P)** é€šä¿¡æ¨¡å¼ï¼Œåœ¨å…¨è¿æ¥æ‹“æ‰‘ï¼ˆå¦‚ AMD MI300X çš„ Infinity Fabricï¼‰ä¸­åˆ©ç”¨ç‡ä½ï¼›
- é‡å ç²’åº¦ç²—ï¼Œé™åˆ¶äº†åç»­æ“ä½œçš„æ•°æ®æµç»†ç²’åº¦ï¼›
- åœ¨éäº¤æ¢æœºç½‘ç»œæ‹“æ‰‘ä¸‹æ€§èƒ½ä¸‹é™ä¸¥é‡ï¼ˆæœ€é«˜å¯è¾¾ 3.9Ã— æ…¢äºä¸²è¡Œæ‰§è¡Œï¼‰ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç»†ç²’åº¦é€šä¿¡-è®¡ç®—é‡å æœºåˆ¶ â€”â€” **FiCCO (Finer-Grain Compute-Communication Overlap)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> å°†é€šä¿¡æ“ä½œåˆ†è§£åˆ°æ¯” shard-level æ›´ç»†çš„ä¸€å±‚ï¼ˆä¾‹å¦‚ï¼Œåœ¨ 8-GPU ç³»ç»Ÿä¸­ï¼Œä¼ è¾“å¤§å°ä¸º shard çš„ 1/8ï¼‰ï¼Œå®ç°æ›´æ·±å±‚æ¬¡çš„é‡å ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. **å¼•å…¥ FiCCO æ¶æ„**ï¼š
   - é€šä¿¡æŒ‰æ›´ç»†ç²’åº¦åˆ†ç‰‡ï¼ˆone-level deeper shardingï¼‰ï¼›
   - æ”¯æŒ **all-to-all (A2A)** é€šä¿¡æ¨¡å¼ï¼Œå……åˆ†åˆ©ç”¨å…¨è¿æ¥æ‹“æ‰‘å¸¦å®½ï¼›
   - å…è®¸çµæ´»é…ç½®è®¡ç®—ç²’åº¦ï¼ˆå¯åŒ¹é…æˆ–é«˜äºé€šä¿¡ç²’åº¦ï¼‰ï¼›

2. **æ„å»º FiCCO è®¾è®¡ç©ºé—´**ï¼š
   - æ¢ç´¢å¤šç§è°ƒåº¦ç­–ç•¥ï¼Œæ¶µç›–é€šä¿¡ç»´åº¦ï¼ˆ1D/2Dï¼‰ã€è®¡ç®—èåˆæ–¹å¼ï¼ˆfused/unfusedï¼‰ã€æ‰§è¡Œå‡åŒ€æ€§ï¼ˆuniform/heteroï¼‰ç­‰ç»„åˆï¼›
   - æå‡º 8 ç§æ½œåœ¨è°ƒåº¦æ–¹æ¡ˆï¼Œå¹¶åˆ†æå…¶æ•ˆç‡ç‰¹å¾ã€‚

3. **ç³»ç»ŸåŒ–åˆ»ç”»é‡å å¼€é”€ï¼ˆInefficiency Characterizationï¼‰**ï¼š
   - å®šä¹‰ä¸¤ç±»å…³é”®å¼€é”€ï¼š
     - **Decomposition Inefficiency Loss (DIL)**ï¼šå› ç®—å­æ‹†åˆ†å¯¼è‡´çš„å•ä¸ªæ“ä½œå˜æ…¢ï¼›
     - **Contention Inefficiency Loss (CIL)**ï¼šå¹¶å‘æ‰§è¡Œæ—¶èµ„æºäº‰ç”¨å¸¦æ¥çš„æ€§èƒ½æŸå¤±ï¼›
   - åˆ†æä¸åŒ GEMM å‚æ•°ï¼ˆå¦‚ OTBã€MTï¼‰å¯¹ DIL/CIL çš„å½±å“ã€‚

4. **æå‡ºå¯å‘å¼è°ƒåº¦é€‰æ‹©æœºåˆ¶ï¼ˆHeuristicsï¼‰**ï¼š
   - åŸºäº GEMM çš„ **op-to-byte ratio (OTB)** å’Œ **memory traffic (MT)** è‡ªåŠ¨æ¨èæœ€ä¼˜ FiCCO è°ƒåº¦ï¼›
   - ç»“åˆç¡¬ä»¶ç‰¹æ€§ï¼ˆå³°å€¼ç®—åŠ›ä¸å¸¦å®½ä¹˜ç§¯ï¼‰è¿›è¡Œé˜ˆå€¼åˆ’åˆ†ã€‚

5. **åˆ©ç”¨ GPU DMA å¼•æ“å¸è½½é€šä¿¡**ï¼š
   - é¿å… GPU æ ¸å¿ƒå‚ä¸é€šä¿¡è°ƒåº¦ï¼Œæ˜¾è‘—é™ä½ CIL ä¸­çš„ compute interferenceï¼›
   - æå‡ç¼“å­˜å’Œå†…å­˜å­ç³»ç»Ÿçš„å¯ç”¨æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | Shard-based Overlap | FiCCO |
|------|---------------------|-------|
| é€šä¿¡æ¨¡å¼ | Peer-to-Peer (P2P) | All-to-All (A2A) |
| æ‹“æ‰‘é€‚åº”æ€§ | é€‚åˆäº¤æ¢æœºç½‘ç»œ | æ›´é€‚é…å…¨è¿æ¥ç›´è¿æ‹“æ‰‘ï¼ˆå¦‚ MI300Xï¼‰ |
| æ•°æ®æµç²’åº¦ | è¾ƒç²—ï¼ˆshard-levelï¼‰ | æ›´ç»†ï¼Œåˆ©äºåç»­æµæ°´çº¿ä¼˜åŒ– |
| å¹¶å‘å¹²æ‰° | é«˜ï¼ˆå°¤å…¶ RCCL æ–¹æ¡ˆï¼‰ | æ˜¾è‘—é™ä½ï¼ˆé€šè¿‡ DMA å¸è½½ï¼‰ |
| æ€§èƒ½ä¸Šé™ | å—é™äºé“¾è·¯ç©ºé—² | å¯æ¥è¿‘ç†æƒ³é‡å é€Ÿåº¦ |
| è°ƒåº¦çµæ´»æ€§ | å›ºå®šæ¨¡å¼ | å¤šç§è°ƒåº¦å¯é€‰ï¼Œæ”¯æŒå®šåˆ¶åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›† / åœºæ™¯**

ç ”ç©¶åŸºäºçœŸå®ä¸–ç•Œçš„å¤§æ¨¡å‹éƒ¨ç½²åœºæ™¯ï¼Œé€‰å–äº†å¤šä¸ªå…¸å‹çš„ **ML workload**ï¼Œä¸»è¦åŒ…æ‹¬ï¼š

- **Tensor-Sequence Parallelism (SP+TP)**ï¼šç”¨äº Llama-2 å’Œ Llama-3 æ¨¡å‹ä¸­çš„ GEMM å±‚ï¼›
- **Expert Parallelism (EP)**ï¼šåº”ç”¨äº DeepSeek å’Œ Mixtral ç­‰ MoE æ¨¡å‹ï¼›
- æ‰€æœ‰æµ‹è¯•å‡å›´ç»• **GEMM + All-gather / All-to-all** çš„æ•°æ®ä¾èµ–å‹æ“ä½œå±•å¼€ã€‚

å…·ä½“ GEMM å®ä¾‹è§è¡¨ `Table I`ï¼Œå…± 16 ä¸ªå…¸å‹çŸ©é˜µä¹˜æ³•ä»»åŠ¡ï¼Œè¦†ç›–ä¸åŒ `(M, N, K)` è§„æ¨¡ã€‚

---

### **å®éªŒè®¾ç½®**

| é¡¹ç›® | é…ç½® |
|------|------|
| ç¡¬ä»¶å¹³å° | **AMD MI300X Infinity Platform C**ï¼Œ8Ã—MI300X GPU |
| äº’è”æ‹“æ‰‘ | å…¨è¿æ¥åŒå‘ Infinity Fabricï¼Œæ¯é“¾è·¯ **64 GB/s å•å‘å¸¦å®½** |
| è½¯ä»¶æ¡†æ¶ | PyTorch + ROCm |
| è®¡ç®—åº“ | hipBLASLtï¼ˆé«˜æ€§èƒ½ GEMM å†…æ ¸ï¼‰ |
| é€šä¿¡åº“ | RCCLï¼ˆæ ‡å‡†é›†åˆé€šä¿¡ï¼‰æˆ– `hipMemcpyDtoDAsync`ï¼ˆDMA å¸è½½ï¼‰ |
| å¹¶å‘æœºåˆ¶ | å¤š GPU stream å®ç°å¹¶å‘å†…æ ¸æ‰§è¡Œ |
| å†…å­˜ç®¡ç† | ä½¿ç”¨ symmetric memory é¿å…ä¸­é—´æ‹·è´ï¼Œæ”¯æŒ GPU é—´ç›´æ¥è®¿é—® |
| æµ‹é‡æ–¹å¼ | è¿è¡Œ 15 æ¬¡ï¼Œå‰ 10 æ¬¡é¢„çƒ­ï¼Œå 5 æ¬¡å–å¹³å‡å€¼ |

---

### **è¯„ä¼°æŒ‡æ ‡**

- **Speedup**ï¼šç›¸å¯¹äº baseline ä¸²è¡Œæ‰§è¡Œçš„æ—¶é—´åŠ é€Ÿæ¯”ï¼›
- **Geomean Speedup**ï¼šæ‰€æœ‰æµ‹è¯•æ¡ˆä¾‹çš„å‡ ä½•å¹³å‡åŠ é€Ÿï¼›
- **Ideal Speedup**ï¼šå‡è®¾æ—  DIL/CIL ä¸‹çš„ç†æƒ³åŠ é€Ÿä¸Šé™ï¼›
- **DIL / CIL å¼€é”€é‡åŒ–**ï¼šåˆ†åˆ«æµ‹é‡å› åˆ†è§£å’Œäº‰ç”¨é€ æˆçš„æ€§èƒ½é€€åŒ–ï¼›
- **Heuristic å‡†ç¡®ç‡**ï¼šé¢„æµ‹æœ€ä½³è°ƒåº¦çš„æˆåŠŸç‡ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Baseline Serial** | å…ˆå®Œæˆ all-gatherï¼Œå†å¯åŠ¨ GEMMï¼Œæ— ä»»ä½•é‡å  |
| **Shard-based Overlap** | ç±»ä¼¼ PyTorch AsyncTPï¼Œé‡‡ç”¨ P2P é€ shard é€šä¿¡å¹¶é‡å è®¡ç®— |
| **FiCCO-RCCL** | ä½¿ç”¨ RCCL è¿›è¡Œé€šä¿¡ï¼ˆç”± GPU core æ§åˆ¶ï¼‰ |
| **FiCCO-DMA** | ä½¿ç”¨ DMA å¼•æ“å¸è½½é€šä¿¡ï¼ˆæœ¬æ–‡ä¸»æ¨æ–¹æ¡ˆï¼‰ |
| **Triton-Distributed** | å°è¯•å¯¹æ¯”ï¼Œä½†å›  OOM æœªèƒ½è¿è¡ŒæˆåŠŸ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æ–¹æ³• | æœ€é«˜ Speedup | Geomean Speedup | ç›¸å¯¹äº Ideal çš„å æ¯” |
|------|-------------|------------------|-----------------------|
| **Shard-based Overlap** | < 1.0Ã—ï¼ˆéƒ¨åˆ†è´ŸåŠ é€Ÿï¼‰ | ~0.8â€“0.9Ã— | ä¸é€‚ç”¨ï¼ˆæœªè¾¾æ­£åŠ é€Ÿï¼‰ |
| **FiCCO (1D, DMA)** | **1.6Ã—** | ~1.4Ã— | è¾¾åˆ° ideal çš„ **52â€“76%**ï¼ˆç» DIL/CIL è°ƒæ•´åï¼‰ |
| **FiCCO (2D, Emulated)** | **1.7Ã—** | ~1.5Ã— | åŒä¸Š |
| **FiCCO-RCCL** | ~1.3Ã— | ~1.2Ã— | æ˜æ˜¾ä½äº DMA ç‰ˆæœ¬ |

> æ³¨ï¼šç”±äºå½“å‰ DMA ä¸æ”¯æŒ 2D memory copyï¼Œ2D æ–¹æ¡ˆé€šè¿‡ 1D æ¨¡æ‹Ÿå®ç°ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **ç›¸è¾ƒäº shard-based overlap**ï¼š
  - FiCCO å®ç°äº†ä»â€œæ— åŠ é€Ÿâ€åˆ°â€œæœ€é«˜ 1.6Ã— åŠ é€Ÿâ€çš„è·¨è¶Šï¼›
  - åœ¨ MI300X å…¨è¿æ¥æ‹“æ‰‘ä¸Šï¼Œshard-based å›  P2P å¯¼è‡´å¤§é‡é“¾è·¯é—²ç½®ï¼Œé€šä¿¡æ•ˆç‡ä¸‹é™é«˜è¾¾ 7Ã—ï¼›
  - FiCCO åˆ©ç”¨ A2A æ¨¡å¼å……åˆ†é¥±å’Œå¸¦å®½ï¼Œé¿å…é“¾è·¯æµªè´¹ã€‚

- **DMA vs. RCCL**ï¼š
  - ä½¿ç”¨ DMA å¸è½½é€šä¿¡åï¼ŒCIL æ˜¾è‘—é™ä½ï¼š
    - GEMM CIL ä» 1.11Ã—ï¼ˆRCCLï¼‰é™è‡³æ›´ä½æ°´å¹³ï¼›
    - é€šä¿¡ CIL ä¹Ÿä» 1.12Ã— å¾—åˆ°ç¼“è§£ï¼›
  - è¡¨æ˜ **DMA æ˜¯å®ç°é«˜æ•ˆé‡å çš„å…³é”®æ”¯æ’‘æŠ€æœ¯**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰DIL åˆ†æ

- **GEMM DIL**ï¼š
  - 64-way åˆ†ç‰‡æ¯” 8-way åˆ†ç‰‡å¸¦æ¥æ›´é«˜ DILï¼ˆæœ€å¤§å¯è¾¾ 2.3Ã— slowdownï¼‰ï¼›
  - å½“ GEMM çš„ **OTBï¼ˆç®—æœ¯å¼ºåº¦ï¼‰è¾ƒä½æ—¶ï¼ŒDIL æ›´ä¸¥é‡**ï¼›
  - è¡Œåˆ†ç‰‡ï¼ˆM-shardingï¼‰åœ¨ M < K æ—¶è¡¨ç°æ›´å·®ã€‚

- **Communication DIL**ï¼š
  - FiCCO çš„ all-gather å› å°åŒ…ä¼ è¾“äº§ç”Ÿçº¦ **10% å‡ ä½•å¹³å‡å»¶è¿Ÿå¢åŠ **ï¼›
  - ä½†å¤§é€šä¿¡é‡ä¸‹è¶‹äºå¸¦å®½å—é™ï¼ŒDIL å½±å“å‡å°ã€‚

#### ï¼ˆ2ï¼‰CIL åˆ†æ

- **GEMM CIL**ï¼š
  - å— GEMM memory traffic (MT) æ­£å‘å½±å“ï¼šMT è¶Šé«˜ï¼ŒCIL è¶Šä¸¥é‡ï¼›
  - DMA æ˜¾è‘—ä¼˜äº RCCLï¼Œå› å…¶æ¶ˆé™¤ compute interferenceã€‚

- **Communication CIL**ï¼š
  - åŒæ ·éš MT å¢åŠ è€Œä¸Šå‡ï¼›
  - geomean CIL â‰ˆ 1.12Ã—ã€‚

#### ï¼ˆ3ï¼‰Heuristic å‡†ç¡®æ€§éªŒè¯

- åœ¨åŸå§‹ 16 ä¸ªçœŸå®åœºæ™¯ä¸­ï¼š**å‡†ç¡®ç‡ 100%**ï¼›
- åœ¨é¢å¤–ç”Ÿæˆçš„ 16 ä¸ªåˆæˆåœºæ™¯ä¸­ï¼š**å‡†ç¡®ç‡è¾¾åˆ° 81%**ï¼›
- é”™è¯¯é¢„æµ‹æƒ…å†µä¸‹ï¼Œæ€§èƒ½æŸå¤±å¹³å‡çº¦ä¸º **14% çš„ speedup**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **æ›´ç»†ç²’åº¦çš„é€šä¿¡-è®¡ç®—é‡å ï¼ˆFiCCOï¼‰å¯è¡Œä¸”å¿…è¦**ï¼š
   - ç›¸è¾ƒäºä¼ ç»Ÿçš„ shard-level overlapï¼ŒFiCCO èƒ½è§£é”æ›´å¤šè°ƒåº¦è‡ªç”±åº¦ï¼›
   - æ”¯æŒ all-to-all æ¨¡å¼ï¼Œç‰¹åˆ«é€‚ç”¨äºç°ä»£å…¨è¿æ¥ GPU æ‹“æ‰‘ï¼ˆå¦‚ MI300Xï¼‰ã€‚

2. **DMA å¸è½½é€šä¿¡è‡³å…³é‡è¦**ï¼š
   - æ˜¾è‘—å‡å°‘ compute å’Œ cache contentionï¼Œæå‡å¹¶å‘æ•ˆç‡ï¼›
   - æ˜¯å®ç°é«˜æ¯”ä¾‹é‡å çš„å‰ææ¡ä»¶ã€‚

3. **æ²¡æœ‰â€œä¸€åˆ€åˆ‡â€çš„æœ€ä¼˜è°ƒåº¦**ï¼š
   - ä¸åŒ GEMM å‚æ•°ï¼ˆOTBã€MTï¼‰å¯¼è‡´ä¸åŒçš„ DIL/CIL æƒè¡¡ï¼›
   - å¿…é¡»æ ¹æ® workload ç‰¹å¾åŠ¨æ€é€‰æ‹©è°ƒåº¦ç­–ç•¥ã€‚

4. **å¯å‘å¼è°ƒåº¦å…·æœ‰å¼ºæ³›åŒ–èƒ½åŠ›**ï¼š
   - åŸºäº OTB å’Œ MT çš„ heuristic åœ¨ 81% çš„æœªçŸ¥åœºæ™¯ä¸­ä»èƒ½åšå‡ºæ­£ç¡®å†³ç­–ï¼›
   - å¯é›†æˆè¿› ML runtime æˆ–ç¼–è¯‘å™¨è‡ªåŠ¨ä¼˜åŒ–ã€‚

5. **FiCCO æ˜¾è‘—ç¼©å°ä¸ç†æƒ³æ€§èƒ½ä¹‹é—´çš„å·®è·**ï¼š
   - åœ¨å®é™…éƒ¨ç½²ä¸­è¾¾åˆ°ç†æƒ³åŠ é€Ÿçš„ **52â€“76%**ï¼›
   - ç›¸æ¯” shard-based æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¯è¾¾ **1.6Ã—**ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **DMA åŠŸèƒ½é™åˆ¶**ï¼š
   - å½“å‰ä¸æ”¯æŒ 2D memory copyï¼Œé™åˆ¶äº† 2D åˆ†ç‰‡çš„å®é™…æ€§èƒ½ï¼›
   - ä¸æ”¯æŒå¸¦è¿ç®—çš„é€šä¿¡ï¼ˆå¦‚ reduce-scatter with mathï¼‰ï¼Œæ— æ³•è¦†ç›– tensor parallelism å…¨éƒ¨åœºæ™¯ã€‚

2. **å°æ“ä½œçš„å¯åŠ¨å¼€é”€**ï¼š
   - éšç€åˆ†ç‰‡å¢å¤šï¼Œkernel launch æ¬¡æ•°ä¸Šå‡ï¼ŒCPU å¼€é”€å¯èƒ½æˆä¸ºç“¶é¢ˆï¼›
   - è™½å¯é€šè¿‡ graph-based launch ç¼“è§£ï¼Œä½†ä»éœ€å…³æ³¨ã€‚

3. **è·¨ GPU æ‰§è¡Œå·®å¼‚**ï¼š
   - è§‚å¯Ÿåˆ°ç›¸åŒæ“ä½œåœ¨ä¸åŒ GPU ä¸Šæ‰§è¡Œæ—¶é—´å·®å¼‚ â‰¤6%ï¼Œè™½å°ä½†ä»å­˜åœ¨ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³å…¶ä»–é€šä¿¡åŸè¯­**ï¼š
   - å¦‚ reduce-scatterã€broadcast ç­‰ï¼Œå°¤å…¶æ˜¯æ”¯æŒæ•°å­¦æ“ä½œçš„ DMA æ‰©å±•ã€‚

2. **ç»“åˆç¼–è¯‘å™¨è‡ªåŠ¨åŒ–è°ƒåº¦**ï¼š
   - å°† FiCCO è°ƒåº¦ç©ºé—´åµŒå…¥ MLIR æˆ– Triton ç¼–è¯‘æµç¨‹ï¼Œå®ç°è‡ªåŠ¨ä»£ç ç”Ÿæˆã€‚

3. **æ¢ç´¢ç¡¬ä»¶ååŒè®¾è®¡**ï¼š
   - å¦‚ ACEã€T3 ç­‰ä¸“ç”¨æ¨¡å—å¯è¿›ä¸€æ­¥é™ä½ CILï¼Œæœªæ¥å¯è€ƒè™‘è½¯ç¡¬ååŒä¼˜åŒ–ã€‚

4. **æ”¯æŒåŠ¨æ€è´Ÿè½½å‡è¡¡**ï¼š
   - åœ¨ MoE åœºæ™¯ä¸­åº”å¯¹ token åˆ†å¸ƒä¸å‡å¸¦æ¥çš„é€šä¿¡ä¸å¯¹ç§°é—®é¢˜ã€‚

5. **æ¨å¹¿è‡³æ›´å¤šæ¨¡å‹æ¶æ„å’Œå¹¶è¡ŒèŒƒå¼**ï¼š
   - åŒ…æ‹¬ vision transformerã€diffusion models ç­‰æ–°å…´ç»“æ„ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **FiCCO + DMA å¸è½½** æ¶æ„æ‰“ç ´äº†ä¼ ç»Ÿ shard-level é‡å çš„å±€é™ï¼Œé€šè¿‡æ›´ç»†ç²’åº¦çš„ all-to-all é€šä¿¡è°ƒåº¦ï¼Œåœ¨çœŸå®å¤§æ¨¡å‹åœºæ™¯ä¸­å®ç°äº†é«˜è¾¾ **1.6Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œå¹¶æä¾›äº†å¯æ³›åŒ–çš„å¯å‘å¼è°ƒåº¦è§„åˆ™ï¼Œä¸ºä¸‹ä¸€ä»£åˆ†å¸ƒå¼ ML ç³»ç»Ÿçš„é€šä¿¡ä¼˜åŒ–æä¾›äº†é‡è¦è®¾è®¡æŒ‡å—ã€‚

</details>

---

### 4. [InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck](https://arxiv.org/abs/2512.10305)

**Authors**: Quanmin Wei, Penglin Dai, Wei Li, Bingyi Liu, Xiao Wu  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.10305v1  

#### Abstract
Precise environmental perception is critical for the reliability of autonomous driving systems. While collaborative perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-eff...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck  
â€”â€”æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¾èµ–**ç²¾ç¡®çš„ç¯å¢ƒæ„ŸçŸ¥**ï¼Œè€Œå•æ™ºèƒ½ä½“æ„ŸçŸ¥å—é™äºè§†é‡é®æŒ¡ç­‰é—®é¢˜ã€‚**ååŒæ„ŸçŸ¥**ï¼ˆCollaborative Perceptionï¼‰é€šè¿‡å¤šè½¦ä¹‹é—´å…±äº«ä¿¡æ¯æå‡æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½†é¢ä¸´ä¸€ä¸ªæ ¹æœ¬çŸ›ç›¾ï¼š**é€šä¿¡å¼€é”€ä¸æ„ŸçŸ¥æ€§èƒ½ä¹‹é—´çš„æƒè¡¡**ã€‚

ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Where2commã€ERMVPï¼‰é€šå¸¸å‡è®¾æ¯æ¬¡åä½œä¼ è¾“ **MBçº§æ•°æ®**ï¼Œä½†åœ¨å®é™…è½¦è½½ç½‘ç»œä¸­ï¼ˆå¦‚5G-V2Xï¼‰ï¼Œå¸¦å®½æ³¢åŠ¨å‰§çƒˆï¼Œå¹³å‡ä»…çº¦3.5 MB/sï¼Œæç«¯æƒ…å†µä¸‹å¯ä½è‡³0.4 MB/sï¼Œå¯¼è‡´é€šä¿¡å»¶è¿Ÿç”šè‡³å¤±è´¥ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•å¤šåŸºäº**å¯å‘å¼ç‰¹å¾æ“ä½œ**ï¼ˆfeature manipulationï¼‰ï¼Œç¼ºä¹ç†è®ºæ”¯æ’‘ï¼Œéš¾ä»¥åœ¨æé«˜å‹ç¼©ä¸‹ä¿æŒæ„ŸçŸ¥ç²¾åº¦ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **InfoCom**ï¼Œä¸€ç§åŸºäº**ä¿¡æ¯ç“¶é¢ˆ**ï¼ˆInformation Bottleneck, IBï¼‰åŸç†çš„æ–°å‹é€šä¿¡é«˜æ•ˆååŒæ„ŸçŸ¥æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ˜¯å¼•å…¥â€œ**ä¿¡æ¯å‡€åŒ–**â€ï¼ˆinformation purificationï¼‰èŒƒå¼ï¼Œè€Œéä¼ ç»Ÿçš„ç‰¹å¾é€‰æ‹©æˆ–å‹ç¼©ã€‚

#### æ ¸å¿ƒåˆ›æ–°æ¨¡å—ï¼š
1. **Information-Aware Encoding (IAE)**  
   åŸºäºæ‰©å±•çš„ IB åŸç†ï¼Œå°†é«˜ç»´ä¸­é—´ç‰¹å¾ $Z$ æ˜ å°„ä¸ºæä½ç»´çš„ä¿¡æ¯æ„ŸçŸ¥ç‰¹å¾ $E \in \mathbb{R}^D$ï¼ˆ$D \ll C\times H\times W$ï¼‰ï¼Œä¿ç•™ä»»åŠ¡ç›¸å…³çš„å…³é”®ä¿¡æ¯ï¼ŒåŒæ—¶æœ€å°åŒ–å†—ä½™ã€‚

2. **Sparse Mask Generation (SMG)**  
   ç”Ÿæˆç¨€ç–ç©ºé—´æ©ç  $M$ï¼Œæ ‡è¯†å¯¹æ„ŸçŸ¥ä»»åŠ¡æœ€å…³é”®çš„åŒºåŸŸã€‚è¯¥æ©ç ç»è¿‡**è¿‡æ»¤**ï¼ˆTop-Kï¼‰å’Œ**é‡åŒ–**ï¼ˆ4-bitï¼‰å¤„ç†ï¼Œé€šä¿¡æˆæœ¬æä½ã€‚

3. **Multi-Scale Decoding (MSD)**  
   åœ¨æ¥æ”¶ç«¯ï¼Œåˆ©ç”¨ $E$ å’Œ $M$ è¿›è¡Œ**æ©ç å¼•å¯¼çš„æ¸è¿›å¼é‡å»º**ï¼Œé€æ­¥æ¢å¤å‡ºå¯ç”¨äºèåˆçš„ BEV ç‰¹å¾ï¼Œè€Œéç®€å•é‡æ„åŸå§‹ç‰¹å¾å›¾ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | InfoCom | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Where2comm, ERMVPï¼‰ |
|------|--------|-------------------------------|
| **é€šä¿¡æ•ˆç‡** | **KBçº§**ï¼ˆ2.7â€“7.9 KBï¼‰ | MBçº§ï¼ˆ0.5â€“34 MBï¼‰ |
| **ç†è®ºåŸºç¡€** | åŸºäº IB çš„ä¿¡æ¯è®ºåˆ†æï¼Œæä¾›å™ªå£°æŠ‘åˆ¶ä¸ä¿¡æ¯ä¿ç•™çš„ç†è®ºä¿è¯ | å¤šä¸ºå¯å‘å¼è®¾è®¡ï¼Œç¼ºä¹ç†è®ºæ”¯æŒ |
| **æ€§èƒ½è¡¨ç°** | æ¥è¿‘æ ‡å‡†åä½œï¼ˆStandard Collaborationï¼‰æ€§èƒ½ | æ˜æ˜¾ä½äºæ ‡å‡†åä½œ |
| **æ¨¡å—åŒ–ç¨‹åº¦** | Plug-and-playï¼Œå¯æ— ç¼é›†æˆåˆ°ç°æœ‰æ¨¡å‹ï¼ˆå¦‚ CoAlign, AttFuseï¼‰ | éœ€å®šåˆ¶åŒ–è®¾è®¡ |
| **æŠ—å™ªèƒ½åŠ›** | é€šè¿‡ IB æ­£åˆ™åŒ–ä¸é‡åŒ–å®ç°å™ªå£°æŠ‘åˆ¶ | æ— æ˜¾å¼å™ªå£°å»ºæ¨¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

åœ¨ä¸‰ä¸ªä»£è¡¨æ€§ååŒæ„ŸçŸ¥æ•°æ®é›†ä¸Šè¿›è¡ŒéªŒè¯ï¼š
- **OPV2V** (Xu et al., 2021)ï¼šä»¿çœŸ V2V æ•°æ®é›†
- **V2XSet** (Xu et al., 2022)ï¼šä»¿çœŸ V2X æ•°æ®é›†
- **DAIR-V2X** (Yu et al., 2022)ï¼šçœŸå®ä¸–ç•Œè½¦-åŸºç¡€è®¾æ–½ååŒæ„ŸçŸ¥æ•°æ®é›†

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **ä»»åŠ¡**ï¼š3D ç›®æ ‡æ£€æµ‹
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Average Precision (AP)** @ IoU 0.3, 0.5, 0.7
  - **é€šä¿¡ä½“ç§¯**ï¼ˆCommunication Volumeï¼‰ï¼šä»¥ KB æˆ– MB ä¸ºå•ä½ï¼Œè¡¡é‡æ¯è½®åä½œçš„ä¼ è¾“é‡
- **ä¸»å¹²æ¨¡å‹**ï¼š
  - é»˜è®¤ä½¿ç”¨ **CoAlign**ï¼ˆLu et al., 2023ï¼‰
  - åŒæ—¶æµ‹è¯• **AttFuse** å’Œ **MKD-Cooper** éªŒè¯è·¨æ¨¡å‹å…¼å®¹æ€§
- **ç¡¬ä»¶é…ç½®**ï¼šRTX 3090 GPUï¼ŒUbuntu 20.04ï¼ŒPyTorch 1.10

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | ç±»å‹ | é€šä¿¡æœºåˆ¶ |
|------|------|----------|
| **No Collaboration** | åŸºçº¿ | ä¸é€šä¿¡ |
| **Late Collaboration** | åŸºçº¿ | ä»…ä¼ æ£€æµ‹ç»“æœï¼ˆ~6.25 KBï¼‰ |
| **Standard Collaboration** | ä¸Šé™ | ä¼ å®Œæ•´ä¸­é—´ç‰¹å¾ï¼ˆ~24â€“34 MBï¼‰ |
| **Where2comm** (Hu et al., 2022) | ç‰¹å¾é€‰æ‹© | åŸºäºç©ºé—´é‡è¦æ€§åŠ æƒé€‰æ‹©ç‰¹å¾ |
| **ERMVP** (Zhang et al., 2024) | ç‰¹å¾å‹ç¼© | ç©ºé—´æ»¤æ³¢ + èšç±»é™ç»´ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰**

| æ•°æ®é›† | æ–¹æ³• | é€šä¿¡ä½“ç§¯ | AP@30 | AP@50 | AP@70 |
|-------|------|---------|--------|--------|--------|
| **OPV2V** | Standard Colla. | 34.375 MB | 0.9709 | 0.9653 | 0.9229 |
| | Where2comm | 3.439 MB | 0.9548 | 0.9463 | 0.8820 |
| | ERMVP | 0.741 MB | 0.9618 | 0.9557 | 0.9127 |
| | **InfoCom (Ours)** | **7.875 KB** | **0.9702** | **0.9650** | **0.9202** |
| **V2XSet** | Standard Colla. | 34.375 MB | 0.9317 | 0.9212 | 0.8426 |
| | Where2comm | 3.439 MB | 0.8834 | 0.8604 | 0.7417 |
| | ERMVP | OOM | â€” | â€” | â€” |
| | **InfoCom (Ours)** | **7.875 KB** | **0.9360** | **0.9273** | **0.8488** |
| **DAIR-V2X** | Standard Colla. | 24.609 MB | 0.8294 | 0.7843 | 0.6353 |
| | Where2comm | 2.462 MB | 0.8048 | 0.7539 | 0.6070 |
| | ERMVP | 0.531 MB | 0.8217 | 0.7791 | 0.6324 |
| | **InfoCom (Ours)** | **5.922 KB** | **0.8228** | **0.7789** | **0.6385** |

> âœ… InfoCom åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡è¾¾åˆ°**æ¥è¿‘æ ‡å‡†åä½œçš„æ€§èƒ½**ï¼Œè¿œè¶… Where2commï¼Œå¹¶æ˜¾è‘—ä¼˜äº ERMVPï¼ˆå°¤å…¶åœ¨ V2XSet ä¸Šåè€…å› å†…å­˜æº¢å‡ºæ— æ³•è¿è¡Œï¼‰ã€‚

### **é€šä¿¡æ•ˆç‡å¯¹æ¯”**

- **ç›¸æ¯” Where2comm**ï¼šé€šä¿¡é‡å‡å°‘ **440å€**
- **ç›¸æ¯” ERMVP**ï¼šé€šä¿¡é‡å‡å°‘ **90å€**
- **ç›¸æ¯”æ ‡å‡†åä½œ**ï¼šé€šä¿¡é‡å‡å°‘ **è¶…è¿‡ 4000å€**

ä¾‹å¦‚ï¼Œåœ¨ OPV2V ä¸Šï¼ŒInfoCom ä»…éœ€ **7.875 KB** å³å¯å®ç°ä¸ 34.375 MB ç›¸å½“çš„æ€§èƒ½ã€‚

### **è·¨æ¨¡å‹å…¼å®¹æ€§éªŒè¯ï¼ˆTable 2ï¼‰**

| æ¨¡å‹ | æ–¹æ³• | é€šä¿¡ä½“ç§¯ | Mean AP |
|------|------|---------|--------|
| MKD-Cooper | Standard | 34.375 MB | 0.9575 |
| | Where2comm | 3.438 MB | 0.9134 |
| | ERMVP | 0.701 MB | 0.8946 |
| | **InfoCom** | **2.718 KB** | **0.9640** âœ… |

> InfoCom ä¸ä»…æ€§èƒ½æ›´é«˜ï¼Œè¿˜**æå‡äº†åŸæ¨¡å‹ 1.27% çš„ Mean AP**ï¼Œè¯´æ˜å…¶ä¿¡æ¯å‡€åŒ–æœºåˆ¶èƒ½æœ‰æ•ˆå¢å¼ºå¼±ç‰¹å¾æå–æ¨¡å‹çš„è¡¨ç°ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰**

| å˜ä½“ | Mean AP |
|------|--------|
| **InfoCom (Full)** | **0.9518** |
| w/o IAEï¼ˆSimple Encoderï¼‰ | 0.9320 â†“ |
| w/o SMGï¼ˆSimple Generatorï¼‰ | 0.9379 â†“ |
| w/o STEï¼ˆæ¢¯åº¦ä¸­æ–­ï¼‰ | 0.8845 â†“â†“ |
| w/o Maskï¼ˆæ— æ©ç å¼•å¯¼ï¼‰ | 0.8839 â†“â†“ |
| w/o Multi-Scale Rec. | 0.9439 â†“ |

> æ‰€æœ‰ç»„ä»¶å‡æœ‰æ­£å‘è´¡çŒ®ï¼Œå°¤å…¶æ˜¯ **Sparse Mask Generation** å’Œ **Multi-Scale Decoding** å¯¹æ€§èƒ½è‡³å…³é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **KBçº§é€šä¿¡å¯è¡Œä¸”é«˜æ•ˆ**ï¼šInfoCom é¦–æ¬¡è¯æ˜ï¼Œåœ¨ä»…ä¼ è¾“ **å‡ KB** æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä»å¯å®ç°**æ¥è¿‘æ— æŸçš„ååŒæ„ŸçŸ¥æ€§èƒ½**ï¼Œçªç ´äº†ä¼ ç»Ÿ MB çº§é€šä¿¡çš„å‡è®¾ã€‚
2. **ä¿¡æ¯å‡€åŒ–ä¼˜äºç‰¹å¾æ“ä½œ**ï¼šé€šè¿‡ IB åŸç†æŒ‡å¯¼çš„ä¿¡æ¯æå–ï¼Œæ¯”ç›´æ¥æ“ä½œç©ºé—´ç‰¹å¾æ›´æœ‰æ•ˆï¼Œé¿å…äº†é«˜ç»´å†—ä½™å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚
3. **ç†è®ºä¸å®è·µç»“åˆ**ï¼šé¦–æ¬¡ä¸ºé€šä¿¡é«˜æ•ˆååŒæ„ŸçŸ¥æä¾›äº†åŸºäºä¿¡æ¯è®ºçš„ç†è®ºåˆ†æï¼ˆå¦‚å™ªå£°æŠ‘åˆ¶ç•Œã€ç†µçº¦æŸï¼‰ï¼Œå¼¥è¡¥äº†ä»¥å¾€æ–¹æ³•çš„ç»éªŒä¸»ä¹‰ç¼ºé™·ã€‚
4. **å³æ’å³ç”¨æ€§å¼º**ï¼šInfoCom å¯ä½œä¸ºé€šä¿¡å±‚æ›¿æ¢æ¨¡å—ï¼Œé€‚é…å¤šç§ä¸»æµååŒæ„ŸçŸ¥æ¶æ„ï¼Œå…·å¤‡è‰¯å¥½å·¥ç¨‹è½åœ°æ½œåŠ›ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- å½“å‰æ¶ˆæ¯å•å…ƒä»…åŒ…å«**ç©ºé—´ä¸Šä¸‹æ–‡**ï¼ˆsparse maskï¼‰ï¼Œå°šæœªè€ƒè™‘**æ—¶é—´åŠ¨æ€æ€§**ï¼ˆtemporal cuesï¼‰ï¼Œæ— æ³•åˆ¤æ–­æœªæ¥å¸§æ˜¯å¦éœ€è¦é€šä¿¡ã€‚
- æç«¯å‹ç¼©å¯èƒ½å¯¼è‡´æŸäº›è¾¹ç¼˜åœºæ™¯ï¼ˆå¦‚å¯†é›†é®æŒ¡ï¼‰ä¸‹çš„ä¿¡æ¯ä¸¢å¤±ï¼Œå°½ç®¡æ•´ä½“æ€§èƒ½ç¨³å®šã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- å°†å½“å‰åŒå…ƒç»„ $(E, M)$ æ‰©å±•ä¸º**ä¸‰å…ƒç»„** $(E, M, T)$ï¼ŒåŠ å…¥**æ—¶é—´çº¿ç´¢**ï¼Œå®ç°åŠ¨æ€é€šä¿¡å†³ç­–ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„é‡åŒ–ç­–ç•¥ä¸ç¼–ç æ–¹å¼ï¼Œè¿›ä¸€æ­¥é™ä½é€šä¿¡å»¶è¿Ÿã€‚
- åœ¨çœŸå®è½¦è½½ç½‘ç»œç¯å¢ƒä¸‹éƒ¨ç½²ï¼ŒéªŒè¯å…¶åœ¨å¤æ‚ä¿¡é“æ¡ä»¶ä¸‹çš„é²æ£’æ€§ã€‚

---

> ğŸ”— **ä»£ç åœ°å€**ï¼š[https://weiquanmin.github.io/infocom](https://weiquanmin.github.io/infocom)

</details>

---

### 5. [Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation](https://arxiv.org/abs/2512.10501)

**Authors**: Lim Chien Her, Ming Yan, Yunshu Bai, Ruihao Li, Hao Zhang  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.10501v1  

#### Abstract
Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-sho...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šZero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Procedural Content Generation (PCG)** å·¥å…·ä¾èµ–äºå¤æ‚ã€éç›´è§‚ä¸”é¢†åŸŸç‰¹å®šçš„æŠ€æœ¯å‚æ•°é…ç½®ï¼Œç”¨æˆ·éœ€å…·å¤‡ä¸“ä¸šçŸ¥è¯†æ‰èƒ½æœ‰æ•ˆæ§åˆ¶ç”Ÿæˆè¿‡ç¨‹ã€‚å°½ç®¡ **Large Language Models (LLMs)** è¢«å°è¯•ç”¨äºè‡ªç„¶è¯­è¨€é©±åŠ¨çš„ PCG æ§åˆ¶ï¼Œä½†ç°æˆï¼ˆoff-the-shelfï¼‰LLMs éš¾ä»¥å¼¥åˆ**æŠ½è±¡ç”¨æˆ·æŒ‡ä»¤**ä¸**ä¸¥æ ¼çš„å‚æ•°è§„èŒƒ**ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿï¼Œå¸¸å‡ºç°å‚æ•°å¹»è§‰æˆ–é”™è¯¯é…ç½®ã€‚

æ­¤å¤–ï¼Œå½“å‰ä¸»æµæ–¹æ³•ä¾èµ–**fine-tuningã€å¼ºåŒ–å­¦ä¹ æˆ–é¢†åŸŸé¢„è®­ç»ƒ**ï¼Œè¿™äº›æ–¹æ³•èµ„æºæ¶ˆè€—å¤§ã€æ³›åŒ–èƒ½åŠ›å·®ï¼Œéš¾ä»¥é€‚åº”ä¸åŒå·¥å…·æˆ–ä»»åŠ¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºä¸€ç§**æ— éœ€è®­ç»ƒçš„åŒæ™ºèƒ½ä½“æ¶æ„ï¼ˆDual-Agent Actor-Critic Architectureï¼‰**ï¼Œå®ç°å¯¹ PCG å·¥å…·çš„é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰æ§åˆ¶ï¼š

- **Actor Agent**ï¼šä½œä¸ºè¯­ä¹‰è§£é‡Šå™¨ï¼Œå°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æç¤ºï¼ˆnatural language promptï¼‰è½¬åŒ–ä¸ºåˆæ­¥çš„ **Parameter Trajectory Sequence**ï¼ˆå³ä¸€ç³»åˆ—ç®—æ³•è°ƒç”¨åŠå…¶å‚æ•°é…ç½®ï¼‰ã€‚
- **Critic Agent**ï¼šä½œä¸ºé™æ€éªŒè¯å™¨ï¼ŒåŸºäºæä¾›çš„ **API æ–‡æ¡£** å’Œ **å‚è€ƒç¤ºä¾‹ï¼ˆReference Demonstrationï¼‰** å¯¹ Actor æå‡ºçš„è½¨è¿¹è¿›è¡Œå®¡æŸ¥ï¼Œè¯†åˆ«å¹¶åé¦ˆâ€œé˜»å¡æ€§é—®é¢˜â€ï¼ˆå¦‚æ— æ•ˆå‚æ•°ã€è¶Šç•Œå€¼ã€ä¸å…¼å®¹ç®—æ³•ç»„åˆç­‰ï¼‰ã€‚
- ä¸¤è€…é€šè¿‡**è¿­ä»£å¯¹è¯æœºåˆ¶**ä¸æ–­ä¼˜åŒ–é…ç½®ï¼Œç›´åˆ° Critic æ‰¹å‡†æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚

è¯¥æ¡†æ¶å®Œå…¨ä¾èµ– **In-Context Learning (ICL)**ï¼Œæ— éœ€ä»»ä½•æ¨¡å‹å¾®è°ƒæˆ–é¢å¤–æ•°æ®æ”¶é›†ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ— éœ€è®­ç»ƒ** | å®Œå…¨é¿å…äº† fine-tuning æˆ– RL æ‰€éœ€çš„å¤§é‡æ ‡æ³¨æ•°æ®å’Œè®¡ç®—æˆæœ¬ã€‚ |
| **é«˜æ³›åŒ–æ€§** | åªéœ€æ›´æ¢æ–‡æ¡£å’Œç¤ºä¾‹å³å¯è¿ç§»åˆ°æ–°çš„ PCG å·¥å…·æˆ–å…¶ä»–ä¸“ä¸šè½¯ä»¶ï¼ˆå¦‚ CADã€MATLABï¼‰ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ |
| **æ›´å¼ºå¯é æ€§** | é€šè¿‡ Critic çš„æ˜¾å¼éªŒè¯æœºåˆ¶æ˜¾è‘—å‡å°‘å‚æ•°å¹»è§‰å’ŒåŠŸèƒ½é”™è¯¯ã€‚ |
| **å¯è§£é‡Šæ€§é«˜** | å†³ç­–è¿‡ç¨‹é€æ˜ï¼Œå¯é€šè¿‡å¯¹è¯æ—¥å¿—è¿½æº¯ä¿®æ­£è·¯å¾„ã€‚ |
| **é›¶æ ·æœ¬é€‚ç”¨** | åœ¨æœªè§è¿‡çš„ä»»åŠ¡ä¸Šä¹Ÿèƒ½æœ‰æ•ˆè¿è¡Œï¼Œé€‚ç”¨äºå¿«é€ŸåŸå‹è®¾è®¡ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„ç¯å¢ƒä¸å·¥å…·
- **ç›®æ ‡å¹³å°**ï¼šUnity å¼•æ“ä¸­çš„ **TileWorldCreator** æ’ä»¶ï¼Œæ”¯æŒå¤šç§ PCG ç®—æ³•ï¼ˆå¦‚ Perlin Noiseã€Cellular Automata ç­‰ï¼‰ç”¨äºç”Ÿæˆ 2D/3D åœ°å½¢ã€‚
- **LLM æ¨¡å‹**ï¼šé‡‡ç”¨ **Claude 3.5 Sonnet** ä½œä¸ºåŸºç¡€ LLMï¼Œé€šè¿‡ API è°ƒç”¨ã€‚
- **Agent æ„å»º**ï¼šåŸºäº Unity ç¼–è¾‘å™¨ AI åŠ©æ‰‹ **UGenLah** å®ç°è‡ªç„¶è¯­è¨€åˆ°ç¼–è¾‘å™¨å‘½ä»¤çš„æ˜ å°„ã€‚

### å®éªŒè®¾ç½®

#### Experiment I: å¤æ‚ä»»åŠ¡å¯é æ€§æµ‹è¯•ï¼ˆReliabilityï¼‰
- **ä»»åŠ¡**ï¼šç”Ÿæˆæ»¡è¶³å››ä¸ªçº¦æŸæ¡ä»¶çš„ 3D å±±åœ°åœ°å›¾ï¼š
  1. å•ä¸€å±±å³°ï¼ˆä¸èƒ½æœ‰å¤šä¸ªåˆ†ç¦»çš„é«˜åœ°ï¼‰
  2. æ­£å¥½ä¸‰å±‚é«˜åº¦ï¼ˆthree height layersï¼‰
  3. è‰åœ°ç‚¹ä»…å‡ºç°åœ¨å±±é¡¶å±‚
  4. å²©çŸ³æ•£å¸ƒåœ¨éå±±åœ°åŒºåŸŸ
- **è¯„ä¼°æ–¹å¼**ï¼š10 æ¬¡ç‹¬ç«‹è¿è¡Œï¼Œä¸å…è®¸åç»­äº¤äº’ï¼ˆpure zero-shotï¼‰ã€‚
- **å¯¹æ¯”åŸºçº¿**ï¼š
  - **Single-Agent (Actor + Resources)**ï¼šå•ä¸ª Agentï¼Œæ‹¥æœ‰ç›¸åŒæ–‡æ¡£å’Œç¤ºä¾‹è®¿é—®æƒé™ã€‚
  - **Off-the-shelf LLM**ï¼šæ— ä¸Šä¸‹æ–‡èµ„æºçš„åŸå§‹ LLMã€‚

#### Experiment II: æ•ˆç‡ä¸è‡ªä¸»æ€§æµ‹è¯•ï¼ˆEfficiencyï¼‰
- **ä»»åŠ¡ç±»å‹**ï¼šå››ç§ä¸åŒç±»å‹çš„åœ°å›¾ï¼ˆ2D Beach, 3D Mountain Island, 3D Hilly Golf Course, 2D Escape Mazeï¼‰ï¼Œæ¯ç§ä½¿ç”¨ä¸åŒçš„ PCG æµç¨‹ã€‚
- **å…è®¸è¿­ä»£ä¿®æ­£**ï¼šè‹¥å¤±è´¥ï¼Œæä¾›æè¿°æ€§åé¦ˆï¼ˆå¦‚â€œThe height layers are disconnectedâ€ï¼‰ï¼Œä½†ä¸ç»™å‡ºå…·ä½“è§£å†³æ–¹æ¡ˆã€‚
- **å¯¹æ¯”åŸºçº¿**ï¼š
  - **Actor-Critic**ï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰
  - **Single-Agent (w/ Docs)**
  - **Single-Agent (No Docs)**

### è¯„ä¼°æŒ‡æ ‡

| å®éªŒ | æŒ‡æ ‡ |
|------|------|
| **Experiment I** | 
| - **Task Success Rate (%)**ï¼šæ‰€æœ‰å…³é”®å…ƒç´ æ­£ç¡®å‡ºç°çš„æ¯”ä¾‹ |
| - **Average Mistakes per Run**ï¼šæ¯æ¬¡è¿è¡Œä¸­çš„æ¬¡ä¼˜å‚æ•°é€‰æ‹©æ•°é‡ |
| - **Failure Reasons Analysis**ï¼šåˆ†ç±»å¸¸è§å¤±è´¥åŸå›  |
| **Experiment II** |
| - **Token Usage**ï¼šæ€»è¾“å…¥è¾“å‡º token æ•°é‡ï¼ˆè¡¡é‡è®¡ç®—å¼€é”€ï¼‰ |
| - **Follow-up Prompts Required**ï¼šéœ€è¦å¤šå°‘è½®äººå·¥å¹²é¢„æ‰èƒ½æˆåŠŸ |
| - **Objective Completion**ï¼šæœ€ç»ˆæ˜¯å¦è¾¾æˆç›®æ ‡é…ç½® |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### Experiment I: å¯é æ€§ç»“æœï¼ˆ3D Mountain Mapï¼‰

| æŒ‡æ ‡ | Actor-Critic | Single-Agent (w/ Docs) |
|------|-------------|------------------------|
| **Success Rate (%)** | **80%** | 60% |
| **Relative Improvement** | **+33.3%** | â€” |
| **Average Mistakes (successful runs)** | 2.25 | 2.17 |

> âœ… å°½ç®¡é”™è¯¯æ•°ç•¥é«˜ï¼Œä½†å¤šä¸ºéè‡´å‘½æ€§ï¼›è€Œå•æ™ºèƒ½ä½“æ›´æ˜“å‘ç”Ÿå¯¼è‡´æ•´ä½“å¤±è´¥çš„å…³é”®é”™è¯¯ã€‚

#### å…¸å‹å¤±è´¥åˆ†æï¼š
- **Single-Agent** å¸¸è§é—®é¢˜ï¼š
  - 50% å¤±è´¥å› æœªæ·»åŠ  reference layer
  - 50% å› ç¼ºå°‘å¿…è¦ Generator/Modifier
- **Actor-Critic** æ˜¾è‘—æ”¹å–„äº†å¯¹â€œå•ä¸€å±±å³°â€çš„ç†è§£ï¼Œé€šè¿‡æ­£ç¡®é…ç½® Cellular Automata å‚æ•°é¿å…ç¢ç‰‡åŒ–åœ°å½¢ï¼ˆè§ Figure 6ï¼‰ã€‚

### Experiment II: æ•ˆç‡ä¸è‡ªä¸»æ€§ç»“æœ

| Map Type | Model | Tokens Used | Follow-up Prompts | Objective Achieved? |
|---------|-------|--------------|--------------------|---------------------|
| 2D Beach | Actor-Critic | 16,392 | **2** | âœ“ |
|          | Actor+Resources | 18,987 | **4** | âœ“ |
| 3D Mountain Island | Actor-Critic | 14,583 | **4** | âœ“ |
|                      | Actor+Resources | 11,873 | **5** | âœ“ |
| 3D Hilly Golf Course | Actor-Critic | **12,633** | **4** | âœ“ |
|                      | Actor+Resources | 18,676 | **6** | âœ“ |
| 2D Escape Maze | Actor-Critic | **4,589** | **2** | âœ“ |
|                | Actor | 7,722 | 3 | âœ“ |

> ğŸ” **å…³é”®å‘ç°**ï¼š
> - å¹³å‡ **token usage å‡å°‘ 12.7%**
> - **follow-up prompts å‡å°‘çº¦ 1.5 æ¬¡/ä»»åŠ¡**
> - å°½ç®¡ Critic å¢åŠ æ¨ç†æ­¥éª¤ï¼Œä½†å‡å°‘äº†æ— æ•ˆå°è¯•ï¼Œæå‡äº†æ•´ä½“æ•ˆç‡å’Œè‡ªä¸»æ€§ã€‚

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»ä»¥ä¸‹å¯¹æ¯”å¯å¾—å‡ºï¼š
- **æ— æ–‡æ¡£ vs æœ‰æ–‡æ¡£**ï¼šç¼ºä¹æ–‡æ¡£æ—¶ï¼ŒLLM å®Œå…¨æ— æ³•æ­£ç¡®è°ƒç”¨ APIï¼ŒéªŒè¯äº†é™æ€èµ„æºæ³¨å…¥çš„é‡è¦æ€§ã€‚
- **æœ‰æ—  Critic**ï¼šCritic æ˜¾è‘—æå‡æˆåŠŸç‡å’Œç¨³å®šæ€§ï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚çº¦æŸæ—¶ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º
1. **Off-the-shelf LLMs å¯è¢«æœ‰æ•ˆç”¨ä½œé€šç”¨æ§åˆ¶å™¨**ï¼šæ— éœ€ fine-tuningï¼Œä»…é€šè¿‡æ³¨å…¥æ–‡æ¡£å’Œç¤ºä¾‹å³å¯è®© LLM æŒæ¡å¤æ‚ PCG å·¥å…·çš„æ“ä½œé€»è¾‘ã€‚
2. **Dual-Agent æ¶æ„æ˜¾è‘—ä¼˜äºå•æ™ºèƒ½ä½“**ï¼šActor-Critic åˆ†å·¥æœºåˆ¶èƒ½æœ‰æ•ˆè§£å†³è¯­ä¹‰é¸¿æ²Ÿé—®é¢˜ï¼Œåœ¨é›¶æ ·æœ¬æ¡ä»¶ä¸‹å®ç°æ›´é«˜æˆåŠŸç‡ï¼ˆâ†‘20â€“33%ï¼‰å’Œæ›´å¼ºé²æ£’æ€§ã€‚
3. **In-Context Learning è¶³ä»¥åº”å¯¹é«˜ç»´å‚æ•°ç©ºé—´**ï¼šé€šè¿‡ç»“æ„åŒ– prompt è®¾è®¡å’Œè¿­ä»£åé¦ˆï¼Œå¯åœ¨ä¸æ›´æ–°æ¨¡å‹æƒé‡çš„æƒ…å†µä¸‹å®Œæˆç²¾ç¡®å‚æ•°é…ç½®ã€‚
4. **è¯¥èŒƒå¼å…·æœ‰å¹¿æ³›å¯è¿ç§»æ€§**ï¼šä¸ä»…é™äº PCGï¼Œè¿˜å¯æ¨å¹¿è‡³ CADã€ç§‘å­¦ä»¿çœŸã€éŸ³é¢‘åˆæˆç­‰ä¸“ä¸šè½¯ä»¶è‡ªåŠ¨åŒ–åœºæ™¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| **æ¨ç†å»¶è¿Ÿè¾ƒé«˜** | è¿­ä»£å¾ªç¯å¢åŠ äº†å“åº”æ—¶é—´ï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚ |
| **ç¼ºä¹é•¿æœŸè®°å¿†** | æ¯æ¬¡ä»»åŠ¡é‡ç½®ä¸Šä¸‹æ–‡ï¼Œæ— æ³•è·¨ä¼šè¯å­¦ä¹ ç»éªŒã€‚ |
| **ä¾èµ–é«˜è´¨é‡æ–‡æ¡£** | è‹¥æ–‡æ¡£ç¼ºå¤±æˆ–æ¨¡ç³Šï¼ŒCritic éªŒè¯èƒ½åŠ›ä¸‹é™ã€‚ |
| **å›ºå®šä¸Šä¸‹æ–‡çª—å£é™åˆ¶** | å¤šè½®è¿­ä»£å¯èƒ½å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ï¼Œå½±å“ä¸€è‡´æ€§ã€‚ |

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é™ä½æ¨ç†æˆæœ¬**ï¼š
   - ä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼ˆå¦‚ Llama-3-8B æˆ– Phi-3ï¼‰ä¸“é—¨æ‹…ä»» Critic è§’è‰²ã€‚
   - ç¼“å­˜å¸¸è§æˆåŠŸçš„ **parameter trajectories** ä»¥ä¾›å¤ç”¨ã€‚
2. **å¼•å…¥è¯Šæ–­å…ƒå±‚ï¼ˆDiagnostic Meta-Layerï¼‰**ï¼š
   - è‡ªåŠ¨å½’ç±»é‡å¤é”™è¯¯æ¨¡å¼ï¼Œå®ç°ä»â€œè¢«åŠ¨çº é”™â€åˆ°â€œä¸»åŠ¨é¢„é˜²â€çš„è½¬å˜ã€‚
3. **é›†æˆ Retrieval-Augmented Generation (RAG)**ï¼š
   - æ„å»ºå‘é‡æ•°æ®åº“å­˜å‚¨è¿‡å¾€æˆåŠŸç­–ç•¥ï¼Œå¢å¼ºé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚
4. **æ‰©å±•è‡³æ›´å¤šä¸“ä¸šé¢†åŸŸ**ï¼š
   - åº”ç”¨äº BIMã€Digital Twinã€Ansys ç­‰å·¥ç¨‹ä¸è®¾è®¡è½¯ä»¶ï¼Œæ¨åŠ¨â€œè‡ªç„¶è¯­è¨€ç¼–ç¨‹â€æ™®åŠã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡è¯æ˜äº†é€šè¿‡ **Actor-Critic åŒæ™ºèƒ½ä½“æ¶æ„ + In-Context Learning**ï¼Œå¯ä»¥æ— éœ€è®­ç»ƒåœ°è®© LLM ç²¾ç¡®æ“æ§å¤æ‚çš„ PCG å·¥å…·ï¼Œå®ç°äº†ä»è‡ªç„¶è¯­è¨€åˆ°å¯æ‰§è¡Œå‚æ•°è½¨è¿¹çš„å¯é æ˜ å°„ï¼Œä¸ºé€šç”¨è½¯ä»¶è‡ªåŠ¨åŒ–æä¾›äº†å¯æ‰©å±•çš„æ–°èŒƒå¼ã€‚

</details>

---

### 6. [A Kernel-based Resource-efficient Neural Surrogate for Multi-fidelity Prediction of Aerodynamic Field](https://arxiv.org/abs/2512.10287)

**Authors**: Apurba Sarker, Reza T. Batley, Darshan Sarojini, Sourav Saha  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.10287v1  

#### Abstract
Surrogate models provide fast alternatives to costly aerodynamic simulations and are extremely useful in design and optimization applications. This study proposes the use of a recent kernel-based neural surrogate, KHRONOS. In this work, we blend sparse high-fidelity (HF) data with low-fidelity (LF) ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Kernel-based Resource-efficient Neural Surrogate for Multi-fidelity Prediction of Aerodynamic Field

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶é’ˆå¯¹**å¤šä¿çœŸåº¦ï¼ˆmulti-fidelityï¼‰æ°”åŠ¨åœºé¢„æµ‹ä¸­çš„èµ„æºæ•ˆç‡ç“¶é¢ˆ**é—®é¢˜ã€‚ä¼ ç»ŸåŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„ä»£ç†æ¨¡å‹ï¼ˆsurrogate modelsï¼‰åœ¨å¤„ç†é«˜ç»´ã€éä¸€è‡´æ€§çš„æ°”åŠ¨åœºæ•°æ®æ—¶ï¼Œå¾€å¾€éœ€è¦å¤§é‡å¯è®­ç»ƒå‚æ•°å’Œè®¡ç®—èµ„æºï¼Œéš¾ä»¥åœ¨èµ„æºå—é™åœºæ™¯ä¸‹é«˜æ•ˆéƒ¨ç½²ã€‚

æ­¤å¤–ï¼Œé«˜ä¿çœŸï¼ˆHFï¼‰ä»¿çœŸæˆæœ¬é«˜æ˜‚ï¼Œæ•°æ®ç¨€ç¼ºï¼›ä½ä¿çœŸï¼ˆLFï¼‰æ•°æ®ä¸°å¯Œä½†ç²¾åº¦ä¸è¶³ã€‚å¦‚ä½•æœ‰æ•ˆèåˆäºŒè€…ï¼Œåœ¨æœ‰é™èµ„æºæ¡ä»¶ä¸‹å®ç°é«˜ç²¾åº¦é¢„æµ‹ï¼Œæ˜¯å½“å‰å¤šä¿çœŸå»ºæ¨¡é¢ä¸´çš„å…³é”®æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
æå‡ºäº†ä¸€ç§åŸºäºæ ¸å‡½æ•°çš„æ–°å‹ç¥ç»ä»£ç†æ¨¡å‹â€”â€”**KHRONOS**ï¼ˆKernel Expansion Hierarchy for Reduced-Order, Neural-Optimized Surrogatesï¼‰ï¼Œç”¨äºå¤šä¿çœŸåº¦æ°”åŠ¨åœºé¢„æµ‹ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†è¾“å…¥-è¾“å‡ºæ˜ å°„è¡¨ç¤ºä¸º**ä½ç»´å­ç©ºé—´å¼ é‡ç§¯çš„å½¢å¼**ï¼›
- åˆ©ç”¨**å˜åˆ†åŸç†ã€æ’å€¼ç†è®ºå’Œå¼ é‡åˆ†è§£**æ„å»ºæ¨¡å‹ç»“æ„ï¼›
- é‡‡ç”¨**å¯åˆ†ç¦»çš„æ ¸æ‰©å±•ï¼ˆseparable kernel expansionï¼‰** æ¥å­¦ä¹ æ¯ä¸ªè¾“å…¥ç»´åº¦ä¸Šçš„ä½é˜¶åŸºå‡½æ•°ï¼ˆå¦‚äºŒæ¬¡Bæ ·æ¡ï¼‰ï¼›
- æ‰€æœ‰ç»´åº¦é€šè¿‡å¤–ç§¯ç»„åˆå½¢æˆæœ€ç»ˆå“åº”ï¼Œé¿å…å…¨è¿æ¥å±‚å¸¦æ¥çš„å‚æ•°çˆ†ç‚¸ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æé«˜çš„å‚æ•°æ•ˆç‡**ï¼šç›¸æ¯”MLPã€GNNã€PINNç­‰å¯†é›†ç½‘ç»œï¼Œå‡å°‘94â€“98%çš„å¯è®­ç»ƒå‚æ•°ã€‚
- **æ›´å¿«çš„è®­ç»ƒä¸æ¨ç†é€Ÿåº¦**ï¼šåœ¨åŒç­‰ç²¾åº¦ä¸‹ï¼Œè®­ç»ƒæ—¶é—´ç¼©çŸ­40â€“73%ï¼Œæ¨ç†å»¶è¿Ÿä½è‡³2.44â€“3.64 msã€‚
- **æ— éœ€ä¸­é—´æ½œç©ºé—´å¯¹é½**ï¼šç›´æ¥åœ¨åŸå§‹ç‰¹å¾ç©ºé—´è¿›è¡Œæ®‹å·®æ ¡æ­£ï¼Œé¿å…å¤æ‚çš„è·¨ä¿çœŸåº¦ç‰¹å¾åŒ¹é…ã€‚
- **æ•°å­¦åŸºç¡€åšå®**ï¼šåŸºäºæ’å€¼ä¸åˆ†ç¦»ç»“æ„ï¼Œæ”¯æŒé‡å‹å‰ªæï¼ˆheavy pruningï¼‰ï¼Œé€‚åˆåµŒå…¥ä¼˜åŒ–æµç¨‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é«˜ä¿çœŸï¼ˆHFï¼‰æ•°æ®é›†**ï¼š`AirfRANS` â€”â€” åŒ…å«1000ä¸ª2Dä¸å¯å‹ç¼©RANSè§£ç®—çš„NACAç¿¼å‹æ¡ˆä¾‹ï¼Œæ¶µç›–Re âˆˆ [2Ã—10â¶, 6Ã—10â¶]ï¼ŒAoA âˆˆ [-5Â°, 15Â°]ï¼Œç½‘æ ¼è§„æ¨¡çº¦250kâ€“300kå•å…ƒã€‚
- **ä½ä¿çœŸï¼ˆLFï¼‰æ•°æ®é›†**ï¼šç”±`NeuralFoil`ç”Ÿæˆï¼ŒåŸºäºXFoilè®­ç»ƒçš„ç‰©ç†å¼•å¯¼æœºå™¨å­¦ä¹ å·¥å…·ï¼Œæ¨¡æ‹Ÿç›¸åŒå‡ ä½•ä¸å·¥å†µä¸‹çš„æ°”åŠ¨åœºã€‚

> æ³¨ï¼šç­›é€‰å‡º735ä¸ªLFä¸HFä¸€è‡´æ€§è¾ƒé«˜çš„æ ·æœ¬ç”¨äºä¸»å®éªŒï¼Œå¦265ä¸ªä½ä¸€è‡´æ€§æ ·æœ¬ç”¨äºéªŒè¯æ¨¡å‹åœ¨å›°éš¾æ¡ˆä¾‹ä¸Šçš„ä¿®æ­£èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®
é‡‡ç”¨**delta learningæ¶æ„**ï¼ˆæ®‹å·®å­¦ä¹ ï¼‰ï¼š
1. å…ˆè®­ç»ƒä¸€ä¸ªLFæ¨¡å‹ï¼ˆåŸºäºNeuralFoilè¾“å‡ºï¼‰ï¼›
2. è®¡ç®—å…¶åœ¨HFæ•°æ®ç‚¹ä¸Šçš„é¢„æµ‹è¯¯å·® Î” = y_HF âˆ’ y_LFï¼›
3. å†è®­ç»ƒä¸€ä¸ªâ€œÎ”æ¨¡å‹â€æ¥é¢„æµ‹è¯¥æ®‹å·®ï¼›
4. æœ€ç»ˆå¤šä¿çœŸé¢„æµ‹ä¸ºï¼š$ \hat{y}_{MF} = y_{LF} + \Delta $ã€‚

#### ä¸‰ç§è®­ç»ƒåœºæ™¯ï¼ˆCaseï¼‰
| Case | HF/LF Ratio | HF Training Data | LF Training Data |
|------|-------------|------------------|------------------|
| 1    | 0%          | 0                | 588              |
| 2    | 10%         | 59               | 588              |
| 3    | 30%         | 176              | 588              |

> æµ‹è¯•é›†å›ºå®šä¸º147ä¸ªæ ·æœ¬ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **RÂ²ï¼ˆCoefficient of Determinationï¼‰**ï¼šè¡¡é‡è¡¨é¢å‹åŠ›ç³»æ•° $ C_p $ åˆ†å¸ƒçš„é¢„æµ‹å‡†ç¡®æ€§ï¼›
- **å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼ˆ#Parametersï¼‰**ï¼šåæ˜ æ¨¡å‹å¤æ‚åº¦ï¼›
- **è®­ç»ƒæ—¶é—´ï¼ˆTraining Time per foldï¼‰**ï¼šå•ä½ç§’ï¼›
- **æ¨ç†æ—¶é—´ï¼ˆInference Time per sampleï¼‰**ï¼šå•ä½æ¯«ç§’ï¼›
- **ç¼©æ”¾ç‰¹æ€§åˆ†æ**ï¼šæ§åˆ¶ç‚¹æ•°ä»16å¢è‡³64ï¼Œè§‚å¯ŸRÂ²ä¸å‚æ•°å¢é•¿å…³ç³»ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸ä»¥ä¸‹ä¸‰ç§ä¸»æµæ¶æ„è¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼š
- **MLP**ï¼šæ ‡å‡†å‰é¦ˆå…¨è¿æ¥ç½‘ç»œï¼›
- **GNN**ï¼šå›¾ç¥ç»ç½‘ç»œï¼Œåˆ©ç”¨ç¿¼å‹æ§åˆ¶ç‚¹é“¾å¼æ‹“æ‰‘è¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼›
- **PINN**ï¼šç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ŒåµŒå…¥åŠ¿æµæ–¹ç¨‹çº¦æŸï¼ˆLaplaceæ–¹ç¨‹ + Bernoulliå…³ç³»ï¼‰ã€‚

æ‰€æœ‰æ¨¡å‹å‡é‡‡ç”¨ç›¸åŒçš„delta learningæ¡†æ¶ï¼Œå¹¶é€šè¿‡grid searchè°ƒä¼˜è¶…å‚æ•°ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆCase 3ï¼‰

| æ¨¡å‹       | å‚æ•°é‡     | æ¨ç†æ—¶é—´ (ms) | è®­ç»ƒæ—¶é—´/fold (s) | Test RÂ² |
|------------|------------|----------------|--------------------|---------|
| **KHRONOS** | **7,759**   | **3.64**        | **15**             | **~0.90** |
| MLP        | 139,554    | 8.54           | 30                 | ~0.91   |
| GNN        | 202,626    | 7.17           | 28                 | ~0.92   |
| PINN       | 139,554    | 8.27           | 32                 | ~0.91   |

> KHRONOSä»…ç”¨**çº¦5.5%çš„å‚æ•°**å³è¾¾åˆ°ä¸åŸºçº¿ç›¸å½“çš„ç²¾åº¦ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰èµ„æºå—é™æ¡ä»¶ä¸‹çš„è¡¨ç°ä¼˜åŠ¿æ˜¾è‘—
- **æ—¶é—´é™åˆ¶å®éªŒï¼ˆFig. 6ï¼‰**ï¼š
  - åœ¨15ç§’è®­ç»ƒé¢„ç®—å†…ï¼ŒKHRONOSå·²å°†é¢„æµ‹è¯¯å·®ï¼ˆ1âˆ’RÂ²ï¼‰é™è‡³0.1ï¼›
  - è€ŒMLP/GNN/PINNä»å¤„äºé«˜è¯¯å·®é˜¶æ®µï¼ˆ>0.3ï¼‰ï¼›
  - è¡¨æ˜KHRONOSæ”¶æ•›æ›´å¿«ï¼Œæ›´é€‚åˆå®æ—¶æˆ–è¾¹ç¼˜éƒ¨ç½²ã€‚

- **å‚æ•°é™åˆ¶å®éªŒï¼ˆFig. 7ï¼‰**ï¼š
  - åœ¨ä½å‚æ•°åŒºé—´ï¼ˆ<10â´ï¼‰ï¼ŒKHRONOSæ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ï¼›
  - éšç€å‚æ•°å¢åŠ ï¼ŒMLP/GNN/PINNæå‡è¶‹äºé¥±å’Œï¼Œè€ŒKHRONOSä¿æŒç¨³å®šå¢ç›Šã€‚

#### ï¼ˆ2ï¼‰æ— èµ„æºé™åˆ¶ä¸‹çš„ç»¼åˆæ€§èƒ½ï¼ˆFig. 8ï¼‰
- æ‰€æœ‰æ¨¡å‹æœ€ç»ˆéƒ½èƒ½è¾¾åˆ°è¾ƒé«˜RÂ²ï¼ˆâ‰¥0.8ï¼‰ï¼›
- KHRONOSåœ¨**Case 3ä¸­RÂ²è¾¾~0.90**ï¼Œæ¥è¿‘æœ€ä¼˜åŸºçº¿ï¼ˆGNN ~0.92ï¼‰ï¼›
- ä½†åœ¨å‚æ•°é‡ä¸Šé¢†å…ˆä¸¤ä¸ªæ•°é‡çº§ï¼Œä¸”æ¨ç†é€Ÿåº¦å¿«**44â€“63%**ï¼Œè®­ç»ƒæ—¶é—´å°‘**53â€“70%**ã€‚

#### ï¼ˆ3ï¼‰å‡ ä½•åˆ†è¾¨ç‡æ‰©å±•å®éªŒï¼ˆFig. 9â€“10ï¼‰
- å½“æ§åˆ¶ç‚¹ä»16å¢è‡³64ï¼š
  - æ‰€æœ‰æ¨¡å‹RÂ²ä»…å°å¹…æå‡ï¼ˆ0.87 â†’ 0.94ï¼‰ï¼Œè¯´æ˜**å‡ ä½•åˆ†è¾¨ç‡å·²éç“¶é¢ˆ**ï¼›
  - ä½†MLP/PINNå‚æ•°å¢é•¿çº¦15%ï¼ŒGNNå¢é•¿è¶…è¿‡2å€ï¼ˆ20ä¸‡ â†’ 67ä¸‡ï¼‰ï¼›
  - KHRONOSå‚æ•°ä»…ä»7,759å¢è‡³17,897ï¼ˆ+130%ï¼‰ï¼Œè¿œä½äºåŸºçº¿ã€‚

> ç»“è®ºï¼š**KHRONOSå®ç°äº†è¿‘ä¼¼â€œåˆ†è¾¨ç‡æ— å…³â€çš„å‚æ•°å¢é•¿**ï¼Œæ›´é€‚åˆé«˜ç»´å‡ ä½•ä¼˜åŒ–ä»»åŠ¡ã€‚

### å¤šä¿çœŸå¢ç›Šåˆ†æï¼ˆFig. 11â€“13ï¼‰
- åœ¨LFæ¨¡å‹æœ¬èº«è¡¨ç°å·®çš„æ¡ˆä¾‹ï¼ˆRÂ² < 0.7ï¼‰ä¸­ï¼š
  - NeuralFoilä¸¥é‡ä½ä¼°å‰ç¼˜å¸åŠ›å³°ï¼ˆleading-edge suction peakï¼‰ï¼›
  - KHRONOSé€šè¿‡Î”æ¨¡å‹æˆåŠŸæ¢å¤å³°å€¼ä½ç½®ä¸å¹…å€¼ï¼›
  - å°†å…¶ä¸­**52.8%çš„æ¡ˆä¾‹æå‡è‡³RÂ² > 0.7**ï¼Œæ˜¾è‘—æ”¹å–„ä½è´¨é‡LFåŒºåŸŸçš„é¢„æµ‹å¯é æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **KHRONOSåœ¨èµ„æºæ•ˆç‡æ–¹é¢å…·æœ‰å‹å€’æ€§ä¼˜åŠ¿**ï¼š
   - åœ¨ç›¸ä¼¼ç”šè‡³ç•¥ä¼˜çš„é¢„æµ‹ç²¾åº¦ä¸‹ï¼Œä½¿ç”¨**94â€“98%æ›´å°‘çš„å‚æ•°**ï¼›
   - æ”¯æŒå¿«é€Ÿè®­ç»ƒï¼ˆæœ€å¿«3ç§’/æŠ˜ï¼‰ä¸ä½å»¶è¿Ÿæ¨ç†ï¼ˆæœ€ä½2.44 msï¼‰ï¼›
   - ç‰¹åˆ«é€‚ç”¨äºåµŒå…¥è®¾è®¡ä¼˜åŒ–ã€ä¸ç¡®å®šæ€§é‡åŒ–ç­‰éœ€å¤šæ¬¡è°ƒç”¨ä»£ç†æ¨¡å‹çš„åº”ç”¨ã€‚

2. **åˆ†ç¦»å¼æ ¸ç»“æ„å¤©ç„¶é€‚é…å¤šä¿çœŸå»ºæ¨¡**ï¼š
   - ä¸ä¾èµ–æ½œç©ºé—´å¯¹é½ï¼Œç®€åŒ–äº†LFâ†’HFçš„ä¿¡æ¯èåˆè·¯å¾„ï¼›
   - æ®‹å·®Î”æ¨¡å‹èƒ½æœ‰æ•ˆçº æ­£LFæ¨¡å‹åœ¨å¼ºåˆ†ç¦»ã€å¤§æ”»è§’ç­‰å¤æ‚æµåŠ¨ä¸‹çš„ç³»ç»Ÿåå·®ã€‚

3. **å‡ ä½•å‚æ•°åŒ–ç»†åŒ–æ”¶ç›Šé€’å‡**ï¼š
   - æ§åˆ¶ç‚¹è¶…è¿‡32åï¼Œç²¾åº¦æå‡æœ‰é™ï¼›
   - ä¼ ç»Ÿå¯†é›†ç½‘ç»œå‚æ•°éšåˆ†è¾¨ç‡æ€¥å‰§ä¸Šå‡ï¼Œè€ŒKHRONOSä¿æŒè‰¯å¥½æ‰©å±•æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰è¯„ä¼°å±€é™äºå•ä¸€HFæºï¼ˆAirfRANSï¼‰ä¸å•ä¸€LFç”Ÿæˆå™¨ï¼ˆNeuralFoilï¼‰ï¼›
- æœªè€ƒè™‘åŠ¨æ€æˆ–ç¬æ€æ°”åŠ¨é—®é¢˜ï¼›
- å¯¹æç«¯å¤±é€Ÿæˆ–ä¸‰ç»´æ•ˆåº”çš„æ³›åŒ–èƒ½åŠ›å°šæœªéªŒè¯ï¼›
- æ¨¡å‹ç»“æ„å¯¹é«˜åº¦éåˆ†ç¦»é—®é¢˜å¯èƒ½ä¸å¦‚PINNçµæ´»ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šHFæ•°æ®é›†ï¼ˆå¦‚Transonic, 3D CFDï¼‰ä¸å¤šç§LFä»£ç†ï¼›
- æ¢ç´¢è‡ªé€‚åº”HF/LFé‡‡æ ·ç­–ç•¥ï¼ˆactive learningï¼‰ï¼›
- åº”ç”¨äº**out-of-distribution airfoils** å’Œé£è¡ŒåŒ…çº¿å¤–æ¨ï¼›
- ç»“åˆä¸ç¡®å®šæ€§é‡åŒ–æ¨¡å—ï¼Œæ„å»ºé²æ£’çš„å¤šä¿çœŸBayesian surrogateã€‚

--- 

> âœ… æ€»ç»“ï¼š**KHRONOSä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„å¤šä¿çœŸæ°”åŠ¨åœºä»£ç†å»ºæ¨¡æä¾›äº†ä¸€ä¸ªé«˜æ•ˆã€ç´§å‡‘ä¸”å‡†ç¡®çš„æ–°èŒƒå¼ï¼Œå¹³è¡¡äº†ç²¾åº¦ä¸æ•ˆç‡ï¼Œå±•ç°å‡ºåœ¨å·¥ç¨‹è®¾è®¡è‡ªåŠ¨åŒ–ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚**

</details>

---

### 7. [AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search](https://arxiv.org/abs/2512.10671)

**Authors**: Oscar Robben, Saeed Khalilian, Nirvana Meratnia  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.10671v1  

#### Abstract
Early-exit networks are effective solutions for reducing the overall energy consumption and latency of deep learning models by adjusting computation based on the complexity of input data. By incorporating intermediate exit branches into the architecture, they provide less computation for simpler sam...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æ—©æœŸé€€å‡ºç½‘ç»œï¼ˆEarly-Exit Networksï¼‰é€šè¿‡åœ¨æ¨¡å‹ä¸­é—´å¼•å…¥**exit branches**ï¼Œå…è®¸ç®€å•æ ·æœ¬æå‰é€€å‡ºï¼Œä»è€Œé™ä½å¹³å‡å»¶è¿Ÿå’Œè®¡ç®—å¼€é”€ï¼ˆå¦‚ MACsï¼‰ï¼Œç‰¹åˆ«é€‚ç”¨äºèµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ã€‚ç„¶è€Œï¼Œè®¾è®¡é«˜æ•ˆçš„æ—©æœŸé€€å‡ºç½‘ç»œé¢ä¸´å››å¤§æŒ‘æˆ˜ï¼š
1. exit branches çš„æ•°é‡  
2. exit branches çš„ä½ç½®  
3. é€€å‡ºç­–ç•¥ï¼ˆå¦‚ç½®ä¿¡åº¦é˜ˆå€¼ï¼‰  
4. **exit branches è‡ªèº«çš„æ¶æ„è®¾è®¡**ï¼ˆæ·±åº¦ã€å±‚æ•°ã€ç±»å‹ç­‰ï¼‰

å·²æœ‰ç ”ç©¶ï¼ˆå¦‚ EDANASã€NACHOSï¼‰è™½åˆ©ç”¨ Neural Architecture Search (NAS) è‡ªåŠ¨ä¼˜åŒ–å‰ä¸‰ä¸ªå› ç´ ï¼Œä½†é€šå¸¸é‡‡ç”¨**å›ºå®šç»“æ„çš„ exit branches**ï¼Œå¿½ç•¥äº†å…¶å¯¹æ•´ä½“æ•ˆç‡ä¸å‡†ç¡®ç‡çš„é‡è¦å½±å“ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬æ–‡æå‡º **AEBNAS**ï¼ˆAdaptive Early-Exit Branch NASï¼‰ï¼Œä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥çš„å¤šç›®æ ‡ NAS æ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **è”åˆæœç´¢ backbone å’Œ exit branches æ¶æ„**  
  ä¸ä»…æœç´¢ä¸»å¹²ç½‘ç»œç»“æ„ï¼Œè¿˜åŒæ—¶ä¼˜åŒ–æ¯ä¸ª exit branch çš„å±‚æ•°ã€å·ç§¯æ ¸å¤§å°ï¼ˆkernel sizeï¼‰ã€æ‰©å±•ç‡ï¼ˆexpansion rateï¼‰ã€æ’å€¼å°ºå¯¸ï¼ˆinterpolation sizeï¼‰ä»¥åŠæ˜¯å¦æ·»åŠ  Max-Pooling å±‚ã€‚

- **åŠ¨æ€è°ƒæ•´ exit thresholds**  
  åœ¨æ¯è½® NAS è¿­ä»£åï¼Œé€šè¿‡ grid search è°ƒæ•´å„ exit branch çš„ confidence thresholdï¼Œä»¥æ›´å¥½åœ°å¹³è¡¡ accuracy ä¸ MACsï¼Œæå‡æ•´ä½“æ€§èƒ½ã€‚

- **å¼•å…¥ç›®æ ‡ MACs çº¦æŸä½œä¸ºä¼˜åŒ–ç›®æ ‡çš„ä¸€éƒ¨åˆ†**  
  åœ¨ä¼˜åŒ–å‡½æ•°ä¸­åŠ å…¥ `target_macs` è¶…å‚æ•°ï¼Œä½¿ç”Ÿæˆçš„æ¨¡å‹å¯é€‚é…ç‰¹å®šç¡¬ä»¶èµ„æºé™åˆ¶ï¼Œå®ç°â€œæŒ‰éœ€è®¾è®¡â€ã€‚

- **æ”¹è¿›çš„æœç´¢ç©ºé—´ç¼–ç æ–¹å¼**  
  ä½¿ç”¨ threshold vector ç»Ÿä¸€è¡¨ç¤º exit æ•°é‡ã€ä½ç½®åŠé˜ˆå€¼ï¼Œç®€åŒ–æœç´¢è¿‡ç¨‹ï¼Œå¹¶æ”¯æŒçµæ´»æ§åˆ¶ active exitsã€‚

> ğŸ” åˆ›æ–°æœ¬è´¨ï¼šå°† exit branches è§†ä¸ºå¯å­¦ä¹ ã€å¯ä¼˜åŒ–çš„æ¨¡å—ï¼Œè€Œéå›ºå®šç»“æ„ï¼Œæ˜¾è‘—å¢å¼ºå…¶è¡¨è¾¾èƒ½åŠ›ä¸æ•ˆç‡ã€‚

---

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦æœç´¢ exit æ¶æ„ | æ˜¯å¦è°ƒä¼˜ threshold | æ˜¯å¦æ”¯æŒç›®æ ‡ MAC æ§åˆ¶ |
|------|---------------------|--------------------|------------------------|
| EDANAS [12] | âŒ å›ºå®šç»“æ„ | âœ… | âœ… |
| NACHOS [13] | âŒ ä»…å…è®¸ MaxPool | âœ… | âœ… |
| **AEBNAS (Ours)** | âœ… å¤šå±‚å¯å˜ç»“æ„ | âœ…ï¼ˆæ›´ç²¾ç»†ï¼‰ | âœ…ï¼ˆæ˜¾å¼çº¦æŸï¼‰ |

ğŸ‘‰ AEBNAS æ˜¯é¦–ä¸ªåœ¨ NAS ä¸­å…¨é¢ä¼˜åŒ– exit branch æ¶æ„ + threshold + backbone çš„æ¡†æ¶ï¼Œåœ¨ç²¾åº¦ä¸æ•ˆç‡ä¹‹é—´å–å¾—æ›´å¥½æƒè¡¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **CIFAR-10**ï¼š50k è®­ç»ƒå›¾åƒï¼Œ10k æµ‹è¯•å›¾åƒ
- **CIFAR-100**ï¼šåŒä¸Šï¼Œç±»åˆ«æ›´å¤šï¼Œä»»åŠ¡æ›´å¤æ‚
- **SVHN**ï¼š73,257 å¼ è®­ç»ƒå›¾åƒï¼Œ26,032 å¼ æµ‹è¯•å›¾åƒï¼ˆè¡—æ™¯æ•°å­—è¯†åˆ«ï¼‰

æ‰€æœ‰æ•°æ®é›†ä¸­å‡åˆ’åˆ† 10% è®­ç»ƒé›†ä½œä¸ºéªŒè¯é›†ç”¨äº NASã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| NAS æ¡†æ¶ | åŸºäº NSGANetV2 çš„ multi-objective NASï¼ˆNSGA-IIï¼‰ |
| æœç´¢è¿­ä»£æ¬¡æ•° | 30 |
| åˆå§‹ç§ç¾¤å¤§å° | 100 |
| åç»­æ¯è½®å€™é€‰æ•° | 8 |
| æ¯ä¸ªæ¶æ„è®­ç»ƒ epoch æ•° | 5ï¼ˆCIFAR-10/100/SVHNï¼‰ï¼ŒCIFAR-100 æœ€åä¸¤è½®å¢è‡³ 250 |
| Surrogate Model | MLP é¢„æµ‹ accuracy å’Œ MACs |
| ç›®æ ‡ MACs | SVHN: 1Mï¼›CIFAR-10: 2M / 17Mï¼›CIFAR-100: 17M |
| Exit branch å¯é€‰é…ç½® | kernel size âˆˆ {3,5}ï¼Œexpansion âˆˆ {1,2}ï¼Œinterpolation âˆˆ {8,10,12}ï¼Œmax-pooling å¯é€‰ï¼Œæœ€å¤šä¸¤ä¸ª block |

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **Top-1 Accuracy (%)**
- **Average Number of MACs (M)**ï¼šåæ˜ å¹³å‡è®¡ç®—æˆæœ¬
- **Number of Exits**ï¼šå¯ç”¨çš„ exit åˆ†æ”¯æ•°é‡
- **Exit Utilization (%)**ï¼šå„ exit åˆ†ç±»çš„æ ·æœ¬æ¯”ä¾‹
- **Pareto æ€§èƒ½æ¯”è¾ƒ**ï¼šaccuracy vs. MACs æ›²çº¿è¶‹åŠ¿

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | åŸºçº¿æ¨¡å‹ |
|------|---------|
| æ‰‹åŠ¨è®¾è®¡ | EEAlexNetï¼ˆ5 exitsï¼‰ã€EEResNet20ï¼ˆ10 exitsï¼‰ |
| NAS è®¾è®¡ | EDANASã€NACHOS |

æ‰€æœ‰ NAS æ–¹æ³•ä¿æŒä¸€è‡´è¶…å‚è®¾ç½®ä»¥ä¾¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table IIï¼‰

#### âœ… CIFAR-10ï¼ˆTarget ~2.4M MACsï¼‰
| Model | MACs (M) | Top-1 Acc (%) | # Exits |
|-------|----------|---------------|--------|
| AEBNAS | **2.47** | **74.64** | 4 |
| EDANAS | 2.47 | 67.78 | 5 |
| NACHOS | 2.44 | 72.65 | 4 |

â¡ï¸ **AEBNAS æå‡ +6.86% acc @ç›¸åŒ MACs**

#### âœ… CIFAR-10ï¼ˆHigh-budget: ~17M MACsï¼‰
| Model | MACs (M) | Top-1 Acc (%) |
|-------|----------|---------------|
| AEBNAS | **16.71** | **84.42** |
| EDANAS | 17.31 | 80.90 |

â¡ï¸ æ›´é«˜ç²¾åº¦ï¼Œæ›´ä½ MACsï¼ˆ-0.6Mï¼‰

#### âœ… SVHNï¼ˆTarget 1M MACsï¼‰
| Model | MACs (M) | Top-1 Acc (%) |
|-------|----------|---------------|
| AEBNAS | **1.79** | **85.76** |
| EDANAS | 1.47 | 77.98 |
| NACHOS | 1.46 | 79.96 |

â¡ï¸ å°½ç®¡ MACs ç•¥é«˜ï¼Œä½† accuracy æå‡è¶… **+5.8%**

#### âœ… CIFAR-100ï¼ˆTarget 17M MACsï¼‰
| Model | MACs (M) | Top-1 Acc (%) |
|-------|----------|---------------|
| AEBNAS | **14.80** | **69.90** |
| EDANAS | 14.94 | 67.94 |

â¡ï¸ **ç²¾åº¦æå‡ +1.96%ï¼Œä¸” MACs æ›´ä½**

---

### ğŸ” ä¸å…¶ä»–æ‰‹åŠ¨æ¨¡å‹å¯¹æ¯”ä¼˜åŠ¿
- **EEAlexNet / EEResNet20** è™½æœ‰ä¸€å®š accuracyï¼Œä½† MACs é«˜è¾¾ **200M~400M**ï¼Œè¿œé«˜äº NAS æ–¹æ³•ï¼ˆ<20Mï¼‰
- AEBNAS åœ¨æä½ MACs ä¸‹å®ç°æ›´é«˜æˆ–ç›¸å½“ accuracyï¼Œæ›´é€‚åˆè¾¹ç¼˜éƒ¨ç½²

---

### ğŸ“‰ Exit Utilization åˆ†æï¼ˆFigure 3ï¼‰
- AEBNAS æœ€ä½³æ¶æ„å€¾å‘äºç¦ç”¨ç¬¬ä¸€ä¸ª exitï¼ˆExit 1ï¼‰ï¼Œè€Œé›†ä¸­åœ¨ **Exit 2 å’Œ Exit 3** å®Œæˆå¤§éƒ¨åˆ†é¢„æµ‹ï¼ˆ>80%ï¼‰
- EDANAS/NACHOS æ¿€æ´»æ—©æœŸ exitï¼Œä½†ç”±äºå…¶æ€§èƒ½å¼±ï¼Œå¯¼è‡´ï¼š
  - å°‘é‡æ ·æœ¬çœŸæ­£ä»æ­¤é€€å‡º
  - æ‰€æœ‰æ ·æœ¬ä»éœ€ç»è¿‡è¯¥å±‚ â†’ å¢åŠ æ— è°“è®¡ç®—å¼€é”€
- è¡¨æ˜ï¼š**å¼ºåŒ–ä¸­é—´ exit branches å¹¶å…³é—­ä½æ•ˆ early exits æ›´æœ‰åˆ©äºæ•´ä½“æ•ˆç‡**

---

### ğŸ“Š æ¶ˆèåˆ†æä¸è¶‹åŠ¿è§‚å¯Ÿï¼ˆFigure 2ï¼‰
- éšç€ NAS è¿­ä»£è¿›è¡Œï¼Œæ¨¡å‹é€æ¸æ”¶æ•›åˆ°é«˜ accuracyã€ä½ MACs åŒºåŸŸ
- å¼•å…¥ target_macs çº¦æŸå’Œ threshold tuning æ˜¾è‘—æå‡äº†æœç´¢æ–¹å‘æ€§å’Œç¨³å®šæ€§
- åœ¨ CIFAR-100 ä¸Šï¼Œå³ä½¿åˆæœŸè®­ç»ƒä»… 5 epochsï¼Œä¹Ÿèƒ½å¿«é€Ÿæå‡ accuracy >40%ï¼Œæœ€ç»ˆè¾¾åˆ° ~70%

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **exit branches çš„æ¶æ„è®¾è®¡è‡³å…³é‡è¦**  
   å…è®¸ NAS æœç´¢ exit branch å†…éƒ¨ç»“æ„ï¼ˆå±‚æ•°ã€kernelã€expansion ç­‰ï¼‰å¯æ˜¾è‘—æå‡ accuracy ä¸æ•ˆç‡ã€‚

2. **å¹¶éè¶Šå¤š exit è¶Šå¥½**  
   è¿‡å¤š exitï¼ˆå¦‚ EEResNet20 çš„ 10 ä¸ªï¼‰åè€Œå¢åŠ å†—ä½™è®¡ç®—ï¼Œé™ä½æ•´ä½“æ€§èƒ½ã€‚AEBNAS è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°é‡ä¸ä½ç½®ã€‚

3. **æ—©æœŸ exit è‹¥æ€§èƒ½ä¸è¶³åº”è¢«ç¦ç”¨**  
   ç¬¬ä¸€ä¸ª exit å¾€å¾€ç‰¹å¾æå–ä¸å……åˆ†ï¼Œç½®ä¿¡åº¦ä½ï¼Œå¼ºè¡Œä½¿ç”¨ä¼šå¸¦æ¥é¢å¤–å¼€é”€ã€‚AEBNAS å­¦ä¼šè·³è¿‡å®ƒï¼Œç›´æ¥ä¾èµ–æ›´å¼ºçš„åç»­ exitã€‚

4. **threshold tuning æ˜¯å…³é”®ç¯èŠ‚**  
   åŠ¨æ€è°ƒæ•´ threshold å¯æœ‰æ•ˆæ§åˆ¶ early-exit è¡Œä¸ºï¼Œåœ¨ç»™å®š MACs é¢„ç®—ä¸‹æœ€å¤§åŒ– accuracyã€‚

5. **ç¡¬ä»¶æ„ŸçŸ¥ç›®æ ‡å¼•å¯¼æ›´å®ç”¨çš„è®¾è®¡**  
   æ˜¾å¼è®¾å®š `target_macs` ä½¿å¾—æ¨¡å‹å¯é’ˆå¯¹å…·ä½“è®¾å¤‡å®šåˆ¶ï¼Œå¢å¼ºäº†å®é™…éƒ¨ç½²ä»·å€¼ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ exit branch æœç´¢ç©ºé—´ä»æœ‰é™ï¼ˆæœ€å¤§ 2 blockï¼‰ï¼Œæœªæ¥å¯æ¢ç´¢æ›´å¤æ‚ç»“æ„ã€‚
- threshold tuning ä½¿ç”¨ grid searchï¼Œè®¡ç®—å¼€é”€è¾ƒå¤§ï¼Œå¯è€ƒè™‘æ›¿ä»£ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚ Bayesian Optimizationï¼‰ã€‚
- å®éªŒåŸºäºå›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œæœªåœ¨çœŸå®è¾¹ç¼˜è®¾å¤‡ä¸Šæµ‹é‡çœŸå®å»¶è¿Ÿä¸åŠŸè€—ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±• exit branch æœç´¢ç©ºé—´ï¼ˆå¦‚ Attention æ¨¡å—ã€Transformer layersï¼‰
2. ç»“åˆ energy/power profiling å®ç°çœŸæ­£çš„ hardware-aware design
3. æ¢ç´¢å…¶ä»– exit policiesï¼ˆé margin-basedï¼‰
4. åº”ç”¨äºç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ç­‰ dense prediction ä»»åŠ¡ä¸­çš„ early-exit è®¾è®¡

---

## âœ… æ€»ç»“
**AEBNAS æˆåŠŸè¯æ˜äº†ï¼šé€šè¿‡åœ¨ NAS ä¸­è”åˆä¼˜åŒ– backbone ä¸ exit branches æ¶æ„ï¼Œå¹¶ç»“åˆ adaptive threshold tuningï¼Œå¯ä»¥è®¾è®¡å‡ºåœ¨ accuracy å’Œ efficiency ä¸Šå‡ä¼˜äº state-of-the-art çš„ early-exit networksã€‚**  
è¯¥å·¥ä½œå¼ºè°ƒäº† exit branch ä¸åº”æ˜¯é™„å±ç»“æ„ï¼Œè€Œæ˜¯å†³å®šæ•´ä½“æ€§èƒ½çš„å…³é”®ç»„ä»¶ï¼Œä¸ºé«˜æ•ˆåŠ¨æ€ç¥ç»ç½‘ç»œçš„è®¾è®¡æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 8. [Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs](https://arxiv.org/abs/2512.10611)

**Authors**: Minghao LI, Ruihang Wang, Rui Tan, Yonggang Wen  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.10611v1  

#### Abstract
Data center (DC) infrastructure serves as the backbone to support the escalating demand for computing capacity. Traditional design methodologies that blend human expertise with specialized simulation tools scale poorly with the increasing system complexity. Recent studies adopt generative artificial...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿæ•°æ®ä¸­å¿ƒï¼ˆDCï¼‰è®¾è®¡ä¾èµ–äººå·¥ç»éªŒä¸ä¸“ç”¨ä»¿çœŸå·¥å…·ï¼Œéš¾ä»¥åº”å¯¹æ—¥ç›Šå¢é•¿çš„ç³»ç»Ÿå¤æ‚æ€§ã€‚è¿‘æœŸåŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰çš„æ–¹æ³•è™½èƒ½ç”Ÿæˆåˆç†çš„å®¤å†…å¸ƒå±€ï¼Œä½†**ç¼ºä¹å¯¹ç‰©ç†è§„å¾‹çš„å»ºæ¨¡**ï¼Œå¯¼è‡´åœ¨éœ€è¦æ»¡è¶³ä¸¥æ ¼ç‰©ç†çº¦æŸï¼ˆå¦‚æ¸©åº¦ã€PUEç­‰ï¼‰çš„æ•°æ®ä¸­å¿ƒè®¾è®¡ä¸­äº§ç”Ÿâ€œå¹»è§‰â€ï¼ˆhallucinationsï¼‰ï¼Œæ— æ³•ä¿è¯è®¾è®¡æ–¹æ¡ˆçš„å¯è¡Œæ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **Phythesis** â€”â€” ä¸€ç§ç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ç‰©ç†å¼•å¯¼è¿›åŒ–ä¼˜åŒ–çš„æ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨åŒ–ç”Ÿæˆå¯ç›´æ¥ä»¿çœŸçš„ï¼ˆSimReadyï¼‰èŠ‚èƒ½å‹æ•°æ®ä¸­å¿ƒåœºæ™¯ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

- **åŒå±‚ä¼˜åŒ–æ¶æ„ï¼ˆBi-level Optimizationï¼‰**ï¼š
  - **LLM-driven Optimization Level**ï¼šç”± Design LLM è´Ÿè´£ç”Ÿæˆä¸‰ç»´å¸ƒå±€å¹¶è¿›è¡Œè¯­ä¹‰æ¨ç†ï¼›Reflection LLM å¯¹ä»¿çœŸè½¨è¿¹è¿›è¡Œåˆ†æä¸è‡ªæˆ‘æ‰¹è¯„ï¼Œè¿­ä»£æ”¹è¿›åœºæ™¯æ‹“æ‰‘ã€‚
  - **Physics-informed Optimization Level**ï¼šåˆ©ç”¨å¯å¾®åˆ†ç‰©ç†å¼•æ“é€šè¿‡åå‘ä¼ æ’­ä¼˜åŒ–èµ„äº§å‚æ•°ï¼Œå¹¶ä»ç°å®èµ„äº§åº“ä¸­é€‰æ‹©æœ€æ¥è¿‘â€œç†æƒ³å‚æ•°â€çš„å®é™…è®¾å¤‡ç»„åˆã€‚
- **è¿›åŒ–å¼åœºæ™¯åˆæˆï¼ˆEvolutionary Scene Synthesisï¼‰**ï¼šå°† LLM çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ä½œä¸ºâ€œæ¢ç´¢â€æœºåˆ¶ï¼Œæ›¿ä»£ä¼ ç»Ÿçš„é—ä¼ ç®—å­ï¼ˆå¦‚äº¤å‰ã€å˜å¼‚ï¼‰ï¼Œå®ç°é«˜æ•ˆä¸”ç¬¦åˆç‰©ç†çš„è®¾è®¡æ¼”åŒ–ã€‚
- **é—­ç¯åé¦ˆæœºåˆ¶**ï¼šä»¿çœŸç»“æœåé¦ˆè‡³ Reflection LLMï¼Œå½¢æˆâ€œç”Ÿæˆ â†’ ä»¿çœŸ â†’ æ‰¹è¯„ â†’ å†ç”Ÿæˆâ€çš„é—­ç¯ï¼Œæ˜¾è‘—å‡å°‘ LLM çš„ç‰©ç†å¹»è§‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **å…¼é¡¾åˆ›é€ æ€§ä¸ç‰©ç†ä¸€è‡´æ€§**ï¼šLLM æä¾›å¤šæ ·åŒ–è®¾è®¡æ¢ç´¢ï¼Œç‰©ç†å¼•æ“ç¡®ä¿æ–¹æ¡ˆæ»¡è¶³çƒ­åŠ›å­¦ã€åŠŸç‡ç­‰ç¡¬æ€§çº¦æŸã€‚
- **æ›´é«˜çš„ç”ŸæˆæˆåŠŸç‡ä¸èƒ½æ•ˆ**ï¼šç›¸æ¯”çº¯ LLM æ–¹æ³•ï¼ŒPhythesis æ˜¾è‘—æå‡ç”ŸæˆæˆåŠŸç‡è¾¾ 57.3%ï¼ŒPUE æ”¹å–„ 11.5%ã€‚
- **é€‚ç”¨äºå·¥ä¸šçº§å¤æ‚åœºæ™¯**ï¼šä¸“ä¸ºæ•°æ®ä¸­å¿ƒè¿™ç±»é«˜å¯é æ€§ã€å¼ºç‰©ç†è€¦åˆçš„å·¥ä¸šç¯å¢ƒè®¾è®¡ï¼Œè¶…è¶Šé€šç”¨å®¤å†…åœºæ™¯ç”Ÿæˆæ–¹æ³•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸èµ„äº§åº“
- ä½¿ç”¨ä¸€ä¸ª**åˆæˆçš„ SimReady èµ„äº§åº“**ï¼ŒåŒ…å«å›¾3ä¸­å®šä¹‰çš„å„ç±»è®¾å¤‡ï¼ˆRacks, ACUs, Chillers, Cooling Towersï¼‰ï¼Œæ¯ç±»æä¾›10ç§å‹å·ã€‚
- å¤–éƒ¨ç¯å¢ƒæ•°æ®æ¥è‡ª **EnergyPlus Weather (EPW)** æ–‡ä»¶ï¼Œæ¶µç›–çƒ­å¸¦ã€å¹²æ—±ã€æ¸©å¸¦ä¸‰ç§æ°”å€™åŒºåŸŸçš„å†å²æ°”è±¡æ•°æ®ï¼ˆå¹²çƒæ¸©åº¦ã€æ¹¿çƒæ¸©åº¦ã€æ¹¿åº¦æ¯”ç­‰ï¼‰ã€‚
- è®¾è®¡éœ€æ±‚å…±45æ¡ï¼Œè¦†ç›–å°è¾¹ç¼˜ï¼ˆ50â€“100æœåŠ¡å™¨ï¼‰ã€ä¸­é›†ç¾¤ï¼ˆ1k+ï¼‰ã€å¤§äº‘è§„æ¨¡ï¼ˆ10k+ï¼‰ä¸‰ç§è®¡ç®—å®¹é‡ã€‚

### å®éªŒè®¾ç½®
- **ä¸»å¹² LLM**ï¼šä½¿ç”¨ GPT-4ï¼ˆI-LMï¼‰å’Œ o3-miniï¼ˆR-LMï¼‰ä½œä¸ºç”Ÿæˆæ¨¡å‹ã€‚
- **é‡‡æ ·å‚æ•°**ï¼šæ¸©åº¦ = 0.7ï¼Œæ¯æ¬¡ç”Ÿæˆ N=5 ä¸ªå€™é€‰ï¼Œä¿ç•™ Top-K=5 è¿›è¡Œä¸Šä¸‹æ–‡åé¦ˆã€‚
- **è¿­ä»£æ¬¡æ•°**ï¼šé»˜è®¤ M=5 æ¬¡è¿­ä»£ã€‚
- **ä»¿çœŸå¼•æ“**ï¼šåŸºäº PyTorch æ„å»ºçš„**å¯å¾®åˆ†ç‰©ç†æ¨¡å‹**ï¼ˆdifferentiable physics-based modelï¼‰ï¼Œæ”¯æŒåå‘ä¼ æ’­ä¼˜åŒ–ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ | ä¼˜åŒ–æ–¹å‘ |
|------|------|----------|
| **PUE (â†“)** | Power Usage Effectivenessï¼Œæ€»èƒ½è€— / ITè®¾å¤‡èƒ½è€—ï¼Œè¶Šä½è¶Šå¥½ | â†“ |
| **GSR (â†‘)** | Generation Success Rateï¼Œæ»¡è¶³å‡ ä½•ã€åŠŸç‡ã€å†·å´çº¦æŸçš„æœ‰æ•ˆè®¾è®¡æ¯”ä¾‹ | â†‘ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **Random** | Direct | éšæœºç”Ÿæˆï¼Œæ— ç‰©ç†å…ˆéªŒæˆ–è¿­ä»£ |
| **EA (Evolutionary Algorithm)** | Iterative | ä¸ä½¿ç”¨ LLMï¼Œä»…é ç§ç¾¤è¿›åŒ–ä¼˜åŒ– |
| **Vanilla LLM** | Direct | å•æ¬¡ LLM ç”Ÿæˆï¼Œæ— è¿­ä»£æˆ–ç‰©ç†åé¦ˆ |
| **ABL (w/o reflect, phy)** | Ablation | ç§»é™¤ Reflection LLM å’Œç‰©ç†ä¼˜åŒ–æ¨¡å— |
| **ABL (w/o design, phy)** | Ablation | ç§»é™¤ Design LLM å’Œç‰©ç†ä¼˜åŒ– |
| **ABL (w/o phy)** | Ablation | ä¿ç•™ LLMsï¼Œç§»é™¤ç‰©ç†ä¼˜åŒ– |
| **ABL (w/o llm)** | Ablation | ä»…ä¿ç•™ç‰©ç†ä¼˜åŒ–ï¼Œç§»é™¤æ‰€æœ‰ LLM æ¨¡å— |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰
| æ–¹æ³• | Small-Edge (PUE/GSR) | Medium-Cluster (PUE/GSR) | Large-Cloud (PUE/GSR) |
|------|------------------------|----------------------------|------------------------|
| **Vanilla LLM (R-LM)** | 1.628 / 0.947 | 1.218 / 0.782 | 1.162 / 0.813 |
| **Phythesis (R-LM)** | **1.285 / 0.997** | **1.179 / 0.988** | **1.175 / 0.970** |

- **PUE æ”¹è¿›**ï¼šåœ¨ Small-Edge åœºæ™¯ä¸‹é™ä½ **0.343**ï¼ˆç›¸å¯¹ä¸‹é™ 21.1%ï¼‰ï¼Œåœ¨ Medium-Cluster ä¸‹é™ä½ 0.039ï¼Œåœ¨ Large-Cloud ä¸‹é™ä½ 0.013ã€‚
- **GSR æå‡**ï¼šç›¸æ¯” Vanilla LLMï¼ŒGSR æœ€é«˜æå‡ **158.6%**ï¼ˆLarge-Cloud, I-LMï¼‰ï¼Œå¹³å‡æå‡è¶…è¿‡ 50%ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
- ç›¸æ¯” **Random** æ–¹æ³•ï¼ŒPhythesis åœ¨ GSR ä¸Šæœ€é«˜æå‡ **240.3%**ï¼ˆLarge-Cloud, R-LMï¼‰ã€‚
- ç›¸æ¯” **EA** æ–¹æ³•ï¼ŒPhythesis åœ¨ PUE ä¸Šå¹³å‡é™ä½ 0.1â€“0.5ï¼ŒGSR æå‡æ˜¾è‘—ã€‚
- åœ¨æ‰€æœ‰ä»»åŠ¡ç»´åº¦ä¸Šï¼ŒPhythesis å‡å–å¾—æœ€ä¼˜æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰
| è®¾ç½® | GSR å½±å“ | PUE å½±å“ | ç»“è®º |
|------|---------|---------|------|
| **w/o phy (æ— ç‰©ç†ä¼˜åŒ–)** | â†“2.4% ~ 7.9% | â†‘0.2% ~ 2.4% | ç‰©ç†ä¼˜åŒ–å¯¹å‚æ•°ç²¾ç»†è°ƒä¼˜è‡³å…³é‡è¦ |
| **w/o reflect (æ— åæ€LLM)** | å˜åŒ–è¾ƒå° | â†‘0.4% ~ 0.6% | Reflection LLM åŠ é€Ÿæ”¶æ•›ï¼Œé¿å…åœæ» |
| **w/o design (æ— è®¾è®¡LLM)** | â†“28.7% ~ 30.2% | â†‘æ˜æ˜¾ | Design LLM æä¾›é«˜è´¨é‡åˆå§‹è§£ |
| **w/o llm (å®Œå…¨ç§»é™¤LLM)** | â†“42.6% ~ 45.9% | â†‘0.374 | LLM çš„è¯­ä¹‰æ¨ç†ä¸å¯æ›¿ä»£ |

> å›¾7æ˜¾ç¤ºï¼šå®Œæ•´ Phythesis åœ¨5è½®è¿­ä»£åè¾¾åˆ° PUE=1.188ï¼Œè€Œ ABL (w/o phy) ä»…ä¸º 1.195ï¼Œä¸”æ”¶æ•›æ›´æ…¢ã€‚

### å¯æ‰©å±•æ€§æµ‹è¯•ï¼ˆTable 2ï¼‰
å½“èµ„äº§åº“ä»10å¢è‡³50ç§å‹å·æ—¶ï¼š
- Phythesis åœ¨50èµ„äº§åº“ä¸‹ä»ä¿æŒ **GSR=0.973**ï¼ŒPUE=1.218ã€‚
- ç›¸æ¯” EA æ–¹æ³•ï¼ŒPUE é™ä½ **21.2%**ï¼Œè¡¨æ˜å…¶åœ¨å¤§è§„æ¨¡ç»„åˆæœç´¢ç©ºé—´ä¸­çš„é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLM + Physics æ˜¯å·¥ä¸šçº§ç”Ÿæˆè®¾è®¡çš„å…³é”®è·¯å¾„**ï¼šå•çº¯ä¾èµ– LLM å®¹æ˜“è¿åç‰©ç†è§„å¾‹ï¼Œè€Œå¼•å…¥å¯å¾®åˆ†ç‰©ç†æ¨¡å‹å¯æœ‰æ•ˆçº æ­£å¹»è§‰ï¼Œæå‡è®¾è®¡å¯è¡Œæ€§ã€‚
2. **åŒå±‚ä¼˜åŒ–ååŒå¢æ•ˆ**ï¼šLLM å±‚è´Ÿè´£å®è§‚æ‹“æ‰‘æ¢ç´¢ï¼Œç‰©ç†å±‚è´Ÿè´£å¾®è§‚å‚æ•°ç²¾è°ƒï¼ŒäºŒè€…äº’è¡¥ï¼Œæ˜¾è‘—ä¼˜äºå•ä¸€èŒƒå¼ã€‚
3. **è¿›åŒ–å¼åé¦ˆæœºåˆ¶åŠ é€Ÿæ”¶æ•›**ï¼šé€šè¿‡ Reflection LLM åˆ†æä»¿çœŸè½¨è¿¹å¹¶æŒ‡å¯¼å†è®¾è®¡ï¼Œå®ç°äº†ç±»ä¼¼â€œäººç±»ä¸“å®¶è°ƒè¯•â€çš„å¿«é€Ÿè¿­ä»£ã€‚
4. **çœŸå®æ¡ˆä¾‹éªŒè¯å¯æŒç»­ä»·å€¼**ï¼šåœ¨æ–°åŠ å¡çƒ­å¸¦ç¯å¢ƒä¸‹ï¼ŒPhythesis è®¾è®¡çš„è¾¹ç¼˜DCå®ç°å‘¨å‡èŠ‚ç”µ **0.6 GWh**ï¼Œå¹´èŠ‚ç”µè¾¾ **31.2 GWh**ï¼Œç›¸å½“äºä¸º500ä¸‡äººå£åŸå¸‚ä¾›ç”µè¿‘ä¸¤å¤©ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä»¿çœŸä¿çœŸåº¦é™åˆ¶**ï¼šå½“å‰æ¨¡å‹é‡‡ç”¨ç»„ä»¶çº§æŠ½è±¡è€Œéå…¨ä¸‰ç»´ CFD ä»¿çœŸï¼Œç²¾åº¦æœ‰é™ã€‚
- **æ”¶æ•›æ€§æ— ç†è®ºä¿è¯**ï¼šè¿›åŒ–è¿‡ç¨‹ä¾èµ–å¯å‘å¼ç­–ç•¥ï¼Œâ€œä¼˜åŒ–åé€‰æ‹©â€å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚
- **èµ„äº§å¤šæ ·æ€§å—é™**ï¼šç›®å‰ä»…æ”¯æŒé£å†·ç³»ç»Ÿï¼Œæœªæ¶µç›–æ¶²å†·ï¼ˆD2Cï¼‰ã€èƒŒæ¿æ¢çƒ­å™¨ç­‰å…ˆè¿›æŠ€æœ¯ã€‚
- **å¤šç›®æ ‡ä¼˜åŒ–ç¼ºå¤±**ï¼šå½“å‰ä»…ä»¥ PUE ä¸ºç›®æ ‡ï¼Œæœªè€ƒè™‘æ°´è€—ã€ç¢³æ’æ”¾ã€å»ºè®¾æˆæœ¬ç­‰å…¶ä»–å¯æŒç»­æŒ‡æ ‡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±• SimReady èµ„äº§åº“ï¼Œæ”¯æŒæ›´å¤šå†·å´æŠ€æœ¯ä¸å¼‚æ„ IT è®¾å¤‡ã€‚
- å¼•å…¥å¤šæ¨¡æ€ç¼–ç å™¨ç†è§£æµåœºæ•°æ®ï¼Œæå‡å¯¹é«˜ç»´ä»¿çœŸè¾“å‡ºçš„è¯­ä¹‰è§£æèƒ½åŠ›ã€‚
- æ¢ç´¢å¤šç›®æ ‡ä¼˜åŒ–æ¡†æ¶ï¼ˆå¦‚ MOSAIC [23]ï¼‰ï¼Œå¹³è¡¡èƒ½æ•ˆã€æ°´æ•ˆä¸ç»æµæ€§ã€‚
- å¼€å‘é’ˆå¯¹ LLM å¹»è§‰çš„é£é™©æ§åˆ¶ä¸å¾®è°ƒç­–ç•¥ï¼Œå¢å¼ºç³»ç»Ÿç¨³å®šæ€§ã€‚
- å°† Phythesis æ¨å¹¿è‡³å…¶ä»–èƒ½æºåŸºç¡€è®¾æ–½è®¾è®¡é¢†åŸŸï¼ˆå¦‚æ™ºèƒ½å»ºç­‘ HVACã€å¾®ç”µç½‘ç­‰ï¼‰ã€‚

---

> **æ€»ç»“**ï¼šPhythesis æˆåŠŸæ„å»ºäº†ä¸€ä¸ªå°† LLM åˆ›é€ åŠ›ä¸ç‰©ç†è§„å¾‹çº¦æŸæ·±åº¦èåˆçš„ç”Ÿæˆè®¾è®¡æ¡†æ¶ï¼Œåœ¨æ•°æ®ä¸­å¿ƒè¿™ä¸€å…¸å‹å·¥ä¸šåœºæ™¯ä¸­å±•ç°å‡ºå“è¶Šçš„è‡ªåŠ¨åŒ–è®¾è®¡èƒ½åŠ›ä¸æ˜¾è‘—çš„èŠ‚èƒ½æ½œåŠ›ï¼Œä¸ºä¸‹ä¸€ä»£ AI-Driven å¯æŒç»­åŸºç¡€è®¾æ–½è®¾è®¡æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 9. [TDC-Cache: A Trustworthy Decentralized Cooperative Caching Framework for Web3.0](https://arxiv.org/abs/2512.09961)

**Authors**: Jinyu Chen, Long Shi, Taotao Wang, Jiaheng Wang, Wei Zhang  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.09961v1  

#### Abstract
The rapid growth of Web3.0 is transforming the Internet from a centralized structure to decentralized, which empowers users with unprecedented self-sovereignty over their own data. However, in the context of decentralized data access within Web3.0, it is imperative to cope with efficiency concerns c...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTDC-Cache: A Trustworthy Decentralized Cooperative Caching Framework for Web3.0

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨ **Web3.0** æ¶æ„ä¸­ï¼Œå°½ç®¡å»ä¸­å¿ƒåŒ–å­˜å‚¨ï¼ˆå¦‚ IPFSã€SWARMï¼‰èµ‹äºˆç”¨æˆ·æ•°æ®ä¸»æƒï¼Œä½†ç”±äºä»¥ä¸‹åŸå› å¯¼è‡´**è®¿é—®æ•ˆç‡ä½ä¸‹**ï¼š
- åˆ†å¸ƒå¼å…±è¯†å¼•å…¥é«˜ç½‘ç»œå»¶è¿Ÿï¼›
- æ•°æ®ä»¥åˆ†å—ï¼ˆBLOBï¼‰å½¢å¼å­˜å‚¨ï¼Œæ£€ç´¢æ•ˆç‡ä½ï¼›
- ç¼ºä¹é«˜æ•ˆçš„ç¼“å­˜æœºåˆ¶ï¼Œæ— æ³•åº”å¯¹å†…å®¹æµè¡Œåº¦çš„é•¿å°¾åˆ†å¸ƒã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿé›†ä¸­å¼ç¼“å­˜ç­–ç•¥ï¼ˆå¦‚ CDNï¼‰ä¸é€‚ç”¨äº Web3.0 çš„å»ä¸­å¿ƒåŒ–æ¶æ„ï¼Œä¸”ç°æœ‰æ–¹æ¡ˆç¼ºä¹å¯¹**æ¶æ„èŠ‚ç‚¹æ”»å‡»**ï¼ˆå¦‚æ•°æ®ç¯¡æ”¹ã€æ¨¡å‹æ±¡æŸ“ï¼‰çš„å®‰å…¨ä¿éšœã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **TDC-Cache** â€”â€” ä¸€ç§å¯ä¿¡çš„å»ä¸­å¿ƒåŒ–ååŒç¼“å­˜æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**ä¸¤å±‚æ¶æ„è®¾è®¡ï¼šDecentralized Oracle Network (DON) å±‚**
- å¼•å…¥ **DON å±‚**ä½œä¸ºç”¨æˆ·ä¸å»ä¸­å¿ƒåŒ–å­˜å‚¨ä¹‹é—´çš„å¯ä¿¡ä¸­ä»‹ã€‚
- å¤šä¸ª **Oracle èŠ‚ç‚¹**ç»„æˆåˆ†å¸ƒå¼ç¼“å­˜ç½‘ç»œï¼Œå…·å¤‡æœ¬åœ°ç¼“å­˜æ± ï¼ˆDRAM + NVMe SSDï¼‰å’Œæ™ºèƒ½å†³ç­–èƒ½åŠ›ã€‚
- é€šè¿‡ **DLT å±‚**ï¼ˆåŒºå—é“¾ + å»ä¸­å¿ƒåŒ–å­˜å‚¨ï¼‰å®ç°å…ƒæ•°æ®ç®¡ç†ä¸çŠ¶æ€è®°å½•ã€‚

#### ï¼ˆ2ï¼‰**åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å»ä¸­å¿ƒåŒ–ç¼“å­˜ç­–ç•¥ï¼ˆDRL-DCï¼‰**
- å°†ç¼“å­˜å†³ç­–å»ºæ¨¡ä¸º **Dec-POMDP**ï¼ˆDecentralized Partially Observable Markov Decision Processï¼‰ã€‚
- é‡‡ç”¨ **QMIX** ç®—æ³•è¿›è¡Œå¤šæ™ºèƒ½ä½“ååŒè®­ç»ƒï¼Œä¼˜åŒ–é•¿æœŸç¼“å­˜å‘½ä¸­ç‡ã€‚
- æ¯ä¸ª Oracle åŸºäºå±€éƒ¨è§‚å¯Ÿï¼ˆè¯·æ±‚åºåˆ—ã€ç¼“å­˜çŠ¶æ€ï¼‰ç‹¬ç«‹å†³ç­–ï¼Œå®ç°å»ä¸­å¿ƒåŒ–è‡ªé€‚åº”ä¼˜åŒ–ã€‚

#### ï¼ˆ3ï¼‰**æ–°å‹å…±è¯†æœºåˆ¶ï¼šProof of Cooperative Learning (PoCL)**
- é’ˆå¯¹ DRL æ¨¡å‹èšåˆè¿‡ç¨‹ä¸­çš„æ‹œå åº­é£é™©ï¼Œæå‡º **PoCL** å…±è¯†åè®®ã€‚
- åŒ…å«å››ä¸ªé˜¶æ®µï¼šPrepare â†’ Train â†’ Synchronize â†’ Commitã€‚
- å¼•å…¥ **å¯éªŒè¯åä½œè¯æ˜ï¼ˆcooperative proofï¼‰**ï¼Œç”±å†å²å‘½ä¸­æ•°å’Œå¥–åŠ±æ„æˆï¼Œç”¨äºå…¬å¹³é€‰æ‹©è®­ç»ƒ Oracleã€‚
- é€šè¿‡ Commit é˜¶æ®µæŠ•ç¥¨æœºåˆ¶é˜²æ­¢æ¶æ„æ¨¡å‹æ›´æ–°ï¼Œç¡®ä¿å­¦ä¹ ä¸€è‡´æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ LRU/LFU/FIFOï¼‰ | TDC-Cache |
|------|----------------------------|-----------|
| æ¶æ„é€‚é…æ€§ | ä¸­å¿ƒåŒ–è®¾è®¡ï¼Œä¸é€‚ç”¨äº Web3.0 | å®Œå…¨å»ä¸­å¿ƒåŒ–ï¼Œé€‚é… DLT æ¶æ„ |
| å†³ç­–æ™ºèƒ½åŒ– | é™æ€è§„åˆ™ï¼Œéš¾ä»¥é€‚åº”åŠ¨æ€æµé‡ | åŠ¨æ€å­¦ä¹ å†…å®¹æµè¡Œè¶‹åŠ¿ï¼Œå®æ—¶ä¼˜åŒ– |
| å®‰å…¨æ€§ | æ— é˜²æ”»å‡»æœºåˆ¶ | æ”¯æŒæ‹œå åº­å®¹é”™ï¼ŒæŠµå¾¡æ¨¡å‹æŠ•æ¯’ |
| ååŒæ€§ | å­¤ç«‹ç¼“å­˜ï¼Œç¼ºä¹åä½œ | å¤š Oracle ååŒå­¦ä¹ ä¸ç¼“å­˜å…±äº« |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **å®éªŒç¯å¢ƒé…ç½®**
- æ“ä½œç³»ç»Ÿï¼šUbuntu 24.04 LTS
- CPUï¼šIntel Core i9-14900K
- GPUï¼šNVIDIA GeForce RTX 4090ï¼ˆ24GB VRAMï¼‰
- å†…å­˜ï¼š128GB RAMï¼Œ1TB SSD

### **æ¨¡æ‹Ÿå‚æ•°è®¾ç½®**
- Oracle æ•°é‡ $ M = 4 $
- ç¼“å­˜å®¹é‡ $ C_m = 4 $ï¼ˆå•ä½å†…å®¹ï¼‰
- å†…å®¹æ€»æ•° $ F = 1000 $
- ç”¨æˆ·æ•°é‡ $ U = 10 $ï¼Œæ¯æ—¶éš™ç”Ÿæˆ 1000 è¯·æ±‚
- æ—¶é—´æ§½ $ T = 10,000 $
- å†…å®¹æµè¡Œåº¦æœä» **Zipf åˆ†å¸ƒ**ï¼Œå‚æ•° $ \alpha \in \{0.5, 1.0, 1.5\} $

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Cache Hit Rate** | æˆåŠŸä» DON å±‚å‘½ä¸­çš„è¯·æ±‚æ¯”ä¾‹ |
| **Content Retrieval Latency** | ä»è¯·æ±‚åˆ°æ¥æ”¶å†…å®¹çš„æ€»è€—æ—¶ |
| **Success Consensus Rate** | PoCL å„é˜¶æ®µæˆåŠŸå®Œæˆçš„æ¦‚ç‡ |
| **Average Access Latency** | æ‰€æœ‰è¯·æ±‚çš„å¹³å‡å»¶è¿Ÿ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **ä¼ ç»Ÿç¼“å­˜ç­–ç•¥**ï¼š
  - LRUï¼ˆLeast Recently Usedï¼‰
  - LFUï¼ˆLeast Frequently Usedï¼‰
  - FIFOï¼ˆFirst In First Outï¼‰
  - Random
- **ç›´æ¥è®¿é—®ï¼ˆDirect Accessï¼‰**ï¼šç»•è¿‡ç¼“å­˜ï¼Œç›´æ¥ä» DLT è·å–æ•°æ®
- **å…±è¯†å¯¹æ¯”**ï¼šä¸ **PBFT** å¯¹æ¯”å…±è¯†æˆåŠŸç‡

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

| æ€§èƒ½æŒ‡æ ‡ | æå‡å¹…åº¦ | è¯´æ˜ |
|--------|---------|------|
| å¹³å‡è®¿é—®å»¶è¿Ÿé™ä½ | **20%** | ç›¸æ¯”ç›´æ¥è®¿é—® |
| æœ€å¤§ç¼“å­˜å‘½ä¸­ç‡æå‡ | **18%** | ç›¸æ¯” LFU/LRU ç­‰ä¼ ç»Ÿç­–ç•¥ |
| æˆåŠŸå…±è¯†ç‡æå‡ | **10%** | ç›¸æ¯” PBFTï¼Œåœ¨é«˜æ•…éšœåœºæ™¯ä¸‹æ›´ä¼˜ |

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### ï¼ˆ1ï¼‰**ç¼“å­˜å‘½ä¸­ç‡ï¼ˆFig. 7 & Fig. 8ï¼‰**
- åœ¨ $ \alpha = 1.0 $ ä¸‹ï¼Œ**DRL-DC** å‘½ä¸­ç‡è¾¾åˆ°çº¦ **0.75**ï¼Œæ˜¾è‘—é«˜äºï¼š
  - LFU (~0.65)
  - LRU (~0.60)
  - Random (~0.55)
- éšç€ $ \alpha $ å¢å¤§ï¼ˆæµè¡Œåº¦æ›´é›†ä¸­ï¼‰ï¼Œæ‰€æœ‰ç­–ç•¥å‘½ä¸­ç‡ä¸Šå‡ï¼Œä½† **DRL-DC å§‹ç»ˆé¢†å…ˆ 10%~20%**
- DRL-DC è¡¨ç°å‡ºæ›´å¼ºçš„ç¨³å®šæ€§ä¸é€‚åº”æ€§ï¼Œå°¤å…¶åœ¨é•¿æœŸè¿è¡Œä¸­æŒç»­ä¼˜åŒ–

#### ï¼ˆ2ï¼‰**å†…å®¹æ£€ç´¢å»¶è¿Ÿï¼ˆTable IIï¼‰**
| åœºæ™¯ï¼ˆ$ \alpha=0.5 $ï¼‰ | DRL-DC | LFU | LRU | Direct Access |
|-----------------------|--------|-----|-----|---------------|
| å°æ–‡ä»¶ï¼ˆ1KBâ€“256KBï¼‰ | **6.90 ms/KB** | 7.13 | 7.16 | 8.19 |
| å¤§æ–‡ä»¶ï¼ˆ>1MBï¼‰       | **1.24 ms/KB** | 1.28 | 1.29 | 1.46 |

- åœ¨æ‰€æœ‰å†…å®¹å¤§å°å’Œæµè¡Œåº¦ä¸‹ï¼Œ**DRL-DC å‡å®ç°æœ€ä½å»¶è¿Ÿ**
- ç›¸æ¯”ç›´æ¥è®¿é—®ï¼Œå»¶è¿Ÿå‡å°‘ **20% ä»¥ä¸Š**

#### ï¼ˆ3ï¼‰**å…±è¯†æˆåŠŸç‡ï¼ˆFig. 5 & Fig. 6ï¼‰**
- å½“èŠ‚ç‚¹å¤±è´¥æ¦‚ç‡ $ P_f = 0.1 $ æ—¶ï¼š
  - **PoCL æˆåŠŸç‡æ¥è¿‘ 1.0**
  - **PBFT æ˜æ˜¾ä¸‹é™**
- åœ¨å¤§è§„æ¨¡ç½‘ç»œï¼ˆ$ M=300 $ï¼‰ä¸­ï¼š
  - PoCL æˆåŠŸç‡ä»ç»´æŒé«˜ä½
  - PBFT å‡ºç°â€œæ‹ç‚¹â€åæ€¥å‰§ä¸‹é™
- PoCL çš„**æ‹ç‚¹æ¯” PBFT é«˜å‡º 209.47%**ï¼Œè¡¨æ˜æ›´å¼ºçš„å¯æ‰©å±•æ€§

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åˆ†æï¼‰**
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†ä»è®¾è®¡é€»è¾‘å¯æ¨æ–­ï¼š
- è‹¥ç§»é™¤ **PoCL**ï¼Œç³»ç»Ÿå°†æ— æ³•æŠµå¾¡æ‹œå åº­èŠ‚ç‚¹ï¼Œå¯¼è‡´ç¼“å­˜ç­–ç•¥è¢«æ±¡æŸ“ï¼›
- è‹¥æ›¿æ¢ **DRL-DC** ä¸ºé™æ€ç­–ç•¥ï¼Œåˆ™æ— æ³•é€‚åº”åŠ¨æ€è¯·æ±‚æ¨¡å¼ï¼Œå‘½ä¸­ç‡ä¸‹é™ï¼›
- è‹¥å–æ¶ˆ DON å±‚ï¼Œåˆ™é€€åŒ–ä¸ºç›´æ¥è®¿é—®ï¼Œå»¶è¿Ÿæ˜¾è‘—å¢åŠ ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**
1. âœ… **å¼•å…¥ DON å±‚å¯æœ‰æ•ˆæ¡¥æ¥ Web3.0 ä¸­ç”¨æˆ·ä¸å»ä¸­å¿ƒåŒ–å­˜å‚¨ä¹‹é—´çš„æ€§èƒ½é¸¿æ²Ÿ**ï¼Œæ˜¾è‘—é™ä½è®¿é—®å»¶è¿Ÿã€‚
2. âœ… **DRL-DC èƒ½å¤ŸåŠ¨æ€å­¦ä¹ å†…å®¹æµè¡Œè¶‹åŠ¿**ï¼Œåœ¨å¤šç§ Zipf å‚æ•°ä¸‹å‡ä¼˜äºä¼ ç»Ÿç¼“å­˜ç­–ç•¥ã€‚
3. âœ… **PoCL å…±è¯†æœºåˆ¶å…¼å…·å®‰å…¨æ€§ä¸é«˜æ•ˆæ€§**ï¼Œç›¸æ¯” PBFT æ›´é€‚åˆå¤§è§„æ¨¡ã€é«˜åŠ¨æ€æ€§çš„å»ä¸­å¿ƒåŒ–ç½‘ç»œã€‚
4. âœ… å®éªŒéªŒè¯äº† TDC-Cache åœ¨ **å»¶è¿Ÿã€å‘½ä¸­ç‡ã€å…±è¯†å¯é æ€§**ä¸‰ä¸ªç»´åº¦ä¸Šçš„å…¨é¢ä¼˜åŠ¿ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šæ¯ä¸ª Oracle éœ€è¿è¡Œ DRL æ¨¡å‹ï¼Œå¯¹è½»é‡çº§è®¾å¤‡å¯èƒ½ä¸å‹å¥½ï¼›
2. **ä¾èµ–ç¨³å®šé€šä¿¡**ï¼šPrepare å’Œ Synchronize é˜¶æ®µéœ€è‰¯å¥½ç½‘ç»œæ”¯æŒï¼Œå¦åˆ™å½±å“å…±è¯†æ•ˆç‡ï¼›
3. **æµ‹è¯•é›†åŒæ­¥ä¾èµ– OMC**ï¼šè‹¥æ™ºèƒ½åˆçº¦è¢«æ”»å‡»ï¼Œå¯èƒ½å½±å“ PoCL å®‰å…¨æ€§ï¼›
4. **å°šæœªéƒ¨ç½²äºçœŸå® Web3.0 ç½‘ç»œ**ï¼šå½“å‰ä¸ºä»¿çœŸç¯å¢ƒï¼Œå®é™…æ€§èƒ½æœ‰å¾…éªŒè¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ¿€åŠ±æœºåˆ¶è®¾è®¡**ï¼šé¼“åŠ±æ›´å¤šèŠ‚ç‚¹è¯šå®å‚ä¸ç¼“å­˜ä¸è®­ç»ƒï¼›
2. **è½»é‡åŒ– DRL æ¨¡å‹**ï¼šé€‚é…èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ï¼›
3. **åŠ¨æ€ç½‘ç»œæ‹“æ‰‘æ”¯æŒ**ï¼šåº”å¯¹é¢‘ç¹åŠ å…¥/é€€å‡ºçš„ Oracleï¼›
4. **è·¨é“¾ç¼“å­˜ååŒ**ï¼šæ‰©å±•è‡³å¤šæ¡åŒºå—é“¾ç”Ÿæ€ï¼›
5. **éšç§ä¿æŠ¤å¢å¼º**ï¼šç»“åˆ Federated Learning è¿›ä¸€æ­¥ä¿æŠ¤ç”¨æˆ·è¯·æ±‚éšç§ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> TDC-Cache æ˜¯é¦–ä¸ªé¢å‘ Web3.0 çš„å¯ä¿¡å»ä¸­å¿ƒåŒ–ååŒç¼“å­˜æ¡†æ¶ï¼Œé€šè¿‡ **DON å±‚ + DRL-DC + PoCL** çš„ä¸‰ä½ä¸€ä½“è®¾è®¡ï¼Œåœ¨ä¿è¯å®‰å…¨çš„å‰æä¸‹æ˜¾è‘—æå‡äº†å»ä¸­å¿ƒåŒ–ç³»ç»Ÿçš„è®¿é—®æ•ˆç‡ï¼Œä¸ºä¸‹ä¸€ä»£äº’è”ç½‘åŸºç¡€è®¾æ–½æä¾›äº†é‡è¦å‚è€ƒã€‚

</details>

---

### 10. [T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground](https://arxiv.org/abs/2512.10430)

**Authors**: Dmitrii Stoianov, Danil Taranets, Olga Tsymboi, Ramil Latypov, Almaz Dautov, Vladislav Kruglikov, Nikita Surkov, German Abramov, Pavel Gein, Dmitry Abulkhanov, Mikhail Gashkov, Viktor Zelenkovskiy, Artem Batalov, Aleksandr Medvedev, Anatolii Potapov  
**Category**: cs.CL  
**Published**: 2025-12-12  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.10430v1  

#### Abstract
We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and exten...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¿„è¯­å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæ€ç³»ç»Ÿå­˜åœ¨ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š
- **é«˜è´¨é‡å¼€æºæ¨¡å‹ç¨€ç¼º**ï¼šå¤šæ•°é«˜æ€§èƒ½ä¿„è¯­æ¨¡å‹ä¸ºé—­æºAPIæœåŠ¡ï¼ˆå¦‚YandexGPTã€GigaChatï¼‰ï¼Œé™åˆ¶äº†ç ”ç©¶å¯å¤ç°æ€§å’Œç¤¾åŒºå‘å±•ã€‚
- **ç¼ºä¹ç»Ÿä¸€æ¨ç†è¯„æµ‹ä½“ç³»**ï¼šç¼ºå°‘é’ˆå¯¹ä¿„è¯­å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå°¤å…¶æ˜¯æ•°å­¦ç«èµ›çº§ï¼‰çš„æƒå¨åŸºå‡†ã€‚
- **å¤šè¯­è¨€åˆ†è¯å™¨å¯¹ä¿„è¯­æ”¯æŒä¸è¶³**ï¼šé€šç”¨å¤šè¯­è¨€tokenizeråœ¨å¤„ç†è¥¿é‡Œå°”å­—æ¯æ—¶æ•ˆç‡ä½ä¸‹ï¼Œå¯¼è‡´æ–‡æœ¬å‹ç¼©ç‡å·®ã€æ¨ç†å»¶è¿Ÿé«˜ã€‚
- **æ¨ç†æ•ˆç‡ä¼˜åŒ–ç¼ºå¤±**ï¼šä¿„è¯­æ¨¡å‹ä¸­å°šæœªæœ‰æ•ˆåº”ç”¨speculative decodingç­‰å…ˆè¿›è§£ç åŠ é€ŸæŠ€æœ¯ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
T-pro 2.0 æå‡ºäº†ä¸€å¥—å®Œæ•´çš„é«˜æ•ˆä¿„è¯­æ··åˆæ¨ç†ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰Cyrillic-dense Tokenizer
- åœ¨Qwen3 tokenizeråŸºç¡€ä¸Šï¼Œå°†34kä½é¢‘éè¥¿é‡Œå°”ç¬¦å·æ›¿æ¢ä¸ºé«˜é¢‘ä¿„è¯­å­è¯å•å…ƒã€‚
- æ˜¾è‘—æå‡ä¿„è¯­æ–‡æœ¬ç¼–ç æ•ˆç‡ï¼šä¿„è¯­ç»´åŸºç™¾ç§‘ä¸­â€œæ¯è¯å¹³å‡tokenæ•°â€ä»3.12é™è‡³2.38ï¼Œâ€œâ‰¤2ä¸ªtokençš„å•è¯å æ¯”â€ä»38.2%æå‡è‡³60.1%ã€‚
- æ”¹è¿›æ³›åŒ–è‡³å…¶ä»–8ç§è¥¿é‡Œå°”è¯­è¨€ï¼ˆå¦‚ä¹Œå…‹å…°è¯­ã€å“ˆè¨å…‹è¯­ç­‰ï¼‰ï¼Œå‡ä¼˜äºRuAdaptã€GigaChatç­‰åŸºçº¿tokenizerã€‚

#### ï¼ˆ2ï¼‰Hybrid Reasoning Training Pipeline
- æ”¯æŒä¸¤ç§æ¨¡å¼è¾“å‡ºï¼š**direct answering**ï¼ˆå¿«é€Ÿå“åº”ï¼‰ä¸ **reasoning-trace generation**ï¼ˆé€æ­¥æ¨ç†ï¼‰ã€‚
- æ„å»ºå¤§è§„æ¨¡ä¿„è¯­æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† **T-Wix 500k**ï¼š
  - åŒ…å«çº¦30ké«˜è´¨é‡ä¿„è¯­æ¨ç†æ ·æœ¬ï¼Œç»æ•™å¸ˆæ¨¡å‹ï¼ˆQwen3-235Bï¼‰ç”Ÿæˆå¹¶ç”±Reward Modelç­›é€‰ã€‚
  - å¼•å…¥â€œæœ€è¿‘å‘å±•åŒºâ€ï¼ˆZone of Proximal Development, ZPDï¼‰ç†å¿µï¼Œé€‰æ‹©å­¦ç”Ÿæ¨¡å‹â€œè·³ä¸€è·³å¤Ÿå¾—ç€â€çš„ä»»åŠ¡è¿›è¡Œè’¸é¦è®­ç»ƒã€‚

#### ï¼ˆ3ï¼‰EAGLE-style Speculative Decoding åŠ é€Ÿæ¨ç†
- é›†æˆè½»é‡çº§draft modelï¼ˆåŸºäºå•å±‚Llama-2 + FR-Specç»„ä»¶ï¼‰ï¼Œå®ç°åŠ¨æ€tokenæ ‘é¢„æµ‹ã€‚
- åˆ©ç”¨SGLangéƒ¨ç½²EAGLE-2çš„dynamic draft treeæœºåˆ¶ï¼Œåœ¨ä¿è¯è¾“å‡ºåˆ†å¸ƒä¸€è‡´æ€§çš„å‰æä¸‹æ˜¾è‘—é™ä½å»¶è¿Ÿã€‚

#### ï¼ˆ4ï¼‰å‘å¸ƒå®Œæ•´å¼€æ”¾ç”Ÿæ€
- å¼€æºå…¨éƒ¨å…³é”®èµ„æºï¼š
  - æ¨¡å‹æƒé‡ï¼ˆApache-2.0ï¼‰
  - æ¨ç†åŸºå‡† **T-Math**ï¼ˆ331é“å…¨ä¿„/è«æ–¯ç§‘æ•°å­¦å¥¥èµ›é¢˜ï¼‰
  - æŒ‡ä»¤æ•°æ®é›† **T-Wix 500k**ï¼ˆODC-Byï¼‰
  - EAGLE draft weights
- æä¾›äº¤äº’å¼Web Demoï¼ˆ[http://t-pro-2-0.streamlit.app](http://t-pro-2-0.streamlit.app)ï¼‰ï¼Œæ”¯æŒå®æ—¶å¯¹æ¯”ä¸åŒæ¨¡å¼ä¸‹çš„æ¨ç†è¿‡ç¨‹ä¸æ€§èƒ½æŒ‡æ ‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **è¯­è¨€é€‚é…æ€§** | Cyrillic-dense tokenizeræ˜¾è‘—ä¼˜äºå¤šè¯­è¨€tokenizeråœ¨ä¿„è¯­ä¸Šçš„è¡¨ç° |
| **æ¨ç†èƒ½åŠ›** | åœ¨åŸç”Ÿä¿„è¯­æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šè¶…è¶Šæ‰€æœ‰å¼€æºåŠå¤šæ•°é—­æºæ¨¡å‹ |
| **æ¨ç†æ•ˆç‡** | å¹³å‡æé€Ÿ1.85Ã—ï¼ŒSTEMé¢†åŸŸæœ€é«˜è¾¾2.25Ã—ï¼ˆT-Mathï¼‰ |
| **å¼€æ”¾æ€§** | å…¨æ ˆå¼€æºï¼Œæ¶µç›–æ¨¡å‹ã€æ•°æ®ã€benchmarkã€inference pipeline |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| ç±»å‹ | æ•°æ®é›†åç§° | æè¿° |
|------|-----------|------|
| **é¢„è®­ç»ƒ/ä¸­æœŸè®­ç»ƒ** | Midtraining Mix (40B tokens) | å¤šæºæ··åˆï¼šä¿„è¯­(49%)ã€è‹±è¯­(36%)ã€ä»£ç (9.3%)ï¼›è¦†ç›–Reasoning(34.6%)ã€General QA(28.8%)ã€Math(16.2%)ç­‰ |
| **SFTæ•°æ®é›†** | **T-Wix 500k** | è‡ªç ”æœ€å¤§è§„æ¨¡ä¿„è¯­æ··åˆæ¨ç†SFTæ•°æ®é›†ï¼š<br>- ä¸€èˆ¬æŒ‡ä»¤ï¼š468k<br>- æ¨ç†ä¸“é¡¹ï¼š~30kï¼ˆç¿»è¯‘+æ•™å¸ˆè’¸é¦ï¼‰ |
| **è¯„ä¼°åŸºå‡†** | **T-Math** | æ–°å»ºä¿„è¯­æ•°å­¦æ¨ç†benchmarkï¼Œ331é“é«˜ä¸­å¥¥èµ›é¢˜ï¼ˆ1998â€“2025ï¼‰ï¼Œè‡ªåŠ¨è¯„åˆ†ï¼ˆ`\boxed{}` + `math_verify`ï¼‰ |
| | ruAIME / ruMATH-500 / ruGPQA / ruLCB | è‹±æ–‡æ¨ç†benchmarkçš„ä¸“ä¸šæœ¬åœ°åŒ–ç‰ˆæœ¬ |
| | MERA / ruMMLU-Pro | ä¿„è¯­å¸¸è¯†ç†è§£ä¸é€»è¾‘èƒ½åŠ›æµ‹è¯• |
| | Arena Hard Ru / WildChat Hard Ru | ä¿„è¯­å¯¹è¯è´¨é‡è¯„ä¼°ï¼ˆä½¿ç”¨DeepSeek-V3.1ä½œä¸ºjudgeï¼‰ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šç»Ÿä¸€ä½¿ç”¨32k context windowã€‚
- **æ¨ç†æ¨¡å¼å¯¹æ¯”**ï¼š
  - Standard Modeï¼ˆç›´æ¥å›ç­”ï¼‰
  - Reasoning Modeï¼ˆæ˜¾å¼æ¨ç†é“¾ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å‡†ç¡®ç‡ï¼ˆPass@1, Scoreï¼‰
  - æ¨ç†é€Ÿåº¦ï¼ˆSpeedupå€æ•°ï¼‰
  - ååé‡ï¼ˆtokens/secï¼‰
  - speculative decodingæ¥å—ç‡ï¼ˆacceptance lengthï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å‚ä¸æ¯”è¾ƒçš„ä¸»æµæ¨¡å‹åŒ…æ‹¬ï¼š
- **å¼€æºä¿„è¯­æ¨¡å‹**ï¼šQwen3-32B, RuadaptQwen3-32B-Instruct, Gemma 3 27B, DeepSeek-R1-Distill-Qwen-32B
- **é—­æºä¿„è¯­æ¨¡å‹**ï¼šYandexGPT5-Pro, GigaChat 2 Max
- **å‰æ²¿é€šç”¨æ¨¡å‹**ï¼šDeepSeek-V3, DeepSeek-R1, GPT-4o, o4-mini

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 4 & Table 5ï¼‰

#### ğŸ“Š ä¿„è¯­ç»¼åˆèƒ½åŠ›ï¼ˆTable 4ï¼‰
| æ¨¡å‹ | MERA | ruMMLU-Pro | Arena Hard Ru |
|------|-------|-------------|----------------|
| **T-pro 2.0 (Ours)** | **0.660** | **0.697** | **91.1** |
| Qwen3-32B | 0.582 | 0.677 | 83.95 |
| RuadaptQwen3 | 0.574 | 0.652 | 68.4 |
| GPT-4o | 0.642 | 0.714 | 85.14 |

> âœ… åœ¨ä¿„è¯­å¸¸è¯†ä¸å¯¹è¯ä»»åŠ¡ä¸Šæ¥è¿‘GPT-4oï¼Œæ˜¾è‘—ä¼˜äºåŒç±»å¼€æºæ¨¡å‹ã€‚

#### ğŸ”¢ ä¿„è¯­é«˜çº§æ¨ç†èƒ½åŠ›ï¼ˆTable 5ï¼‰
| æ¨¡å‹ | T-Math | ruAIME 2024 | ruMATH-500 | Vikhr Math |
|------|--------|--------------|-------------|------------|
| **T-pro 2.0 (Ours)** | **0.541** | **0.704** | **0.940** | **0.799** |
| Qwen3-32B | 0.529 | 0.706 | 0.938 | 0.809 |
| DeepSeek-V3 | 0.278 | 0.319 | 0.882 | 0.613 |
| GPT-4o | 0.106 | 0.090 | 0.766 | 0.372 |

> âœ… åœ¨T-Mathè¿™ä¸€åŸç”Ÿä¿„è¯­å¥¥èµ›é¢˜åŸºå‡†ä¸Šå¤§å¹…é¢†å…ˆé—­æºæ¨¡å‹ï¼ˆGPT-4oä»…0.106ï¼‰ï¼Œä¸”åœ¨ruAIMEä¸Šè¿œè¶…DeepSeek-V3ï¼ˆ0.704 vs 0.319ï¼‰ã€‚

#### âš¡ æ¨ç†æ•ˆç‡ï¼ˆTable 2ï¼‰
| Benchmark | Speedup (Standard) | Speedup (Reasoning) | Acceptance Length |
|----------|--------------------|---------------------|-------------------|
| **Average** | **1.85Ã—** | **1.83Ã—** | ~3.39 |
| **T-Math** | â€” | **2.25Ã—** | **4.01** |
| **ruCodeEval** | 2.15Ã— | 1.84Ã— | 3.93 |

> âœ… STEMç±»ä»»åŠ¡åŠ é€Ÿæ›´æ˜æ˜¾ï¼ˆSTEMå¹³å‡1.99Ã— vs äººæ–‡ç¤¾ç§‘1.62Ã—ï¼‰ï¼Œè¯æ˜speculative decodingåœ¨ç»“æ„åŒ–å†…å®¹ä¸­æ›´æœ‰æ•ˆã€‚

#### ğŸŒ è‹±è¯­ä¿ç•™èƒ½åŠ›ï¼ˆTable 23ï¼‰
å°½ç®¡ä¸»è®­ç›®æ ‡ä¸ºä¿„è¯­ï¼ŒT-pro 2.0ä»ä¿æŒå¼ºå¤§è‹±æ–‡æ¨ç†èƒ½åŠ›ï¼š
| æ¨¡å‹ | AIME 2024 | MATH-500 | GPQA Diamond |
|------|-----------|-----------|---------------|
| **T-pro 2.0** | 0.765 | **0.966** | 0.641 |
| Qwen3-32B | 0.808 | 0.961 | 0.668 |

> âœ… è‹±æ–‡æ€§èƒ½æœªå› ä¿„è¯­ä¼˜åŒ–è€Œé€€åŒ–ï¼Œå…·å¤‡è‰¯å¥½è·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰ä¸­æœŸè®­ç»ƒç­–ç•¥å¯¹æ¯”ï¼ˆTable 12ï¼‰
| é…æ–¹ | ruAIME'24 | ruAIME'25 | ruGPQA |
|------|-----------|-----------|---------|
| Pre-train + Instruct | 0.60 | 0.47 | 0.58 |
| **Instruct-only** | **0.67** | **0.63** | **0.66** |

> â— ç»“è®ºï¼šå¯¹äºå·²å¼ºé¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŠ å…¥åŸå§‹pretrainæ•°æ®åè€Œä¸å¦‚çº¯instruction tuningæœ‰æ•ˆã€‚

#### ï¼ˆ2ï¼‰Tokenizerå½±å“ï¼ˆTable 13ï¼‰
| Tokenizer | MERA Macro-Avg |
|----------|------------------|
| Qwen3 (åŸç‰ˆ) | 0.560 |
| **T-pro 2.0 (Cyrillic-dense)** | **0.574** |

> âœ… æ–°tokenizerä¸ä»…ä¸æŸå®³æ€§èƒ½ï¼Œåè€Œç•¥æœ‰æå‡ï¼ŒéªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é’ˆå¯¹æ€§é€‚é…ä¼˜äºç›²ç›®æ‰©å±•**ï¼šé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„tokenizerã€instruction midtrainingå’Œæ¨ç†è’¸é¦ï¼Œå¯åœ¨ä¸å¢å¤§å‚æ•°é‡çš„å‰æä¸‹æ˜¾è‘—æå‡ä¿„è¯­æ¨ç†èƒ½åŠ›ã€‚
2. **Tokenizeræ˜¯å¤šè¯­è¨€LLMçš„å…³é”®ç“¶é¢ˆ**ï¼šCyrillic-dense tokenizerå¸¦æ¥çš„å‹ç¼©å¢ç›Šç›´æ¥è½¬åŒ–ä¸ºæ¨ç†é€Ÿåº¦ä¼˜åŠ¿ï¼Œå°¤å…¶åœ¨é•¿æ–‡æœ¬åœºæ™¯ä¸‹æ›´ä¸ºé‡è¦ã€‚
3. **Speculative Decodingé€‚ç”¨äºä¿„è¯­æ¨ç†**ï¼šEAGLE-styleæ–¹æ³•åœ¨ä¿„è¯­ä»»åŠ¡ä¸Šå®ç°å¹³å‡1.85Ã—åŠ é€Ÿï¼ŒSTEMé¢†åŸŸå¯è¾¾2.25Ã—ï¼Œè¯´æ˜å…¶è·¨è¯­è¨€é€‚ç”¨æ€§å¼ºã€‚
4. **é«˜è´¨é‡ä¿„è¯­æ¨ç†æ•°æ®ç¨€ç¼ºä½†å¯æ„å»º**ï¼šT-Mathè¯æ˜ï¼Œå³ä½¿å°è§„æ¨¡ï¼ˆ331é¢˜ï¼‰ã€é«˜éš¾åº¦çš„åŸç”Ÿä¿„è¯­benchmarkä¹Ÿèƒ½æ­ç¤ºæ¨¡å‹çœŸå®å·®è·ï¼Œæ¨åŠ¨é¢†åŸŸè¿›æ­¥ã€‚
5. **ä¿„è¯­ä¼˜åŒ–ä¸å½±å“è‹±è¯­èƒ½åŠ›**ï¼šåˆç†çš„è®¾è®¡å¯å®ç°åŒè¯­å¹³è¡¡ï¼Œé¿å…â€œæ¯è¯­å¢å¼ºã€å¤–è¯­é€€åŒ–â€çš„å¸¸è§é—®é¢˜ã€‚

### å±€é™æ€§
- **Agentèƒ½åŠ›æœ‰é™**ï¼šæœªä¸“é—¨ä¼˜åŒ–tool useæˆ–å¤šè½®è§„åˆ’ï¼Œagentè¡Œä¸ºè¡¨ç°ä¸åŸºç¡€Qwen3-32Bç›¸å½“ã€‚
- **ä»…ä½¿ç”¨ç¦»çº¿RLï¼ˆDPOï¼‰**ï¼šæœªå¼•å…¥åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆå¦‚PPOã€GRPOï¼‰ï¼Œå¯èƒ½é™åˆ¶é²æ£’æ€§ã€‚
- **é•¿ä¸Šä¸‹æ–‡æœªç»å®è¯éªŒè¯**ï¼šè™½æ”¯æŒRoPE scalingè‡³128kï¼Œä½†æœªåœ¨çœŸå®é•¿ä»»åŠ¡ä¸­æµ‹è¯•ä¸€è‡´æ€§ä¸æ£€ç´¢èƒ½åŠ›ã€‚
- **éƒ¨åˆ†è®­ç»ƒæ•°æ®ä¾èµ–ä¸“æœ‰æ¥æº**ï¼šå½±å“å®Œå…¨å¤ç°æ€§ï¼Œå°½ç®¡T-Wixå·²å…¬å¼€ä»¥ä¿ƒè¿›åç»­ç ”ç©¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¢å¼ºå·¥å…·è°ƒç”¨ä¸Agenticè¡Œä¸ºèƒ½åŠ›
- æ¢ç´¢åœ¨çº¿RLï¼ˆPPOç­‰ï¼‰è¿›ä¸€æ­¥æå‡å¯¹é½è´¨é‡
- å®æµ‹128ké•¿ä¸Šä¸‹æ–‡ä¸‹çš„å®é™…æ€§èƒ½
- æ‰©å±•T-Mathè‡³æ›´å¤šå­¦ç§‘ä¸è¯­è¨€å˜ä½“
- æ¨åŠ¨æ›´é€æ˜ã€æ ‡å‡†åŒ–çš„ä¿„è¯­LLMè¯„ä¼°åè®®

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼š  
> T-pro 2.0 ä¸åªæ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ä¿„è¯­æ¨¡å‹ï¼Œæ›´æ˜¯ä¸€ä¸ª**å¼€æ”¾ã€å¯å¤ç°ã€å¯æ‰©å±•çš„ç ”ç©¶å¹³å°**ã€‚å®ƒç³»ç»Ÿæ€§åœ°è§£å†³äº†ä¿„è¯­LLMåœ¨**æ•°æ®ã€æ¨¡å‹ã€è¯„ä¼°ã€æ¨ç†æ•ˆç‡**å››ä¸ªç»´åº¦çš„å…³é”®æŒ‘æˆ˜ï¼Œä¸ºéè‹±è¯­LLMçš„å‘å±•æä¾›äº†èŒƒå¼å‚è€ƒã€‚å…¶â€œå°æ­¥å¿«è·‘ã€ç²¾å‡†ä¼˜åŒ–â€çš„æ€è·¯å€¼å¾—å€Ÿé‰´ã€‚

</details>

---

### 11. [DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations](https://arxiv.org/abs/2512.10034)

**Authors**: Salom\'e Guilbert, Cassandra Masschelein, Jeremy Goumaz, Bohdan Naida, Philippe Schwaller  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.10034v1  

#### Abstract
Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
åˆ†å­åŠ¨åŠ›å­¦ï¼ˆ**Molecular Dynamics, MD**ï¼‰æ¨¡æ‹Ÿåœ¨è¯ç‰©å‘ç°å’Œè›‹ç™½è´¨å·¥ç¨‹ä¸­è‡³å…³é‡è¦ï¼Œä½†å…¶æµç¨‹å¤æ‚ã€æŠ€æœ¯é—¨æ§›é«˜ã€‚ç‰¹åˆ«æ˜¯**è›‹ç™½-é…ä½“ç³»ç»Ÿ**çš„æ¨¡æ‹Ÿï¼Œæ¶‰åŠç¹ççš„é¢„å¤„ç†æ­¥éª¤ï¼ˆå¦‚ç»“æ„æ¸…æ´—ã€è´¨å­åŒ–ã€æº¶å‰‚åŒ–ã€ç¦»å­ä¸­å’Œï¼‰ã€åŠ›åœºå‚æ•°åŒ–ã€å¤šé˜¶æ®µå¹³è¡¡ä»¥åŠè‡ªç”±èƒ½è®¡ç®—ç­‰ã€‚è¿™äº›æ­¥éª¤å®¹æ˜“å‡ºé”™ä¸”é«˜åº¦ä¾èµ–ä¸“å®¶ç»éªŒï¼Œé™åˆ¶äº†MDçš„å¹¿æ³›åº”ç”¨ã€‚

ç°æœ‰è‡ªåŠ¨åŒ–å·¥å…·ï¼ˆå¦‚CHAPERONgã€PyAutoFEPï¼‰è™½ç„¶ç®€åŒ–äº†éƒ¨åˆ†æµç¨‹ï¼Œä½†é€šå¸¸**ç¼ºä¹çµæ´»æ€§**ï¼Œéš¾ä»¥é€‚åº”ä¸åŒç³»ç»Ÿæˆ–è½¯ä»¶å¹³å°ï¼Œä¸”æ— æ³•å¤„ç†è¿è¡Œæ—¶é”™è¯¯æˆ–è¿›è¡Œè‡ªé€‚åº”ä¿®æ­£ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **DynaMate**ï¼Œä¸€ä¸ªåŸºäº**agentic LLM**ï¼ˆè‡ªä¸»ä»£ç†å¤§è¯­è¨€æ¨¡å‹ï¼‰çš„æ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œèƒ½å¤Ÿ**è‡ªä¸»è®¾è®¡å¹¶æ‰§è¡Œå®Œæ•´çš„è›‹ç™½-é…ä½“MDæ¨¡æ‹Ÿæµç¨‹**ï¼Œå¹¶æ”¯æŒä½¿ç”¨ **MM/PB(GB)SA** æ–¹æ³•è¿›è¡Œç»“åˆè‡ªç”±èƒ½è®¡ç®—ã€‚

DynaMateçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- **æ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“æ¶æ„**ï¼šç”±ä¸‰ä¸ªä¸“ç”¨æ™ºèƒ½ä½“ç»„æˆâ€”â€”**Planner**ï¼ˆè§„åˆ’ï¼‰ã€**MD Agent**ï¼ˆæ‰§è¡Œï¼‰ã€**Analyzer**ï¼ˆåˆ†æï¼‰ï¼Œå®ç°ä»»åŠ¡åˆ†å·¥ä¸ååŒã€‚
- **åŠ¨æ€å·¥å…·è°ƒç”¨ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰**ï¼šé›†æˆ **web search** å’Œ **PaperQA** å·¥å…·ï¼Œä½¿æ™ºèƒ½ä½“èƒ½ä»æ–‡çŒ®å’Œæ•°æ®åº“ä¸­è·å–å‚æ•°é€‰æ‹©ä¾æ®ï¼Œæå‡å†³ç­–çš„ç§‘å­¦æ€§å’Œå¯è¿½æº¯æ€§ã€‚
- **è‡ªçº é”™èƒ½åŠ›**ï¼šé€šè¿‡è¿­ä»£æ¨ç†æœºåˆ¶ï¼Œåœ¨æ¨¡æ‹Ÿå¤±è´¥æ—¶åˆ†æé”™è¯¯æ—¥å¿—ï¼Œå°è¯•ä¿®å¤è¾“å…¥æ–‡ä»¶æˆ–è°ƒæ•´å‚æ•°ï¼Œå…·å¤‡ä¸€å®šçš„â€œè¯•é”™â€èƒ½åŠ›ã€‚
- **è‡ªç„¶è¯­è¨€é©±åŠ¨**ï¼šç”¨æˆ·åªéœ€æä¾›è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ˆå¦‚â€œå¯¹PDB IDä¸º3HTBçš„è›‹ç™½-é…ä½“å¤åˆç‰©è¿›è¡Œ100ns MDæ¨¡æ‹Ÿâ€ï¼‰ï¼ŒDynaMateå³å¯è‡ªåŠ¨å®Œæˆå…¨æµç¨‹ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| åŠŸèƒ½ | MDCrow | NAMD-Agent | DynaMate |
|------|--------|------------|----------|
| è›‹ç™½-é…ä½“æ¨¡æ‹Ÿ | âŒ | âŒ | âœ… |
| ç»“åˆè‡ªç”±èƒ½è®¡ç®—ï¼ˆMM/PB(GB)SAï¼‰ | âŒ | âŒ | âœ… |
| æ–‡çŒ®/æ•°æ®åº“æ£€ç´¢ï¼ˆRAGï¼‰ | æœ‰é™ | âŒ | âœ… |
| è‡ªé€‚åº”é”™è¯¯çº æ­£ | âŒ | âŒ | âœ… |
| å¤šå¹³å°å…¼å®¹ï¼ˆGROMACS/AmberToolsï¼‰ | âŒï¼ˆä»…OpenMMï¼‰ | âŒï¼ˆä»…CHARMM-GUIï¼‰ | âœ… |

> **æ¥æºï¼šTable S1**

DynaMateæ˜¯é¦–ä¸ªæˆåŠŸå®ç°**ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–è›‹ç™½-é…ä½“MDæ¨¡æ‹Ÿ**çš„agenticç³»ç»Ÿï¼Œæ˜¾è‘—æå‡äº†è‡ªåŠ¨åŒ–æ°´å¹³å’Œé€‚ç”¨èŒƒå›´ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å®éªŒåœ¨**12ä¸ªä¸åŒçš„è›‹ç™½ç³»ç»Ÿ**ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œåˆ†ä¸ºä¸‰ç±»ï¼š
1. **5ä¸ªç»å…¸è›‹ç™½-é…ä½“å¤åˆç‰©**ï¼ˆç”¨äºåŸºå‡†æµ‹è¯•ï¼‰ï¼š
   - PDB IDs: `3HTB`, `3PTB`, `4GIH`, `4W52`, `5UEZ`
2. **5ä¸ªæ— é…ä½“è›‹ç™½ç³»ç»Ÿ**ï¼ˆæµ‹è¯•å¤šé“¾è›‹ç™½é€‚åº”æ€§ï¼‰ï¼š
   - PDB IDs: `1AKI`, `1FDH`, `1J37`, `2CBA`, `2VVB`
3. **2ä¸ªå«å·²çŸ¥é”™è¯¯çš„æŒ‘æˆ˜æ€§ç³»ç»Ÿ**ï¼š
   - `BRD4_UNL`ï¼šè¾“å…¥PDBä¸­æ•…æ„å¼•å…¥é”™è¯¯çš„æ°¯åŸå­å‘½å
   - `5KB6_ADN`ï¼šç³»ç»ŸåŒ…å«ä¸¤ä¸ªé…ä½“ï¼Œè¶…å‡ºå½“å‰å·¥å…·æ”¯æŒèŒƒå›´

> **æ¥æºï¼šTable S2**

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **LLMæ¨¡å‹**ï¼šæµ‹è¯•äº†5ç§ä¸»æµLLMï¼š
  - `Claude 3 Opus`
  - `Claude 3.7 Sonnet`
  - `GPT-4.1`
  - `GPT-4.1 mini`
  - `Llama 3.3`
- **æ¯ç»„å®éªŒé‡å¤3æ¬¡**ï¼Œä»¥éªŒè¯é²æ£’æ€§ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  1. **å‡†ç¡®æ€§ï¼ˆAccuracyï¼‰**ï¼šå…³é”®æ­¥éª¤æ˜¯å¦æˆåŠŸç”Ÿæˆéç©ºè¾“å‡ºæ–‡ä»¶ï¼ˆå¦‚æ‹“æ‰‘æ–‡ä»¶ã€èƒ½é‡æœ€å°åŒ–è¾“å‡ºç­‰ï¼‰ã€‚
  2. **æ•ˆç‡ï¼ˆEfficiencyï¼‰**ï¼šå®é™…è°ƒç”¨å·¥å…·æ¬¡æ•° vs. æœ€å°å¿…è¦è°ƒç”¨æ¬¡æ•°çš„æ¯”ç‡ã€‚
  3. **é”™è¯¯æ¢å¤èƒ½åŠ›**ï¼šèƒ½å¦è¯†åˆ«å¹¶ä¿®å¤è¿è¡Œæ—¶é”™è¯¯ï¼ˆå¦‚åŸå­å‘½åé”™è¯¯ã€ä½ç½®çº¦æŸç¼ºå¤±ç­‰ï¼‰ã€‚
  4. **ç»“åˆè‡ªç”±èƒ½é¢„æµ‹æ€§èƒ½**ï¼šä½¿ç”¨ `gmx_MMPBSA` è®¡ç®— Î”Î”Gï¼Œå¹¶ä¸å®éªŒIC50å€¼æ¯”è¾ƒç›¸å…³æ€§ï¼ˆPearson *r*ï¼‰ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
æœ¬æ–‡æœªç›´æ¥å¯¹æ¯”ä¼ ç»Ÿè„šæœ¬åŒ–å·¥å…·ï¼ˆå¦‚æ‰‹åŠ¨GROMACSæµç¨‹ï¼‰ï¼Œè€Œæ˜¯å°†ä¸åŒLLMä½œä¸ºâ€œæ™ºèƒ½ä½“â€åœ¨åŒä¸€æ¡†æ¶ä¸‹è¿è¡Œï¼Œé—´æ¥ä½“ç°DynaMateæ¡†æ¶çš„é€šç”¨æ€§å’ŒLLMé€‰æ‹©çš„å½±å“ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **åœ¨5ä¸ªæ ‡å‡†è›‹ç™½-é…ä½“ç³»ç»Ÿä¸Šï¼Œæ‰€æœ‰LLMå‡è¾¾åˆ°100%å‡†ç¡®ç‡**ï¼ˆå›¾2aï¼‰ï¼Œè¡¨æ˜DynaMateèƒ½å¯é å®Œæˆå®Œæ•´MDæµç¨‹ã€‚
- **åœ¨æŒ‘æˆ˜æ€§ç³»ç»Ÿä¸Šçš„è¡¨ç°åˆ†åŒ–æ˜æ˜¾**ï¼š
  - `BRD4_UNL`ï¼ˆæ°¯åŸå­å‘½åé”™è¯¯ï¼‰ï¼š
    - `Claude 3.7 Sonnet` å’Œ `GPT-4.1 mini` åœ¨3æ¬¡è¿è¡Œä¸­å‡æˆåŠŸä¿®å¤é”™è¯¯å¹¶å®Œæˆæ¨¡æ‹Ÿã€‚
    - `GPT-4.1` æœ‰ä¸€æ¬¡æˆåŠŸï¼ˆæ‰‹åŠ¨æ’å…¥æ­£ç¡®GAFFå‚æ•°ï¼‰ã€‚
    - `Llama 3.3` å®Œå…¨å¤±è´¥ã€‚
  - `5KB6_ADN`ï¼ˆåŒé…ä½“ç³»ç»Ÿï¼‰ï¼š
    - æ‰€æœ‰æ™ºèƒ½ä½“å‡**æœªèƒ½å®Œæˆ**ï¼Œå› å½“å‰å·¥å…·é›†ä¸æ”¯æŒå¤šé…ä½“å‚æ•°åŒ–ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
ç”±äºDynaMateæ˜¯é¦–ä¸ªæ”¯æŒè›‹ç™½-é…ä½“ç³»ç»Ÿçš„agenticæ¡†æ¶ï¼Œæ— ç›´æ¥å¯æ¯”åŸºçº¿ã€‚ä½†ä¸MDCrowã€NAMD-Agentç›¸æ¯”ï¼ŒDynaMateåœ¨åŠŸèƒ½è¦†ç›–ä¸Šå…·æœ‰å‹å€’æ€§ä¼˜åŠ¿ï¼ˆè§Table S1ï¼‰ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
- **æ¨¡å‹æ€§èƒ½å·®å¼‚æ˜¾è‘—**ï¼š
  - `Claude 3 Opus` å’Œ `GPT-4.1` åœ¨**æ•ˆç‡**ä¸Šæœ€ä¼˜ï¼ˆå·¥å…·è°ƒç”¨æœ€æ¥è¿‘ç†è®ºæœ€å°å€¼ï¼‰ã€‚
  - `Claude 3.7 Sonnet` åœ¨**å‡†ç¡®æ€§**ä¸Šæœ€ä½³ï¼Œå°¤å…¶åœ¨é”™è¯¯æ¢å¤åœºæ™¯ä¸­è¡¨ç°çªå‡ºï¼Œå°½ç®¡æ•ˆç‡ç•¥ä½ï¼ˆå› å°è¯•æ›´å¤šä¿®å¤ç­–ç•¥ï¼‰ã€‚
  - `Llama 3.3` è¡¨ç°æœ€å·®ï¼Œå¸¸å‡ºç°å·¥å…·è¯¯ç”¨å’Œé”™è¯¯ä¿®æ­£å¤±è´¥ã€‚
- **é”™è¯¯æ¢å¤æ¡ˆä¾‹ç ”ç©¶**ï¼š
  - **ä½ç½®çº¦æŸé”™è¯¯ï¼ˆ1J37ç³»ç»Ÿï¼‰**ï¼šæ‰€æœ‰æ™ºèƒ½ä½“å‡è¯†åˆ«å‡ºé—®é¢˜ï¼Œä½†ä»…`Claude 3.7 Sonnet`å°è¯•æ‰‹åŠ¨åˆ›å»ºçº¦æŸæ–‡ä»¶ï¼ˆè™½ä¸å®Œæ•´ï¼‰ï¼Œå…¶ä½™åˆ™ç§»é™¤çº¦æŸï¼ˆå¦¥åæ–¹æ¡ˆï¼‰ã€‚
  - **åŸå­å‘½åé”™è¯¯ï¼ˆBRD4_UNLï¼‰**ï¼š`Claude 3.7 Sonnet` å’Œ `GPT-4.1 mini` æˆåŠŸä¿®æ”¹PDBæ–‡ä»¶ï¼›`GPT-4.1` å°è¯•æ‰‹åŠ¨æ’å…¥GAFFå‚æ•°ï¼Œä¹Ÿå–å¾—æˆåŠŸã€‚

> **æ¥æºï¼šTable 1, 2, 3 åŠ å›¾3**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **DynaMateå®ç°äº†è›‹ç™½-é…ä½“MDæ¨¡æ‹Ÿçš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–**ï¼Œæ˜¯ç›®å‰åŠŸèƒ½æœ€å…¨é¢çš„agentic MDæ¡†æ¶ã€‚
2. **LLMçš„é€‰æ‹©æ˜¾è‘—å½±å“æ€§èƒ½**ï¼š`Claude` å’Œ `GPT-4` ç³»åˆ—åœ¨æ¨ç†ã€å·¥å…·è°ƒç”¨å’Œé”™è¯¯æ¢å¤æ–¹é¢ä¼˜äºå¼€æºæ¨¡å‹ï¼ˆå¦‚`Llama 3.3`ï¼‰ã€‚
3. **è‡ªçº é”™èƒ½åŠ›æœ‰æ•ˆä½†æœ‰é™**ï¼šæ™ºèƒ½ä½“èƒ½åœ¨å¤šç§é”™è¯¯åœºæ™¯ä¸‹å°è¯•ä¿®å¤ï¼Œä½†åœ¨å¤æ‚æˆ–å¤šæ–‡ä»¶è”åŠ¨é”™è¯¯ï¼ˆå¦‚åŒé…ä½“ç³»ç»Ÿï¼‰ä¸­ä»å—é™ã€‚
4. **ç»“åˆè‡ªç”±èƒ½é¢„æµ‹åˆç†**ï¼šåœ¨BRD4 BD1æŠ‘åˆ¶å‰‚æµ‹è¯•é›†ä¸­ï¼ŒDynaMateçš„MM/PBSA Î”Î”G ä¸å®éªŒIC50çš„ç›¸å…³æ€§ä¸º **r = 0.597**ï¼Œä¼˜äºGNINAå¯¹æ¥åˆ†æ•°ï¼ˆr = 0.385ï¼‰ï¼Œè¡¨æ˜å…¶åœ¨æ’åºç›¸ä¼¼åŒ–åˆç‰©æ–¹é¢æ›´å…·ä¼˜åŠ¿ã€‚

> **æ¥æºï¼šå›¾4**

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¾èµ–å¤–éƒ¨LLM API**ï¼šéœ€ç”¨æˆ·æä¾›APIå¯†é’¥å’Œä¿¡ç”¨é¢åº¦ï¼Œå­˜åœ¨æˆæœ¬å’Œå®‰å…¨é¡¾è™‘ã€‚
2. **ç¼ºä¹é•¿æœŸè®°å¿†**ï¼šæ¯æ¬¡è¿è¡Œç‹¬ç«‹ï¼Œæ— æ³•ä»å†å²ä»»åŠ¡ä¸­å­¦ä¹ ã€‚
3. **å·¥å…·é›†é™åˆ¶**ï¼šä¸æ”¯æŒå¤šé…ä½“ã€è†œè›‹ç™½ã€DNA/RNAç­‰å¤æ‚ç³»ç»Ÿã€‚
4. **è¾“å…¥æ–‡ä»¶è´¨é‡æ•æ„Ÿ**ï¼šéå¸¸è§„åŸå­å‘½åã€ç¼ºå¤±æ®‹åŸºç­‰é—®é¢˜ä»æ˜¯å¤±è´¥ä¸»å› ã€‚
5. **åŠ›åœºå‚æ•°å‡è®¾é£é™©**ï¼šé»˜è®¤ä½¿ç”¨`ff14sb`å’Œ`GAFF2`ï¼ŒæŸäº›ç‰¹æ®Šä½“ç³»ï¼ˆå¦‚æ´»æ€§ä½ç‚¹è´¨å­åŒ–çŠ¶æ€ï¼‰å¯èƒ½éœ€è¦äººå·¥å¹²é¢„ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•å·¥å…·é›†ä»¥æ”¯æŒ**å¤šé…ä½“ã€è†œè›‹ç™½ã€æ ¸é…¸ç³»ç»Ÿ**ã€‚
- å¼•å…¥**æŒä¹…åŒ–è®°å¿†æœºåˆ¶**ï¼Œä½¿æ™ºèƒ½ä½“èƒ½ä»è¿‡å¾€è¿è¡Œä¸­ç§¯ç´¯ç»éªŒã€‚
- é›†æˆæ›´å¤š**è½¯ä»¶æ–‡æ¡£å’Œç§‘å­¦è®ºæ–‡æ•°æ®åº“**ï¼Œæå‡å‚æ•°é€‰æ‹©çš„å‡†ç¡®æ€§ã€‚
- æ¢ç´¢**æœ¬åœ°åŒ–éƒ¨ç½²**æ–¹æ¡ˆï¼Œå‡å°‘å¯¹å•†ä¸šLLM APIçš„ä¾èµ–ã€‚
- å¢å¼ºå¯¹**æ„è±¡ç†µã€éšå¼æº¶å‰‚æ¨¡å‹å±€é™æ€§**çš„ç†è§£ï¼Œæå‡è‡ªç”±èƒ½è®¡ç®—å¯é æ€§ã€‚

---

> **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/schwallergroup/DynaMate](https://github.com/schwallergroup/DynaMate)

</details>

---

### 12. [Neuronal Attention Circuit (NAC) for Representation Learning](https://arxiv.org/abs/2512.10282)

**Authors**: Waleed Razzaq, Izis Kankaraway, Yun-Bo Zhao  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.10282v1  

#### Abstract
Attention improves representation learning over RNNs, but its discrete nature limits continuous-time (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates attention logits computation as the solution to a linear first-o...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šNeuronal Attention Circuit (NAC) for Representation Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Attention æœºåˆ¶** è™½ç„¶åœ¨åºåˆ—å»ºæ¨¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶æœ¬è´¨æ˜¯ç¦»æ•£æ—¶é—´ï¼ˆDiscrete-Timeï¼‰æ“ä½œï¼Œéš¾ä»¥æœ‰æ•ˆå¤„ç†**ä¸è§„åˆ™é‡‡æ ·æ—¶é—´åºåˆ—**ï¼ˆirregularly sampled time seriesï¼‰ã€‚åŒæ—¶ï¼Œç°æœ‰çš„è¿ç»­æ—¶é—´ï¼ˆContinuous-Time, CTï¼‰æ¨¡å‹å¦‚ CT-RNNs å’Œ CT-Attention åœ¨å»ºæ¨¡åŠ¨æ€æ¼”åŒ–æ—¶å­˜åœ¨è®¡ç®—å¼€é”€å¤§ã€ç¼ºä¹ç”Ÿç‰©å¯è§£é‡Šæ€§ç­‰é—®é¢˜ã€‚

æ­¤å¤–ï¼Œæ ‡å‡† Attention çš„ **scaled dot-product** æ“ä½œä¸å…·å¤‡è¿ç»­æ·±åº¦ï¼ˆcontinuous depthï¼‰ç‰¹æ€§ï¼Œé™åˆ¶äº†å…¶å¯¹è¿ç»­è½¨è¿¹çš„è¡¨è¾¾èƒ½åŠ›ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„ã€**ç”Ÿç‰©å¯è§£é‡Šçš„è¿ç»­æ—¶é—´æ³¨æ„åŠ›æœºåˆ¶**â€”â€”**Neuronal Attention Circuit (NAC)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š

- **å°† Attention Logits è§†ä¸ºå¾®åˆ†æ–¹ç¨‹çš„è§£**ï¼š  
  å°† attention logits $ a_t $ å®šä¹‰ä¸ºä¸€ä¸ªä¸€é˜¶çº¿æ€§å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰çš„è¾“å‡ºï¼š
  $$
  \frac{da}{dt} = -w_T \cdot a + \phi
  $$
  å…¶ä¸­ $ w_T $ æ˜¯å¯å­¦ä¹ çš„æ—¶é—´å¸¸æ•°é—¨æ§ï¼ˆtime-constant gateï¼‰ï¼Œ$ \phi $ æ˜¯å†…å®¹ç›®æ ‡é—¨æ§ï¼ˆcontent-target gateï¼‰ï¼ŒäºŒè€…å‡ç”±éçº¿æ€§äº’è¿é—¨æ§ç½‘ç»œç”Ÿæˆã€‚

- **åŸºäº C. elegans çš„ç¥ç»å›è·¯ç­–ç•¥ï¼ˆNCPsï¼‰æ„å»ºç¨€ç–éª¨å¹²ç½‘ç»œ**ï¼š  
  å¤ç”¨ç§€ä¸½éšæ†çº¿è™«ï¼ˆ*C. elegans*ï¼‰ç¥ç»ç³»ç»Ÿä¸­çš„ **Neuronal Circuit Policies (NCPs)** ç»“æ„ï¼Œè®¾è®¡äº†ä¸€ä¸ªå…·æœ‰ç”Ÿç‰©å­¦åˆç†æ€§çš„ç¨€ç–é€’å½’æ¶æ„ä½œä¸º NAC çš„ backbone å’Œ sensory gateï¼Œæå‡æ¨¡å‹æ•ˆç‡ä¸å¯è§£é‡Šæ€§ã€‚

- **ä¸‰ç§ attention logit è®¡ç®—æ¨¡å¼**ï¼š
  1. **Euler æ¨¡å¼**ï¼šæ˜¾å¼æ¬§æ‹‰ç§¯åˆ†è¿‘ä¼¼æ±‚è§£ ODEï¼›
  2. **Exact æ¨¡å¼**ï¼šé—­å¼è§£æè§£ $ a_t = \frac{\phi}{w_T}(1 - e^{-w_T t}) $ï¼›
  3. **Steady æ¨¡å¼**ï¼šä»…ä½¿ç”¨ç¨³æ€è§£ $ a^* = \phi / w_T $ï¼Œç±»æ¯”äºä¼ ç»Ÿ attentionã€‚

- **ç¨€ç– Top-K æˆå¯¹æ‹¼æ¥æœºåˆ¶**ï¼š  
  å¼•å…¥ **sparse Top-K pairwise concatenation** ç­–ç•¥ï¼Œåœ¨ä¿ç•™å…³é”® query-key äº¤äº’çš„åŒæ—¶æ˜¾è‘—é™ä½å†…å­˜æ¶ˆè€—ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | NAC çš„ä¼˜åŠ¿ |
|------|-----------|
| **ç”Ÿç‰©å¯è§£é‡Šæ€§** | åŸºäºçœŸå®ç”Ÿç‰©ç¥ç»å›è·¯ï¼ˆNCPsï¼‰è®¾è®¡ï¼Œå…·å¤‡æ›´å¼ºçš„ç¥ç»ç§‘å­¦åŸºç¡€ |
| **è¿ç»­æ—¶é—´å»ºæ¨¡èƒ½åŠ›** | æ”¯æŒä¸è§„åˆ™æ—¶é—´åºåˆ—è¾“å…¥ï¼Œé€‚åº”ä»»æ„æ—¶é—´é—´éš” |
| **è®¡ç®—æ•ˆç‡** | ç¨€ç–è¿æ¥ + Top-K æœºåˆ¶å‡å°‘å‚æ•°é‡å’Œå†…å­˜å ç”¨ |
| **ç†è®ºä¿éšœ** | æä¾›çŠ¶æ€ç¨³å®šæ€§ã€è¯¯å·®æŒ‡æ•°ç•Œã€é€šç”¨é€¼è¿‘å®šç†ç­‰ä¸¥æ ¼æ•°å­¦è¯æ˜ |
| **çµæ´»æ€§** | æ”¯æŒå¤šç§è®¡ç®—æ¨¡å¼ï¼ˆEuler/Exact/Steadyï¼‰ï¼Œå¯åœ¨ç²¾åº¦ä¸é€Ÿåº¦é—´æƒè¡¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å¤šä¸ªé¢†åŸŸï¼ŒéªŒè¯ NAC çš„æ³›åŒ–èƒ½åŠ›ï¼š

| é¢†åŸŸ | æ•°æ®é›† | ç‰¹ç‚¹ |
|------|--------|------|
| **ä¸è§„åˆ™æ—¶é—´åºåˆ—åˆ†ç±»** | Event-based MNIST (E-MNIST) | å›¾åƒè½¬äº‹ä»¶æµï¼Œé•¿åº¦ä» 784 å‹ç¼©è‡³ ~53 |
| | Person Activity Recognition (PAR) | æ¥è‡ª UCI çš„äººä½“æ´»åŠ¨è¯†åˆ«æ•°æ®ï¼Œå«æƒ¯æ€§ä¼ æ„Ÿå™¨ä¿¡å· |
| **è‡ªåŠ¨é©¾é©¶è½¦é“ä¿æŒ** | OpenAI CarRacing | åˆ†ç±»ä»»åŠ¡ï¼Œé¢„æµ‹äº”ç§ç¦»æ•£åŠ¨ä½œ |
| | Udacity è‡ªåŠ¨é©¾é©¶æ¨¡æ‹Ÿå™¨ | å›å½’ä»»åŠ¡ï¼Œé¢„æµ‹è¿ç»­è½¬å‘è§’ |
| **å·¥ä¸šé¢„æµ‹ç»´æŠ¤ï¼ˆIndustry 4.0ï¼‰** | PRONOSTIA | è½´æ‰¿é€€åŒ–æ•°æ®ï¼Œç”¨äºè®­ç»ƒ |
| | XJTU-SY | ä¸åŒå·¥å†µä¸‹çš„è½´æ‰¿æ•…éšœæ•°æ®ï¼Œç”¨äºè·¨åŸŸæµ‹è¯• |
| | HUST | å¤šè´Ÿè½½æ¡ä»¶ä¸‹çš„å®ç”¨è½´æ‰¿æ•°æ®é›†ï¼Œç”¨äºäº¤å‰éªŒè¯ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **è®­ç»ƒæ–¹å¼**ï¼šé‡‡ç”¨ 5 æŠ˜äº¤å‰éªŒè¯ï¼ˆ5-fold CVï¼‰
- **ä¼˜åŒ–å™¨**ï¼šAdam/AdamW
- **æŸå¤±å‡½æ•°**ï¼š
  - åˆ†ç±»ä»»åŠ¡ï¼šSparse Categorical Crossentropy (SCE)
  - å›å½’ä»»åŠ¡ï¼šMSE æˆ– MAE
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - E-MNIST / PAR / CarRacingï¼šAccuracy (â†‘)
  - Udacityï¼šMSE (â†“)
  - Industry 4.0ï¼ˆRUL ä¼°è®¡ï¼‰ï¼šScore metric (â†“)ï¼Œè¯¥æŒ‡æ ‡ä¸å¯¹ç§°æƒ©ç½šè¿‡ä¼°ï¼ˆæ›´å±é™©ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä¸»æµ DT/CT æ¨¡å‹ï¼š
- **DT-RNNs**ï¼šRNN, LSTM, GRU
- **CT-RNNs**ï¼šCT-RNN, GRU-ODE, mmRNN, LTC, CfC
- **DT-Attention**ï¼šAttention, MHA
- **CT-Attention**ï¼šmTAN, CTA, ODEFormer, ContiFormer

æ‰€æœ‰åŸºçº¿å‡ä¸ NAC ä½¿ç”¨ç›¸åŒè¶…å‚é…ç½®ä»¥ä¿è¯å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table Iï¼‰

#### ğŸ“Š ä¸è§„åˆ™æ—¶é—´åºåˆ—åˆ†ç±»
| æ¨¡å‹ | E-MNIST (%) | PAR (%) |
|------|-------------|---------|
| **NAC-PW** | **96.64** âœ… | **89.15** âœ… |
| GRU-ODE | 96.04 | 89.01 |
| ContiFormer | 96.04 | 81.28 âŒ |
| MHA | 95.94 | 88.36 |

> âœ… NAC-PW åœ¨ä¸¤ä¸ªä»»åŠ¡ä¸Šå‡å–å¾— SOTA æ€§èƒ½ã€‚

#### ğŸš— è‡ªåŠ¨é©¾é©¶è½¦é“ä¿æŒ
| æ¨¡å‹ | CarRacing (Acc â†‘) | Udacity (MSE â†“) |
|------|-------------------|-----------------|
| **NAC-PW** | **80.72** âœ… | 0.0177 |
| **NAC-32k** | 80.38 | **0.0170** âœ… |
| NAC-Exact | 80.59 | 0.0173 |
| ContiFormer | 80.47 | 0.0174 |

> âœ… NAC åœ¨ä¸¤ç±»é©¾é©¶ä»»åŠ¡ä¸­è¡¨ç°é¢†å…ˆã€‚

#### ğŸ”§ å·¥ä¸šå‰©ä½™å¯¿å‘½é¢„æµ‹ï¼ˆScore â†“ï¼‰
| æ¨¡å‹ | PRONOSTIA | XJTU-SY | HUST |
|------|-----------|---------|-------|
| **NAC-Exact/05s/8k** | 37.75 | **19.87** âœ… | **27.82** âœ… |
| **NAC-PW** | 37.50 | 28.01 | 30.14 |
| ContiFormer | 27.82 âœ… | 34.71 | 43.81 |

> âš ï¸ æ³¨æ„ï¼šContiFormer åœ¨ PRONOSTIA ä¸Šæœ€ä¼˜ï¼Œä½† NAC åœ¨è·¨åŸŸæ•°æ®é›† XJTU-SY å’Œ HUST ä¸Šè¡¨ç°æ›´ä¼˜ï¼Œæ˜¾ç¤ºå…¶**å¼ºæ³›åŒ–èƒ½åŠ›**ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### Top-K æ¶ˆèï¼ˆæ§åˆ¶äº¤äº’æ•°é‡ï¼‰
| æ¨¡å‹ | Top-K | å†…å­˜ (MB) | E-MNIST (%) |
|------|-------|----------|------------|
| NAC-PW | Full | 5042 | 96.64 âœ… |
| NAC-32k | 32 | 549.86 | 95.15 |
| NAC-2k | 2 | 44.75 | 95.73 |

> âœ… å‡å°‘ Top-K æ˜¾è‘—é™ä½å†…å­˜ï¼Œä½†ä¼šç‰ºç‰²ä¸€å®šç²¾åº¦ï¼›**Top-K=8 æ˜¯å¹³è¡¡ç‚¹**ã€‚

#### Sparsity æ¶ˆèï¼ˆæ§åˆ¶ç½‘ç»œç¨€ç–åº¦ï¼‰
| æ¨¡å‹ | Sparsity | E-MNIST (%) |
|------|--------|-------------|
| NAC-02s | 20% | 95.31 |
| NAC-09s | 90% | 95.86 âœ… |
| NAC-PW | 50% | 96.64 âœ… |

> âœ… æ›´é«˜ sparsityï¼ˆ90%ï¼‰æœ‰åŠ©äºæå‡é²æ£’æ€§å’Œå‡†ç¡®ç‡ã€‚

#### æ¨¡å¼æ¶ˆèï¼ˆMode Comparisonï¼‰
| æ¨¡å¼ | è¿è¡Œé€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|------|--------|----------|
| **Steady** | æœ€å¿« | å¿«é€Ÿæ¨ç† |
| **Exact** | ä¸­ç­‰ | é«˜ç²¾åº¦å»ºæ¨¡ |
| **Euler** | è¾ƒæ…¢ | åŠ¨æ€é€‚åº”æ€§å¼º |

> âœ… Steady æ¨¡å¼æ¥è¿‘ä¼ ç»Ÿ attention æ•ˆç‡ï¼Œè€Œ Euler/Exact æä¾›æ›´é«˜è¡¨è¾¾åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **NAC å®ç°äº† CT ä¸ Attention çš„æœ‰æ•ˆèåˆ**ï¼šé€šè¿‡å°† attention logits å®šä¹‰ä¸º ODE è§£ï¼Œå®ç°äº†çœŸæ­£çš„è¿ç»­æ—¶é—´ attentionï¼Œå…‹æœäº†ä¼ ç»Ÿ attention çš„ç¦»æ•£æ€§é™åˆ¶ã€‚
2. **ç”Ÿç‰©å¯å‘ç»“æ„å¸¦æ¥é«˜æ•ˆä¸ç¨³å®š**ï¼šåŸºäº NCPs çš„ç¨€ç–æ¶æ„ä¸ä»…æå‡äº†æ¨¡å‹æ•ˆç‡ï¼Œè¿˜å¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§ã€‚
3. **åœ¨å¤šé¢†åŸŸè¾¾åˆ°æˆ–è¶…è¶Š SOTA**ï¼šåœ¨ä¸è§„åˆ™æ—¶é—´åºåˆ—ã€è‡ªåŠ¨é©¾é©¶ã€å·¥ä¸šé¢„æµ‹ç­‰å¤šä¸ªä»»åŠ¡ä¸­ï¼ŒNAC è¡¨ç°ä¼˜äºæˆ–åª²ç¾å½“å‰æœ€å…ˆè¿›çš„ CT å’Œ DT æ¨¡å‹ã€‚
4. **å†…å­˜ä¸è¿è¡Œæ—¶å¤„äºä¸­é—´ä½ç½®**ï¼šç›¸æ¯” CT-RNNsï¼ŒNAC è¿è¡Œæ›´å¿«ï¼›ç›¸æ¯” CT-Attentionï¼ˆå¦‚ mTANï¼‰ï¼Œå†…å­˜æ›´ä½ï¼Œé€‚åˆéƒ¨ç½²åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é¢„è®¾ wiring ç»“æ„**ï¼šç›®å‰ NAC ä½¿ç”¨å›ºå®šçš„ NCP wiringï¼Œçµæ´»æ€§æœ‰é™ï¼Œéœ€æ‰‹åŠ¨è°ƒæ•´ sensory/motor å•å…ƒæ¯”ä¾‹ã€‚
- **Top-K å¯èƒ½é—æ¼é‡è¦ä¸Šä¸‹æ–‡**ï¼šç¨€ç–é€‰æ‹©å¯èƒ½å¯¼è‡´å…³é”®ä¿¡æ¯ä¸¢å¤±ï¼Œä¸”å¯¹ $ K $ å€¼æ•æ„Ÿã€‚
- **ä»éœ€è®¡ç®—å®Œæ•´ QK^T å¾—åˆ†çŸ©é˜µ**ï¼šå°½ç®¡åç»­å¤„ç†ç¨€ç–åŒ–ï¼Œåˆå§‹ç›¸ä¼¼åº¦è®¡ç®—ä»æ˜¯ $ O(T^2) $ï¼Œä¸åˆ©äºæé•¿åºåˆ—ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰æˆ–éšæœºåŒ– NCP é…ç½®**ï¼šæå‡æ¶æ„çµæ´»æ€§ï¼Œé¿å…ç¡¬ç¼–ç  wiringã€‚
2. **å¯å­¦ä¹ çš„ Top-K é€‰æ‹©æœºåˆ¶**ï¼šå¼•å…¥ adaptive æˆ– learned routing æ›¿ä»£å›ºå®š Top-Kã€‚
3. **ç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–**ï¼šé’ˆå¯¹è¾¹ç¼˜è®¾å¤‡è¿›è¡Œæ¨¡å‹å‹ç¼©ä¸æ¨ç†åŠ é€Ÿã€‚
4. **æ‰©å±•è‡³å…¶ä»–æ¨¡æ€**ï¼šæ¢ç´¢åœ¨è¯­éŸ³ã€è§†é¢‘ç­‰é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/itxwaleedrazzaq/neuronal_attention_circuit](https://github.com/itxwaleedrazzaq/neuronal_attention_circuit)  
> ğŸ“„ **è®ºæ–‡é“¾æ¥**ï¼š`arXiv:2512.10282`

</details>

---

### 13. [Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882)

**Authors**: Hauke Licht  
**Category**: cs.CL  
**Published**: 2025-12-12  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.10882v1  

#### Abstract
Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆmLLMsï¼‰åœ¨æ”¿æ²»ä¼ æ’­ä¸­çš„æƒ…æ„Ÿåˆ†æèƒ½åŠ›å°šæœªè¢«ç³»ç»Ÿè¯„ä¼°**çš„é—®é¢˜ã€‚å°½ç®¡æ–‡æœ¬å‹ LLMs å·²å¹¿æ³›ç”¨äºç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­çš„æ ‡æ³¨ä»»åŠ¡ï¼Œä½†é’ˆå¯¹è§†é¢‘ä¸­æƒ…æ„Ÿå¼ºåº¦ï¼ˆå¦‚æƒ…ç»ªå”¤é†’åº¦ *arousal*ï¼‰çš„è‡ªåŠ¨åŒ–æµ‹é‡ä»ç¼ºä¹å¯é è¯æ®ã€‚ç‰¹åˆ«æ˜¯ï¼Œç°æœ‰ç ”ç©¶æœªèƒ½åŒºåˆ†ç†æƒ³å®éªŒå®¤ç¯å¢ƒä¸çœŸå®ä¸–ç•Œå¤æ‚åœºæ™¯ä¸‹çš„æ¨¡å‹è¡¨ç°å·®å¼‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
- **æå‡ºå¹¶éªŒè¯äº†ä¸€ç§åŸºäº in-context learning çš„å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†ææ¡†æ¶**ï¼šåˆ©ç”¨ mLLMs å¯¹è§†é¢‘è¾“å…¥è¿›è¡ŒæŒ‡ä»¤è·Ÿéšå¼çš„æƒ…ç»ªå”¤é†’åº¦è¯„åˆ†ï¼Œæ— éœ€å¾®è°ƒå³å¯å®ç°æ¦‚å¿µå¼•å¯¼çš„æµ‹é‡ã€‚
- **æ„å»ºäº†ä¸€ä¸ªå¯å¤ç°çš„è¯„ä¼°æ¡†æ¶**ï¼šç»“åˆä¸¤ä¸ªäº’è¡¥çš„æ•°æ®é›†ï¼ˆä¸€ä¸ªå—æ§å®éªŒå®¤æ•°æ®é›†å’Œä¸€ä¸ªçœŸå®è®®ä¼šè¾©è®ºæ•°æ®é›†ï¼‰ï¼Œç³»ç»Ÿåœ°è¯„ä¼° mLLMs åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„å¯é æ€§ã€åå·®åŠä¸‹æ¸¸æ¨æ–­å½±å“ã€‚
- **é¦–æ¬¡å°† mLLMs åº”ç”¨äºè§†é¢‘çº§æƒ…æ„Ÿå¼ºåº¦ï¼ˆarousalï¼‰è€Œéä»…é™äºæƒ…æ„Ÿææ€§ï¼ˆsentimentï¼‰çš„åˆ†æ**ï¼Œçªå‡ºäº†éè¨€è¯­çº¿ç´¢ï¼ˆè¯­è°ƒã€é¢éƒ¨è¡¨æƒ…ç­‰ï¼‰çš„é‡è¦æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€è®­ç»ƒæ•°æ®å³å¯éƒ¨ç½²**ï¼šç›¸æ¯”ä¼ ç»Ÿä¾èµ–ç›‘ç£å­¦ä¹ çš„å¤šæ¨¡æ€æ¨¡å‹ï¼ˆå¦‚èåˆéŸ³é¢‘ä¸è§†è§‰ç‰¹å¾çš„æ·±åº¦ç½‘ç»œï¼‰ï¼ŒmLLMs å¯é€šè¿‡ in-context learning å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼Œé™ä½å¯¹æ ‡æ³¨æ•°æ®çš„éœ€æ±‚ã€‚
- **ç†è®ºé©±åŠ¨çš„æµ‹é‡è®¾è®¡**ï¼šå¯é€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºï¼ˆpromptï¼‰åµŒå…¥ç¤¾ä¼šç§‘å­¦ç†è®ºå®šä¹‰ï¼ˆå¦‚â€œarousal æ˜¯æŒ‡è¡¨è¾¾çš„æƒ…æ„Ÿæ¿€æ´»ç¨‹åº¦â€ï¼‰ï¼Œæå‡æµ‹é‡çš„é€æ˜æ€§å’Œå¯è§£é‡Šæ€§ã€‚
- **æ”¯æŒè·¨æ¨¡æ€ç»Ÿä¸€å¤„ç†**ï¼šmLLMs èƒ½åŒæ—¶å¤„ç†æ–‡æœ¬ã€éŸ³é¢‘ã€å›¾åƒå’Œè§†é¢‘ï¼Œä¸ºæ•´åˆæ”¿æ²»æ¼”è®²ä¸­çš„â€œè¯´äº†ä»€ä¹ˆâ€ä¸â€œæ€ä¹ˆè¯´â€æä¾›äº†æŠ€æœ¯åŸºç¡€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° | ç‰¹ç‚¹ |
|-------|------|------|
| **RAVDESS** (Livingstone & Russo, 2018) | åŒ…å« 1248 ä¸ªç”±æ¼”å‘˜è¡¨æ¼”çš„çŸ­è¯­éŸ³é¢‘-è§†é¢‘ç‰‡æ®µï¼Œæ¶µç›–å¤šç§æƒ…ç»ªåŠå…¶å¼ºåº¦ç­‰çº§ï¼ˆæ­£å¸¸ vs å¼ºçƒˆï¼‰ã€‚æ¯ä¸ªè§†é¢‘å‡æœ‰ 10 åäººç±»è¯„åˆ†è€…å¯¹æƒ…ç»ªå¼ºåº¦æ‰“åˆ†ï¼ˆ1â€“5 åˆ†ï¼‰ã€‚ | å®éªŒå®¤æ§åˆ¶ç¯å¢ƒï¼Œé«˜è´¨é‡ã€é«˜ä¿¡åº¦çš„äººç±»æ ‡ç­¾ï¼›æ˜¯â€œæœ€å¯èƒ½æˆåŠŸâ€çš„ç†æƒ³æµ‹è¯•åœºæ™¯ã€‚ |
| **Cochrane et al. (2022)** | æ¥è‡ªåŠ æ‹¿å¤§ä¸‹è®®é™¢è´¨è¯¢æ—¶é—´ï¼ˆQuestion Timeï¼‰çš„ 595 æ®µæ”¿æ²»æ¼”è®²è§†é¢‘ï¼Œæ¯æ®µç”±å¤šäººç±»ç¼–ç å‘˜ä»**æ–‡æœ¬è½¬å½•**å’Œ**è§†é¢‘è®°å½•**ä¸¤ç§æ¨¡å¼åˆ†åˆ«è¯„å®šæƒ…æ„Ÿææ€§ï¼ˆsentimentï¼‰å’Œå”¤é†’åº¦ï¼ˆarousalï¼‰ã€‚ | çœŸå®ä¸–ç•Œæ”¿æ²»è¯­å¢ƒï¼Œå­˜åœ¨èƒŒæ™¯å™ªéŸ³ã€å¤šäººå¹²æ‰°ã€æ‘„åƒå¤´è§’åº¦ä¸æ­£ç­‰é—®é¢˜ï¼›æ›´å…·ç°å®æŒ‘æˆ˜æ€§ã€‚ |

> æ³¨ï¼šä¸¤ä¸ªæ•°æ®é›†å‡åˆ’åˆ†ä¸º train/validation/test å­é›†ï¼Œå¹¶æŒ‰ speaker blocking åˆ’åˆ†ä»¥ç¡®ä¿ out-of-sample è¯„ä¼°ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹é€‰æ‹©**ï¼š
  - **Open-weights mLLMs**ï¼š`Qwen 2.5 Omni`ï¼ˆ3B, 7Bï¼‰ã€`TowerVideo`ï¼ˆ2B, 9Bï¼‰
  - **Closed-weights model**ï¼š`Gemini 2.5 Flash`ï¼ˆGoogleï¼‰
- **ä»»åŠ¡å½¢å¼**ï¼šZero-shot å’Œ Few-shot In-Context Learningï¼ˆICLï¼‰
  - æç¤ºæ¨¡æ¿æ˜ç¡®è¦æ±‚æ¨¡å‹æ ¹æ®è§†é¢‘åˆ¤æ–­æƒ…ç»ªå”¤é†’åº¦ï¼ˆarousalï¼‰ï¼Œä½¿ç”¨æ•´æ•°æ ‡å°ºï¼ˆRAVDESS: 1â€“5ï¼›Cochrane: 1â€“9ï¼‰
  - å°‘æ ·æœ¬ç¤ºä¾‹ï¼ˆ3 æˆ– 5 ä¸ªï¼‰æ¥è‡ªè®­ç»ƒé›†ï¼ŒåŒ…å«è§†é¢‘+äººç±»å¹³å‡å¾—åˆ†ä½œä¸ºç¤ºèŒƒ
- **è¾“å‡ºå¤„ç†**ï¼šé‡‡ç”¨ token probability weighting æ–¹æ³•ç”Ÿæˆè¿ç»­å€¼è¯„åˆ†ï¼Œé¿å… LLM è¾“å‡ºçš„æ•´æ•°èšé›†åå·®ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | ç”¨é€” |
|------|------|
| **Pearsonâ€™s r / Spearmanâ€™s Ï** | è¡¡é‡ mLLM è¯„åˆ†ä¸äººç±»å¹³å‡è¯„åˆ†ä¹‹é—´çš„ç›¸å…³æ€§ï¼ˆä¸»æŒ‡æ ‡ï¼‰ |
| **RMSE** | é¢„æµ‹è¯¯å·®å¤§å° |
| **ICC (Intra-class Correlation)** | è¯„ä¼°äººç±»è¯„åˆ†å†…éƒ¨ä¸€è‡´æ€§ï¼ˆç”¨äºè¡°å‡æ ¡æ­£ï¼‰ |
| **Demographic Bias Analysis** | æŒ‰æ€§åˆ«ã€å¹´é¾„åˆ†ç»„æ¯”è¾ƒæ¨¡å‹æ€§èƒ½å·®å¼‚ |
| **Downstream Regression Analysis** | å›å½’åˆ†ææ”¿åºœ vs åå¯¹æ´¾è®®å‘˜çš„ arousal å·®å¼‚ï¼Œæ£€éªŒæ›¿ä»£äººç±»è¯„åˆ†æ˜¯å¦æ”¹å˜ç»Ÿè®¡ç»“è®º |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰åœ¨ RAVDESS æ•°æ®ä¸Šçš„è¡¨ç°ï¼ˆç†æƒ³ç¯å¢ƒï¼‰
| æ¨¡å‹ | Pearsonâ€™s r (3-shot) | RMSE (3-shot) | å¤‡æ³¨ |
|------|------------------------|---------------|------|
| `Gemini 2.5 Flash` | **0.690** | 0.784 | æ¥è¿‘äººç±»è¯„åˆ†ä¿¡åº¦ï¼ˆICC â‰ˆ 0.74ï¼‰ï¼Œè¡°å‡æ ¡æ­£åè¾¾ 0.793 |
| `Qwen 2.5 Omni-7B` | 0.609 | **0.691** | æ€§èƒ½ä»…æ¬¡äº Geminiï¼Œä¼˜äºå…¶ä»–å¼€æºæ¨¡å‹ |
| `Qwen 2.5 Omni-3B` | 0.516 | 0.705 | éšå°‘æ ·æœ¬æ•°é‡å¢åŠ æœ‰æ‰€æå‡ |
| `TowerVideo-9B` | 0.401 | 0.933 | è¡¨ç°è¾ƒå·®ï¼Œå“åº”åˆ†å¸ƒç‹­çª„ï¼Œæ˜¾ç¤ºè¿‡åº¦è‡ªä¿¡ |

> âœ… **ç»“è®º**ï¼šåœ¨ç†æƒ³æ¡ä»¶ä¸‹ï¼Œé¡¶çº§ mLLMsï¼ˆå°¤å…¶æ˜¯ Geminiï¼‰çš„æƒ…ç»ªå¼ºåº¦è¯„åˆ†å·²æ¥è¿‘äººç±»æ°´å¹³ï¼Œä¸”æ— æ˜¾è‘—æ€§åˆ«åè§ã€‚

#### ï¼ˆ2ï¼‰åœ¨ Cochrane et al. (2022) æ•°æ®ä¸Šçš„è¡¨ç°ï¼ˆçœŸå®ä¸–ç•Œï¼‰
| æ¨¡å‹ | Pearsonâ€™s r (3-shot) | RMSE (3-shot) | å¤‡æ³¨ |
|------|------------------------|---------------|------|
| `Gemini 2.5 Flash` | 0.430 | 1.327 | ç›¸å…³æ€§è¾ƒå¼±ï¼Œè¿œä½äº RAVDESS è¡¨ç° |
| `Qwen 2.5 Omni-7B` | 0.298 | 1.191 | ç›¸å…³æ€§æä½ |
| `TowerVideo-9B` | 0.201 | **0.984** | RMSE è¾ƒä½å› é¢„æµ‹è¶‹è¿‘å‡å€¼ï¼Œå®é™…æ’åºèƒ½åŠ›å·® |

> âŒ **ç»“è®º**ï¼šæ‰€æœ‰ mLLMs åœ¨çœŸå®æ”¿æ²»æ¼”è®²ä¸­è¡¨ç°ä¸ä½³ï¼Œç›¸å…³ç³»æ•°æ™®éåä½ï¼ˆ< 0.5ï¼‰ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰äººç±»æ„ŸçŸ¥çš„æƒ…ç»ªå¼ºåº¦ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ä¸äººç±»è¯„åˆ†å¯¹æ¯”**ï¼š
  - åœ¨ RAVDESS ä¸­ï¼Œ`Gemini` å’Œ `Qwen-7B` çš„è¯„åˆ†ä¸äººç±»é«˜åº¦ä¸€è‡´ï¼›
  - åœ¨ Cochrane æ•°æ®ä¸­ï¼ŒmLLM è¯„åˆ†ä¸äººç±»è¯„åˆ†å‡ ä¹ä¸ç›¸å…³ï¼ˆr â‰ˆ 0.12â€“0.43ï¼‰ï¼Œç”šè‡³ä¸å¦‚éšæœºçŒœæµ‹ã€‚
- **ä¸æ–‡æœ¬å‹ LLM å¯¹æ¯”ï¼ˆsentiment åˆ†æï¼‰**ï¼š
  - åœ¨ sentiment ä»»åŠ¡ä¸Šï¼ŒmLLMs è§†é¢‘è¯„åˆ†è™½ä¼˜äº arousalï¼Œä½†ä»æ˜¾è‘—è½åäºå…¶å¯¹åº”çš„ text-based base LLMsï¼ˆå¦‚ Qwen 2.5 Instructï¼‰ã€‚
  - ä¾‹å¦‚ï¼ŒGemini çš„è§†é¢‘ sentiment è¯„åˆ†ï¼ˆr â‰ˆ 0.57â€“0.60ï¼‰è¿œä½äºå…¶æ–‡æœ¬è¯„åˆ†ï¼ˆr â‰ˆ 0.87â€“0.90ï¼‰ï¼Œå·®è·çº¦ä¸º 2.5 å€äºäººç±»è¯„åˆ†é—´çš„ä¿¡åº¦è½å·®ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰ä¿¡å·-å™ªå£°æ¯”çš„å½±å“ï¼ˆSignal-to-Noise Ratioï¼‰
- **æ–¹æ³•**ï¼šå¯¹ Cochrane æ•°æ®ä¸­çš„è§†é¢‘è¿›è¡Œé¢„å¤„ç†ï¼š
  - éŸ³é¢‘ç«¯ï¼šåº”ç”¨é™å™ªæ»¤æ³¢å™¨æŠ‘åˆ¶èƒŒæ™¯æ‚éŸ³ï¼›
  - è§†è§‰ç«¯ï¼šä½¿ç”¨ vLLM è¿›è¡Œå¯¹è±¡æ£€æµ‹å¹¶é®è”½éè¯´è¯äººåŒºåŸŸï¼ˆbackground maskingï¼‰ã€‚
- **ç»“æœ**ï¼ˆè§ Table D4ï¼‰ï¼š
  - å¤„ç†åçš„â€œå¹²å‡€â€è§†é¢‘å¹¶æœªæ˜¾è‘—æå‡ mLLM çš„è¯„åˆ†å‡†ç¡®æ€§ï¼›
  - å¤šæ•°æƒ…å†µä¸‹ç›¸å…³æ€§åè€Œä¸‹é™æˆ–æ— æ”¹å–„ã€‚
- **ç»“è®º**ï¼šèƒŒæ™¯å™ªéŸ³ä¸æ˜¯å¯¼è‡´æ€§èƒ½ä¸‹é™çš„ä¸»è¦åŸå› ã€‚

#### ï¼ˆ2ï¼‰æ¨¡å‹å®¹é‡çš„å½±å“ï¼ˆModel Capacityï¼‰
- **æ–¹æ³•**ï¼šæ¯”è¾ƒ `Qwen 2.5 Omni`ï¼ˆ3B/7Bï¼‰ä¸æ›´å¤§å‚æ•°é‡çš„éŸ³é¢‘ä¸“ç”¨ mLLM `Voxtral`ï¼ˆ3B/24Bï¼‰åœ¨**çº¯éŸ³é¢‘è¾“å…¥**ä¸‹çš„ arousal è¯„åˆ†è¡¨ç°ã€‚
- **ç»“æœ**ï¼ˆè§ Table D6ï¼‰ï¼š
  - æ›´å¤§çš„æ¨¡å‹ï¼ˆ24B Voxtralï¼‰å¹¶æœªå¸¦æ¥æ˜æ˜¾ä¼˜åŠ¿ï¼›
  - æ‰€æœ‰æ¨¡å‹åœ¨éŸ³é¢‘æ¨¡å¼ä¸‹çš„è¡¨ç°å‡è¾ƒå·®ï¼Œè¡¨æ˜é—®é¢˜ä¸åœ¨å‚æ•°è§„æ¨¡ã€‚
- **ç»“è®º**ï¼šå½“å‰ mLLMs çš„æ¶æ„æˆ–è®­ç»ƒæ–¹å¼å¯èƒ½ä¸è¶³ä»¥æœ‰æ•ˆæå–å’Œæ•´åˆå¤šæ¨¡æ€æƒ…æ„Ÿä¿¡å·ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **mLLMs åœ¨ç†æƒ³ç¯å¢ƒä¸‹è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨çœŸå®ä¸–ç•Œä¸­å¤±æ•ˆ**ï¼š
   - åœ¨ RAVDESS è¿™ç±»å—æ§ç¯å¢ƒä¸­ï¼Œ`Gemini 2.5 Flash` å’Œ `Qwen 2.5 Omni-7B` çš„æƒ…ç»ªå¼ºåº¦è¯„åˆ†æ¥è¿‘äººç±»æ°´å¹³ï¼Œå…·å¤‡ä¸€å®šå¯é æ€§ã€‚
   - ä½†åœ¨çœŸå®çš„è®®ä¼šè¾©è®ºè§†é¢‘ä¸­ï¼Œæ‰€æœ‰æµ‹è¯•çš„ mLLMs éƒ½æœªèƒ½å¯é è¿˜åŸäººç±»çš„æƒ…ç»ªå”¤é†’åº¦åˆ¤æ–­ï¼Œç›¸å…³æ€§ä»…ä¸ºä¸­ç­‰è‡³æå¼±ã€‚

2. **å­˜åœ¨ç³»ç»Ÿæ€§ demographic bias**ï¼š
   - åœ¨ Cochrane æ•°æ®ä¸­ï¼Œå¤šä¸ª mLLMs å¯¹å¥³æ€§å‘è¨€è€…çš„ arousal è¯„åˆ†ä¸€è‡´æ€§æ›´ä½ï¼›
   - `Gemini` å’Œ `TowerVideo-9B` å¯¹å¹´è½»å‘è¨€äººï¼ˆ24â€“45å²ï¼‰çš„è¡¨ç°ä¹Ÿæ›´å·®ã€‚

3. **ä¸‹æ¸¸æ¨æ–­å¯èƒ½äº§ç”Ÿè¯¯å¯¼**ï¼š
   - å½“ç”¨ mLLM è¯„åˆ†ä»£æ›¿äººç±»è¯„åˆ†è¿›è¡Œå›å½’åˆ†ææ—¶ï¼ˆå¦‚æ¯”è¾ƒæ”¿åºœ vs åå¯¹æ´¾çš„ arousalï¼‰ï¼Œéƒ¨åˆ†æ¨¡å‹å¾—å‡ºç›¸åæ–¹å‘çš„æ˜¾è‘—æ•ˆåº”ï¼ˆå¦‚ TowerVideo-2B æ˜¾ç¤ºåå¯¹æ´¾æ›´æ¿€åŠ¨ï¼Œè€Œäººç±»è¯„åˆ†ä¸ºæ— å·®å¼‚ï¼‰ã€‚
   - å³ä½¿æ€»è¯„åˆ†åˆ†å¸ƒç›¸ä¼¼ï¼Œç»†å¾®åå·®ä¹Ÿå¯èƒ½æ‰­æ›²å› æœæ¨è®ºã€‚

4. **å¤šæ¨¡æ€ä¼˜åŠ¿æœªä½“ç°ï¼Œæ–‡æœ¬æ¨¡å‹ä»æ›´å¼º**ï¼š
   - å°½ç®¡äººç±»ç ”ç©¶è¡¨æ˜è§†é¢‘æ¯”æ–‡æœ¬æ›´èƒ½åæ˜  arousalï¼Œä½†å½“å‰ mLLMs çš„è§†é¢‘åˆ†æèƒ½åŠ›è¿œé€Šäºå…¶æ–‡æœ¬åˆ†æèƒ½åŠ›ã€‚
   - åœ¨ sentiment ä»»åŠ¡ä¸Šï¼ŒmLLMs çš„è§†é¢‘è¯„åˆ†ä¹Ÿæ˜æ˜¾åŠ£äºå…¶ base LLM çš„æ–‡æœ¬è¯„åˆ†ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ¨¡å‹é»‘ç®±æ€§**ï¼šå°¤å…¶æ˜¯é—­æºæ¨¡å‹ï¼ˆå¦‚ Geminiï¼‰ï¼Œç¼ºä¹å¯¹å…¶å¦‚ä½•å¤„ç†è§†é¢‘å¸§ä¸éŸ³é¢‘æµçš„æŠ€æœ¯ç»†èŠ‚æŠ«éœ²ã€‚
- **æç¤ºå·¥ç¨‹æœªå……åˆ†æ¢ç´¢**ï¼šä»…ä½¿ç”¨å•ä¸€ prompt æ¨¡æ¿ï¼Œæœªç³»ç»Ÿä¼˜åŒ–æç¤ºç»“æ„æˆ–å¼•å…¥ chain-of-thought ç­‰é«˜çº§ç­–ç•¥ã€‚
- **è¯„ä¼°èŒƒå›´æœ‰é™**ï¼šä»…èšç„¦ arousal å’Œ sentimentï¼Œæœªæ¶‰åŠç¦»æ•£æƒ…ç»ªåˆ†ç±»æˆ–å¤šç»´æƒ…æ„Ÿè½¨è¿¹å»ºæ¨¡ã€‚
- **æ•°æ®å¤šæ ·æ€§ä¸è¶³**ï¼šä¸¤ä¸ªæ•°æ®é›†å‡é›†ä¸­äºè‹±è¯­æ”¿æ²»æ¼”è®²ï¼Œç¼ºä¹è·¨æ–‡åŒ–ã€è·¨å¹³å°ï¼ˆå¦‚ TikTokï¼‰çš„å†…å®¹ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ·±å…¥æ¢ç©¶å¤±è´¥æœºåˆ¶**ï¼š
   - åˆ†æç‰¹å®šå£°å­¦å±æ€§ï¼ˆé‡å è¯­éŸ³ã€èƒŒæ™¯éŸ³é‡ï¼‰æˆ–è§†è§‰å› ç´ ï¼ˆæ‘„åƒè§’åº¦ã€èº«ä½“å§¿æ€ï¼‰å¦‚ä½•å½±å“æ¨¡å‹åˆ¤æ–­ã€‚
   - å¼€å±• controlled perturbation å®éªŒï¼Œè¯†åˆ«å…³é”®å¹²æ‰°å˜é‡ã€‚

2. **æ‹“å±•ä»»åŠ¡ç±»å‹**ï¼š
   - æµ‹è¯• mLLMs åœ¨æ£€æµ‹ discrete emotionsï¼ˆæ„¤æ€’ã€å–œæ‚¦ç­‰ï¼‰æˆ–è¿½è¸ªæƒ…ç»ªåŠ¨æ€å˜åŒ–æ–¹é¢çš„èƒ½åŠ›ã€‚
   - æ¢ç´¢å…¶åœ¨ short-form political contentï¼ˆå¦‚ TikTokã€Instagram Reelsï¼‰ä¸­çš„é€‚ç”¨æ€§ã€‚

3. **æ”¹è¿›æ¨¡å‹æ¶æ„ä¸è®­ç»ƒ**ï¼š
   - è®¾è®¡æ›´é€‚åˆæ”¿æ²»è¯­å¢ƒçš„å¤šæ¨¡æ€é¢„è®­ç»ƒç›®æ ‡ï¼›
   - å¼•å…¥ attention masking æœºåˆ¶ä»¥å¢å¼ºå¯¹ä¸»è®²äººçš„èšç„¦èƒ½åŠ›ã€‚

4. **å»ºç«‹æ ‡å‡†åŒ– benchmark**ï¼š
   - æ¨åŠ¨å¼€å‘é¢å‘ç¤¾ä¼šç§‘å­¦çš„å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æåŸºå‡†æ•°æ®é›†ä¸è¯„ä¼°åè®®ï¼Œä¿ƒè¿›å¯æ¯”æ€§ç ”ç©¶ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼šæœ¬æ–‡æ˜¯ä¸€ç¯‡å…·æœ‰è­¦ç¤ºæ„ä¹‰çš„é‡è¦ç ”ç©¶ã€‚å®ƒæ­ç¤ºäº†å½“å‰ mLLMs åœ¨çœŸå®ä¸–ç•Œå¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æä¸­çš„ä¸¥é‡å±€é™æ€§ï¼Œæé†’ç ”ç©¶è€…ä¸å¯ç›²ç›®ä¿¡ä»»â€œé€šç”¨æ™ºèƒ½â€æ¨¡å‹çš„è¾“å‡ºã€‚å°½ç®¡å‰æ™¯å¹¿é˜”ï¼Œä½†è¦å°†å…¶ä½œä¸ºå¯é çš„ drop-in replacement for human codersï¼Œä»éœ€æ›´å¤šä¸¥è°¨éªŒè¯ä¸æ–¹æ³•é©æ–°ã€‚

</details>

---

### 14. [HGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding](https://arxiv.org/abs/2512.09947)

**Authors**: Fuyan Ou, Siqi Ai, Yulin Hu  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.09947v1  

#### Abstract
Heterogeneous graph neural networks (HGNNs) have demonstrated strong capability in modeling complex semantics across multi-type nodes and relations. However, their scalability to large-scale graphs remains challenging due to structural redundancy and high-dimensional node features. Existing graph co...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„å›¾ç¥ç»ç½‘ç»œï¼ˆHGNNsï¼‰åœ¨å¤„ç†å¤§è§„æ¨¡å¼‚æ„å›¾ï¼ˆHeterogeneous Graphï¼‰æ—¶é¢ä¸´è®¡ç®—å¼€é”€å¤§ã€å†…å­˜å ç”¨é«˜ä»¥åŠè®­ç»ƒæ•ˆç‡ä½ç­‰é—®é¢˜ã€‚ä¼ ç»Ÿçš„å›¾å‹ç¼©æ–¹æ³•å¦‚ GCond ä¸»è¦é’ˆå¯¹åŒæ„å›¾è®¾è®¡ï¼Œä¾èµ–æ¢¯åº¦åŒ¹é…ï¼ˆgradient matchingï¼‰ï¼Œå¯¼è‡´ä¼˜åŒ–å¤æ‚ã€è®¡ç®—æˆæœ¬é«˜ï¼Œä¸”éš¾ä»¥æ‰©å±•åˆ°å¤šç±»å‹èŠ‚ç‚¹å’Œå…³ç³»çš„å¼‚æ„åœºæ™¯ã€‚

æ­¤å¤–ï¼Œé‡‡æ ·ç±»æ–¹æ³•ï¼ˆå¦‚ GraphSAINTï¼‰è™½ç„¶é™ä½äº†è®¡ç®—è´Ÿæ‹…ï¼Œä½†å®¹æ˜“å¼•å…¥ä¿¡æ¯ä¸¢å¤±å’Œç»“æ„åå·®ï¼Œå°¤å…¶åœ¨ä¿ç•™å…ƒè·¯å¾„ï¼ˆmetapathï¼‰è¯­ä¹‰å’Œè·¨ç±»å‹è¿æ¥æ–¹é¢è¡¨ç°ä¸ä½³ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **HGC-Herd** â€”â€” ä¸€ç§æ— éœ€è®­ç»ƒçš„å¼‚æ„å›¾å‹ç¼©æ¡†æ¶ï¼ˆtraining-free heterogeneous graph condensationï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡â€œä»£è¡¨æ€§èŠ‚ç‚¹èšé›†â€ï¼ˆRepresentative Node Herdingï¼‰ç”Ÿæˆç´§å‡‘è€Œä¿¡æ¯ä¸°å¯Œçš„å­å›¾ã€‚

è¯¥æ–¹æ³•åŒ…å«ä¸‰ä¸ªå…³é”®æ¨¡å—ï¼š
1. **Feature Propagation**ï¼šåŸºäºé¢„å®šä¹‰ metapath è¿›è¡Œè½»é‡çº§ç‰¹å¾ä¼ æ’­ï¼Œèåˆå¤šè·³é‚»åŸŸè¯­ä¹‰ä¿¡æ¯ï¼›
2. **Class-wise Prototype Construction**ï¼šä¸ºæ¯ä¸ªç±»åˆ«æ„å»ºç±»åŸå‹ï¼ˆprototypeï¼‰ï¼Œä½œä¸ºè¯­ä¹‰ä¸­å¿ƒï¼›
3. **Strategic Herding Selection**ï¼šé‡‡ç”¨è´ªå¿ƒç­–ç•¥é€‰æ‹©æœ€æ¥è¿‘ç±»åŸå‹çš„èŠ‚ç‚¹ï¼Œå½¢æˆæ¯ç±»çš„â€œherdâ€ï¼Œç¡®ä¿è¯­ä¹‰å¤šæ ·æ€§å’Œç±»åˆ«å¹³è¡¡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **æ— éœ€è®­ç»ƒ**ï¼šé¿å…äº†æ¢¯åº¦ä¼˜åŒ–è¿‡ç¨‹ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å’Œå†…å­˜å¼€é”€ï¼›
- âœ… **é«˜æ•ˆå¯å¤ç°**ï¼šé€‰æ‹©è¿‡ç¨‹ç¡®å®šæ€§å¼ºï¼Œä¸å—éšæœºç§å­å½±å“ï¼Œæ”¯æŒè·¨ä»»åŠ¡å¤ç”¨ï¼›
- âœ… **ä¿æŒè¯­ä¹‰ä¸ç»“æ„ä¿çœŸåº¦**ï¼šé€šè¿‡ç±»æ„ŸçŸ¥ï¼ˆclass-wiseï¼‰é€‰æ‹©æœºåˆ¶ç»´æŒç±»åˆ«åˆ†å¸ƒå’Œè·¨ç±»å‹è¿æ¥ï¼›
- âœ… **çµæ´»å¯æ§**ï¼šæ”¯æŒæŒ‰ç±»åˆ«è®¾å®šå‹ç¼©é¢„ç®—ï¼ˆbudgetï¼‰ï¼Œé€‚åº”ç±»åˆ«ä¸å¹³è¡¡åœºæ™¯ï¼›
- âœ… **å³æ’å³ç”¨**ï¼šç”Ÿæˆçš„å‹ç¼©å›¾å¯ç›´æ¥ç”¨äºæ ‡å‡† HGNN æ¨¡å‹ï¼ˆå¦‚ Simple-HGNï¼‰è®­ç»ƒï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹æ¶æ„ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨ä¸‰ä¸ªæ ‡å‡†å¼‚æ„å›¾åŸºå‡†ä¸Šè¿›è¡Œï¼š
| æ•°æ®é›† | èŠ‚ç‚¹æ•° | è¾¹æ•° | èŠ‚ç‚¹ç±»å‹æ•° | è¾¹ç±»å‹æ•° | ç›®æ ‡èŠ‚ç‚¹ç±»å‹ | åˆ†ç±»ç±»åˆ«æ•° |
|--------|--------|------|-------------|-------------|----------------|--------------|
| **ACM** | 10,942 | 547,872 | 4 | 8 | paper | 3 |
| **DBLP** | 26,128 | 239,566 | 4 | 6 | author | 4 |
| **Freebase** | ~180k | ~1M | 8 | 36 | book | 7 |

æ‰€æœ‰æ•°æ®é›†å‡ä½¿ç”¨åŸå§‹ç‰¹å¾ï¼Œæœªå¼•å…¥å¤–éƒ¨é¢„è®­ç»ƒä¿¡æ¯ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä»»åŠ¡**ï¼šç›®æ ‡èŠ‚ç‚¹ç±»å‹çš„ Node Classification
- **è¯„ä¼°æŒ‡æ ‡**ï¼šåˆ†ç±»å‡†ç¡®ç‡ï¼ˆAccuracy %ï¼‰
- **å‹ç¼©æ¯”ä¾‹ï¼ˆcondensation ratioï¼‰**ï¼š`{1.2%, 2.4%, 4.8%, 9.6%}`
- **æ¨¡å‹æ¶æ„**ï¼šSimple-HGNï¼ˆ2å±‚ï¼Œ64éšè—å•å…ƒï¼ŒAdamä¼˜åŒ–å™¨ï¼Œlr=5e-4ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA RTX 3050 GPU
- **é‡å¤æ¬¡æ•°**ï¼š5æ¬¡è¿è¡Œå–å¹³å‡å€¼ï¼Œå›ºå®šéšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§
- **å‹ç¼©å›¾æ„é€ æ–¹å¼**ï¼šæ¯ä¸ªæ¯”ä¾‹ä¸‹ä»…æ„å»ºä¸€æ¬¡ï¼Œä¾›å¤šæ¬¡è®­ç»ƒå¤ç”¨

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Random-HG** | éšæœºé‡‡æ · | å‡åŒ€éšæœºé€‰å–ç›®æ ‡èŠ‚ç‚¹ |
| **K-Center-HG** | è´ªå¿ƒè¦†ç›– | åŸºäºKä¸­å¿ƒèšç±»é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„èŠ‚ç‚¹ |
| **Coarsening-HG** | ç»“æ„ç²—åŒ– | ä½¿ç”¨ METIS é£æ ¼çš„å›¾ç²—åŒ–æ–¹æ³• |
| **GCond** | æ¢¯åº¦åŒ¹é…æ³• | åŒæ„å›¾å‹ç¼©ä»£è¡¨ï¼Œéœ€åŒå±‚ä¼˜åŒ– |
| **Whole Dataset** | ä¸Šç•Œå‚è€ƒ | å…¨å›¾è®­ç»ƒç»“æœï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table Iï¼‰

#### åœ¨ ACM ä¸Šçš„è¡¨ç°ï¼ˆFull: 93.11%ï¼‰
| Ratio | HGC-Herd | GCond | K-Center-HG | Coarsening-HG | Random-HG |
|-------|----------|--------|--------------|----------------|------------|
| 1.2% | **91.88%** | 41.17% | 62.66% | 64.17% | 53.37% |
| 9.6% | **93.01%** | 65.56% | 75.68% | 70.91% | 66.25% |

> ğŸ”¥ å³ä½¿åªä¿ç•™ **1.2% çš„æ•°æ®**ï¼ŒHGC-Herd å‡†ç¡®ç‡å·²è¾¾å…¨å›¾çš„ **98.7%**

#### åœ¨ DBLP ä¸Šçš„è¡¨ç°ï¼ˆFull: 95.19%ï¼‰
| Ratio | HGC-Herd | GCond | K-Center-HG | Coarsening-HG | Random-HG |
|-------|----------|--------|--------------|----------------|------------|
| 1.2% | **89.86%** | 53.26% | 61.39% | 53.27% | 38.73% |
| 9.6% | **94.79%** | 64.25% | 79.68% | 76.91% | 56.01% |

> ğŸ’¡ è¡¨ç°å‡ºæå¼ºçš„ä¿¡æ¯ä¿ç•™èƒ½åŠ›ï¼Œæ¥è¿‘å…¨å›¾æ€§èƒ½

#### åœ¨ Freebase ä¸Šçš„è¡¨ç°ï¼ˆFull: 63.67%ï¼‰
| Ratio | HGC-Herd | GCond | K-Center-HG | Coarsening-HG | Random-HG |
|-------|----------|--------|--------------|----------------|------------|
| 1.2% | **57.18%** | 51.24% | 48.18% | 46.28% | 45.32% |
| 9.6% | **61.42%** | 57.03% | 52.68% | 52.91% | 50.01% |

> âš ï¸ å°½ç®¡ Freebase æ›´å¤æ‚ï¼ŒHGC-Herd ä»æ˜æ˜¾ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå°¤å…¶åœ¨ä½å‹ç¼©æ¯”ä¸‹ä¼˜åŠ¿æ˜¾è‘—

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨æ‰€æœ‰æ•°æ®é›†å’Œå‹ç¼©æ¯”ä¾‹ä¸‹ï¼Œ**HGC-Herd æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•**ï¼›
- ç›¸æ¯”ä¾èµ–æ¢¯åº¦çš„ GCondï¼ŒHGC-Herd ä¸ä»…ç²¾åº¦æ›´é«˜ï¼Œè€Œä¸”ç¨³å®šæ€§æ›´å¼ºï¼ˆæ–¹å·®æ›´å°ï¼‰ï¼›
- åœ¨ 1.2% æç«¯å‹ç¼©ä¸‹ï¼ŒHGC-Herd æ€§èƒ½è¿œè¶…ç¬¬äºŒåï¼ˆé€šå¸¸é«˜å‡º 20â€“30 ä¸ªç™¾åˆ†ç‚¹ï¼‰ï¼›
- K-Center-HG å’Œ Coarsening-HG è¡¨ç°å°šå¯ï¼Œä½†ä»æ— æ³•æœ‰æ•ˆä¿æŒç±»åˆ«å¹³è¡¡å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable IIï¼Œ1.2% ratioï¼‰

| å˜ä½“ | ACM | Freebase |
|------|-----|----------|
| **HGC-Herd (å®Œæ•´)** | **91.88%** | **57.18%** |
| w/o Feature Propagation | 89.45% | 55.12% |
| w/o Herding | 81.23% | 48.67% |

> ğŸ“Œ ç»“è®ºï¼š
- ç§»é™¤ **Feature Propagation** å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜å¤šè·³è¯­ä¹‰èšåˆå¯¹æå‡ä»£è¡¨æ€§è‡³å…³é‡è¦ï¼›
- ç§»é™¤ **Herding Selection** å¯¼è‡´æœ€å¤§æ€§èƒ½æŸå¤±ï¼ŒéªŒè¯äº†ç±»æ„ŸçŸ¥é€‰æ‹©æœºåˆ¶çš„å…³é”®ä½œç”¨ï¼›
- ä¸¤è€…ååŒå·¥ä½œæ‰èƒ½å®ç°æœ€ä¼˜å‹ç¼©æ•ˆæœã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
- **HGC-Herd èƒ½åœ¨æé«˜å‹ç¼©æ¯”ï¼ˆä½è‡³ 1.2%ï¼‰ä¸‹é€¼è¿‘å…¨å›¾è®­ç»ƒæ€§èƒ½**ï¼Œè¯æ˜å…¶å¼ºå¤§çš„è¯­ä¹‰ä¿ç•™èƒ½åŠ›ï¼›
- **æ— éœ€æ¢¯åº¦ä¼˜åŒ–å³å¯å®ç°é«˜è´¨é‡å›¾å‹ç¼©**ï¼Œæ‰“ç ´äº†ä»¥å¾€â€œå¿…é¡»é€šè¿‡æ¢¯åº¦åŒ¹é…â€çš„èŒƒå¼ï¼›
- **ç±»åŸå‹å¼•å¯¼ + herding æœºåˆ¶** æ˜¯å®ç°è¯­ä¹‰å¤šæ ·æ€§ä¸ç±»åˆ«å¹³è¡¡çš„å…³é”®ï¼›
- **è½»é‡çº§ç‰¹å¾ä¼ æ’­ + ç¡®å®šæ€§é€‰æ‹©ç­–ç•¥** ä½¿å¾—æ•´ä¸ªæµç¨‹é«˜æ•ˆã€ç¨³å®šã€å¯å¤ç°ï¼›
- å®éªŒè¡¨æ˜ï¼ŒHGC-Herd åœ¨ä¸åŒè§„æ¨¡å’Œå¤æ‚åº¦çš„å¼‚æ„å›¾ä¸Šå‡å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ–¹æ³•ä¾èµ–äººå·¥æŒ‡å®š metapathï¼Œå¯èƒ½é™åˆ¶å…¶åœ¨ç¼ºä¹é¢†åŸŸçŸ¥è¯†åœºæ™¯ä¸‹çš„åº”ç”¨ï¼›
- å¯¹äºåŠ¨æ€å›¾æˆ–æµå¼å›¾æ•°æ®ï¼Œå°šæœªæä¾›å¢é‡æ›´æ–°æœºåˆ¶ï¼›
- å‹ç¼©åçš„å›¾è™½å°ï¼Œä½†ä»æ˜¯çœŸå®èŠ‚ç‚¹çš„å­é›†ï¼ˆéåˆæˆèŠ‚ç‚¹ï¼‰ï¼Œåœ¨æç«¯å‹ç¼©ä¸‹å¯èƒ½ä»å­˜åœ¨å†—ä½™ï¼›
- å¤šç±»å‹è¾¹çš„å…¨å±€ç»“æ„ä¿çœŸåº¦ä»æœ‰è¿›ä¸€æ­¥æå‡ç©ºé—´ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **åŠ¨æ€å›¾ï¼ˆDynamic Graphsï¼‰** åœºæ™¯ï¼Œæ”¯æŒæ—¶é—´æ¼”åŒ–ä¸‹çš„æŒç»­å‹ç¼©ï¼›
- æ¢ç´¢ **è‡ªé€‚åº” per-class budget allocation**ï¼Œæ ¹æ®ç±»åˆ«éš¾åº¦æˆ–ç¨€ç–æ€§è‡ªåŠ¨è°ƒæ•´å‹ç¼©æ¯”ä¾‹ï¼›
- ç ”ç©¶ä¸ **è”é‚¦å­¦ä¹ ï¼ˆFederated Learningï¼‰** å’Œ **éšç§ä¿æŠ¤** è®¾ç½®çš„ç»“åˆï¼Œåœ¨ä¸å…±äº«åŸå§‹æ•°æ®çš„å‰æä¸‹è¿›è¡Œåˆ†å¸ƒå¼å›¾å‹ç¼©ï¼›
- å¼•å…¥ **å…ƒå­¦ä¹ æˆ–è‡ªç›‘ç£æœºåˆ¶** è‡ªåŠ¨å‘ç°æœ€ä¼˜ metapath æˆ–ä¼ æ’­ç­–ç•¥ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼š  
HGC-Herd æå‡ºäº†ä¸€ç§ç®€æ´ã€é«˜æ•ˆã€å¯å¤ç°çš„å¼‚æ„å›¾å‹ç¼©æ–°èŒƒå¼ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ã€ä¼˜åŒ–éš¾åº¦å’Œè¯­ä¹‰ä¿çœŸä¹‹é—´çš„æƒè¡¡éš¾é¢˜ï¼Œåœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå…·æœ‰å¾ˆå¼ºçš„å®é™…éƒ¨ç½²ä»·å€¼ã€‚

</details>

---

### 15. [Multi-Objective Reward and Preference Optimization: Theory and Algorithms](https://arxiv.org/abs/2512.10601)

**Authors**: Akhil Agnihotri  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.10601v1  

#### Abstract
This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Multi-Objective Reward and Preference Optimization: Theory and Algorithms*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥åšå£«è®ºæ–‡ç³»ç»Ÿåœ°ç ”ç©¶äº†**å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­çš„å¤šç›®æ ‡ä¼˜åŒ–ä¸åå¥½å¯¹é½é—®é¢˜**ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»¥ä¸‹ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜åœºæ™¯ä¸­ï¼š
- **å®‰å…¨çº¦æŸä¸‹çš„ç­–ç•¥ä¼˜åŒ–**ï¼šåœ¨å¹³å‡å¥–åŠ±å‡†åˆ™ä¸‹ï¼Œå¦‚ä½•æœ‰æ•ˆå¤„ç†é•¿æœŸå®‰å…¨çº¦æŸï¼ˆå¦‚æœºå™¨äººæ§åˆ¶ã€LLM å®‰å…¨æ€§ï¼‰ã€‚
- **ç¦»çº¿åå¥½ä¸åœ¨çº¿å¥–åŠ±çš„èåˆ**ï¼šå¦‚ä½•åˆ©ç”¨æ¥è‡ªä¸åŒå¯é åº¦è¯„åˆ†è€…çš„ç¦»çº¿åå¥½æ•°æ®ï¼Œå¹¶ç»“åˆåœ¨çº¿æ•°å€¼å¥–åŠ±è¿›è¡Œé«˜æ•ˆå­¦ä¹ ã€‚
- **å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šç›®æ ‡å¯¹é½**ï¼šå¦‚ä½•åœ¨ä¸ä¾èµ–å•ä¸€æ ‡é‡åŒ–å¥–åŠ±çš„å‰æä¸‹ï¼Œå¹³è¡¡å¤šä¸ªå†²çªçš„ç›®æ ‡ï¼ˆå¦‚ helpfulnessã€harmlessnessã€truthfulnessï¼‰ã€‚

è¿™äº›é—®é¢˜åœ¨ç°å®åº”ç”¨ä¸­æ™®éå­˜åœ¨ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ PPOã€DPOï¼‰å¾€å¾€é€šè¿‡ç®€å•åŠ æƒæˆ–å¿½ç•¥çº¦æŸæ¥å¤„ç†ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€reward hacking æˆ–æ— æ³•é€¼è¿‘ Pareto å‰æ²¿ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

è®ºæ–‡æå‡ºäº†äº”ä¸ªæ ¸å¿ƒç®—æ³•ï¼Œè¦†ç›–ä»ç†è®ºåˆ°å®è·µçš„å®Œæ•´é“¾æ¡ï¼š

| æ–¹æ³• | æ‰€å±ç« èŠ‚ | åˆ›æ–°ç‚¹ |
|------|----------|--------|
| **ACPO** (Average-Constrained Policy Optimization) | Chapter 1 | é¦–ä¸ªé€‚ç”¨äº **average-reward CMDP** çš„å®ç”¨ä¿¡ä»»åŒºåŸŸç­–ç•¥ä¼˜åŒ–ç®—æ³•ã€‚å¼•å…¥åŸºäºæ•æ„Ÿæ€§åˆ†æå’Œå­æ°´å¹³é›†ï¼ˆsublevel setsï¼‰çš„æŠ•å½±æœºåˆ¶ï¼Œåœ¨ä¿è¯çº¦æŸæ»¡è¶³çš„åŒæ—¶æä¾›å¼ºç†è®ºä¿éšœã€‚ |
| **e-COP** (episodic Constrained Optimization Problem) | Chapter 2 | å°†çº¦æŸ RL æ‰©å±•è‡³ **episodic MDPs**ï¼Œæå‡ºä¸€ç§æ–°é¢–çš„è¿‘ä¼¼çº¿æœç´¢ç¨‹åºï¼Œæå‡ç­–ç•¥æ›´æ–°æ•ˆç‡ï¼Œå¹¶é¦–æ¬¡ä¸º episodic è®¾ç½®è®¾è®¡äº†æœ‰æ•ˆçš„çº¦æŸä¼˜åŒ–æ¡†æ¶ã€‚ |
| **warmPref-PS** | Chapter 3 | ä¸€ç§è´å¶æ–¯åéªŒé‡‡æ ·ï¼ˆPosterior Samplingï¼‰ç®—æ³•ï¼Œç”¨äºçº¿æ€§ bandits åœºæ™¯ã€‚**å»ºæ¨¡è¯„åˆ†è€…èƒ½åŠ›ï¼ˆrater competenceï¼‰**ï¼ŒåŠ¨æ€è°ƒæ•´ç¦»çº¿åå¥½çš„å¯ä¿¡åº¦ï¼Œé¿å…ä½è´¨é‡æ•°æ®è¯¯å¯¼å­¦ä¹ è¿‡ç¨‹ã€‚ |
| **PSPL** (Posterior Sampling for Preference-based Learning) | Chapter 4 | åœ¨ preference-based RL ä¸­å®ç° **best-policy identification**ï¼Œé¦–æ¬¡ç»™å‡º **Bayesian simple regret bounds**ã€‚æ”¯æŒè½¨è¿¹çº§åé¦ˆä¸‹çš„ä¿¡ç”¨åˆ†é…ï¼Œå¹¶æå‡º bootstrap ç‰ˆæœ¬ä»¥é€‚åº”é«˜ç»´å‡½æ•°é€¼è¿‘ã€‚ |
| **MOPO** (Multi-Objective Preference Optimization) | Chapter 5 | é¢å‘ LLM å¯¹é½çš„å¯æ‰©å±•å¤šç›®æ ‡ä¼˜åŒ–æ¡†æ¶ã€‚å°†ä¸»ç›®æ ‡æœ€å¤§åŒ–ï¼ŒåŒæ—¶å°†æ¬¡çº§ç›®æ ‡ä½œä¸º**å¯è°ƒé˜ˆå€¼çš„çº¦æŸé¡¹**ï¼Œç›´æ¥ä½œç”¨äº pairwise preferencesï¼Œé¿å… reward hackingï¼Œé€¼è¿‘ Pareto frontã€‚ |

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | ç›¸æ¯”ä¼˜åŠ¿ |
|------|--------|
| **ACPO vs CPO / PPO** | åœ¨ average-reward è®¾ç½®ä¸‹è¡¨ç°æ›´ä¼˜ï¼›ç†è®ºä¸Šæœ‰æ›´å¼ºçš„æ€§èƒ½é€€åŒ–ç•Œï¼›èƒ½å¤„ç†é•¿æœŸå¹³å‡çº¦æŸï¼Œæ›´é€‚åˆå®‰å…¨å…³é”®ä»»åŠ¡ã€‚ |
| **warmPref-PS vs vanilla PS / DPO** | æ˜¾å¼å»ºæ¨¡ rater competenceï¼Œå‡å°‘å™ªå£°å½±å“ï¼›æ”¯æŒ offline + online æ··åˆå­¦ä¹ ï¼Œæ ·æœ¬æ•ˆç‡æ›´é«˜ã€‚ |
| **PSPL vs optimism-based baselines** | æ›´æ˜“äºå®ç°ä¸”è®¡ç®—é«˜æ•ˆï¼›é¦–æ¬¡æä¾› simple regret ç†è®ºä¿è¯ï¼›é€‚ç”¨äºéè¡¨æ ¼å‹ç¯å¢ƒçš„è¿‘ä¼¼ç‰ˆæœ¬ï¼ˆBootstrapped PSPLï¼‰ã€‚ |
| **MOPO vs DPO / MODPO / RiC** | ä¸ä¾èµ– reward scalarizationï¼Œèƒ½æ¢ç´¢æ•´ä¸ª Pareto frontï¼›æ— éœ€æ¨ç†æ—¶æ¡ä»¶è¾“å…¥ï¼›é—­å¼æ›´æ–°ä½¿å…¶å¯æ‰©å±•è‡³æ•°åäº¿å‚æ•°æ¨¡å‹ï¼›ä¼˜åŒ–æ›´ç¨³å®šã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ ‡å‡† RL ç¯å¢ƒ**ï¼šOpenAI Gym (MuJoCo) è¿ç»­æ§åˆ¶ä»»åŠ¡ï¼ˆå¦‚ HalfCheetah, Walker2dï¼‰ï¼Œç”¨äºè¯„ä¼° ACPO å’Œ e-COPã€‚
- **åˆæˆåå¥½æ•°æ®é›†**ï¼šæ„é€ å…·æœ‰å·²çŸ¥ Pareto front çš„äºŒç»´/ä¸‰ç»´ reward å‡½æ•°ï¼ˆå¦‚ $r_1(x,y)=(x+y)^2$, $r_2(x,y)=\log(xy)$ï¼‰ï¼Œç”¨äºéªŒè¯ MOPO æ˜¯å¦èƒ½æ¢å¤æœ€ä¼˜ç­–ç•¥ã€‚
- **çœŸå®ä¸–ç•Œ LLM æ•°æ®é›†**ï¼š
  - **Helpful Assistant Task**ï¼šäººç±»æ ‡æ³¨çš„åŠ©æ‰‹å›å¤åå¥½æ•°æ®ã€‚
  - **Reddit Summary Task**ï¼šç¤¾åŒºæ‘˜è¦ç”Ÿæˆä»»åŠ¡çš„äººç±»åå¥½æ•°æ®ã€‚
  - å¼€æºæ¨¡å‹æµ‹è¯•é›†ï¼šZephyr-7b-beta, Mistral-7b-v0.2, Llama2-7b-chat ç­‰ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| æ–¹æ³• | è®¾ç½® | ä¸»è¦è¯„ä¼°æŒ‡æ ‡ |
|------|------|-------------|
| **ACPO / e-COP** | ä½¿ç”¨ 5 æ¬¡ç‹¬ç«‹è¿è¡Œå–å‡å€¼ï¼›discount factor è®¾ä¸ºæ¥è¿‘ 1 çš„å€¼ï¼ˆæ¨¡æ‹Ÿ average settingï¼‰ï¼›é‡‡ç”¨ Lagrangian æ–¹æ³•ä½œä¸º baselineã€‚ | å¹³å‡ rewardã€constraint violationï¼ˆvs thresholdï¼‰ã€æ”¶æ•›é€Ÿåº¦ |
| **warmPref-PS** | çº¿æ€§ bandit è®¾ç½®ï¼ŒA=10 armsï¼›ç¦»çº¿æ•°æ®å¤§å° N å˜åŒ–ï¼›å¼•å…¥ä¸åŒ competence levels çš„ raterã€‚ | Bayesian regret $\mathcal{O}(\sqrt{T} + \alpha_{\text{rater}})$ |
| **PSPL** | Gridworld ä¸éšæœº MDPï¼›trajectory-level feedbackï¼›æ¯”è¾ƒä¸åŒ offline æ•°æ®é‡çš„å½±å“ã€‚ | Simple regretã€policy identification accuracy |
| **MOPO** | å¤šäº¿å‚æ•° LLMï¼ˆå¦‚ Llama-3.1-8Bï¼‰fine-tuningï¼›batch size=128ï¼›ä½¿ç”¨ trl åº“å®ç°ï¼›lagged reference policy every $t_0$ stepsã€‚ | Normalized reward per objectiveã€Pareto dominance rateã€overfitting on held-out comparisons |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ACPO**: vs CPO, PCPO, PPO, BVF-PPO, ATRPO
- **warmPref-PS**: vs vanilla PS, LinTS, Hybrid-DPO
- **PSPL**: vs optimism-based methodsï¼ˆè™½ä¸å¯è¡Œï¼Œä½†ä»ä½œæ¦‚å¿µå¯¹æ¯”ï¼‰
- **MOPO**: vs DPO, MODPO, RiC, PARM, SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **ACPO**ï¼šåœ¨ MuJoCo ç¯å¢ƒä¸­ï¼Œç›¸æ¯” CPO å’Œ PPOï¼Œ**å¹³å‡ reward æå‡ 12â€“18%**ï¼ŒåŒæ—¶å°† constraint violation æ§åˆ¶åœ¨é˜ˆå€¼ä»¥å†…ï¼ˆ<5% è¶…é™ï¼‰ï¼Œè€Œå…¶ä»–æ–¹æ³•å¸¸å‡ºç°ä¸¥é‡è¿è§„ã€‚
- **warmPref-PS**ï¼šå½“ rater competence è¾ƒä½æ—¶ï¼Œå…¶ regret æ¯” vanilla PS é™ä½ **è¶…è¿‡ 40%**ï¼›ç†è®ºç•Œçš„ $\alpha_{\text{rater}}$ é¡¹è¢«å®éªŒè¯å®æœ‰æ•ˆã€‚
- **PSPL**ï¼šåœ¨ small MDP ä¸Šï¼Œsimple regret æ”¶æ•›é€Ÿåº¦å¿«äºéšæœºç­–ç•¥çº¦ **3å€**ï¼›bootstrap ç‰ˆæœ¬åœ¨é«˜ç»´ç©ºé—´ä»ä¿æŒé²æ£’æ€§ã€‚
- **MOPO**ï¼š
  - åœ¨ synthetic benchmarks ä¸Šï¼Œ**å®Œå…¨æ¢å¤äº†çœŸå® Pareto front**ï¼ˆè§ Fig 5.9ï¼‰ï¼›
  - åœ¨ LLM å®éªŒä¸­ï¼Œç›¸æ¯” DPOï¼Œ**held-out comparison å‡†ç¡®ç‡æé«˜ 6.2%**ï¼Œè¡¨æ˜æ— è¿‡æ‹Ÿåˆï¼›
  - åœ¨ Helpfulness-Harmlessness æƒè¡¡ä¸­ï¼Œ**Pareto-dominates æ‰€æœ‰ baseline**ï¼ˆFig 5.5ï¼‰ï¼›
  - è®­ç»ƒæ—¶é—´ä»…éœ€ **4.1 å°æ—¶**ï¼ˆvs PPO 5.1h, MODPO 5.7hï¼‰ï¼Œå…·å¤‡è‰¯å¥½å¯æ‰©å±•æ€§ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **MOPO æ˜¾è‘—ä¼˜äºæ‰€æœ‰ scalarization-based æ–¹æ³•**ï¼ˆå¦‚ DPO, MODPOï¼‰ï¼Œåè€…åªèƒ½å­¦åˆ°ç‰¹å®šæƒé‡ä¸‹çš„è§£ï¼Œæ— æ³•æ³›åŒ–ã€‚
- **ACPO åœ¨é•¿æœŸå®‰å…¨çº¦æŸä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äº Lagrangian æ–¹æ³•**ï¼ˆå¦‚ PPO-Lagï¼‰ï¼Œåè€…å¸¸å›  dual variable æ›´æ–°ä¸ç¨³å®šè€Œå¯¼è‡´ constraint violationã€‚
- **warmPref-PS åœ¨ä½è´¨é‡ç¦»çº¿æ•°æ®ä¸‹è¡¨ç°è¿œè¶… Hybrid-DPO**ï¼Œè¯æ˜å»ºæ¨¡ rater competence çš„å¿…è¦æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **MOPO æ¶ˆèå®éªŒ**ï¼ˆFig 5.8ï¼‰ï¼š
  - **Lagged reference policy ($t_0 > 0$)**ï¼šè®¾ç½® $t_0=100$ æ¯” $t_0=0$ï¼ˆæ— å»¶è¿Ÿï¼‰reward æå‡ 9%ï¼Œè¯´æ˜ç›®æ ‡ç­–ç•¥æ»åæœ‰åŠ©äºç¨³å®šè®­ç»ƒã€‚
  - **Constraint relaxation ($\beta$)**ï¼š$\beta=0.95$ æœ€ä½³ï¼Œè¿‡å¤§ï¼ˆ0.999ï¼‰å¯¼è‡´çº¦æŸå¤ªæ¾ï¼Œè¿‡å°ï¼ˆ0.9ï¼‰é™åˆ¶æ¢ç´¢ã€‚
  - **KL æ­£åˆ™å¼ºåº¦ ($\tau$)**ï¼š$\tau=0.5$ å¹³è¡¡ exploration-exploitationï¼Œè¿‡å¤§å¯¼è‡´åç¦»å‚è€ƒç­–ç•¥ä¸è¶³ã€‚
- **ACPO æ¢å¤æ­¥éª¤**ï¼šå½“çº¦æŸè¿åæ—¶ï¼Œå¼•å…¥ recovery step å¯ä½¿ç­–ç•¥å¿«é€Ÿå›åˆ°å¯è¡ŒåŸŸï¼Œé¿å…è®­ç»ƒå´©æºƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¹³å‡å¥–åŠ±ä¸‹çš„çº¦æŸ RL æ˜¯å¯è¡Œä¸”å¿…è¦çš„**ï¼šACPO æˆåŠŸè§£å†³äº† average-CMDP çš„ä¼˜åŒ–éš¾é¢˜ï¼Œä¸ºé•¿æœŸå®‰å…¨æ§åˆ¶æä¾›äº†æ–°å·¥å…·ã€‚
2. **ç¦»çº¿åå¥½å¿…é¡»è€ƒè™‘è¯„åˆ†è€…å¯é æ€§**ï¼šç›²ç›®ä¿¡ä»»æ‰€æœ‰åå¥½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼›warmPref-PS é€šè¿‡å»ºæ¨¡ $\lambda$ å’Œ $\beta$ å®ç°é€‰æ‹©æ€§å­¦ä¹ ã€‚
3. **å¤šç›®æ ‡å¯¹é½ä¸åº”ä¾èµ– reward scalarization**ï¼šMOPO è¡¨æ˜ï¼Œå°†æ¬¡è¦ç›®æ ‡è®¾ä¸ºçº¦æŸè€ŒéåŠ æƒé¡¹ï¼Œèƒ½æ›´å¥½åœ°é€¼è¿‘ Pareto frontï¼Œé¿å… reward hackingã€‚
4. **åéªŒé‡‡æ ·æ˜¯è¿æ¥ offline ä¸ online å­¦ä¹ çš„æœ‰æ•ˆèŒƒå¼**ï¼šPSPL å’Œ warmPref-PS å±•ç¤ºäº† PS åœ¨ preference learning ä¸­çš„æ½œåŠ›ï¼Œå°¤å…¶é€‚åˆæœ€ç»ˆç­–ç•¥é€‰æ‹©ä»»åŠ¡ï¼ˆsimple regretï¼‰ã€‚
5. **ç»Ÿä¸€æ¡†æ¶çš„å¯èƒ½æ€§**ï¼šACPOã€e-COPã€warmPref-PSã€PSPLã€MOPO æ„æˆäº†ä¸€ä¸ªä»æ˜¾å¼çº¦æŸåˆ°éšå¼åå¥½çš„ç»Ÿä¸€ constrained RL æ¡†æ¶ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ACPO / e-COP**ï¼šä¾èµ–äºç­–ç•¥æ¢¯åº¦ä¼°è®¡ï¼Œå¯èƒ½å—æ–¹å·®å½±å“ï¼›æœªåœ¨çœŸå®æœºå™¨äººä¸Šéƒ¨ç½²éªŒè¯ã€‚
- **warmPref-PS / PSPL**ï¼šå½“å‰ç†è®ºåˆ†æé›†ä¸­åœ¨ tabular æˆ–çº¿æ€§ settingï¼Œå°šæœªæ¨å¹¿åˆ° full deep RLã€‚
- **MOPO**ï¼šå‡è®¾ preference dataset è¦†ç›–è¶³å¤ŸçŠ¶æ€ç©ºé—´ï¼›adaptive constraint scheduling å¼•å…¥é¢å¤–è¶…å‚ $\beta$ã€‚
- æ‰€æœ‰æ–¹æ³•å‡å‡è®¾åå¥½ä¸€è‡´æ€§è¾ƒå¼ºï¼Œæœªå……åˆ†å¤„ç†çŸ›ç›¾æˆ–æ¨¡ç³Šåå¥½ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ continuous state/action spaces**ï¼šå°† posterior sampling ç±»ç®—æ³•ï¼ˆå¦‚ warmPref-PS, PSPLï¼‰æ¨å¹¿åˆ° deep function approximation settingã€‚
2. **åŠ¨æ€æˆ–å¤šå±‚çº§çº¦æŸå»ºæ¨¡**ï¼šç ”ç©¶æ—¶é—´å˜åŒ–çš„å®‰å…¨é˜ˆå€¼æˆ–å±‚æ¬¡åŒ–ç›®æ ‡ç»“æ„ã€‚
3. **åœ¨çº¿è‡ªé€‚åº” rater competence learning**ï¼šè®©æ¨¡å‹è‡ªåŠ¨è¯†åˆ«å¹¶æ ¡å‡†ä¸åŒç”¨æˆ·çš„è¯„åˆ†åå·®ã€‚
4. **ç»“åˆ MOPO ä¸ reasoning agents**ï¼šåœ¨å¤æ‚å†³ç­–é“¾ä¸­å®ç°å¤šç›®æ ‡åå¥½å¯¼èˆªã€‚
5. **å¼€æ”¾æ›´å¤šä»£ç ä¸åŸºå‡†**ï¼šæ¨åŠ¨ community å¯¹ multi-objective alignment çš„æ ‡å‡†åŒ–è¯„ä¼°ï¼ˆå¦‚ HarmBench å·²åˆæ­¥å°è¯•ï¼‰ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªä»ç†è®ºåˆ°åº”ç”¨çš„å®Œæ•´â€œçº¦æŸå¼ºåŒ–å­¦ä¹ â€ä½“ç³»ï¼Œæå‡ºäº†ä¸€ç³»åˆ—åˆ›æ–°ç®—æ³•ï¼ˆå°¤å…¶æ˜¯ MOPO å’Œ ACPOï¼‰ï¼Œåœ¨å®‰å…¨æ§åˆ¶ä¸ LLM å¯¹é½ç­‰å…³é”®é¢†åŸŸå®ç°äº†æ€§èƒ½çªç ´ï¼Œå¼ºè°ƒäº†**é¿å… reward hackingã€å°Šé‡ Pareto æƒè¡¡ã€å»ºæ¨¡äººç±»åå¥½å¼‚è´¨æ€§**çš„é‡è¦æ€§ï¼Œä¸ºä¸‹ä¸€ä»£ AI å¯¹é½æŠ€æœ¯å¥ å®šäº†åŸºç¡€ã€‚

</details>

---

### 16. [EpiPlanAgent: Agentic Automated Epidemic Response Planning](https://arxiv.org/abs/2512.10313)

**Authors**: Kangkun Mao, Fang Xu, Jinru Ding, Yidong Jiang, Yujun Yao, Yirong Chen, Junming Liu, Xiaoqin Wu, Qian Wu, Xiaoyan Huang, Jie Xu  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.10313v1  

#### Abstract
Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi...

---

### 17. [User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation](https://arxiv.org/abs/2512.10322)

**Authors**: Yongqiang Yu, Xuhui Li, Hazza Mahmood, Jinxing Zhou, Haodong Hong, Longtao Jiang, Zhiqiang Xu, Qi Wu, Xiaojun Chang  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.10322v1  

#### Abstract
Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static ...

---

### 18. [Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution](https://arxiv.org/abs/2512.10696)

**Authors**: Zouying Cao, Jiaji Deng, Li Yu, Weikang Zhou, Zhaoyang Liu, Bolin Ding, Hai Zhao  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.10696v1  

#### Abstract
Procedural memory enables large language model (LLM) agents to internalize "how-to" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a "passive accumulation" paradigm, treating memory as a static append-only archive. To bridge the ga...

---

### 19. [Multi-Granular Node Pruning for Circuit Discovery](https://arxiv.org/abs/2512.10903)

**Authors**: Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, A. B. Siddique  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.10903v1  

#### Abstract
Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP bloc...

---

### 20. [AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence](https://arxiv.org/abs/2512.10624)

**Authors**: Bo Yang, Lanfei Feng, Yunkui Chen, Yu Zhang, Jianyu Zhang, Xiao Xu, Nueraili Aierken, Shijian Li  
**Category**: cs.CL  
**Published**: 2025-12-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.10624v1  

#### Abstract
Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-fram...

---

### 21. [CloudFix: Automated Policy Repair for Cloud Access Control Policies Using Large Language Models](https://arxiv.org/abs/2512.09957)

**Authors**: Bethel Hall, Owen Ungaro, William Eiers  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.09957v1  

#### Abstract
Access control policies are vital for securing modern cloud computing, where organizations must manage access to sensitive data across thousands of users in distributed system settings. Cloud administrators typically write and update policies manually, which can be an error-prone and time-consuming ...

---

### 22. [Uncertainty-Preserving QBNNs: Multi-Level Quantization of SVI-Based Bayesian Neural Networks for Image Classification](https://arxiv.org/abs/2512.10602)

**Authors**: Hendrik Borras, Yong Wu, Bernhard Klein, Holger Fr\"oning  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.10602v1  

#### Abstract
Bayesian Neural Networks (BNNs) provide principled uncertainty quantification but suffer from substantial computational and memory overhead compared to deterministic networks. While quantization techniques have successfully reduced resource requirements in standard deep learning models, their applic...

---

### 23. [Exploring LLMs for Scientific Information Extraction Using The SciEx Framework](https://arxiv.org/abs/2512.10004)

**Authors**: Sha Li, Ayush Sadekar, Nathan Self, Yiqi Su, Lars Andersland, Mira Chaplin, Annabel Zhang, Hyoju Yang, James B Henderson, Krista Wigginton, Linsey Marr, T. M. Murali, Naren Ramakrishnan  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.10004v1  

#### Abstract
Large language models (LLMs) are increasingly touted as powerful tools for automating scientific information extraction. However, existing methods and tools often struggle with the realities of scientific literature: long-context documents, multi-modal content, and reconciling varied and inconsisten...

---

### 24. [Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules](https://arxiv.org/abs/2512.10300)

**Authors**: Yanbei Jiang, Xueqi Ma, Shu Liu, Sarah Monazam Erfani, Tongliang Liu, James Bailey, Jey Han Lau, Krista A. Ehinger  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.10300v1  

#### Abstract
Despite excelling on multimodal benchmarks, vision-language models (VLMs) largely remain a black box. In this paper, we propose a novel interpretability framework to systematically analyze the internal mechanisms of VLMs, focusing on the functional roles of attention heads in multimodal reasoning. T...

---

### 25. [Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences](https://arxiv.org/abs/2512.10147)

**Authors**: Sarwan Ali, Taslim Murad  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.10147v1  

#### Abstract
Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however,...

---

### 26. [Interpretable and Steerable Concept Bottleneck Sparse Autoencoders](https://arxiv.org/abs/2512.10805)

**Authors**: Akshay Kulkarni, Tsui-Wei Weng, Vivek Narayanaswamy, Shusen Liu, Wesam A. Sakla, Kowshik Thopalli  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.10805v1  

#### Abstract
Sparse autoencoders (SAEs) promise a unified approach for mechanistic interpretability, concept discovery, and model steering in LLMs and LVLMs. However, realizing this potential requires that the learned features be both interpretable and steerable. To that end, we introduce two new computationally...

---

### 27. [CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models](https://arxiv.org/abs/2512.10655)

**Authors**: Tong Zhang, Carlos Hinojosa, Bernard Ghanem  
**Category**: cs.AI  
**Published**: 2025-12-12  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.10655v1  

#### Abstract
Diffusion models can unintentionally reproduce training examples, raising privacy and copyright concerns as these systems are increasingly deployed at scale. Existing inference-time mitigation methods typically manipulate classifier-free guidance (CFG) or perturb prompt embeddings; however, they oft...

---

### 28. [ESS: An Offload-Centric Latent-Cache Management Architecture for DeepSeek-V3.2-Exp](https://arxiv.org/abs/2512.10576)

**Authors**: Xinhang Chen, Chao Zhang, Jiahuan He, Wei Liu, Jianming Zhang, Wenlong Zhou, Xiao Li, Pai Zeng, Shiyong Li, Yuanpan Qian, Dong Li, Zhaogeng Li  
**Category**: cs.DC  
**Published**: 2025-12-12  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.10576v1  

#### Abstract
DeepSeek-V3.2-Exp introduces a sparse attention mechanism that significantly reduces inference latency in long-context scenarios. Although the overall throughput has improved greatly, the Decode-stage of PD disaggregation remains to be a major bottleneck. This bottleneck primarily stems from the con...

---

### 29. [\textsc{Text2Graph}: Combining Lightweight LLMs and GNNs for Efficient Text Classification in Label-Scarce Scenarios](https://arxiv.org/abs/2512.10061)

**Authors**: Jo\~ao Lucas Luz Lima Sarcinelli, Ricardo Marcondes Marcacini  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.10061v1  

#### Abstract
Large Language Models (LLMs) have become effective zero-shot classifiers, but their high computational requirements and environmental costs limit their practicality for large-scale annotation in high-performance computing (HPC) environments. To support more sustainable workflows, we present \textsc{...

---

### 30. [Unlocking the Address Book: Dissecting the Sparse Semantic Structure of LLM Key-Value Caches via Sparse Autoencoders](https://arxiv.org/abs/2512.10547)

**Authors**: Qingsen Ma, Dianyun Wang, Jiaming Lyu, Yaoye Wang, Lechen Ning, Sujie Zhu, Zhenbo Xu, Liuyu Xiang, Huining Li, Huijia Wu, Zhaofeng He  
**Category**: cs.LG  
**Published**: 2025-12-12  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.10547v1  

#### Abstract
The Key-Value (KV) cache is the primary memory bottleneck in long-context Large Language Models, yet it is typically treated as an opaque numerical tensor. In this work, we propose \textbf{STA-Attention}, a framework that utilizes Top-K Sparse Autoencoders (SAEs) to decompose the KV cache into inter...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
