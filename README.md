# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-09 05:54:21 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Stable-MoE: Lyapunov-based Token Routing for Distributed Mixture-of-Experts Training over Edge Networks](https://arxiv.org/abs/2512.06784)

**Authors**: Long Shi, Bingyan Ou, Kang Wei, Weihao Zhu, Zhe Wang, Zhiyong Chen  
**Category**: cs.DC  
**Published**: 2025-12-09  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2512.06784v1  

#### Abstract
The sparse activation mechanism of mixture of experts (MoE) model empowers edge intelligence with enhanced training efficiency and reduced computational resource consumption. However, traditional token routing in distributed MoE training faces significant challenges in resource-constrained edge netw...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šStable-MoE: Lyapunov-based Token Routing for Distributed Mixture-of-Experts Training over Edge Networks**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
åœ¨èµ„æºå—é™ã€è®¡ç®—èƒ½åŠ›å¼‚æ„ä¸”å­˜åœ¨éšæœºtokenåˆ°è¾¾çš„è¾¹ç¼˜ç½‘ç»œä¸­ï¼Œä¼ ç»Ÿçš„ **distributed MoE**ï¼ˆMixture-of-Expertsï¼‰è®­ç»ƒé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **Token backlog**ï¼šç”±äºè¾¹ç¼˜è®¾å¤‡è®¡ç®—èƒ½åŠ›ä¸å‡ï¼Œéƒ¨åˆ†æœåŠ¡å™¨è´Ÿè½½è¿‡é‡ï¼Œå¯¼è‡´tokenç§¯å‹ã€‚
- **èµ„æºåˆ©ç”¨ç‡ä½**ï¼šä¼ ç»Ÿè·¯ç”±ç­–ç•¥ï¼ˆå¦‚top-Kï¼‰ä»…åŸºäºtokenç‰¹å¾è¿›è¡Œä¸“å®¶é€‰æ‹©ï¼Œå¿½ç•¥è®¾å¤‡çš„å®æ—¶è®¡ç®—å’Œèƒ½é‡çŠ¶æ€ï¼Œé€ æˆèµ„æºæµªè´¹æˆ–ç“¶é¢ˆã€‚
- **ç³»ç»Ÿååé‡ä¸‹é™ä¸æ€§èƒ½é€€åŒ–**ï¼šç¼ºä¹å¯¹tokené˜Ÿåˆ—å’Œèƒ½é‡é˜Ÿåˆ—çš„é•¿æœŸç¨³å®šæ€§æ§åˆ¶ï¼Œå½±å“è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹ç²¾åº¦ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Stable-MoE** çš„æ–°å‹ **Lyapunov-based token routing framework**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†åˆ†å¸ƒå¼MoEä¸­çš„tokenè·¯ç”±ä¸è®¡ç®—é¢‘ç‡åˆ†é…å»ºæ¨¡ä¸ºä¸€ä¸ª**è”åˆä¼˜åŒ–é—®é¢˜**ï¼Œç›®æ ‡æ˜¯åœ¨æœ€å¤§åŒ–ç³»ç»Ÿååé‡çš„åŒæ—¶ä¿æŒ**gating consistency**ï¼ˆè·¯ç”±ä¸€è‡´æ€§ï¼‰ã€‚
- å¼•å…¥ **Lyapunov optimizationç†è®º**ï¼Œå°†åŸæœ¬éš¾ä»¥æ±‚è§£çš„é•¿æœŸéšæœºä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºæ¯ä¸ªæ—¶éš™å¯åœ¨çº¿å†³ç­–çš„å­é—®é¢˜ï¼Œæ— éœ€é¢„çŸ¥æœªæ¥çš„ç³»ç»ŸçŠ¶æ€ã€‚
- è®¾è®¡è™šæ‹Ÿé˜Ÿåˆ—æœºåˆ¶ï¼ˆtoken queue å’Œ energy queueï¼‰ï¼Œé€šè¿‡æœ€å°åŒ– **Lyapunov drift-plus-penaltyå‡½æ•°** æ¥ä¿è¯ç³»ç»Ÿçš„é•¿æœŸç¨³å®šæ€§å’Œèµ„æºé«˜æ•ˆåˆ©ç”¨ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **åŠ¨æ€é€‚åº”æ€§å¼º**ï¼šèƒ½å¤Ÿå®æ—¶å“åº”å¼‚æ„è¾¹ç¼˜è®¾å¤‡çš„è®¡ç®—èƒ½åŠ›å’Œèƒ½é‡çº¦æŸï¼Œé¿å…è¿‡è½½ã€‚
- **æ— éœ€å…ˆéªŒä¿¡æ¯**ï¼šåœ¨çº¿å†³ç­–ï¼Œé€‚ç”¨äºå®é™…éƒ¨ç½²ä¸­ä¸å¯é¢„æµ‹çš„tokenåˆ°è¾¾æ¨¡å¼ã€‚
- **å…¼é¡¾æ€§èƒ½ä¸ç¨³å®šæ€§**ï¼šä¸ä»…æå‡ç³»ç»Ÿååé‡ï¼Œè¿˜ç¡®ä¿tokenå’Œèƒ½é‡é˜Ÿåˆ—çš„é•¿æœŸç¨³å®šï¼Œé˜²æ­¢å´©æºƒæˆ–èµ„æºè€—å°½ã€‚
- **é€šç”¨æ€§å¼º**ï¼šæ¡†æ¶å¯æ‰©å±•è‡³å…¶ä»–èµ„æºå—é™çš„åˆ†å¸ƒå¼AIè®­ç»ƒåœºæ™¯ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **SVHN**ï¼ˆStreet View House Numbersï¼‰ï¼šåŒ…å«32Ã—32å½©è‰²æ•°å­—å›¾åƒï¼Œç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚
- **CIFAR-100**ï¼šåŒæ ·ä¸º32Ã—32å½©è‰²å›¾åƒï¼Œå…±100ç±»ï¼Œæ›´å…·æŒ‘æˆ˜æ€§ã€‚

### **å®éªŒè®¾ç½®**
- **è¾¹ç¼˜ç½‘ç»œé…ç½®**ï¼š
  - $ J = 10 $ ä¸ªå¼‚æ„è¾¹ç¼˜æœåŠ¡å™¨ï¼ˆedge serversï¼‰ï¼Œæ¯å°éƒ¨ç½²ä¸€ä¸ªexpertã€‚
  - æ—¶é—´æ§½ï¼ˆtime slotï¼‰é•¿åº¦ $ T = 1 $ ç§’ã€‚
  - å¹³å‡tokenåˆ°è¾¾ç‡ $ \lambda = 390 $ tokens/slotï¼ˆæœä»æ³Šæ¾åˆ†å¸ƒï¼‰ã€‚
  - CPUé¢‘ç‡ä¸Šé™ $ f_{\text{max}} = 3 $ GHzï¼Œè®¡ç®—å¤æ‚åº¦ $ c = 10^7 $ cycles/tokenã€‚
  - èƒ½é‡é¢„ç®— $ E^{\text{max}} \in [3J, 15J] $ï¼Œå¹³å‡å¯ç”¨èƒ½é‡ $ E^{\text{avg}} \in [1.5J, 9.5J] $ã€‚
  - åˆ‡æ¢ç”µå®¹ç³»æ•° $ \kappa = 2 \times 10^{-27} $ã€‚
- **æ¨¡å‹ç»“æ„**ï¼š
  - gating networkï¼šå‰é¦ˆç¥ç»ç½‘ç»œã€‚
  - expert networkï¼šå·ç§¯å±‚ï¼Œç”¨äºå›¾åƒåˆ†ç±»ã€‚
- **Top-Kè®¾ç½®**ï¼š$ K = 3 $ï¼Œå³æ¯ä¸ªtokenè¢«è·¯ç”±åˆ°3ä¸ªä¸“å®¶ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
- **ç³»ç»Ÿååé‡**ï¼ˆSystem Throughputï¼‰ï¼šå•ä½æ—¶é—´å†…å®Œæˆå¤„ç†çš„tokenæ•°é‡ã€‚
- **æµ‹è¯•å‡†ç¡®ç‡**ï¼ˆTest Accuracyï¼‰ï¼šæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡ã€‚
- **é˜Ÿåˆ—ç¨³å®šæ€§**ï¼štoken queue å’Œ energy queue çš„ backlog å˜åŒ–è¶‹åŠ¿ã€‚
- **gating consistency**ï¼šä¼˜åŒ–åçš„è·¯ç”±ä¸åŸå§‹gating scoreçš„ä¸€è‡´æ€§ç¨‹åº¦ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
1. **Strategy Aï¼ˆRandom Routingï¼‰**ï¼šéšæœºå‡åŒ€åœ°å°†tokenåˆ†é…ç»™æ‰€æœ‰expertã€‚
2. **Strategy Bï¼ˆTraditional Top-K Routingï¼‰**ï¼šæ ¹æ®gating scoreé€‰æ‹©top-3ä¸“å®¶ï¼Œä¸è€ƒè™‘èµ„æºçŠ¶æ€ã€‚
3. **Strategy Cï¼ˆQueue-aware Routingï¼‰**ï¼šä¼˜å…ˆè·¯ç”±åˆ°tokené˜Ÿåˆ—æœ€çŸ­çš„expertã€‚
4. **Strategy Dï¼ˆEnergy-aware Routingï¼‰**ï¼šä¼˜å…ˆè·¯ç”±åˆ°energy queue backlogæœ€å°çš„expertã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- åœ¨ **SVHN** æ•°æ®é›†ä¸Šï¼ŒStable-MoE è¾¾åˆ°çº¦ **400,000 tokens** çš„ç´¯è®¡ååé‡ï¼ˆ1000è½®åï¼‰ï¼Œæ˜¾è‘—é«˜äºæ‰€æœ‰åŸºçº¿ã€‚
- åœ¨ **CIFAR-100** ä¸Šä¹Ÿè¡¨ç°å‡ºæŒç»­å¢é•¿çš„é«˜ååä¼˜åŠ¿ã€‚
- æµ‹è¯•å‡†ç¡®ç‡æ–¹é¢ï¼š
  - **SVHN**ï¼šStable-MoE å¿«é€Ÿæ”¶æ•›è‡³ **80%** å‡†ç¡®ç‡ï¼Œè¿œè¶…åŸºçº¿ã€‚
  - **CIFAR-100**ï¼šåŒæ ·å–å¾—æœ€é«˜å‡†ç¡®ç‡ï¼Œä¼˜äºæ‰€æœ‰å¯¹æ¯”æ–¹æ³•ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
| æŒ‡æ ‡ | Stable-MoE vs. Baselines |
|------|--------------------------|
| **ç³»ç»Ÿååé‡å¢ç›Š** | ç›¸æ¯”æœ€ä¼˜åŸºçº¿ï¼ˆStrategy Dï¼‰æå‡è‡³å°‘ **40%** |
| **æµ‹è¯•å‡†ç¡®ç‡å¢ç›Š** | æå‡çº¦ **5%** æˆ–ä»¥ä¸Š |
| **é˜Ÿåˆ—ç¨³å®šæ€§** | tokenå’Œenergyé˜Ÿåˆ—å¿«é€Ÿç¨³å®šï¼Œæ— æŒç»­å¢é•¿ç°è±¡ |

> å›¾3æ˜¾ç¤ºï¼ŒStable-MoEçš„ååé‡æ›²çº¿å§‹ç»ˆé¢†å…ˆä¸”å·®è·éšæ—¶é—´æ‰©å¤§ï¼›å›¾4è¡¨æ˜å…¶å‡†ç¡®ç‡æ”¶æ•›æ›´å¿«ã€æ›´ç¨³å®šã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆæ–‡ä¸­æœªæ˜ç¡®æä¾›ï¼‰**
- æ–‡ä¸­æœªå•ç‹¬åˆ—å‡ºæ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œä½†ä»è®¾è®¡é€»è¾‘å¯çŸ¥ï¼š
  - è‹¥ç§»é™¤Lyapunov drifté¡¹ï¼Œåˆ™é˜Ÿåˆ—å¯èƒ½ä¸ç¨³å®šï¼›
  - è‹¥ç§»é™¤gating consistencyæ­£åˆ™é¡¹ï¼Œåˆ™å¯èƒ½åç¦»åŸå§‹MoEè¯­ä¹‰ï¼Œå½±å“æ¨¡å‹è¡¨ç°ï¼›
  - å‚æ•° $ V $ æ§åˆ¶ååé‡ä¸ç¨³å®šæ€§çš„æƒè¡¡ï¼Œå®éªŒä¸­é€šè¿‡è°ƒå‚å®ç°æœ€ä½³å¹³è¡¡ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Stable-MoEæœ‰æ•ˆè§£å†³äº†è¾¹ç¼˜ç½‘ç»œä¸­MoEè®­ç»ƒçš„token backlogé—®é¢˜**ï¼Œå®ç°äº†é«˜ååã€ä½å»¶è¿Ÿçš„ç¨³å®šè®­ç»ƒã€‚
2. **åŸºäºLyapunovçš„åœ¨çº¿ä¼˜åŒ–æ¡†æ¶èƒ½å¤Ÿåœ¨æœªçŸ¥æœªæ¥çŠ¶æ€çš„æƒ…å†µä¸‹åšå‡ºè¿‘ä¼˜å†³ç­–**ï¼Œé€‚åˆçœŸå®è¾¹ç¼˜ç¯å¢ƒã€‚
3. **ç»¼åˆè€ƒè™‘tokené˜Ÿåˆ—å’Œenergyé˜Ÿåˆ—çš„åŒè™šæ‹Ÿé˜Ÿåˆ—æœºåˆ¶** æ˜¾è‘—æå‡äº†èµ„æºåˆ©ç”¨ç‡å’Œç³»ç»Ÿé²æ£’æ€§ã€‚
4. **åœ¨SVHNå’ŒCIFAR-100ä¸Šçš„å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨ååé‡å’Œå‡†ç¡®ç‡ä¸Šçš„åŒé‡ä¼˜åŠ¿**ï¼Œè¯æ˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–æ··åˆæ•´æ•°è§„åˆ’æ±‚è§£å™¨**ï¼ˆå¦‚branch-and-boundï¼‰è§£å†³æ¯æ—¶éš™çš„ä¼˜åŒ–é—®é¢˜ï¼Œå¯èƒ½å¸¦æ¥è¾ƒé«˜è®¡ç®—å¼€é”€ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡expertç³»ç»Ÿä¸­ã€‚
- å½“å‰å‡è®¾ä¸º**one-to-one expert-serveræ˜ å°„**ï¼Œæœªè€ƒè™‘å¤šexpertå…±äº«åŒä¸€è®¾å¤‡çš„æƒ…å†µã€‚
- å®éªŒåŸºäºæ¨¡æ‹Ÿç¯å¢ƒï¼Œå°šæœªåœ¨çœŸå®æ— çº¿è¾¹ç¼˜ç½‘ç»œä¸­éƒ¨ç½²éªŒè¯é€šä¿¡å»¶è¿Ÿã€å¸¦å®½æ³¢åŠ¨ç­‰å½±å“ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢è½»é‡åŒ–æ±‚è§£ç­–ç•¥ï¼ˆå¦‚å¯å‘å¼ç®—æ³•æˆ–ç¥ç»æ±‚è§£å™¨ï¼‰ä»¥é™ä½åœ¨çº¿å†³ç­–å»¶è¿Ÿã€‚
- æ‰©å±•è‡³æ”¯æŒ **multi-token batching** å’Œ **dynamic expert scaling** çš„åœºæ™¯ã€‚
- ç»“åˆæ— çº¿ä¿¡é“è´¨é‡ï¼ˆchannel stateï¼‰è¿›ä¸€æ­¥ä¼˜åŒ–ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚
- å°†æ¡†æ¶æ¨å¹¿è‡³è”é‚¦å­¦ä¹ æˆ–å…¶ä»–åˆ†å¸ƒå¼AIæ¶æ„ä¸­ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **Stable-MoEé€šè¿‡Lyapunovä¼˜åŒ–å®ç°äº†èµ„æºæ„ŸçŸ¥çš„åŠ¨æ€tokenè·¯ç”±ï¼Œåœ¨ä¿éšœè¾¹ç¼˜è®¾å¤‡é˜Ÿåˆ—ç¨³å®šçš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†distributed MoEè®­ç»ƒçš„ååé‡å’Œæ¨¡å‹å‡†ç¡®æ€§ï¼Œä¸ºè¾¹ç¼˜æ™ºèƒ½çš„å¤§è§„æ¨¡éƒ¨ç½²æä¾›äº†æ–°æ€è·¯ã€‚**

</details>

---

### 2. [Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE](https://arxiv.org/abs/2512.07710)

**Authors**: Anxiang Zeng, Haibo Zhang, Hailing Zhang, Kaixiang Mo, Liang Yao, Ling Hu, Long Zhang, Shuman Liu, Shuyi Xie, Yanshi Li, Yizhang Chen, Yuepeng Sheng, Yuwei Huang, Zhaochen Xu, Zhiqiang Zhou, Ziqin Liew  
**Category**: cs.AI  
**Published**: 2025-12-09  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2512.07710v1  

#### Abstract
We present CompassMax-V3-Thinking, a hundred-billion-scale MoE reasoning model trained with a new RL framework built on one principle: each prompt must matter. Scaling RL to this size exposes critical inefficiencies-zero-variance prompts that waste rollouts, unstable importance sampling over long ho...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹åœ¨**ç™¾äº¿å‚æ•°è§„æ¨¡çš„ Mixture-of-Experts (MoE)** æ¨¡å‹ä¸Šè¿›è¡Œé•¿é“¾æ¨ç†ï¼ˆLongCoTï¼‰å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰æ—¶é¢ä¸´çš„å¤šä¸ªç³»ç»Ÿæ€§å’Œç®—æ³•æ€§æŒ‘æˆ˜ï¼Œä¸»è¦åŒ…æ‹¬ï¼š

- **Zero-Variance Prompts (ZVP)**ï¼šå¤§é‡æç¤ºï¼ˆpromptsï¼‰åœ¨è®­ç»ƒä¸­äº§ç”Ÿç›¸åŒå¥–åŠ±ï¼Œå¯¼è‡´æ— æœ‰æ•ˆæ¢¯åº¦ä¿¡å·ï¼Œæµªè´¹ rollout èµ„æºã€‚
- **Importance Sampling ä¸ç¨³å®š**ï¼šåœ¨ token å’Œ sequence å±‚é¢çš„é‡è¦æ€§é‡‡æ ·åœ¨é•¿åºåˆ—ä¸‹æ˜“å´©æºƒã€‚
- **Train-Infer Mismatch**ï¼šè®­ç»ƒä¸æ¨ç†é˜¶æ®µ MoE è·¯ç”±å™¨ï¼ˆrouterï¼‰è¡Œä¸ºä¸ä¸€è‡´ï¼Œå¼•å‘æ•°å€¼è¯¯å·®å’Œè®­ç»ƒä¸ç¨³å®šã€‚
- **Advantage Inversion**ï¼šæ ‡å‡† Bradley-Terry (BT) å¥–åŠ±æ¨¡å‹åœ¨å‡å€¼é™„è¿‘å‡ºç°ä¼˜åŠ¿åè½¬ï¼ˆadvantage flippingï¼‰ï¼Œè¯¯å¯¼ä¼˜åŒ–æ–¹å‘ã€‚
- **ç³»ç»Ÿç“¶é¢ˆ**ï¼šrollout é˜¶æ®µå»¶è¿Ÿé«˜ã€GPU åˆ©ç”¨ç‡ä½ï¼Œé™åˆ¶ç«¯åˆ°ç«¯è®­ç»ƒååã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

ä½œè€…æå‡ºä¸€ä¸ª**ç»Ÿä¸€çš„ RL æ¡†æ¶**ï¼Œä»¥â€œæ¯ä¸ª prompt éƒ½åº”æä¾›æœ‰æ•ˆå­¦ä¹ ä¿¡å·â€ä¸ºæ ¸å¿ƒåŸåˆ™ï¼Œé›†æˆå¤šé¡¹ç®—æ³•ä¸ç³»ç»Ÿçº§åˆ›æ–°ï¼š

#### ï¼ˆ1ï¼‰Multi-Stage Zero-Variance Eliminationï¼ˆå¤šé˜¶æ®µé›¶æ–¹å·®æ¶ˆé™¤ï¼‰
- **ç›®æ ‡**ï¼šè¯†åˆ«å¹¶å¤„ç†å¯¼è‡´ç»„å†…å¥–åŠ±æ–¹å·®ä¸ºé›¶çš„ promptsã€‚
- **æ–¹æ³•**ï¼š
  - æ‰©å±•æ¢ç´¢ç©ºé—´ï¼ˆå¢å¤§ sampling size $N$ï¼‰ï¼›
  - å¼•å…¥é•¿åº¦æƒ©ç½šã€é‡å¤æƒ©ç½šç­‰é‡å¡‘å¥–åŠ±ï¼›
  - ä½¿ç”¨ RL-ZVP æŠ€æœ¯æ³¨å…¥éšæœºæ€§ä»¥ç¨³å®šä¼˜åŠ¿ä¼°è®¡ã€‚
- **ä¼˜åŠ¿**ï¼šå‡å°‘çº¦ 17% çš„ ZVPï¼Œæ˜¾è‘—æå‡æ”¶æ•›é€Ÿåº¦ä¸ç¨³å®šæ€§ã€‚

#### ï¼ˆ2ï¼‰ESPO: Entropy Importance Sampling Policy Optimization
- **ç›®æ ‡**ï¼šè§£å†³ GRPO ä¸­ token-level é‡è¦æ€§é‡‡æ ·ä¸å‡è¡¡é—®é¢˜ã€‚
- **æ–¹æ³•**ï¼š
  - å°†åºåˆ—æŒ‰ç†µå€¼åˆ†ç»„ï¼Œåœ¨ token-group çº§åˆ«è¿›è¡Œç­–ç•¥ä¼˜åŒ–ï¼›
  - å¼•å…¥ entropy-adaptive clipping åŠ¨æ€è°ƒæ•´è£å‰ªé˜ˆå€¼ï¼›
  - æ”¹è¿›ç›®æ ‡å‡½æ•°ä»¥å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ã€‚
- **ä¼˜åŠ¿**ï¼šç›¸æ¯” GRPO çš„å‡åŒ€å¤„ç†ï¼ŒESPO æ›´å¥½åœ°ä¿ç•™é«˜ç†µåŒºåŸŸçš„å­¦ä¹ ä¿¡å·ï¼Œæå‡é•¿åºåˆ—ä¸‹çš„å­¦ä¹ ç¨³å®šæ€§ã€‚

#### ï¼ˆ3ï¼‰Router Replay ä¸ Advantage Stabilization
- **Router Replay**ï¼š
  - åœ¨ vLLM rollout é˜¶æ®µè®°å½• MoE è·¯ç”±å†³ç­–ï¼›
  - åœ¨ Megatron è®­ç»ƒé˜¶æ®µé‡æ”¾è¿™äº›è·¯ç”±é€‰æ‹©ï¼Œå¯¹é½è®­ç»ƒä¸æ¨ç†è¡Œä¸ºã€‚
  - **æ•ˆæœ**ï¼šlog-prob å·®å¼‚ä» $10^{-3}$ é™è‡³ $10^{-4}$ï¼Œæœ‰æ•ˆé˜²æ­¢ RL å´©æºƒã€‚
- **Generative Reward Model (GenRM)**ï¼š
  - ä½¿ç”¨å…·å¤‡ CoT æ¨ç†èƒ½åŠ›çš„ GenRM æ›¿ä»£ä¼ ç»Ÿ ORMï¼›
  - å¼•å…¥ä¸‰ç±»åˆ¤æ–­ï¼ˆbetter/tie/worseï¼‰ï¼Œé¿å… near-mean ä¼˜åŠ¿åè½¬ã€‚
  - **æ•ˆæœ**ï¼šä¸ GPT-4 åˆ¤æ–­ä¸€è‡´æ€§è¾¾ 84.3%ï¼Œè¿œè¶…åŸºçº¿ ORM çš„ 74.1%ã€‚

#### ï¼ˆ4ï¼‰High-Throughput Rollout System
- **FP8-Quantized Rollout**ï¼šä½¿ç”¨ FP8 ç²¾åº¦åŠ é€Ÿæ¨ç†ï¼Œé™ä½ rollout å»¶è¿Ÿã€‚
- **Length-Aware Scheduling**ï¼šåŸºäºé¢„æµ‹ç”Ÿæˆé•¿åº¦åŠ¨æ€è´Ÿè½½å‡è¡¡ï¼Œå‡å°‘ worker åŒæ­¥ç­‰å¾…ã€‚
- **Overlapped Reward Computation**ï¼šrollout å®Œæˆå°±ç«‹å³è®¡ç®— rewardï¼Œå®ç°æµæ°´çº¿å¹¶è¡Œã€‚
- **Multi-Detokenization Parallelism**ï¼šå¹¶è¡ŒåŒ– detokenization è¿‡ç¨‹ï¼Œç¼“è§£ CPU ç“¶é¢ˆã€‚
- **æ€»ä½“æ”¶ç›Š**ï¼šç«¯åˆ°ç«¯è®­ç»ƒæ—¶é—´å‡å°‘è¿‘ 20%ï¼Œç³»ç»Ÿååæå‡ 1.66Ã—ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **å†…éƒ¨æ„å»ºå¤šé¢†åŸŸæ•°æ®é›†**ï¼š
  - **E-commerce**ï¼šè¦†ç›–ä¸œå—äºšä¸ƒå›½è¯­è¨€ï¼ˆen, tw, id, my, pt, th, viï¼‰ï¼Œä»»åŠ¡åŒ…æ‹¬å•†å“æ¨èã€å”®åé—®é¢˜ã€å±æ€§æå–ã€æ ‡é¢˜ä¼˜åŒ–ç­‰ã€‚
  - **Multilingual General Tasks**ï¼šæ¶µç›–çŸ¥è¯†ç†è§£ã€åˆ›æ„ç”Ÿæˆã€æ•°å­¦ã€ä»£ç ã€å®‰å…¨ç­‰ã€‚
- **å…¬å¼€åŸºå‡†æµ‹è¯•é›†**ï¼š
  - **ARC èƒ½åŠ›è¯„ä¼°å¥—ä»¶**ï¼šåŒ…æ‹¬ MMLU-Reduxã€GPQA-Diamondã€AIME/HMMTï¼ˆæ•°å­¦ï¼‰ã€HumanEval/MBPPï¼ˆä»£ç ï¼‰ã€BFCLï¼ˆAgent ä»»åŠ¡ï¼‰ã€IFevalï¼ˆæŒ‡ä»¤éµå¾ªï¼‰ç­‰ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šCompassMax-V3-Thinkingï¼Œç™¾äº¿å‚æ•° MoE æ¶æ„ã€‚
- **è®­ç»ƒæµç¨‹ä¸‰é˜¶æ®µ**ï¼š
  1. **Cold-Start SFT**ï¼šåŸºäº DeepSeek-R1 è’¸é¦ Long-CoT æ•°æ®ï¼›
  2. **Model Merge**ï¼šèåˆé€šç”¨ Long-CoT æ¨¡å‹ä¸ç”µå•†ä¸“ç”¨æ¨¡å‹ï¼ˆé‡‡ç”¨ TIES æ–¹æ³•ï¼‰ï¼›
  3. **Large-Scale RL**ï¼šä¸¤é˜¶æ®µ RL å¾®è°ƒï¼ˆå…ˆ code/math/IFï¼Œåæ‰©å±•è‡³ e-commerce/tool-use/general QAï¼‰ã€‚
- **è¯„ä¼°æ–¹å¼**ï¼š
  - å†…éƒ¨ä»»åŠ¡ä½¿ç”¨è‡ªåŠ¨åŒ– verifier æˆ– GPT-4.1 ä½œä¸ºè£åˆ¤ï¼›
  - å…¬å¼€åŸºå‡†ä½¿ç”¨æ ‡å‡† metricï¼ˆå¦‚ Pass@1, EM, Accï¼‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **æ¨¡å‹åŸºçº¿**ï¼š
  - CompassMax-V3
  - GPT-5-Thinking(medium)
  - DeepSeek-R1
  - Qwen3-235B-A22B(think)
  - Gemini-2.5-pro
  - GLM-4.5
- **ç®—æ³•åŸºçº¿**ï¼š
  - GRPOï¼ˆGroup Relative Policy Optimizationï¼‰
  - ORMï¼ˆOrdinary Reward Modelï¼‰
  - BF16/FP16 æ¨ç†ç²¾åº¦æ–¹æ¡ˆ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰å†…éƒ¨ç”µå•†åŸºå‡†ï¼ˆTable 2ï¼‰
| æŒ‡æ ‡ | CompassMax-V3-Thinking |
|------|------------------------|
| **Ecom QA å¹³å‡å¾—åˆ†** | 92.17 |
| **After-Sales Issue** | 98.48 |
| **Product Recommendation** | **94.58** |
| **Overall Macro Average** | **85.79** |

> æ˜¾è‘—ä¼˜äº CompassMax-V3ï¼ˆ74.65ï¼‰åŠå…¶ä»–é—­æºæ¨¡å‹ï¼Œå°¤å…¶åœ¨ç”Ÿäº§å…³é”®ä»»åŠ¡ä¸Šè¡¨ç°ç¨³å¥ã€‚

#### ï¼ˆ2ï¼‰å¤šè¯­è¨€è¯„ä¼°ï¼ˆTable 3ï¼‰
| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **SEA 7è¯­è¨€å¹³å‡åˆ†** | **86.41** |
| è‹±æ–‡ï¼ˆenï¼‰ | 88.07 |
| å°å°¼è¯­ï¼ˆidï¼‰ | 87.89 |
| æ³°è¯­ï¼ˆthï¼‰ | 86.04 |
| è‘¡è„ç‰™è¯­ï¼ˆptï¼‰ | 86.84 |

> è¡¨ç°å‡ºé«˜åº¦è·¨å¸‚åœºç¨³å®šæ€§ï¼Œç¼©å°äº†ä¸ GPT-4o/GPT-5 çš„å·®è·ï¼Œä¸”åœ¨ä½èµ„æºè¯­è¨€ä¸Šä¿æŒä¸€è‡´æ€§ã€‚

#### ï¼ˆ3ï¼‰é€šç”¨èƒ½åŠ›è¯„ä¼°ï¼ˆTable 4ï¼‰
| é¢†åŸŸ | CompassMax-V3-Thinking |
|------|-------------------------|
| Knowledge & Comprehension | 62.07 |
| Creative Generation | **77.75** |
| Reasoning | **74.54** |
| Code | **76.83** |
| Safety | **88.86** |
| **Overall Average** | **76.01** |

> ç›¸æ¯”åŸå§‹ CompassMax-V3ï¼ˆ64.49ï¼‰æå‡è¶…è¿‡ 11 ä¸ªç™¾åˆ†ç‚¹ï¼Œå°¤å…¶åœ¨å®‰å…¨æ€§ä¸ä»£ç ç”Ÿæˆæ–¹é¢é¢†å…ˆã€‚

#### ï¼ˆ4ï¼‰å¼€æº ARC åŸºå‡†ï¼ˆTable 5ï¼‰
| Benchmark | CompassMax-V3-Thinking |
|----------|------------------------|
| **HumanEval (Pass@1)** | **98.17** |
| MBPP (Pass@1) | 73.54 |
| AIME24 (Pass@1) | 83.30 |
| AIME25 (Pass@1) | 80.00 |
| HMMT (Pass@1) | 46.70 |
| IFeval (prompt strict) | 85.40 |
| GPQA-Diamond (EM) | 68.69 |
| BFCL_AST_NON_LIVE | 83.73 |

> åœ¨ä»£ç ç”Ÿæˆæ¥è¿‘å®Œç¾ï¼ˆHumanEval 98.17ï¼‰ï¼Œæ•°å­¦ä¸æ¨ç†æ˜¾è‘—ä¼˜äºå¤šæ•°åŸºçº¿ï¼Œagent å¤šè½®äº¤äº’ä»æœ‰æå‡ç©ºé—´ï¼ˆBFCL_MULTI_TURN_LIVE: 19.50ï¼‰ã€‚

### ä¸åŸºçº¿å¯¹æ¯”ç»“æœ
- åœ¨æ‰€æœ‰å†…éƒ¨è¯„æµ‹ä¸­å‡è¶…è¶Š GPT-5-Thinking(medium)ã€DeepSeek-R1ã€Qwen3-235B-A22Bã€‚
- åœ¨ HumanEval ä¸Šè¶…è¿‡ DeepSeek-R1ï¼ˆ96.95 â†’ 98.17ï¼‰ï¼Œåœ¨ Safety ä¸Šè¶…è¶Š GPT-5ï¼ˆ88.57 vs 88.86ï¼‰ã€‚
- å¤šè¯­è¨€å¹³å‡åˆ†ï¼ˆ86.41ï¼‰æ¥è¿‘ GPT-5-Thinking(medium) çš„ 86.64ï¼Œä¼˜äºå…¶ä»–å¼€æºæ¨¡å‹ã€‚

### æ¶ˆèå®éªŒï¼ˆFigure 3ï¼‰
- **Zero-Variance Rate vs N**ï¼šéšç€ sampling size $N$ å¢å¤§ï¼ŒZVP ç‡ä¸‹é™ï¼ŒPass@n ä¸Šå‡ï¼›
- **Advantage per Compute**ï¼šæœ€ä¼˜ $N$ å¯ä½¿å•ä½ç®—åŠ›è·å–çš„ä¼˜åŠ¿æœ€å¤§åŒ–ï¼›
- **ç³»ç»Ÿä¼˜åŒ–å åŠ æ•ˆæœï¼ˆTable 1ï¼‰**ï¼š
  - +FP8 rollout â†’ 1.52Ã— åŠ é€Ÿ
  - +Length-based load balancing â†’ 1.66Ã— æ•´ä½“æé€Ÿ

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **â€œæ¯ä¸ª prompt éƒ½é‡è¦â€æ˜¯å¯å®ç°çš„è®¾è®¡åŸåˆ™**ï¼šé€šè¿‡ ZVP æ¶ˆé™¤æœºåˆ¶ï¼Œå¯ä»¥æ˜¾è‘—å‡å°‘æ— æ•ˆ rolloutï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚
2. **ESPO æ¯” GRPO æ›´é€‚åˆé•¿åºåˆ— MoE æ¨¡å‹**ï¼štoken-group çº§åˆ«çš„ entropy-aware é‡è¦æ€§é‡‡æ ·æå‡äº†å­¦ä¹ ç¨³å®šæ€§ã€‚
3. **Router Replay æ˜¯ç¨³å®š MoE RL çš„å…³é”®**ï¼šè®­ç»ƒä¸æ¨ç†è·¯ç”±å¯¹é½èƒ½ä»æ ¹æœ¬ä¸Šç¼“è§£ train-infer mismatchã€‚
4. **GenRM + ä¸‰ç±»æ ‡ç­¾è®¾è®¡å¯é˜²æ­¢ advantage inversion**ï¼šç»“æ„åŒ–æ¨ç†å¥–åŠ±æ¨¡å‹æ›´å¯é ï¼Œå°¤å…¶åœ¨è´¨é‡ç›¸è¿‘æ ·æœ¬ä¸­ã€‚
5. **ç³»ç»Ÿçº§ä¼˜åŒ–ä¸å¯å¿½è§†**ï¼šFP8ã€length-aware schedulingã€reward overlap å…±åŒè´¡çŒ®è¿‘ 70% çš„ç«¯åˆ°ç«¯åŠ é€Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¤šè½® Agent æ€§èƒ½ä»ä¸è¶³**ï¼šåœ¨ BFCL_MULTI_TURN_LIVE ä¸Šä»…å¾— 19.50ï¼Œè¡¨æ˜å¤æ‚å·¥å…·é“¾è§„åˆ’èƒ½åŠ›æœ‰å¾…åŠ å¼ºã€‚
- **ä¾èµ–é«˜è´¨é‡å‚è€ƒç­”æ¡ˆ**ï¼šGenRM åœ¨æ—  reference åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›æœªå……åˆ†éªŒè¯ã€‚
- **ç¡¬ä»¶ä¾èµ–è¾ƒå¼º**ï¼šFP8 rollout ä¾èµ– H100 ç­‰é«˜ç«¯ GPUï¼Œå¯èƒ½é™åˆ¶éƒ¨ç½²çµæ´»æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±• GenRM è‡³ fully online preference learningï¼›
- æ¢ç´¢ asynchronous RL ä¸æ›´ç»†ç²’åº¦çš„ entropy groupingï¼›
- å¼•å…¥ memory-augmented routing ä»¥è¿›ä¸€æ­¥æå‡ MoE ç¨³å®šæ€§ï¼›
- æ„å»ºæ›´å¤§è§„æ¨¡çš„ multilingual agent benchmarkã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é€šè¿‡ç®—æ³•ä¸ç³»ç»Ÿçš„ååŒåˆ›æ–°ï¼Œé¦–æ¬¡å®ç°äº†**ç™¾äº¿å‚æ•° MoE æ¨¡å‹ä¸Šçš„é«˜æ•ˆã€ç¨³å®š LongCoT å¼ºåŒ–å­¦ä¹ **ï¼Œæå‡ºâ€œæ¯ä¸ª prompt éƒ½é‡è¦â€çš„ç†å¿µï¼Œå¹¶é€šè¿‡ ESPOã€Router Replayã€GenRM å’Œ FP8 rollout ç­‰æŠ€æœ¯ç»„åˆï¼Œåœ¨ç”µå•†ã€å¤šè¯­è¨€ã€ä»£ç ã€æ•°å­¦ç­‰å¤šä¸ªç»´åº¦è¾¾åˆ° SOTA è¡¨ç°ï¼Œä¸ºå¤§è§„æ¨¡æ¨ç†æ¨¡å‹è®­ç»ƒæä¾›äº†å¯å¤ç”¨çš„å·¥ç¨‹ä¸ç†è®ºæ¡†æ¶ã€‚

</details>

---

### 3. [Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning](https://arxiv.org/abs/2512.07461)

**Authors**: Tong Wu, Yang Liu, Jun Bai, Zixia Jia, Shuyi Zhang, Ziyong Lin, Yanting Wang, Song-Chun Zhu, Zilong Zheng  
**Category**: cs.CL  
**Published**: 2025-12-09  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2512.07461v1  

#### Abstract
We introduce Native Parallel Reasoner (NPR), a teacher-free framework that enables Large Language Models (LLMs) to self-evolve genuine parallel reasoning capabilities. NPR transforms the model from sequential emulation to native parallel cognition through three key innovations: 1) a self-distilled p...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ **Large Language Models (LLMs)** åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ä»ä¾èµ–äº**é¡ºåºé“¾å¼æ€ç»´ï¼ˆChain-of-Thought, CoTï¼‰**ï¼Œå­˜åœ¨ä»¥ä¸‹ä¸‰å¤§ç“¶é¢ˆï¼š
1. **ç®—æ³•ä¸æ¶æ„ä¸å…¼å®¹**ï¼šç°æœ‰æ¨ç†å¼•æ“ï¼ˆå¦‚ SGLangï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç®—æ³•éš¾ä»¥æ”¯æŒçœŸæ­£çš„å¹¶è¡Œåˆ†æ”¯ç”Ÿæˆä¸èšåˆã€‚
2. **ä½æ•ˆçš„æ‰‹å·¥å¹¶è¡ŒåŒ–**ï¼šå·²æœ‰æ–¹æ³•ï¼ˆå¦‚ Multiverseï¼‰ä¾èµ–ç‹¬ç«‹é‡‡æ ·è¿›è¡Œä»»åŠ¡åˆ†è§£ï¼Œæ— æ³•å…±äº« Key-Value (KV) ç¼“å­˜ï¼Œå¯¼è‡´å†—ä½™è®¡ç®—å’Œçº¿æ€§å»¶è¿Ÿå¢é•¿ï¼ˆO(N)ï¼‰ï¼Œæ•ˆç‡ä½ä¸‹ã€‚
3. **ä¾èµ–ç›‘ç£è’¸é¦**ï¼šå¤šæ•°å¹¶è¡Œæ¨ç†æ¡†æ¶ï¼ˆå¦‚ Multiverseï¼‰ä¾èµ–æ›´å¼ºæ•™å¸ˆæ¨¡å‹ç”Ÿæˆçš„è½¨è¿¹æ•°æ®ï¼Œé™åˆ¶äº†å­¦ç”Ÿæ¨¡å‹æ¢ç´¢æ–°é¢–ã€å†…åœ¨çš„å¹¶è¡Œç­–ç•¥çš„èƒ½åŠ›ï¼Œå½¢æˆâ€œæ™ºèƒ½å¤©èŠ±æ¿â€ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **Native Parallel Reasoner (NPR)**ï¼Œä¸€ä¸ªæ— éœ€å¤–éƒ¨æ•™å¸ˆã€å®Œå…¨è‡ªæ¼”åŒ–çš„å¹¶è¡Œæ¨ç†æ¡†æ¶ï¼Œé€šè¿‡ä¸‰ä¸ªé˜¶æ®µå®ç°ä»é¡ºåºæ¨¡æ‹Ÿåˆ°åŸç”Ÿå¹¶è¡Œè®¤çŸ¥çš„è½¬å˜ï¼š

#### åˆ›æ–°ç‚¹ä¸€ï¼šè‡ªè’¸é¦æ¸è¿›è®­ç»ƒèŒƒå¼ï¼ˆSelf-Distilled Progressive Trainingï¼‰
- **Stage 1ï¼ˆæ ¼å¼å¼•å¯¼ RLï¼‰**ï¼šä½¿ç”¨ **DAPO** ç®—æ³•å¯¹åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ Qwen3-4B-Instructï¼‰è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä»…é€šè¿‡æ ¼å¼å¥–åŠ±ï¼ˆæ˜¯å¦ç¬¦åˆ `<plan>/<step>/<takeaway>` ç»“æ„ï¼‰å’Œç­”æ¡ˆæ­£ç¡®æ€§å¥–åŠ±ï¼Œè¯±å¯¼æ¨¡å‹è‡ªå‘ç”Ÿæˆç»“æ„åŒ–å¹¶è¡Œè¾“å‡ºï¼Œå¾—åˆ° **NPR-ZERO**ã€‚
- **Stage 2ï¼ˆæ‹’ç»é‡‡æ · + å¹¶è¡Œé¢„çƒ­ï¼‰**ï¼šå¯¹ NPR-ZERO è¿›è¡Œå¤šæ¬¡é‡‡æ ·ï¼Œé€šè¿‡ **rejection sampling** ç­›é€‰å‡ºæ ¼å¼æ­£ç¡®ä¸”ç­”æ¡ˆæ­£ç¡®çš„é«˜è´¨é‡è½¨è¿¹ï¼Œæ„å»ºè‡ªè’¸é¦æ•°æ®é›†ï¼›éšååœ¨è¿™äº›æ•°æ®ä¸Šè¿›è¡Œ **Parallel SFT**ï¼Œå¼•å…¥ä¸¥æ ¼çš„å¹¶è¡Œæ³¨æ„åŠ›æ©ç ï¼ˆParallel Attention Maskï¼‰å’Œä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰ï¼Œä½¿æ¨¡å‹è¡Œä¸ºçœŸæ­£è½¬å˜ä¸ºåŸç”Ÿå¹¶è¡Œæ‰§è¡Œã€‚
- **Stage 3ï¼ˆåŸç”Ÿå¹¶è¡Œ RLï¼‰**ï¼šåŸºäº NPR-BETA æ¨¡å‹ï¼Œä½¿ç”¨æ–°æå‡ºçš„ **PAPOï¼ˆParallel-Aware Policy Optimizationï¼‰** ç®—æ³•ï¼Œåœ¨çœŸå®å¹¶è¡Œå›¾ç»“æ„ä¸­ä¼˜åŒ–åˆ†æ”¯ç­–ç•¥ï¼Œè®©æ¨¡å‹é€šè¿‡è¯•é”™å­¦ä¹ è‡ªé€‚åº”çš„ä»»åŠ¡åˆ†è§£èƒ½åŠ›ã€‚

#### åˆ›æ–°ç‚¹äºŒï¼šPAPO å¼ºåŒ–å­¦ä¹ ç®—æ³•
- é’ˆå¯¹å¹¶è¡Œè§£ç ç‰¹æ€§è®¾è®¡ï¼Œç›´æ¥åœ¨å¹¶è¡Œæ‰§è¡Œå›¾ä¸­ä¼˜åŒ–ç­–ç•¥ã€‚
- æ”¹è¿›æ ‡å‡† PPOï¼š
  - ä½¿ç”¨ **batch-level advantage normalization** æ›¿ä»£ group-levelï¼Œé¿å…å› æ ¼å¼è¿‡æ»¤å¯¼è‡´æ–¹å·®åç¼©ã€‚
  - **ä¿ç•™ç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚ `<step>`ï¼‰ä¸Šçš„æ¢¯åº¦**ï¼Œé˜²æ­¢ç»“æ„å´©æºƒã€‚
  - ç§»é™¤é‡è¦æ€§é‡‡æ ·ï¼ˆimportance samplingï¼‰ï¼Œé‡‡ç”¨ä¸¥æ ¼ on-policy æ›´æ–°ä»¥æå‡ç¨³å®šæ€§ã€‚

#### åˆ›æ–°ç‚¹ä¸‰ï¼šNPR Engineï¼ˆå·¥ç¨‹çº§å¢å¼ºï¼‰
ä¸ºæ”¯æŒå¤§è§„æ¨¡ç¨³å®šå¹¶è¡Œ RL è®­ç»ƒï¼Œé‡æ„äº†åº•å±‚æ¨ç†å¼•æ“ï¼ˆåŸºäº SGLangï¼‰ï¼Œè§£å†³äº†å¤šä¸ªå…³é”®é—®é¢˜ï¼š
- **KV-cache å†…å­˜æ³„æ¼**ï¼šå¼•å…¥é¢„ç®—æ„ŸçŸ¥çš„æ˜¾å¼å›æ”¶æœºåˆ¶ã€‚
- **token æ•°é‡è¯¯ç®—**ï¼šæ”¹è¿›å…¨å±€ token è´¦æœ¬ï¼Œè€ƒè™‘åˆ†æ”¯å› å­ã€‚
- **éæ³•å¹¶è¡Œç»“æ„å¯¼è‡´æœªå®šä¹‰çŠ¶æ€**ï¼šå¢åŠ è½»é‡çº§å‰ç½®éªŒè¯å™¨ã€‚
- **å±€éƒ¨é‡å¤é—®é¢˜**ï¼šåœ¨ `<step>` å—å†…æ–½åŠ è½»å¾®é‡å¤æƒ©ç½šã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Multiverseï¼‰ | NPR |
|------|--------------------------|-----|
| **è®­ç»ƒæ–¹å¼** | ä¾èµ–å¼ºæ•™å¸ˆæ¨¡å‹è’¸é¦ | å®Œå…¨è‡ªè’¸é¦ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£ |
| **å¹¶è¡ŒçœŸå®æ€§** | å­˜åœ¨ ~30% AR fallbackï¼ˆé€€åŒ–ä¸ºé¡ºåºç”Ÿæˆï¼‰ | **100% genuine parallelism** |
| **KV å…±äº«** | ä¸å……åˆ†æˆ–æœªåˆ©ç”¨ | æ”¯æŒé«˜æ•ˆ KV-cache å¤ç”¨ |
| **æ¨ç†é€Ÿåº¦** | åŠ é€Ÿæœ‰é™ï¼ˆ1.3Ã—â€“2.4Ã—ï¼‰ | æœ€é«˜ **4.6Ã— wall-clock speedup** |
| **æ³›åŒ–èƒ½åŠ›** | å—é™äºæ•™å¸ˆæ¨¡å‹æ¨¡å¼ | å¯æ¼”åŒ–å‡ºæ–°å‹å¹¶è¡Œç­–ç•¥ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šåŸºäº **ORZ æ•°æ®é›†**ï¼ˆ57k é—®ç­”å¯¹ï¼‰ï¼Œä»ä¸­æŠ½å–å›ºå®šå­é›† **8k ç¤ºä¾‹**ç”¨äºæ‰€æœ‰è®­ç»ƒé˜¶æ®µã€‚
- **è¯„ä¼°åŸºå‡†**ï¼ˆå…± 8 ä¸ªï¼‰ï¼š
  - æ•°å­¦ç«èµ›ç±»ï¼š**AIME25**, **AIME24**, **HMMT25**, **AMC23**
  - ç»¼åˆæ¨ç†ç±»ï¼š**OlympiadBench**, **Minerva-Math**, **ZebraLogic**, **MATH500**

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹åŸºç¡€**ï¼šåŸºäº **Qwen3-4B-Instruct-2507** å’Œ **Qwen3-4B (Non-Thinking)**ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **avg@k**ï¼šk æ¬¡é‡‡æ ·ä¸­æ­£ç¡®ç­”æ¡ˆçš„æ¯”ä¾‹æœŸæœ›å€¼ã€‚
  - **best@8**ï¼š8 æ¬¡é‡‡æ ·ä¸­æœ€ä¼˜ç»“æœçš„å‡†ç¡®ç‡ï¼Œè¡¡é‡ test-time scalabilityã€‚
  - **Tokens Per Second (TPS)** ä¸ **Speedup Ratio**ï¼šè¯„ä¼°æ¨ç†æ•ˆç‡ã€‚
  - **Parallel Reasoning Trigger Rate**ï¼šè§¦å‘å¹¶è¡Œæ¨ç†çš„æ ·æœ¬å æ¯”ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | å¯¹æ¯”æ–¹æ³• |
|------|--------|
| **é¡ºåºæ¨ç†å™¨** | Qwen2.5-32B-Instruct, Qwen3-4B-Instruct, SR-BETA/SR |
| **å¹¶è¡Œæ¨ç†å™¨** | Multiverse-32B, Multiverse-4Bï¼ˆå¤ç°ï¼‰ |
| **å˜ä½“å¯¹æ¯”** | NPR-BETAï¼ˆä»… SFTï¼‰ã€SRï¼ˆé¡ºåº RLï¼‰ç­‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2ï¼‰

| æ¨¡å‹ | AIME25 | AIME24 | HMMT25 | AVG |
|------|--------|--------|--------|-----|
| Qwen3-4B-Instruct | 47.4 | 60.0 | 31.0 | 63.7 |
| Multiverse-4B | 42.9 | 46.7 | 20.8 | 50.1 |
| **NPR (Qwen3-4B-Instruct)** | **50.4** | **63.3** | **30.8** | **65.0** |
| Multiverse-32B | 45.8 | 53.8 | 20.8 | 52.5 |

> âœ… NPR åœ¨ **AIME25 ä¸Šè¾¾åˆ° 50.4%**ï¼Œè¶…è¶Š Multiverse-32Bï¼ˆ45.8ï¼‰å’Œ Multiverse-4Bï¼ˆ42.9ï¼‰ï¼Œå³ä½¿åè€…ä½¿ç”¨æ›´å¼ºæ•™å¸ˆæ¨¡å‹è’¸é¦ã€‚

å½“è®­ç»ƒèµ·ç‚¹ä¸ºéæ€è€ƒæ¨¡å¼çš„ Qwen3-4B æ—¶ï¼š
- NPR å¹³å‡æ€§èƒ½å¢ç›Šè¶…è¿‡ **24.5%**ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### âœ… è‡ªè’¸é¦æ•°æ®æ›´ä¼˜
- NPR ä½¿ç”¨è‡ªè’¸é¦æ•°æ®ï¼ˆorz-8kï¼‰ç›¸æ¯” Multiverse ä½¿ç”¨æ•™å¸ˆè’¸é¦æ•°æ®ï¼ˆs1.1-8kï¼‰ï¼Œå¹³å‡å¾—åˆ†æå‡ **+8.9 pts**ã€‚
- åœ¨ ZebraLogic ä¸Šæå‡é«˜è¾¾ **+15.9 pts**ï¼Œè¯´æ˜è‡ªæ¼”åŒ–çš„å¹¶è¡Œç­–ç•¥æ›´å…·å¤šæ ·æ€§ä¸å‡†ç¡®æ€§ã€‚

#### âœ… å¹¶è¡Œ SFT ä¼˜äºé¡ºåº SFT
- NPR-BETAï¼ˆParallel SFTï¼‰ç›¸æ¯” SR-BETAï¼ˆSequential SFTï¼‰åœ¨ AIME25 ä¸Šæå‡ **+5.8 pts**ï¼ˆ42.9 vs 37.1ï¼‰ã€‚
- è¡¨æ˜å¹¶è¡Œç›‘ç£èƒ½ç¼“è§£é¡ºåºå…ˆéªŒåå·®ï¼Œä¿ƒè¿›çµæ´»ä»»åŠ¡åˆ†è§£ã€‚

#### âœ… å¹¶è¡Œ RL æ˜¾è‘—å¢å¼ºæ€§èƒ½
- NPRï¼ˆParallel RLï¼‰ç›¸æ¯” SRï¼ˆSequential RLï¼‰å¹³å‡æå‡ **+3.0 pts**ã€‚
- åœ¨ AIME24 ä¸Šä» 57.1 â†’ 63.3ï¼ˆ+6.2ï¼‰ï¼ŒHMMT25 ä¸Š 26.3 â†’ 30.8ï¼ˆ+4.5ï¼‰ï¼Œæ˜¾ç¤º PAPO èƒ½æœ‰æ•ˆæ”¾å¤§é«˜å¥–åŠ±è·¯å¾„ã€‚

---

### æ¨ç†åŠ é€Ÿæ•ˆæœï¼ˆTable 3ï¼‰
| æ–¹æ³• | AIME25 Speedup | HMMT25 Speedup | AMC23 Speedup |
|------|---------------|---------------|--------------|
| Multiverse | 2.4Ã— | 2.1Ã— | 1.7Ã— |
| **NPR** | **4.6Ã—** | **4.1Ã—** | **2.9Ã—** |

> âš¡ï¸ NPR åœ¨éš¾é¢˜ä¸ŠåŠ é€Ÿæ›´æ˜¾è‘—ï¼Œè¡¨æ˜å…¶åœ¨éœ€è¦æ·±åº¦æ¢ç´¢çš„ä»»åŠ¡ä¸­ä¼˜åŠ¿æ›´å¤§ã€‚

---

### å¹¶è¡Œæ€§åˆ†æï¼ˆTable 4ï¼‰
| æ¨¡å‹ | AIME25 | ZebraLogic | MATH500 | å¹³å‡ |
|------|--------|------------|---------|------|
| Multiverse-32B | 65.0% | 45.8% | 76.0% | ~63% |
| **NPR-Inst.** | **100.0%** | **100.0%** | **100.0%** | **100%** |

> ğŸ¯ NPR å®ç°äº† **100% genuine parallel reasoning**ï¼Œæ— ä»»ä½• AR fallbackï¼Œè€Œ Multiverse å­˜åœ¨ä¸¥é‡ä¼ªå¹¶è¡Œè¡Œä¸ºã€‚

---

### Test-Time Scalabilityï¼ˆTable 5ï¼‰
- åœ¨ Non-Thinking æ¨¡å‹ä¸Šï¼ŒNPR å°† AIME25 çš„ **best@8** ä» 36.7ï¼ˆåŸå§‹ï¼‰â†’ 70.0ï¼ˆSFTï¼‰â†’ **76.7ï¼ˆNPRï¼‰**ï¼Œè¿›ä¸€æ­¥æå‡ 6.7 ptsã€‚
- è¡¨æ˜ NPR æ˜¾è‘—å¢å¼ºäº†é‡‡æ ·å¤šæ ·æ€§ä¸æœ€ä¼˜è§£è¦†ç›–ç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è‡ªè’¸é¦å¯æ›¿ä»£æ•™å¸ˆæ¨¡å‹**ï¼šæ— éœ€ä¾èµ–å¤–éƒ¨å¼ºæ¨¡å‹ï¼ŒLLM å¯é€šè¿‡è‡ªæˆ‘æ¼”åŒ–æŒæ¡é«˜æ•ˆçš„å¹¶è¡Œæ¨ç†èƒ½åŠ›ã€‚
2. **åŸç”Ÿå¹¶è¡Œä¼˜äºæ¨¡æ‹Ÿå¹¶è¡Œ**ï¼šé€šè¿‡ä¸¥æ ¼çš„å¹¶è¡Œæ³¨æ„åŠ›ç»“æ„å’Œä½ç½®ç¼–ç ï¼Œå¯å®ç°çœŸæ­£æ„ä¹‰ä¸Šçš„å¹¶å‘æ‰§è¡Œï¼Œè€Œéé¡ºåºæ¨¡æ‹Ÿã€‚
3. **PAPO + NPR Engine æ˜¯å…³é”®æ”¯æ’‘**ï¼šä¸“ç”¨ RL ç®—æ³•ä¸ç¨³å®šå¼•æ“å…±åŒä¿éšœäº†å¤§è§„æ¨¡å¹¶è¡Œ RL çš„å¯è¡Œæ€§ä¸æœ‰æ•ˆæ€§ã€‚
4. **å¹¶è¡Œå¸¦æ¥åŒé‡æ”¶ç›Š**ï¼šä¸ä»…æå‡ **accuracy**ï¼ˆæœ€é«˜ +24.5%ï¼‰ï¼Œè¿˜å®ç° **4.6Ã— æ¨ç†åŠ é€Ÿ**ï¼Œæ‰“ç ´â€œç²¾åº¦ vs æ•ˆç‡â€ trade-offã€‚
5. **100% genuine parallelism å¯è¾¾**ï¼šNPR å½»åº•æ¶ˆé™¤ AR fallbackï¼Œå»ºç«‹æ–°çš„å¹¶è¡Œæ¨ç†æ ‡å‡†ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä¸»è¦åœ¨ **Qwen3-4B** ä¸ŠéªŒè¯ï¼Œå°šæœªæ‰©å±•è‡³æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ 70B+ï¼‰ã€‚
- åˆæ­¥å°è¯•åœ¨ Qwen2.5 ç³»åˆ—å¤±è´¥ï¼Œè¯´æ˜å¯¹åŸºç¡€æ¨¡å‹çš„æŒ‡ä»¤éµå¾ªä¸æ¨ç†èƒ½åŠ›æœ‰ä¸€å®šè¦æ±‚ã€‚
- å¹¶è¡Œç»“æ„ç›®å‰ä¾èµ–é¢„å®šä¹‰æ¨¡æ¿ï¼ˆ`<plan>/<step>/<takeaway>`ï¼‰ï¼Œçµæ´»æ€§å—é™ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šæ¨¡å‹å®¶æ—ï¼ˆLlamaã€DeepSeek ç­‰ï¼‰ã€‚
- æ¢ç´¢åŠ¨æ€ã€å¯å­¦ä¹ çš„å¹¶è¡Œç»“æ„ï¼Œè€Œéå›ºå®šæ¨¡æ¿ã€‚
- å°† NPR åº”ç”¨äºé•¿æ–‡æœ¬ç”Ÿæˆã€ä»£ç åˆæˆã€å¤šæ¨¡æ€æ¨ç†ç­‰æ›´å¹¿æ³›åœºæ™¯ã€‚
- æ„å»ºå¼€æ”¾çš„å¹¶è¡Œæ¨ç†ç”Ÿæ€ç³»ç»Ÿï¼ˆå·²å¼€æºä»£ç ã€æ¨¡å‹ã€ç½‘ç«™ï¼‰ã€‚

---

## æ€»ç»“
**NPR** æ˜¯é¦–ä¸ªå®ç° **å®Œå…¨è‡ªæ¼”åŒ–ã€100% åŸç”Ÿå¹¶è¡Œæ¨ç†** çš„æ¡†æ¶ï¼Œé€šè¿‡ **è‡ªè’¸é¦ + å¹¶è¡Œ SFT + PAPO RL** ä¸‰é˜¶æ®µè®­ç»ƒï¼Œç»“åˆå·¥ç¨‹çº§ **NPR Engine** æ”¯æ’‘ï¼Œå®ç°äº†æ¨ç†èƒ½åŠ›ä¸æ•ˆç‡çš„åŒé‡çªç ´ã€‚å®ƒä¸ä»…è¶…è¶Šäº†ä¾èµ–æ•™å¸ˆè’¸é¦çš„ Multiverse ç­‰ SOTA æ–¹æ³•ï¼Œæ›´ä¸ºæœªæ¥ agentic AI çš„è§„æ¨¡åŒ–ã€é«˜æ•ˆåŒ–æ¨ç†æä¾›äº†æ–°èŒƒå¼ã€‚

> ğŸ”— å¼€æºåœ°å€ï¼š
> - Code: [https://github.com/bigai-nlco/Native-Parallel-Reasoner](https://github.com/bigai-nlco/Native-Parallel-Reasoner)
> - Model: [https://huggingface.co/bigai-NPR](https://huggingface.co/bigai-NPR)
> - Website: [https://bigai-nlco.github.io/Native-Parallel-Reasoner](https://bigai-nlco.github.io/Native-Parallel-Reasoner)

</details>

---

### 4. [Communication-Efficient Serving for Video Diffusion Models with Latent Parallelism](https://arxiv.org/abs/2512.07350)

**Authors**: Zhiyuan Wu, Shuai Wang, Li Chen, Kaihui Gao, Dan Li, Yanyu Ren, Qiming Zhang, Yong Wang  
**Category**: cs.DC  
**Published**: 2025-12-09  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.07350v1  

#### Abstract
Video diffusion models (VDMs) perform attention computation over the 3D spatio-temporal domain. Compared to large language models (LLMs) processing 1D sequences, their memory consumption scales cubically, necessitating parallel serving across multiple GPUs. Traditional parallelism strategies partiti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCommunication-Efficient Serving for Video Diffusion Models with Latent Parallelism

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆ**Video Diffusion Models, VDMs**ï¼‰åœ¨ç”Ÿæˆé«˜è´¨é‡ã€é•¿æ—¶åºä¸€è‡´çš„è§†é¢‘æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼ˆå¦‚ Soraã€Veoã€WANï¼‰ã€‚ç„¶è€Œï¼ŒVDMs åœ¨æ¨ç†è¿‡ç¨‹ä¸­éœ€è¦å¯¹ä¸‰ç»´æ—¶ç©ºåŸŸï¼ˆæ—¶é—´ã€é«˜åº¦ã€å®½åº¦ï¼‰è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ï¼Œå¯¼è‡´å…¶ **GPU å†…å­˜æ¶ˆè€—å‘ˆç«‹æ–¹çº§å¢é•¿**ï¼Œè¿œè¶…å¤„ç†ä¸€ç»´åºåˆ—çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚è¿™ä½¿å¾—å•å¡éƒ¨ç½²å‡ ä¹ä¸å¯è¡Œï¼Œå¿…é¡»ä¾èµ–å¤š GPU å¹¶è¡ŒæœåŠ¡ã€‚

ä¼ ç»Ÿçš„å¹¶è¡Œç­–ç•¥ï¼ˆå¦‚ **Naive Model Parallelism (NMP)**ã€**Pipeline Parallelism (PP)** å’Œ **Tensor Parallelism (TP)**ï¼‰è™½ç„¶èƒ½åˆ†æ‘Šå†…å­˜å‹åŠ›ï¼Œä½†åœ¨ VDM æ¨ç†ä¸­ä¼šå¼•å…¥ä¸¥é‡çš„é€šä¿¡ç“¶é¢ˆâ€”â€”å› ä¸ºå®ƒä»¬éœ€è¦åœ¨æ¯ä¸ªå»å™ªæ­¥ï¼ˆdiffusion timestepï¼‰é¢‘ç¹ä¼ è¾“é«˜ç»´ä¸­é—´æ¿€æ´»å¼ é‡ï¼ˆactivation tensorsï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨å¸¦å®½å—é™çš„ PCIe äº’è”ç¯å¢ƒä¸­ï¼Œé€šä¿¡å¼€é”€æˆä¸ºç³»ç»Ÿæ€§èƒ½çš„ç“¶é¢ˆã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šLatent Parallelism (LP)
æœ¬æ–‡æå‡ºäº† **Latent Parallelism (LP)**ï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸º VDM æœåŠ¡è®¾è®¡çš„å¹¶è¡ŒåŒ–ç­–ç•¥ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **å°†å¹¶è¡ŒåŒ–çš„å¯¹è±¡ä»â€œæ¨¡å‹â€è½¬ç§»åˆ°â€œè¯·æ±‚çš„æ½œåœ¨ç©ºé—´ï¼ˆlatent tensorï¼‰â€æœ¬èº«**ã€‚

å…·ä½“è€Œè¨€ï¼ŒLP å°†æ•´ä¸ªè§†é¢‘çš„å…¨å±€æ½œåœ¨ç©ºé—´ï¼ˆlatent spaceï¼‰åŠ¨æ€åœ°åˆ’åˆ†ä¸ºå¤šä¸ªå­åŒºåŸŸï¼ˆsub-latentsï¼‰ï¼Œè¿™äº›å­åŒºåŸŸè¢«åˆ†é…åˆ°ä¸åŒçš„ GPU ä¸Šå¹¶è¡Œæ‰§è¡Œå»å™ªæ“ä½œï¼Œæœ€åå†åˆå¹¶é‡æ„ä¸ºå®Œæ•´çš„æ½œåœ¨è¡¨ç¤ºã€‚

#### åˆ›æ–°æœºåˆ¶
1. **åŠ¨æ€æ—‹è½¬åˆ†åŒºï¼ˆDynamic Rotating Partitionï¼‰**  
   åœ¨ä¸åŒçš„å»å™ªæ—¶é—´æ­¥ï¼Œäº¤æ›¿æ²¿æ—¶é—´ã€é«˜åº¦ã€å®½åº¦ä¸‰ä¸ªç»´åº¦è¿›è¡Œåˆ†åŒºã€‚è¿™ç§æ—‹è½¬ç¡®ä¿äº†æ¯ä¸ªå±€éƒ¨åŒºåŸŸåœ¨å¤šä¸ªæ—¶é—´æ­¥åéƒ½èƒ½è·å¾—å®Œæ•´çš„æ—¶ç©ºä¸Šä¸‹æ–‡ï¼Œä»è€Œç»´æŒå…¨å±€ä¸€è‡´æ€§ã€‚

2. **åŸºäºè§†è§‰å—å¯¹é½çš„é‡å åˆ†åŒºï¼ˆPatch-Aligned Overlapping Partitionï¼‰**  
   åˆ†åŒºè¾¹ç•Œä¸ VDM å†…éƒ¨çš„è§†è§‰å—ï¼ˆvisual patchesï¼‰å¯¹é½ï¼Œå¹¶å¼•å…¥å¯æ§çš„é‡å åŒºåŸŸï¼Œé˜²æ­¢å› åˆ‡å‰²ç ´åç‰¹å¾å®Œæ•´æ€§è€Œå¯¼è‡´çš„è¾¹ç•Œä¼ªå½±ã€‚

3. **ä½ç½®æ„ŸçŸ¥çš„æ½œåœ¨é‡æ„ï¼ˆPosition-Aware Latent Reconstructionï¼‰**  
   åœ¨åˆå¹¶é˜¶æ®µï¼Œé‡‡ç”¨åŸºäºä½ç½®çš„è‡ªé€‚åº”åŠ æƒå¹³å‡ï¼Œä½¿é‡å åŒºåŸŸçš„é¢„æµ‹æ›´åŠ å¹³æ»‘ï¼Œæ¶ˆé™¤æ‹¼æ¥ç—•è¿¹ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é€šä¿¡æ•ˆç‡æé«˜**ï¼šä»…éœ€åœ¨ GPU é—´ä¼ è¾“ç´§å‡‘çš„æ½œåœ¨å¼ é‡ï¼ˆlatent tensorsï¼‰ï¼Œè€Œéåºå¤§çš„ä¸­é—´æ¿€æ´»å¼ é‡ï¼Œé€šä¿¡å¼€é”€é™ä½é«˜è¾¾ **97%**ã€‚
- **éä¾µå…¥å¼æ’ä»¶èŒƒå¼**ï¼šLP å¯æ— ç¼é›†æˆåˆ°ç°æœ‰çš„å¹¶è¡Œç­–ç•¥ï¼ˆå¦‚ DPã€TPã€PPï¼‰ä¹‹ä¸Šï¼Œå½¢æˆæ··åˆå¹¶è¡Œæ¡†æ¶ã€‚
- **ä¿æŒç”Ÿæˆè´¨é‡**ï¼šé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„åˆ†åŒºä¸é‡æ„æœºåˆ¶ï¼Œç”Ÿæˆè§†é¢‘çš„è´¨é‡ä¸é›†ä¸­å¼ï¼ˆCentralizedï¼‰ç”Ÿæˆç›¸å½“ã€‚
- **å¯æ‰©å±•æ€§å¼º**ï¼šé€‚ç”¨äºä¸åŒé•¿åº¦çš„è§†é¢‘å’Œä¸åŒè§„æ¨¡çš„ GPU é›†ç¾¤ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„è§†é¢‘ç”ŸæˆåŸºå‡†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼š
- **EvalCrafter** [17]
- **T2V-CompBench** [25]
- **VBench** [12]

ç”±äºæ•°æ®é›†è§„æ¨¡è¾ƒå¤§ï¼Œä½œè€…ä½¿ç”¨å›ºå®šéšæœºç§å­é€‰å–ä»£è¡¨æ€§å­é›†ä»¥ä¿è¯å¯å¤ç°æ€§ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š4 å° NVIDIA RTX A6000 GPUï¼Œé€šè¿‡ PCIe æ€»çº¿äº’è”ï¼Œé…å¤‡ 80 æ ¸ CPU å’Œ 280GB RAMã€‚
- **æ¨¡å‹é…ç½®**ï¼šé‡‡ç”¨ **WAN2.1-1.3B** ä½œä¸ºåŸºç¡€ VDMï¼ŒåŒ…å« 30 ä¸ª DiT Blocksã€T5 æ–‡æœ¬ç¼–ç å™¨å’Œé¢„è®­ç»ƒ VAE è§£ç å™¨ã€‚
- **é»˜è®¤å‚æ•°**ï¼š
  - è§†é¢‘å¸§ç‡ï¼š16 FPS
  - åˆ†è¾¨ç‡ï¼š480p
  - å»å™ªæ­¥æ•°ï¼š60 æ­¥
  - å¹¶è¡Œ GPU æ•°ï¼š4

### è¯„ä¼°æŒ‡æ ‡
1. **é€šä¿¡å¼€é”€ï¼ˆCommunication Overheadï¼‰**ï¼šä»¥ MB ä¸ºå•ä½æµ‹é‡æ€»ç½‘ç»œæµé‡ã€‚
2. **ç”Ÿæˆè´¨é‡ï¼ˆGeneration Qualityï¼‰**ï¼šä½¿ç”¨ **VBench** æ¡†æ¶è¯„ä¼°ä»¥ä¸‹äº”ä¸ªå­æŒ‡æ ‡ï¼š
   - Subject Consistency (SC)
   - Background Consistency (BC)
   - Temporal Flickering (TF)
   - Motion Smoothness (MS)
   - Imaging Quality (IQ)

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **NMP**ï¼ˆNaive Model Parallelismï¼‰ï¼šè¿ç»­åˆ’åˆ† DiT Blocksã€‚
- **PP**ï¼ˆPipeline Parallelismï¼‰ï¼šåˆ©ç”¨ CFG çš„æ¡ä»¶/æ— æ¡ä»¶é€šè·¯æ„é€ å¾®æ‰¹æ¬¡æµæ°´çº¿ã€‚
- **HP**ï¼ˆHybrid Parallelismï¼‰ï¼šç»“åˆ FSDP ä¸ xDiT çš„ç®—å­çº§å¹¶è¡Œæ¡†æ¶ã€‚
- **Centralized**ï¼šå•å¡é›†ä¸­å¼ç”Ÿæˆï¼ˆç†æƒ³å‚è€ƒï¼‰ã€‚
- **VideoCrafter**ï¼šä½œä¸ºå¤–éƒ¨æ¨¡å‹æ€§èƒ½å‚è€ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### é€šä¿¡å¼€é”€å¯¹æ¯”ï¼ˆTable 1ï¼‰
| æ–¹æ³• | 49å¸§ï¼ˆ3ç§’ï¼‰æ€»å¼€é”€ | 81å¸§ï¼ˆ5ç§’ï¼‰æ€»å¼€é”€ |
|------|------------------|------------------|
| NMP | 57,950.17 MB (~57.9 GB) | 93,050.17 MB (~93.1 GB) |
| PP | 57,590.16 MB (~57.6 GB) | 92,690.16 MB (~92.7 GB) |
| HP | 4,758.08 MB (~4.8 GB) | 7,686.12 MB (~7.7 GB) |
| **LP (r=0.5)** | **1,354.34 MB (~1.4 GB)** | **2,191.29 MB (~2.2 GB)** |
| **LP (r=1.0)** | **1,811.88 MB (~1.8 GB)** | **2,912.81 MB (~2.9 GB)** |

> âœ… **LP ç›¸æ¯” NMP/PP å‡å°‘çº¦ 97% é€šä¿¡å¼€é”€ï¼Œç›¸æ¯” HP å‡å°‘çº¦ 72%**ã€‚

#### ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆTable 2ï¼‰
| æ–¹æ³• | æ¨ç†å»¶è¿Ÿï¼ˆç§’ï¼‰ |
|------|---------------|
| NMP | 239.33 s |
| LP (r=1.0) | 220.69 s |
| **LP (r=0.5)** | **195.27 s** |

> âœ… å³ä½¿æœ‰æ›´å¤§é‡å ï¼ˆr=1.0ï¼‰ï¼ŒLP ä»æ¯” NMP æ›´å¿«ï¼Œè¡¨æ˜é€šä¿¡ç“¶é¢ˆçš„æœ‰æ•ˆç¼“è§£ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **ç”Ÿæˆè´¨é‡**ï¼ˆFigure 4 & Table 3ï¼‰ï¼š
  - LPï¼ˆr=0.5 å’Œ r=1.0ï¼‰åœ¨æ‰€æœ‰ VBench å­æŒ‡æ ‡ä¸Šçš„è¡¨ç°ä¸ **Centralizedã€NMPã€PPã€HP** å¤„äºåŒä¸€é«˜æ€§èƒ½å±‚çº§ã€‚
  - æ‰€æœ‰ LP é…ç½®çš„å¹³å‡è´¨é‡å¾—åˆ†ä¸ Centralized çš„å·®å¼‚ä¸è¶…è¿‡ **0.6%**ã€‚
  - æ˜¾è‘—ä¼˜äº **VideoCrafter**ï¼Œå°¤å…¶åœ¨ IQã€SC å’Œ MS æŒ‡æ ‡ä¸Šã€‚

- **å¯è§†åŒ–å¯¹æ¯”**ï¼ˆFigure 5, 11â€“13ï¼‰ï¼š
  - LP ç”Ÿæˆçš„è§†é¢‘åœ¨èµ·å§‹ã€ä¸­é—´ã€ç»“æŸå¸§å‡ä¸ Centralized ç»“æœè§†è§‰ä¸Šéš¾ä»¥åŒºåˆ†ã€‚
  - æˆåŠŸä¿ç•™é¢éƒ¨ç»†èŠ‚ã€çº¹ç†æ¸…æ™°åº¦ã€è‰²å½©å‡†ç¡®æ€§ï¼Œæœªå‡ºç°è¾¹ç•Œä¼ªå½±æˆ–ç©ºé—´ä¸è¿ç»­æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœ

| å®éªŒæ–¹å‘ | å‘ç° |
|--------|------|
| **é‡å æ¯”ä¾‹ r**ï¼ˆFig 6â€“7ï¼‰ | - é€šä¿¡å¼€é”€éš r å¢å¤§è€Œå¢åŠ ï¼ˆr=0.1â†’1.0ï¼Œå¼€é”€ç¿»å€ï¼‰<br>- ä½†è´¨é‡æå‡è¶‹äºé¥±å’Œï¼Œ**r=0.5 å·²è¾¾æœ€ä¼˜æƒè¡¡ç‚¹** |
| **GPU æ•°é‡**ï¼ˆFig 8ï¼‰ | - LP åœ¨ 2â€“8 GPU ä¸Šå‡ä¿æŒé«˜è´¨é‡<br>- æ€§èƒ½ç¨³å®šï¼Œä¼˜äº VideoCrafterï¼ŒéªŒè¯å¯æ‰©å±•æ€§ |
| **è§†é¢‘æ—¶é•¿**ï¼ˆFig 9ï¼‰ | - HP å¼€é”€éšè§†é¢‘å˜é•¿æ€¥å‰§ä¸Šå‡ï¼ˆ3sâ†’10sï¼Œ5GBâ†’15GBï¼‰<br>- LP ä»…å¢åŠ çº¦ 4GBï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„é•¿è§†é¢‘é€‚åº”èƒ½åŠ› |
| **åˆ†åŒºç­–ç•¥æ¶ˆè**ï¼ˆFig 10ï¼‰ | - å›ºå®šæ—¶é—´ç»´åº¦åˆ†åŒºï¼ˆw/o LPï¼‰æ€§èƒ½å…¨é¢è½å<br>- éªŒè¯äº†åŠ¨æ€æ—‹è½¬ã€å—å¯¹é½ã€ä½ç½®æ„ŸçŸ¥é‡æ„ä¸‰è€…ååŒä½œç”¨çš„é‡è¦æ€§ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é€šä¿¡ç“¶é¢ˆçš„æ ¹æœ¬åŸå› åœ¨äºé«˜ç»´æ¿€æ´»ä¼ è¾“**ï¼Œè€Œ LP é€šè¿‡åœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œå¹¶è¡ŒåŒ–ï¼Œä»æ ¹æœ¬ä¸Šè§„é¿äº†è¿™ä¸€é—®é¢˜ã€‚
2. **Latent Parallelism æ˜¯é¦–ä¸ªä¸“ä¸º VDM è®¾è®¡çš„å¹¶è¡Œç­–ç•¥**ï¼Œå®ç°äº†é€šä¿¡æ•ˆç‡ä¸ç”Ÿæˆè´¨é‡çš„åŒé‡ä¿éšœã€‚
3. **ç†è®ºåˆ†æè¯æ˜ LP å…·å¤‡â€œ2-å®Œå¤‡æ€§â€ï¼ˆ2-Completenessï¼‰**ï¼šä»»æ„ä½ç½®åœ¨ä¸¤ä¸ªå»å™ªæ­¥å†…å³å¯è·å–å®Œæ•´æ—¶ç©ºä¸Šä¸‹æ–‡ï¼Œç¡®ä¿å…¨å±€ä¸€è‡´æ€§ã€‚
4. **LP æ˜¯éä¾µå…¥å¼æ’ä»¶**ï¼Œå¯ä¸ç°æœ‰å¹¶è¡Œç­–ç•¥ç»„åˆï¼Œæ„å»ºå±‚æ¬¡åŒ–æ··åˆå¹¶è¡Œæ¶æ„ï¼ˆHierarchical Hybrid Parallelismï¼‰ï¼Œè¿›ä¸€æ­¥æå‡å¤§è§„æ¨¡é›†ç¾¤ä¸‹çš„å¯æ‰©å±•æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å®ç°å‡è®¾æ‰€æœ‰ GPU å…·æœ‰ç›¸åŒç®—åŠ›ï¼Œæœªè€ƒè™‘å¼‚æ„è®¾å¤‡åœºæ™¯ã€‚
- åŠ¨æ€æ—‹è½¬åˆ†åŒºå¯èƒ½å¸¦æ¥è½»å¾®è´Ÿè½½ä¸å‡è¡¡ï¼Œå°¤å…¶åœ¨éå‡åŒ€åˆ†è¾¨ç‡è¾“å…¥ä¸‹ã€‚
- è™½ç„¶é€šä¿¡å¤§å¹…å‡å°‘ï¼Œä½†æ½œåœ¨ç©ºé—´çš„åˆ†å‰²ä¸é‡æ„æœ¬èº«å¼•å…¥é¢å¤–è®¡ç®—å¼€é”€ï¼Œåœ¨æå°æ¨¡å‹æˆ–çŸ­è§†é¢‘ä¸­ä¼˜åŠ¿å¯èƒ½å‡å¼±ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† LP æ‰©å±•è‡³æ”¯æŒ **Mixture-of-Experts (MoE)** æ¶æ„çš„ VDMã€‚
- æ¢ç´¢ä¸ **runtime-adaptive caching**ï¼ˆå¦‚ MagCacheã€TeaCacheï¼‰ç­‰åŠ é€ŸæŠ€æœ¯çš„è”åˆä¼˜åŒ–ã€‚
- åœ¨çœŸå®ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½² LPï¼Œç ”ç©¶å…¶åœ¨åŠ¨æ€æ‰¹å¤„ç†ï¼ˆdynamic batchingï¼‰ã€æµå¼ç”Ÿæˆç­‰åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ–åˆ†åŒºç­–ç•¥ï¼Œå®ç°æ›´æ™ºèƒ½çš„è‡ªé€‚åº”åˆ†å‰²ï¼ˆadaptive partitioningï¼‰ã€‚

---

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ **Latent Parallelism (LP)** ä¸º VDM çš„é«˜æ•ˆæœåŠ¡æä¾›äº†ä¸€ç§å…¨æ–°çš„èŒƒå¼ã€‚å®ƒä¸ä»…è§£å†³äº†ä¼ ç»Ÿå¹¶è¡Œç­–ç•¥å¸¦æ¥çš„ä¸¥é‡é€šä¿¡ç“¶é¢ˆï¼Œè¿˜é€šè¿‡ç²¾å·§çš„è®¾è®¡ä¿æŒäº†ç”Ÿæˆè´¨é‡ï¼Œæ˜¯è¿ˆå‘å®ç”¨åŒ–ã€ä½æˆæœ¬ã€é«˜ååè§†é¢‘ç”ŸæˆæœåŠ¡çš„å…³é”®ä¸€æ­¥ã€‚

</details>

---

### 5. [Bandwidth-Aware Network Topology Optimization for Decentralized Learning](https://arxiv.org/abs/2512.07536)

**Authors**: Yipeng Shen, Zehan Zhu, Yan Huang, Changzhi Yan, Cheng Zhuo, Jinming Xu  
**Category**: cs.DC  
**Published**: 2025-12-09  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.07536v1  

#### Abstract
Network topology is critical for efficient parameter synchronization in distributed learning over networks. However, most existing studies do not account for bandwidth limitations in network topology design. In this paper, we propose a bandwidth-aware network topology optimization framework to maxim...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBandwidth-Aware Network Topology Optimization for Decentralized Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨**Decentralized Learning**ï¼ˆå»ä¸­å¿ƒåŒ–å­¦ä¹ ï¼‰ä¸­ï¼Œç½‘ç»œæ‹“æ‰‘ç»“æ„å¯¹å‚æ•°åŒæ­¥æ•ˆç‡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰ç ”ç©¶åœ¨è®¾è®¡ç½‘ç»œæ‹“æ‰‘æ—¶**å¿½ç•¥äº†å¸¦å®½é™åˆ¶**ï¼Œå¯¼è‡´åœ¨å®é™…å¼‚æ„ç½‘ç»œç¯å¢ƒä¸­æ€§èƒ½ä¸‹é™ã€‚æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
- å¦‚ä½•åœ¨**è€ƒè™‘èŠ‚ç‚¹é—´å¸¦å®½å·®å¼‚**çš„å‰æä¸‹ï¼Œä¼˜åŒ–ç½‘ç»œæ‹“æ‰‘ä»¥æœ€å¤§åŒ–å…±è¯†é€Ÿåº¦ï¼ˆconsensus speedï¼‰ã€‚
- å¦‚ä½•åœ¨é€šä¿¡å¼€é”€ï¼ˆæ¯è½®è¿­ä»£æ—¶é—´ï¼‰ä¸æ”¶æ•›é€Ÿåº¦ä¹‹é—´å–å¾—æ›´å¥½å¹³è¡¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ä¸ª**å¸¦å®½æ„ŸçŸ¥çš„ç½‘ç»œæ‹“æ‰‘ä¼˜åŒ–æ¡†æ¶ï¼ˆBandwidth-Aware Network Topology Optimizationï¼‰**ï¼Œå‘½åä¸º **BA-Topo**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å°†æ‹“æ‰‘è®¾è®¡å»ºæ¨¡ä¸ºå¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜**ï¼š
  - ä»¥æœ€å°åŒ–**æ¸è¿‘æ”¶æ•›å› å­** $ r_{\text{asym}}(W) = \max\{|\lambda_2(W)|, |\lambda_n(W)|\} $ ä¸ºç›®æ ‡ï¼Œå³æœ€å¤§åŒ–å…±è¯†é€Ÿåº¦ã€‚
  - å¼•å…¥**è¾¹åŸºæ•°çº¦æŸ**ï¼ˆcardinality constraintï¼‰ï¼Œæ§åˆ¶æ‹“æ‰‘ç¨€ç–æ€§ã€‚
  - æ˜¾å¼å»ºæ¨¡**åŒæ„ä¸å¼‚æ„å¸¦å®½åœºæ™¯ä¸‹çš„ç‰©ç†èµ„æºé™åˆ¶**ï¼ˆå¦‚èŠ‚ç‚¹ç«¯å£ã€æœåŠ¡å™¨å†…é“¾è·¯ã€äº¤æ¢æœºç«¯å£ç­‰ï¼‰ã€‚

- **æå‡ºæœ€å¤§å¸¦å®½åˆ†é…ç­–ç•¥ï¼ˆMaximum Bandwidth Allocation Strategyï¼‰**ï¼š
  - åœ¨å¼‚æ„å¸¦å®½åœºæ™¯ä¸‹ï¼Œé€šè¿‡ç®—æ³•åŠ¨æ€åˆ†é…æ¯æ¡é€»è¾‘è¾¹æ‰€å ç”¨çš„ç‰©ç†èµ„æºï¼Œä»¥**æœ€å¤§åŒ–æœ€å°è¾¹å¸¦å®½**ï¼Œä»è€Œå‡å°‘é€šä¿¡ç“¶é¢ˆã€‚

- **é—®é¢˜é‡æ„ä¸ºæ··åˆæ•´æ•°åŠå®šè§„åˆ’ï¼ˆMixed-Integer SDPï¼‰**ï¼š
  - åˆ©ç”¨æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µå˜æ¢å’Œå¼•ç†ï¼ˆLemma 1ï¼‰å°†éå‡¸ç‰¹å¾å€¼ä¼˜åŒ–è½¬åŒ–ä¸ºå¯è§£çš„**çº¿æ€§çŸ©é˜µä¸ç­‰å¼ï¼ˆLMIï¼‰** å½¢å¼ã€‚
  - é‡‡ç”¨åŸºäº **ADMM** çš„æ±‚è§£æ¡†æ¶ï¼Œå¹¶ç»“åˆ **Conjugate Gradient Method**ï¼ˆå…·ä½“ä¸º Bi-CGSTABï¼‰é«˜æ•ˆæ±‚è§£å¤§è§„æ¨¡çº¿æ€§ç³»ç»Ÿï¼Œæå‡å¯æ‰©å±•æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•å±€é™ | BA-Topo æ”¹è¿› |
|------|---------------|-------------|
| **å¸¦å®½å»ºæ¨¡** | å¤šå‡è®¾åŒæ„å¸¦å®½ï¼Œéš¾ä»¥åº”ç”¨äºçœŸå®å¼‚æ„ç¯å¢ƒ | ç»Ÿä¸€æ”¯æŒåŒæ„ä¸å¤šç§å¼‚æ„å¸¦å®½åœºæ™¯ï¼ˆèŠ‚ç‚¹çº§ã€æœåŠ¡å™¨å†…ã€è·¨æœåŠ¡å™¨ï¼‰ |
| **æ‹“æ‰‘è®¾è®¡æ–¹å¼** | å¤šä¸ºå¯å‘å¼è®¾è®¡ï¼ˆå¦‚ ring, exponentialï¼‰æˆ–ç®€åŒ–æƒé‡è®¾å®šï¼ˆå¦‚ç­‰æƒï¼‰ | è”åˆä¼˜åŒ–æ‹“æ‰‘ç»“æ„ä¸è¾¹æƒé‡ï¼Œåœ¨å®Œæ•´è§£ç©ºé—´ä¸­æœç´¢æœ€ä¼˜è§£ |
| **ä¼˜åŒ–ç›®æ ‡** | å¿½è§†ç¡¬ä»¶é™åˆ¶ï¼Œä»…å…³æ³¨ç†è®ºæ”¶æ•›ç‡ | åŒæ—¶ä¼˜åŒ–å…±è¯†é€Ÿåº¦ä¸é€šä¿¡æ•ˆç‡ï¼Œå®ç°æ›´ä¼˜çš„å®é™…è®­ç»ƒåŠ é€Ÿ |
| **å¯æ‰©å±•æ€§** | éƒ¨åˆ†æ–¹æ³•è®¡ç®—å¤æ‚åº¦é«˜ï¼Œéš¾æ‰©å±•è‡³ç™¾èŠ‚ç‚¹è§„æ¨¡ | ä½¿ç”¨é¢„æ¡ä»¶å…±è½­æ¢¯åº¦æ³•ï¼ˆILU + Bi-CGSTABï¼‰ï¼Œæ”¯æŒæ•°ç™¾èŠ‚ç‚¹è§„æ¨¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **CIFAR-10** å’Œ **CIFAR-100**ï¼šç”¨äºéªŒè¯ BA-Topo åœ¨çœŸå®åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚
- æ¨¡å‹ï¼š**ResNet-18**
- åˆ†å¸ƒå¼è®­ç»ƒç®—æ³•ï¼š**DSGD**ï¼ˆDecentralized SGDï¼‰

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š2 Ã— Intel Xeon Gold 6226R CPU + 8 Ã— NVIDIA RTX 2080 Ti GPU
- **é€šä¿¡åç«¯**ï¼šPyTorch 2.0.0 + Gloo
- **æœ¬åœ°æ‰¹é‡å¤§å°**ï¼š32ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ï¼‰
- **è¶…å‚æ•°**ï¼šå­¦ä¹ ç‡ 0.05ï¼ŒåŠ¨é‡ 0.9ï¼Œweight decay 0.0001ï¼Œè®­ç»ƒ 100 epochs
- **é€šä¿¡ä¸è®¡ç®—æ—¶é—´æµ‹é‡**ï¼š
  - å•æ¬¡å‰å‘ä¼ æ’­æ—¶é—´ $ t_{\text{comp}} = 15.21 \, \text{ms} $
  - å‚æ•°é€šä¿¡æ—¶é—´ $ t_{\text{comm}} = 5.01 \, \text{ms} $ï¼ˆå¸¦å®½ 9.76 GB/sï¼‰
  - è¿­ä»£æ—¶é—´æŒ‰æœ€å°è¾¹å¸¦å®½è¿›è¡Œå½’ä¸€åŒ–ï¼š  
    $$
    t_{\text{iter}} = \frac{b_{\text{avail}}}{b_{\min}} \times t_{\text{comm}}, \quad t_{\text{epoch}} = \left(\frac{b_{\text{avail}}}{b_{\min}} \times t_{\text{comm}} + t_{\text{comp}}\right) \times C_{\text{iter}}
    $$

### è¯„ä¼°æŒ‡æ ‡
- **å…±è¯†é€Ÿåº¦**ï¼ˆConsensus Speedï¼‰ï¼š
  - æ¸è¿‘æ”¶æ•›å› å­ $ r_{\text{asym}}(W) $
  - è¾¾æˆå…±è¯†è¯¯å·® $ \|x_k - \bar{x}\| < 10^{-4} $ æ‰€éœ€æ—¶é—´
- **è®­ç»ƒæ•ˆç‡**ï¼š
  - è¾¾åˆ°ç›®æ ‡æµ‹è¯•å‡†ç¡®ç‡æ‰€éœ€çš„æ—¶é—´ï¼ˆå¦‚ CIFAR-10 ä¸Š 84%ï¼ŒCIFAR-100 ä¸Š 62%ï¼‰
  - ç›¸å¯¹äºåŸºçº¿çš„**åŠ é€Ÿæ¯”**ï¼ˆspeedupï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- Ring
- 2D Grid
- 2D Torus
- Exponential Topology
- Equitopoï¼ˆåŠå…¶é™æ€å˜ä½“ U-EquiStaticï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰å…±è¯†é€Ÿåº¦è¡¨ç°ï¼ˆConsensus Speedï¼‰
- åœ¨ **n=16 èŠ‚ç‚¹ã€åŒæ„å¸¦å®½** åœºæ™¯ä¸‹ï¼Œå½“è¾¹æ•° $ r=32 $ æ—¶ï¼Œ**BA-Topo å…·æœ‰æœ€å¿«çš„å…±è¯†é€Ÿåº¦**ï¼Œæ˜¾è‘—ä¼˜äº exponential å’Œ U-EquiStaticã€‚
- åœ¨ **èŠ‚ç‚¹çº§å¼‚æ„å¸¦å®½**ï¼ˆ8ä¸ªé«˜å¸¦å®½èŠ‚ç‚¹ + 8ä¸ªä½å¸¦å®½èŠ‚ç‚¹ï¼‰åœºæ™¯ä¸‹ï¼ŒBA-Topo åœ¨ $ r=32 $ å’Œ $ r=48 $ æ—¶å‡ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚
- åœ¨ **æœåŠ¡å™¨å†…é“¾è·¯å¼‚æ„** åœºæ™¯ä¸­ï¼Œexponential æ‹“æ‰‘å› å°†è¿‡å¤šè¾¹æ˜ å°„åˆ° SYS é“¾è·¯ï¼ˆå¯¼è‡´æœ€å°å¸¦å®½ä»…ä¸º 0.976 GB/sï¼‰ï¼Œæ€§èƒ½ä¸¥é‡ä¸‹é™ï¼›è€Œ BA-Topo è‡ªåŠ¨é¿å…æ­¤ç±»ç“¶é¢ˆã€‚
- åœ¨ **BCube æ¶æ„ä¸‹çš„è·¨æœåŠ¡å™¨ç«¯å£å¼‚æ„** åœºæ™¯ä¸­ï¼ŒBA-Topo åœ¨ç›¸åŒæ—¶é—´å†…è¾¾æˆæ›´ä½å…±è¯†è¯¯å·®ã€‚

#### ï¼ˆ2ï¼‰è®­ç»ƒæ•ˆç‡æå‡ï¼ˆDSGD æ€§èƒ½ï¼‰
| åœºæ™¯ | æ•°æ®é›† | BA-Topo æœ€ä½³é…ç½® | è¾¾æ ‡æ—¶é—´ï¼ˆç§’ï¼‰ | ç›¸å¯¹æœ€å¿«åŸºçº¿åŠ é€Ÿæ¯” |
|------|--------|------------------|----------------|--------------------|
| åŒæ„å¸¦å®½ | CIFAR-10 | $ r=32 $ | 110.1 | **1.22Ã—** |
| åŒæ„å¸¦å®½ | CIFAR-100 | $ r=32 $ | 127.6 | **1.11Ã—** |
| èŠ‚ç‚¹çº§å¼‚æ„ | CIFAR-10 | $ r=32 $ | 181.6 | **1.58Ã—** |
| èŠ‚ç‚¹çº§å¼‚æ„ | CIFAR-100 | $ r=48 $ | 194.7 | **1.55Ã—** |
| æœåŠ¡å™¨å†…å¼‚æ„ | CIFAR-10 | $ r=8 $ | 266.8 | **1.53Ã—** |
| æœåŠ¡å™¨å†…å¼‚æ„ | CIFAR-100 | $ r=8 $ | 261.8 | **1.34Ã—** |
| è·¨æœåŠ¡å™¨å¼‚æ„ | CIFAR-10 | $ r=48 $ | 86.3 | **1.56Ã—** |
| è·¨æœåŠ¡å™¨å¼‚æ„ | CIFAR-100 | $ r=48 $ | 117.3 | **1.21Ã—** |

> æ³¨ï¼šä»¥ä¸Šæ•°æ®æ¥è‡ª Table IIï¼Œå±•ç¤ºäº† BA-Topo åœ¨ä¸åŒåœºæ™¯ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ‹“æ‰‘ã€‚

#### ï¼ˆ3ï¼‰å¯æ‰©å±•æ€§åˆ†æï¼ˆScalabilityï¼‰
- è¡¨æ ¼ I æ˜¾ç¤ºï¼Œåœ¨èŠ‚ç‚¹æ•°ä» 4 åˆ° 128 å˜åŒ–æ—¶ï¼ŒBA-Topo çš„**æ¸è¿‘æ”¶æ•›å› å­å§‹ç»ˆä½äº exponential å’Œ U-EquiStatic**ã€‚
- åœ¨ n=128 æ—¶ï¼ŒBA-Topo æ”¶æ•›æ—¶é—´ä¸º 1127msï¼Œè¿œä½äº exponential çš„ 1157ms å’Œ U-EquiStatic çš„ 1242msã€‚
- ç»“æœè¡¨æ˜ BA-Topo åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹ä»ä¿æŒä¼˜è¶Šçš„å…±è¯†æ€§èƒ½ã€‚

#### ï¼ˆ4ï¼‰æ¶ˆèå®éªŒä¸åˆå§‹åŒ–ç­–ç•¥
- ä½¿ç”¨ **Simulated Annealing** åˆå§‹åŒ–æ‹“æ‰‘ï¼Œä»¥è·å¾—è¾ƒå°çš„å¹³å‡æœ€çŸ­è·¯å¾„é•¿åº¦ï¼ˆASPLï¼‰ï¼Œæœ‰åŠ©äºé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚
- å®éªŒè¡¨æ˜è¯¥ warm-start ç­–ç•¥æœ‰æ•ˆæå‡äº†æœ€ç»ˆæ‹“æ‰‘è´¨é‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¸¦å®½å¼‚æ„æ€§ä¸¥é‡å½±å“ä¼ ç»Ÿæ‹“æ‰‘æ€§èƒ½**ï¼šexponential ç­‰é«˜æ€§èƒ½æ‹“æ‰‘åœ¨å¼‚æ„ç¯å¢ƒä¸‹å¯èƒ½å› é›†ä¸­ä½¿ç”¨ä½å®¹é‡é“¾è·¯è€Œå¯¼è‡´é€šä¿¡ç“¶é¢ˆã€‚
2. **è”åˆä¼˜åŒ–æ‹“æ‰‘ç»“æ„ä¸è¾¹æƒé‡å¯æ˜¾è‘—æå‡å…±è¯†é€Ÿåº¦**ï¼šBA-Topo åœ¨å®Œæ•´è§£ç©ºé—´ä¸­æœç´¢ï¼Œé¿å…äº†äººä¸ºè®¾å®šæƒé‡å¸¦æ¥çš„æ¬¡ä¼˜æ€§ã€‚
3. **BA-Topo åœ¨å¤šç§ç°å®åœºæ™¯ä¸‹å‡å®ç°æ˜¾è‘—åŠ é€Ÿ**ï¼š
   - åœ¨åŒæ„åœºæ™¯ä¸‹æé€Ÿ **1.11Ã— ~ 1.22Ã—**
   - åœ¨å¼‚æ„åœºæ™¯ä¸‹æé€Ÿå¯è¾¾ **1.58Ã—**
4. **æå‡ºçš„ ADMM + Bi-CGSTAB æ¡†æ¶å…·å¤‡è‰¯å¥½å¯æ‰©å±•æ€§**ï¼šæ”¯æŒç™¾èŠ‚ç‚¹çº§åˆ«æ‹“æ‰‘ä¼˜åŒ–ï¼Œé€‚ç”¨äºå®é™…éƒ¨ç½²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶é’ˆå¯¹**é™æ€å¸¦å®½ç¯å¢ƒ**è®¾è®¡ï¼Œæ— æ³•åº”å¯¹åŠ¨æ€å˜åŒ–çš„ç½‘ç»œæ¡ä»¶ï¼ˆå¦‚çªå‘æ‹¥å¡ã€é“¾è·¯æ•…éšœï¼‰ã€‚
- æ‹“æ‰‘ä¼˜åŒ–è¿‡ç¨‹æœ¬èº«éœ€è¦ä¸€å®šè®¡ç®—å¼€é”€ï¼Œè™½ç¦»çº¿è¿è¡Œï¼Œä½†åœ¨é¢‘ç¹å˜æ›´é›†ç¾¤é…ç½®æ—¶å¯èƒ½å¸¦æ¥é¢å¤–è´Ÿæ‹…ã€‚
- å®éªŒä¸»è¦åŸºäºå•æœåŠ¡å™¨æˆ–å¤šæœåŠ¡å™¨å°è§„æ¨¡é›†ç¾¤ï¼Œæœªåœ¨è¶…å¤§è§„æ¨¡æ•°æ®ä¸­å¿ƒï¼ˆå¦‚åƒèŠ‚ç‚¹ä»¥ä¸Šï¼‰éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ç ”ç©¶**åŠ¨æ€å¸¦å®½æ„ŸçŸ¥çš„æ—¶å˜æ‹“æ‰‘ä¼˜åŒ–æ–¹æ¡ˆ**ï¼Œé€‚åº”å®æ—¶ç½‘ç»œæ³¢åŠ¨ã€‚
- æ¢ç´¢è½»é‡åŒ–åœ¨çº¿æ‹“æ‰‘è°ƒæ•´æœºåˆ¶ï¼Œé™ä½é‡æ–°ä¼˜åŒ–æˆæœ¬ã€‚
- å°†è¯¥æ¡†æ¶æ‰©å±•è‡³ **Federated Learning** æˆ– **data-heterogeneous** åœºæ™¯ï¼Œè¿›ä¸€æ­¥æå‡å®ç”¨æ€§ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ç§**å¸¦å®½æ„ŸçŸ¥çš„å»ä¸­å¿ƒåŒ–å­¦ä¹ ç½‘ç»œæ‹“æ‰‘ä¼˜åŒ–æ¡†æ¶ BA-Topo**ï¼Œé€šè¿‡å°†æ‹“æ‰‘è®¾è®¡å»ºæ¨¡ä¸º Mixed-Integer SDP å¹¶ç»“åˆ ADMM ä¸å…±è½­æ¢¯åº¦æ³•æ±‚è§£ï¼Œåœ¨å¤šç§å¼‚æ„å¸¦å®½åœºæ™¯ä¸‹å®ç°äº†æ¯”ç°æœ‰æ‹“æ‰‘æ›´å¿«çš„å…±è¯†é€Ÿåº¦å’Œæ›´é«˜çš„è®­ç»ƒæ•ˆç‡ï¼Œæœ€é«˜æé€Ÿè¾¾ **1.58Ã—**ã€‚

</details>

---

### 6. [Think-While-Generating: On-the-Fly Reasoning for Personalized Long-Form Generation](https://arxiv.org/abs/2512.06690)

**Authors**: Chengbing Wang, Yang Zhang, Wenjie Wang, Xiaoyan Zhao, Fuli Feng, Xiangnan He, Tat-Seng Chua  
**Category**: cs.CL  
**Published**: 2025-12-09  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.06690v1  

#### Abstract
Preference alignment has enabled large language models (LLMs) to better reflect human expectations, but current methods mostly optimize for population-level preferences, overlooking individual users. Personalization is essential, yet early approaches-such as prompt customization or fine-tuning-strug...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Think-While-Generating: On-the-Fly Reasoning for Personalized Long-Form Generation è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Preference Alignment** æŠ€æœ¯ä¸»è¦é’ˆå¯¹ç¾¤ä½“åå¥½è¿›è¡Œä¼˜åŒ–ï¼Œå¿½è§†äº†ä¸ªä½“ç”¨æˆ·çš„ç‹¬ç‰¹éœ€æ±‚ã€‚åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œä¼ ç»Ÿçš„â€œthink-then-generateâ€èŒƒå¼å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **é™æ€æ¨ç†ï¼ˆstatic one-shot reasoningï¼‰** éœ€è¦åœ¨ç”Ÿæˆå‰ä¸€æ¬¡æ€§æ•æ‰æ‰€æœ‰ä¿¡æ¯ï¼Œéš¾ä»¥é€‚åº”å†…å®¹æ¼”è¿›è¿‡ç¨‹ä¸­çš„åŠ¨æ€å˜åŒ–ï¼›
- æ¨ç†ä¸ç”Ÿæˆä¹‹é—´å­˜åœ¨å¼ºä¾èµ–å…³ç³»ï¼Œå¯¼è‡´è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ä½ä¸‹ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†æ¨¡å‹å¯¹éšå¼ç”¨æˆ·åå¥½çš„å»ºæ¨¡èƒ½åŠ›ï¼Œå½±å“ä¸ªæ€§åŒ–ç”Ÿæˆçš„è´¨é‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šFlyThinker
ä½œè€…æå‡º **FlyThinker**ï¼Œä¸€ç§é«˜æ•ˆçš„ â€œ**think-while-generating**â€ æ¡†æ¶ï¼Œç”¨äºä¸ªæ€§åŒ–é•¿æ–‡æœ¬ç”Ÿæˆã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **å¹¶è¡ŒåŒ–çš„â€œè¾¹æ€è€ƒè¾¹ç”Ÿæˆâ€èŒƒå¼ï¼ˆThink-While-Generatingï¼‰**
   - ä¸åŒäºä¼ ç»Ÿâ€œå…ˆæ€è€ƒåç”Ÿæˆâ€ï¼ŒFlyThinker åœ¨æ¯ä¸ª token ç”Ÿæˆè¿‡ç¨‹ä¸­åŠ¨æ€æ’å…¥ latent reasoning æ­¥éª¤ï¼Œå®ç°ç»†ç²’åº¦çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨ç†ã€‚
   - æ›´ç¬¦åˆäººç±»å†™ä½œæ—¶é€æ­¥æ·±åŒ–ç†è§£çš„è¿‡ç¨‹ã€‚

2. **åŒæ¨¡å‹æ¶æ„è®¾è®¡ï¼ˆSeparate Reasoner & Generatorï¼‰**
   - å¼•å…¥ä¸€ä¸ªç‹¬ç«‹çš„ **Reasoner** æ¨¡å‹ï¼Œä¸“é—¨è´Ÿè´£ç”Ÿæˆ token-level çš„ latent reasoningï¼›
   - **Generator** åˆ™èåˆè¿™äº› reasoning ä¿¡å·æ¥æŒ‡å¯¼è¾“å‡ºã€‚
   - ä¸¤è€…å¯å¹¶è¡Œè¿è¡Œï¼Œæ˜¾è‘—æå‡æ•ˆç‡ã€‚

3. **ä¿æŒè®­ç»ƒå¹¶è¡Œæ€§ï¼ˆPreserved Training Parallelismï¼‰**
   - Reasoner çš„æ¨ç†ä»…ä¾èµ–äºå·²ç”Ÿæˆçš„ response tokensï¼Œè€Œä¸ä¾èµ–è‡ªèº«å…ˆå‰çš„ reasoning è¾“å‡ºï¼›
   - è¿™ä½¿å¾—æ‰€æœ‰ reasoning tokens å¯ä»¥é€šè¿‡ä¸€æ¬¡å‰å‘ä¼ æ’­æ‰¹é‡ç”Ÿæˆï¼ˆç±»ä¼¼ teacher-forcingï¼‰ï¼Œä»è€Œä¿ç•™äº†æ ‡å‡† LLM è®­ç»ƒçš„å¹¶è¡Œä¼˜åŠ¿ã€‚

4. **é«˜æ•ˆæ¨ç†æœºåˆ¶**
   - åœ¨æ¨ç†é˜¶æ®µï¼ŒGenerator ç”Ÿæˆå½“å‰ token çš„åŒæ—¶ï¼ŒReasoner å¹¶è¡Œå‡†å¤‡ä¸‹ä¸€ä¸ª step çš„ reasoningï¼›
   - å®ç°è¿‘ä¹é›¶å»¶è¿Ÿçš„æ¨ç†å¼€é”€ï¼Œæ¥è¿‘éæ¨ç†å¢å¼ºæ¨¡å‹ï¼ˆå¦‚ SFTï¼‰çš„å»¶è¿Ÿæ°´å¹³ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦æ”¯æŒåŠ¨æ€æ¨ç† | è®­ç»ƒæ•ˆç‡ | æ¨ç†æ•ˆç‡ | ä¸ªæ€§åŒ–æ•ˆæœ |
|------|------------------|----------|----------|------------|
| Prompt/Fine-tuning | âŒ | âœ… | âœ… | âš ï¸ï¼ˆéš¾æ•è·éšå¼åå¥½ï¼‰ |
| Think-then-generate (e.g., CoT, Coconut) | âŒï¼ˆé™æ€æ¨ç†ï¼‰ | âŒï¼ˆè‡ªå›å½’æ¨ç†æ…¢ï¼‰ | âŒï¼ˆéœ€é¢å¤–ç”Ÿæˆæ¨ç†é“¾ï¼‰ | âœ… |
| **FlyThinker** | âœ…ï¼ˆtoken-level åŠ¨æ€æ¨ç†ï¼‰ | âœ…ï¼ˆå¹¶è¡Œè®­ç»ƒï¼‰ | âœ…ï¼ˆè¿‘ä¼¼ SFT å»¶è¿Ÿï¼‰ | âœ…âœ… |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨ **LONGLAMP benchmark** çš„ä¸‰ä¸ªç”¨æˆ·åˆ’åˆ†ï¼ˆuser-based splitï¼‰ä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- **Product Review**ï¼šæ’°å†™äº§å“è¯„è®º
- **Abstract Generation**ï¼šç”Ÿæˆå­¦æœ¯æ‘˜è¦
- **Topic Writing**ï¼šä¸»é¢˜æ€§é•¿æ–‡å†™ä½œ  
è¿™äº›ä»»åŠ¡è¦æ±‚æ¨¡å‹åŸºäºç”¨æˆ·å†å²è¡Œä¸ºæ¨æ–­å…¶é£æ ¼ä¸åå¥½ï¼Œå¹¶ç”Ÿæˆä¸€è‡´çš„é•¿æ–‡æœ¬ã€‚

ä¸»å¹²æ¨¡å‹ï¼š`Qwen2.5-3B-Instruct`ï¼Œå¹¶åœ¨é™„å½•ä¸­éªŒè¯äº† `Qwen2.5-7B-Instruct` å’Œ `Gemma-7B-it` ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

---

### å®éªŒè®¾ç½®
- æ‰€æœ‰å®éªŒåœ¨ 4Ã—NVIDIA A100 GPU ä¸Šå®Œæˆï¼›
- ä½¿ç”¨ HuggingFace Transformers å’Œ Verl æ¡†æ¶å®ç°ï¼›
- é‡‡ç”¨æ ‡å‡†çš„ next-token prediction loss è¿›è¡Œç«¯åˆ°ç«¯è”åˆä¼˜åŒ–ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
ä½¿ç”¨å¤šä¸ªè‡ªåŠ¨è¯„ä»·æŒ‡æ ‡è¡¡é‡ç”Ÿæˆè´¨é‡ï¼š
- **ROUGE-1 / ROUGE-L**ï¼šè¯„ä¼° n-gram åŒ¹é…å’Œæœ€é•¿å…¬å…±å­åºåˆ—
- **BLEU**ï¼šè¡¡é‡è¯æ±‡ç²¾ç¡®åŒ¹é…
- **METEOR**ï¼šè€ƒè™‘åŒä¹‰è¯å’Œè¯å½¢å˜åŒ–
- **BERTScore**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§çš„è¯„åˆ†

æ­¤å¤–è¿˜è¿›è¡Œäº†ï¼š
- **LLM-based evaluationï¼ˆGPT-4oï¼‰**ï¼šäººå·¥æ‰“åˆ†æ¨¡æ‹Ÿ
- **Position-sensitive evaluation**ï¼šåˆ†æä¸åŒç”Ÿæˆä½ç½®çš„è¡¨ç°
- **Difficulty-aware evaluation**ï¼šæŒ‰éš¾åº¦åˆ†å±‚æµ‹è¯•æ€§èƒ½

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸¤ç±»ï¼š

#### ï¼ˆ1ï¼‰æ— éœ€å¾®è°ƒçš„æ–¹æ³•ï¼ˆTuning-freeï¼‰
- **Non-pers**ï¼šæ— ä¸ªæ€§åŒ–
- **RAG**ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ
- **CoS**ï¼šContext Steering

#### ï¼ˆ2ï¼‰éœ€è¦å¾®è°ƒçš„æ–¹æ³•ï¼ˆTuning-basedï¼‰
- **SFT**ï¼šç›‘ç£å¾®è°ƒï¼ˆå¼ºåŸºçº¿ï¼‰
- **LLM-TRSR**ï¼šåŸºäºæ‘˜è¦çš„è®­ç»ƒ
- **NextQuill**ï¼šå› æœåå¥½å»ºæ¨¡
- **CoT**ï¼šChain-of-Thought æ¨ç†
- **Coconut**ï¼šlatent reasoningï¼ˆthink-then-generate èŒƒå¼ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| æ–¹æ³• | Product Review (BLEU) | Abstract Gen. (BLEU) | Topic Writing (BLEU) |
|------|------------------------|------------------------|------------------------|
| SFT | 3.91 | 5.82 | 3.89 |
| CoT | 3.37 | 5.85 | 3.00 |
| Coconut | 3.32 | 5.24 | 3.07 |
| **FlyThinker** | **4.36** (+11.5%) | **6.34** (+8.8%) | **4.06** (+4.4%) |

> FlyThinker åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡ä¼˜äºæœ€å¼ºåŸºçº¿ SFT å’Œå…¶ä»–æ¨ç†æ–¹æ³•ï¼Œåœ¨ BLEU ä¸Šå¹³å‡æå‡çº¦ 10%ï¼Œä¸”åœ¨ ROUGE ç³»åˆ—æŒ‡æ ‡ä¸Šä¹Ÿå…¨é¢é¢†å…ˆã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Obs 1**: FlyThinker åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Š consistently è¶…è¿‡ SFT å’Œå…¶ä»– tuning-based æ–¹æ³•ï¼›
- **Obs 2**: åœ¨ Abstract Generation ä¸Šè¡¨ç°å°¤ä¸ºçªå‡ºï¼Œè¯´æ˜å…¶åœ¨é•¿åºåˆ—è¿è´¯æ€§å’Œç›¸å…³æ€§ç»´æŠ¤æ–¹é¢æ›´å¼ºï¼›
- **Obs 3**: æ˜¾è‘—ä¼˜äº Coconut ç­‰ latent reasoning æ–¹æ³•ï¼Œè¯æ˜ **interleaved reasoning æ›´æœ‰æ•ˆ**ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰Reasoner è§„æ¨¡çš„å½±å“ï¼ˆFigure 5 & Table 9ï¼‰
| Reasoner Size | æ€§èƒ½è¶‹åŠ¿ |
|---------------|---------|
| 3B â†’ 1.5B | å‡ ä¹æ— æŸï¼ŒROUGE/BLEU ç»´æŒé«˜ä½ |
| 1.5B â†’ 0.5B | æ˜æ˜¾ä¸‹é™ï¼Œå°¤å…¶åœ¨ ROUGE-L å’Œ BLEU ä¸Š |

ğŸ‘‰ ç»“è®ºï¼šé€‚åº¦ç¼©å° Reasonerï¼ˆå¦‚ 1.5Bï¼‰å¯åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å¤§å¹…æå‡æ•ˆç‡ã€‚

#### ï¼ˆ2ï¼‰èåˆç³»æ•° Î» çš„æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 6 & Table 10ï¼‰
- æœ€ä½³èŒƒå›´ï¼š**Î» âˆˆ [0.5, 2.0]**
- Î» è¿‡å° â†’ reasoning ä¿¡å·å¼±åŒ–
- Î» è¿‡å¤§ â†’ ç”Ÿæˆä¸ç¨³å®š
- åœ¨åˆç†èŒƒå›´å†…æ€§èƒ½ç¨³å®šï¼Œè¡¨æ˜æ–¹æ³•é²æ£’æ€§å¼º

#### ï¼ˆ3ï¼‰Latent Reasoning æ³¨å…¥ä½ç½®ï¼ˆTable 2ï¼‰
| é…ç½® | æ€§èƒ½ |
|------|------|
| Input-only | å¤šæ ·æ€§é«˜ä½†å¯¹é½å·®ï¼ˆROUGEâ†“ï¼‰ |
| Output-only | ç¼ºä¹ä¸Šä¸‹æ–‡ groundingï¼Œæ€§èƒ½å¼± |
| **Global enhancementï¼ˆè¾“å…¥+è¾“å‡ºï¼‰** | âœ… æœ€ä¼˜ï¼Œå…¼é¡¾å¯¹é½ä¸è¡¨è¾¾åŠ› |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **â€œthink-while-generatingâ€ èŒƒå¼ä¼˜äº â€œthink-then-generateâ€**
   - åŠ¨æ€ã€é€ token çš„ reasoning æ›´é€‚åˆå¤„ç†é•¿æ–‡æœ¬ä¸­ä¸æ–­æ¼”å˜çš„å†…å®¹å’Œç”¨æˆ·æ„å›¾ã€‚
   
2. âœ… **FlyThinker æ˜¾è‘—ç¼“è§£â€œcontext driftâ€é—®é¢˜**
   - å¦‚ Figure 4 æ‰€ç¤ºï¼Œåœ¨ç”ŸæˆåæœŸï¼ˆ[200,300] token åŒºé—´ï¼‰ï¼ŒFlyThinker ä»èƒ½ç»´æŒé«˜è´¨é‡ä¸ªæ€§åŒ–è¾“å‡ºï¼Œè€Œ SFTã€CoT ç­‰æ–¹æ³•æ˜æ˜¾é€€åŒ–ã€‚

3. âœ… **è®­ç»ƒä¸æ¨ç†æ•ˆç‡ä¿±ä½³**
   - è®­ç»ƒæ—¶é—´æ¥è¿‘ SFTï¼Œè¿œå¿«äº CoT/Coconutï¼›
   - æ¨ç†å»¶è¿Ÿå‡ ä¹ä¸ SFT ç›¸å½“ï¼Œå…·å¤‡å®é™…éƒ¨ç½²æ½œåŠ›ã€‚

4. âœ… **Reasoner å¯è½»é‡åŒ–**
   - ä½¿ç”¨ 1.5B æˆ–æ›´å°çš„ Reasoner å³å¯è·å¾—è‰¯å¥½æ€§èƒ½ï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯ã€‚

5. âœ… **è·¨æ¶æ„æ³›åŒ–èƒ½åŠ›å¼º**
   - åœ¨ Qwen å’Œ Gemma ç­‰ä¸åŒ backbone ä¸Šå‡å–å¾—ä¸€è‡´å¢ç›Šã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **å¢åŠ å†…å­˜å ç”¨**ï¼šç”±äºå¼•å…¥é¢å¤–çš„ Reasoner æ¨¡å‹ï¼Œæ€»å‚æ•°é‡å’Œæ˜¾å­˜æ¶ˆè€—ä¸Šå‡ï¼›
- **ä¾èµ–é«˜è´¨é‡å†å²æ•°æ®**ï¼šè‹¥ç”¨æˆ·å†å²äº¤äº’ç¨€ç–æˆ–å™ªå£°å¤šï¼Œå¯èƒ½å½±å“ Reasoner å¯¹åå¥½çš„å‡†ç¡®å»ºæ¨¡ï¼›
- **latent reasoning å¯è§£é‡Šæ€§æœ‰é™**ï¼šè™½å¯é€šè¿‡ t-SNE å¯è§†åŒ–å‘ç°ä¸åŒç”¨æˆ·æœ‰ä¸åŒçš„ reasoning è½¨è¿¹ï¼ˆAppendix Hï¼‰ï¼Œä½†å…·ä½“è¯­ä¹‰ä»ä¸å¤Ÿé€æ˜ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¢ç´¢æ›´è½»é‡çš„ Reasoner æ¶æ„**ï¼Œä¾‹å¦‚ MoE æˆ–è’¸é¦æ–¹æ¡ˆï¼›
2. **ç»“åˆ RLHF æˆ– DPO** è¿›ä¸€æ­¥ä¼˜åŒ–åå¥½å¯¹é½ç›®æ ‡ï¼›
3. **æ‰©å±•è‡³å¤šæ¨¡æ€ä¸ªæ€§åŒ–ç”Ÿæˆ** åœºæ™¯ï¼ˆå¦‚å›¾æ–‡ç”Ÿæˆï¼‰ï¼›
4. **æå‡ latent reasoning çš„å¯è§£é‡Šæ€§ä¸å¯æ§æ€§**ï¼Œä¾¿äºäººå·¥å¹²é¢„ä¸è°ƒè¯•ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼šFlyThinker é€šè¿‡åˆ›æ–°çš„ **parallel think-while-generating** æ¶æ„ï¼Œåœ¨ä¿è¯è®­ç»ƒä¸æ¨ç†æ•ˆç‡çš„åŒæ—¶ï¼Œå®ç°äº†æ›´ç²¾å‡†ã€æ›´æŒä¹…çš„ä¸ªæ€§åŒ–é•¿æ–‡æœ¬ç”Ÿæˆï¼Œæ˜¯è¿ˆå‘çœŸæ­£ç”¨æˆ·ä¸­å¿ƒåŒ– LLM çš„é‡è¦ä¸€æ­¥ã€‚

</details>

---

### 7. [Revolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models](https://arxiv.org/abs/2512.07419)

**Authors**: Haidong Kang, Jun Du, Lihong Lin  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.07419v1  

#### Abstract
Mixed-Precision Quantization (MPQ) liberates the Deep Neural Networks (DNNs) from the Out-Of-Memory (OOM) bottleneck, which garnered increasing research attention. However, conventional methods either searched from costly differentiable optimization, which is neither efficient nor flexible, or learn...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRevolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **Mixed-Precision Quantization (MPQ)** æ–¹æ³•å­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š
- **ä¾èµ–ä¸“å®¶è®¾è®¡çš„ä»£ç†ï¼ˆproxyï¼‰è§„åˆ™**ï¼šå¦‚ HAWQ ä½¿ç”¨ Hessian åˆ†æã€OMPQ æ‰‹åŠ¨é€‰æ‹©æƒé‡/æ¿€æ´»ç»Ÿè®¡é‡ï¼Œè¿™äº›éœ€è¦å¤§é‡é¢†åŸŸçŸ¥è¯†å’Œè¯•é”™æˆæœ¬ï¼›
- **é«˜è®¡ç®—å¼€é”€æˆ–å¼ºæ ¡å‡†æ•°æ®ä¾èµ–**ï¼šå¯å¾®æœç´¢æ–¹æ³•ï¼ˆå¦‚ EdMIPSï¼‰è®­ç»ƒæ˜‚è´µï¼›è®­ç»ƒå…è´¹æ–¹æ³•ä»éœ€æ•°åƒæ ·æœ¬å’Œå¤šæ¬¡è¿­ä»£ï¼ˆå¦‚ HAWQ-V2 éœ€ 8,192 æ ¡å‡†æ ·æœ¬ + 50 è½®ä¼˜åŒ–ï¼‰ã€‚

è¯¥è®ºæ–‡æå‡ºï¼š**èƒ½å¦åœ¨æ— éœ€äººå·¥å¹²é¢„å’Œæ¨¡å‹è®­ç»ƒçš„å‰æä¸‹ï¼Œè‡ªåŠ¨å‘ç°é«˜è´¨é‡çš„ MPQ ä»£ç†ï¼Ÿ**

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº† **TAPï¼ˆTraining-free Automatic Proxyï¼‰** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯ï¼š
- åˆ©ç”¨ **Large Language Models (LLMs)** è‡ªåŠ¨ç”Ÿæˆé€‚ç”¨äº MPQ çš„é›¶æˆæœ¬é‡åŒ–ä»£ç†ï¼ˆproxyï¼‰ï¼Œå®Œå…¨æ‘†è„±æ‰‹å·¥è§„åˆ™ï¼›
- å¼•å…¥åŸºäº **Direct Preference Optimization (DPO)** çš„è½»é‡çº§å¼ºåŒ–å­¦ä¹ æœºåˆ¶ï¼Œé€šè¿‡åé¦ˆä¿¡å·ä¼˜åŒ– LLM çš„æç¤ºï¼ˆpromptï¼‰ï¼Œå®ç°â€œæ¨ç†-è¯„ä¼°-æ”¹è¿›â€é—­ç¯ã€‚

#### TAP çš„ä¸‰å¤§ç»„ä»¶ï¼š
1. **Proxy Candidate Generator**ï¼šç”± LLM æ„å»ºï¼Œç”ŸæˆåŒ…å«è‡ªç„¶è¯­è¨€é€»è¾‘ã€å¯æ‰§è¡Œä»£ç å’Œä½å®½åˆ†é…ç­–ç•¥çš„å€™é€‰ä»£ç†ã€‚
2. **Fitness Evaluator**ï¼šåŸºäº Spearman ç›¸å…³ç³»æ•°è¡¡é‡ä»£ç†é¢„æµ‹æ•æ„Ÿåº¦ä¸çœŸå®é‡åŒ–è¯¯å·®çš„ä¸€è‡´æ€§ï¼Œå¹¶ç»“åˆ Top-1 å‡†ç¡®ç‡è¿›è¡Œç»¼åˆè¯„åˆ†ã€‚
3. **DPO Evolution Scheduler**ï¼šåˆ©ç”¨åå¥½å¯¹ï¼ˆpreferred vs. dispreferred proxyï¼‰æ›´æ–° LLM çš„ prompt ç”Ÿæˆç­–ç•¥ï¼Œå½¢æˆæ­£å‘åé¦ˆå¾ªç¯ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ HAWQ, OMPQï¼‰ | TAP |
|------|--------------------------|-----|
| æ˜¯å¦éœ€è¦ä¸“å®¶å‚ä¸ | æ˜¯ï¼ˆä¾èµ–æ‰‹å·¥è§„åˆ™ï¼‰ | å¦ï¼ˆå…¨è‡ªåŠ¨ï¼‰ |
| æ˜¯å¦éœ€è¦è®­ç»ƒ | å¦ï¼ˆä½†éœ€è°ƒä¼˜ï¼‰ | å¦ |
| æ ¡å‡†æ•°æ®é‡ | å¤§ï¼ˆ64~8192 æ ·æœ¬ï¼‰ | æå°ï¼ˆä»… 16 æ ·æœ¬ï¼‰ |
| æ”¶æ•›é€Ÿåº¦ | æ…¢ï¼ˆ2500+ æ›´æ–° / 50 è½®ï¼‰ | å¿«ï¼ˆ5 è½®å†…æ”¶æ•›ï¼‰ |
| æ³›åŒ–èƒ½åŠ› | å¼±ï¼ˆä»»åŠ¡ç‰¹å®šï¼‰ | å¼ºï¼ˆè·¨æ¶æ„ã€è·¨æ•°æ®é›†è¿ç§»ï¼‰ |
| æœç´¢æ•ˆç‡ | ä¸­åˆ°é«˜ï¼ˆGPU å°æ—¶çº§ï¼‰ | æé«˜ï¼ˆÎ¼s çº§æ¨ç†ï¼‰ |

> âœ… **TAP å®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„â€œzero-cost + zero-humanâ€ä»£ç†å‘ç°èŒƒå¼è½¬å˜ã€‚**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ä¸»åŸºå‡†**ï¼šImageNet-1kï¼ˆç”¨äºé‡åŒ–æ€§èƒ½è¯„ä¼°ï¼‰
- **ä»£ç†æœç´¢æ•°æ®é›†**ï¼šCIFAR-10ï¼ˆç”¨äº TAP-C çš„ proxy å‘ç°ï¼‰
- **å…¶ä»–éªŒè¯æ•°æ®é›†**ï¼šCIFAR-10, PASCAL VOC 2007, MS COCO 2017
- **æµ‹è¯•æ¨¡å‹è¦†ç›–å¹¿æ³›æ¶æ„**ï¼š
  - CNNs: ResNet-18/50, MobileNetV2
  - Transformers: ViT-B, DeiT-B, Swin-B

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | è®¾ç½®è¯´æ˜ |
|------|--------|
| **ç¡¬ä»¶å¹³å°** | NVIDIA 3090 GPUï¼ˆ24GBï¼‰ |
| **é‡åŒ–æ–¹å¼** | Mixed-Precision Quantizationï¼ˆW/A ä¸åŒä½å®½ï¼‰ |
| **ç›®æ ‡å‹ç¼©ç‡** | å‚æ•°å‹ç¼©ç‡è¾¾ ~80%-90% |
| **æ ¡å‡†æ ·æœ¬æ•°** | TAP-C ä»…ç”¨ 16 æ ·æœ¬ï¼›å¯¹æ¯”æ–¹æ³•ç”¨ 64~8192 |
| **è¯„ä¼°æŒ‡æ ‡** | 
| - Top-1 Accuracy (%) | ä¸»è¦ç²¾åº¦æŒ‡æ ‡ |
| - #Params (M) | æ¨¡å‹å‚æ•°é‡ |
| - Cost. (GPU hours) | æœç´¢è€—æ—¶ï¼ˆä½“ç°æ•ˆç‡ï¼‰ |
| - Comp. (%) | å‹ç¼©æ¯”ç‡ |
| - BOPs (G) | è¿ç®—é‡ |
| - Runtime (s) | æ¨ç†å»¶è¿Ÿï¼ˆè¡¨7ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–å¤šç§ä¸»æµ MPQ æ–¹æ³•ï¼š
- **Fixed-precision**: PACT, LSQ
- **RL-based**: HAQ
- **Sensitivity-based**: HAWQ, HAWQ-V3
- **Differentiable**: DNAS, EdMIPS, FracBits-SAT, GMPQ
- **Training-free**: OMPQ, EMQ
- **Transformer-specific PTQ**: FQ-ViT, APQ-ViT, OMSE ç­‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3â€“6ï¼‰

#### åœ¨ ResNet-18 ä¸Šçš„è¡¨ç°ï¼ˆImageNetï¼‰
| æ–¹æ³• | Top-1 (%) | Bit (W/A) | Cost. (GPU h) |
|------|-----------|-----------|---------------|
| Full-precision | 73.09 | 32/32 | â€” |
| OMPQ | 72.08 | */5 | 0.45 |
| EMQ | 72.28 | */6 | 0.51 |
| **TAP-C** | **72.93** | ***/8** | **9.17Ã—10â»â¶** |

> â¬†ï¸ **è¶…è¶Šæ‰€æœ‰ baselineï¼Œä¸”æœç´¢æ—¶é—´å¿«çº¦ 50,000 å€ï¼**

#### åœ¨ ResNet-50 ä¸Šçš„è¡¨ç°
| æ–¹æ³• | Top-1 (%) | Bit (W/A) | Cost. (GPU h) |
|------|-----------|-----------|---------------|
| Full-precision | 77.72 | â€” | â€” |
| EMQ | 76.70 | */6 | 0.52 |
| **TAP-C** | **76.81** | ***/8** | **8.75Ã—10â»â¶** |

> âœ… è¾¾åˆ° SOTA ç²¾åº¦ï¼ŒåŒæ—¶å‡ ä¹ä¸ºâ€œç¬æ—¶æœç´¢â€ã€‚

#### Post-Training Quantization ç»“æœï¼ˆResNet-18 & MobileNetV2ï¼‰
| æ–¹æ³• | Model | Top-1 (%) | Data (#samples) |
|------|-------|------------|------------------|
| OMPQ | ResNet-18 | 69.41 | 64 |
| EMQ | ResNet-18 | 69.92 | 64 |
| **TAP-C** | **ResNet-18** | **70.26** | **16** |
| OMPQ | MobileNetV2 | 69.62 | 32 |
| EMQ | MobileNetV2 | 70.75 | 64 |
| **TAP-C** | **MobileNetV2** | **71.81** | **16** |

> ğŸ”¥ **ä»¥æ›´å°‘æ ¡å‡†æ•°æ®å®ç°æ›´é«˜ç²¾åº¦ï¼Œå±•ç°æå¼ºæ•°æ®æ•ˆç‡ã€‚**

#### Transformer æ¶æ„ä¸Šçš„æ³›åŒ–èƒ½åŠ›ï¼ˆViT-B / DeiT-B / Swin-Bï¼‰
| æ–¹æ³• | Comp. Ratio | ViT-B | DeiT-B | Swin-B |
|------|-------------|-------|--------|--------|
| APQ-ViT | 81.25% | 82.21 | 80.42 | 84.18 |
| OMSE | 75% | 73.39 | 79.57 | 48.55 |
| **TAP-C** | **82%** | **83.56** | **81.24** | **83.79** |

> ğŸš€ **é¦–æ¬¡è¯æ˜ LLM-driven proxy å¯æ— ç¼è¿ç§»åˆ°å¤æ‚ Transformer æ¶æ„ï¼Œåœ¨é«˜å‹ç¼©ä¸‹ä¿æŒé¢†å…ˆç²¾åº¦ã€‚**

### æ¶ˆèå®éªŒç»“æœ

#### (1) è¶…å‚æ•° Î± çš„å½±å“ï¼ˆTable 8ï¼‰
- Î± æ§åˆ¶ `sensitivity score` ä¸ `quantization accuracy` çš„æƒè¡¡ã€‚
- å®éªŒè¡¨æ˜ï¼šTAP åœ¨ä¸åŒ Î± ä¸‹è¡¨ç°ç¨³å®šï¼ˆå¦‚ ResNet-18 ä¸Šæ³¢åŠ¨ <1.5%ï¼‰ï¼Œè¯´æ˜å…¶é²æ£’æ€§å¼ºã€‚

#### (2) ä¸åŒ LLM çš„å½±å“ï¼ˆTable 9ï¼‰
| LLM | Average Top-1 (%) |
|------|--------------------|
| Deepseek-chat | 71.44 |
| Qwen3-max | 71.35 |
| Grok 3 | 71.01 |

> âœ… æ€§èƒ½é«˜åº¦ä¸€è‡´ï¼Œè¡¨æ˜ TAP å¯¹åº•å±‚ LLM çš„æ¨ç†é£æ ¼å…·æœ‰å¼ºé€‚åº”æ€§å’Œç¨³å®šæ€§ã€‚

#### (3) æ•ˆç‡åˆ†æï¼ˆTable 7ï¼‰
| æ­¥éª¤ | å¹³å‡è€—æ—¶ (s) |
|------|--------------|
| Proxy Generation | 0.0133 |
| Bit Allocation | 0.0645 |
| **Total** | **< 0.1 s** |

> ğŸ’¡ å®Œæ•´é‡åŒ–æµç¨‹å¯åœ¨ **100ms å†…å®Œæˆ**ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²åœºæ™¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLMs å¯æœ‰æ•ˆæ›¿ä»£äººç±»ä¸“å®¶è¿›è¡Œ MPQ ä»£ç†è®¾è®¡**ï¼šTAP é¦–æ¬¡å®ç°äº†æ— éœ€äººå·¥å¹²é¢„çš„è‡ªåŠ¨åŒ– proxy å‘ç°ã€‚
2. **DPO æ˜¾è‘—æå‡ LLM æ¨ç†è´¨é‡**ï¼šé€šè¿‡æ„å»ºâ€œä»»åŠ¡æ„ŸçŸ¥â€çš„åé¦ˆæœºåˆ¶ï¼Œä½¿ LLM é€æ­¥ç”Ÿæˆæ›´ä¼˜çš„ Chain-of-Thought å¼æ¨ç†è·¯å¾„ã€‚
3. **TAP å…·å¤‡å“è¶Šçš„æ³›åŒ–èƒ½åŠ›**ï¼š
   - è·¨ç½‘ç»œæ¶æ„ï¼ˆCNN â†’ Transformerï¼‰
   - è·¨æ•°æ®é›†ï¼ˆCIFAR-10 â†’ ImageNetï¼‰
   - è·¨ä»»åŠ¡ç±»å‹ï¼ˆQAT â†’ PTQï¼‰
4. **æè‡´é«˜æ•ˆ**ï¼šæœç´¢æˆæœ¬é™è‡³ Î¼s çº§ï¼Œè¿œä½äºç°æœ‰ä»»ä½•å¯å¾®æˆ–è¿›åŒ–æ–¹æ³•ã€‚

### æ–¹æ³•çš„å±€é™æ€§ï¼ˆè§ Appendix Eï¼‰
- å½“å‰ TAP ä¾èµ–äºé¢„å®šä¹‰çš„è¾“å…¥è¾“å‡ºå¥‘çº¦ï¼ˆIO contractï¼‰ï¼Œå°šä¸èƒ½å¤„ç†æç«¯éç»“æ„åŒ–ä»»åŠ¡ï¼›
- å¯¹éå¸¸å°çš„ LLMï¼ˆ<7Bï¼‰æ•ˆæœä¸‹é™æ˜æ˜¾ï¼Œæç¤ºéœ€è¦ä¸€å®šè§„æ¨¡çš„è¯­è¨€æ¨¡å‹æ”¯æŒï¼›
- æš‚æœªæ¢ç´¢åŠ¨æ€è¾“å…¥é•¿åº¦æˆ–å¤æ‚çº¦æŸä¸‹çš„å¤šç›®æ ‡ä¼˜åŒ–ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šç¡¬ä»¶åç«¯ï¼ˆå¦‚ NPUã€MCUï¼‰å®šåˆ¶åŒ– proxy å‘ç°ï¼›
- æ¢ç´¢å¤šæ¨¡æ€ LLM åœ¨è§†è§‰-ç¡¬ä»¶è”åˆå»ºæ¨¡ä¸­çš„æ½œåŠ›ï¼›
- å°† TAP æ¡†æ¶æ¨å¹¿åˆ°å…¶ä»–ç¥ç»ç½‘ç»œå‹ç¼©ä»»åŠ¡ï¼ˆå¦‚å‰ªæã€è’¸é¦ï¼‰ï¼›
- å¼€å‘å¼€æºå·¥å…·é“¾ï¼Œæ¨åŠ¨ LLM-driven è®¾è®¡ç®—æ³•ç”Ÿæ€å‘å±•ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **TAP å¼€åˆ›äº† LLM-driven è‡ªåŠ¨åŒ–æ¨¡å‹å‹ç¼©æ–°èŒƒå¼â€”â€”ç”¨å¤§æ¨¡å‹â€œæ€è€ƒâ€å¦‚ä½•é‡åŒ–æ¨¡å‹ï¼Œåœ¨æ— éœ€è®­ç»ƒã€æ— éœ€ä¸“å®¶çš„æƒ…å†µä¸‹ï¼Œå®ç°é«˜æ•ˆã€ç²¾å‡†ã€é€šç”¨çš„æ··åˆç²¾åº¦é‡åŒ–ã€‚**

</details>

---

### 8. [UniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting](https://arxiv.org/abs/2512.07184)

**Authors**: Da Zhang, Bingyu Li, Zhuyuan Zhao, Junyu Gao, Feiping Nie, Xuelong Li  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.07184v1  

#### Abstract
As multimodal data proliferates across diverse real-world applications, leveraging heterogeneous information such as texts and timestamps for accurate time series forecasting (TSF) has become a critical challenge. While diffusion models demonstrate exceptional performance in generation tasks, their ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šUniDiff: A Unified Diffusion Framework for Multimodal Time Series Forecasting

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰çš„æ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆTSFï¼‰æ¨¡å‹å¤§å¤šå±€é™äºå¤„ç†å•ä¸€æ¨¡æ€çš„æ•°å€¼åºåˆ—ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ç°å®åº”ç”¨ä¸­å¹¿æ³›å­˜åœ¨çš„**å¤šæ¨¡æ€å¼‚æ„ä¿¡æ¯**ï¼ˆå¦‚æ–‡æœ¬æè¿°ã€æ—¶é—´æˆ³ç­‰ï¼‰ã€‚å°½ç®¡æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰åœ¨ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤šæ¨¡æ€TSFä¸­çš„åº”ç”¨ä»å¤„äºåˆçº§é˜¶æ®µï¼Œæ™®éå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

- å¤šæ¨¡æ€èåˆç­–ç•¥ç®€å•ï¼ˆå¦‚ç‰¹å¾æ‹¼æ¥ï¼‰ï¼Œæ— æ³•æ•æ‰åŠ¨æ€è·¨æ¨¡æ€äº¤äº’ï¼›
- æ¡ä»¶æ§åˆ¶æœºåˆ¶ï¼ˆå¦‚Classifier-Free Guidance, CFGï¼‰ä»…æ”¯æŒå•æ¨¡æ€å¼•å¯¼ï¼Œç¼ºä¹å¯¹å¤šæºæ¡ä»¶çš„ç‹¬ç«‹è°ƒæ§èƒ½åŠ›ï¼›
- å¿½è§†å¤–éƒ¨äº‹ä»¶ï¼ˆå¦‚æ–°é—»ã€æŠ¥å‘Šï¼‰å¯¹æ—¶é—´åºåˆ—çªå˜çš„å½±å“ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **UniDiff** â€”â€” ä¸€ä¸ªç»Ÿä¸€çš„æ‰©æ•£æ¡†æ¶ï¼Œç”¨äº**å¤šæ¨¡æ€æ—¶é—´åºåˆ—é¢„æµ‹**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… ç»Ÿä¸€å¹¶è¡Œèåˆæ¨¡å—ï¼ˆUnified Parallel Fusion Moduleï¼‰
- å°†æ—¶é—´åºåˆ—åˆ’åˆ†ä¸ºpatchï¼Œå¹¶é€šè¿‡è½»é‡çº§MLPåµŒå…¥ä¸º`Z`ï¼›
- æ—¶é—´æˆ³ï¼ˆTimestampsï¼‰å’Œæ–‡æœ¬ï¼ˆTextï¼‰åˆ†åˆ«ç¼–ç ä¸º`t`å’Œ`d`ï¼›
- åœ¨æ¯ä¸€å±‚èåˆæ¨¡å—ä¸­ï¼Œé‡‡ç”¨**å•ä¸€äº¤å‰æ³¨æ„åŠ›æœºåˆ¶**ï¼ˆcross-attentionï¼‰å®ç°ä¸‰è€…çš„ä¸€ä½“åŒ–èåˆï¼š
  - Queryæ¥è‡ªæ—¶é—´åºåˆ—åµŒå…¥ `Z`
  - Key å’Œ Value æ¥è‡ª `[t; d]` çš„æ‹¼æ¥
- å®ç°äº†**ä¸€æ­¥å®Œæˆã€å¹¶è¡ŒåŠ¨æ€åŠ æƒ**çš„å¤šæ¨¡æ€èåˆï¼Œé¿å…äº†ä¸²è¡Œå¤„ç†å¸¦æ¥çš„ä¿¡æ¯ç“¶é¢ˆã€‚

#### âœ… é¢å‘å¤šæºæ¡ä»¶çš„è§£è€¦å¼Classifier-Free Guidanceï¼ˆDecoupled CFGï¼‰
- æå‡ºä¸€ç§æ–°å‹CFGæœºåˆ¶ï¼Œå…è®¸åœ¨æ¨ç†æ—¶**ç‹¬ç«‹è°ƒèŠ‚æ–‡æœ¬å’Œæ—¶é—´æˆ³çš„å¼•å¯¼å¼ºåº¦**ï¼ˆ`wt` å’Œ `wd`ï¼‰ï¼›
- è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒæ–‡æœ¬æˆ–æ—¶é—´æˆ³æ¡ä»¶ï¼ˆä½¿ç”¨null tokenï¼‰ï¼Œä½¿æ¨¡å‹èƒ½å­¦ä¹ åˆ°éƒ¨åˆ†æ— æ¡ä»¶ä¸‹çš„é¢„æµ‹èƒ½åŠ›ï¼›
- æ¨ç†å…¬å¼å¦‚ä¸‹ï¼š
  $$
  \hat{y}_k^{\text{guided}} = y_k + w_t(y_k - y_{k,\text{no-T}}) + w_d(y_k - y_{k,\text{no-D}})
  $$
- æ˜¾è‘—æå‡äº†æ¨¡å‹é²æ£’æ€§å’Œå¯æ§æ€§ã€‚

#### âœ… å®Œæ•´çš„å¤šæ¨¡æ€æ‰©æ•£æ¶æ„è®¾è®¡
- åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š
  1. **Modality-specific Encoders**ï¼šåˆ†åˆ«å¤„ç†æ•°å€¼åºåˆ—ã€æ—¶é—´æˆ³ã€æ–‡æœ¬ï¼›
  2. **Unified Fusion Module**ï¼šå®ç°é«˜æ•ˆè·¨æ¨¡æ€äº¤äº’ï¼›
  3. **Prediction Head**ï¼šé€šè¿‡å¯å­¦ä¹ æƒé‡èåˆå„æ¨¡æ€é¢„æµ‹è¾“å‡ºã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | UniDiffä¼˜åŠ¿ |
|------|--------------|------------|
| èåˆæ–¹å¼ | æ‹¼æ¥ã€ä¸²è¡Œèåˆï¼ˆrigid pipelineï¼‰ | å¹¶è¡Œã€è‡ªé€‚åº”èåˆï¼ˆadaptive weightingï¼‰ |
| æ‰©æ•£æ¡ä»¶æ§åˆ¶ | å•ä¸€CFGæƒé‡ï¼Œæ— æ³•åŒºåˆ†æ¨¡æ€é‡è¦æ€§ | è§£è€¦å¼CFGï¼Œç‹¬ç«‹æ§åˆ¶æ¯ç§æ¨¡æ€å½±å“ |
| æ•°å€¼ä¿çœŸåº¦ | LLM-centricæ–¹æ³•å°†æ•°å€¼è½¬ä¸ºæ–‡æœ¬ï¼ŒæŸå¤±ç²¾åº¦ | ä¿ç•™åŸå§‹æ•°å€¼ç»“æ„ï¼Œä¸è¿›è¡Œæ ¼å¼è½¬æ¢ |
| ä¸ç¡®å®šæ€§å»ºæ¨¡ | å¤šæ•°ä¸ºç¡®å®šæ€§é¢„æµ‹ | åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œå¤©ç„¶æ”¯æŒæ¦‚ç‡é¢„æµ‹ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

æ‰€æœ‰å®éªŒåŸºäº **Time-MMD** æ•°æ®é›†ï¼Œè¿™æ˜¯ç›®å‰æœ€å…¨é¢çš„å¤šé¢†åŸŸå¤šæ¨¡æ€æ—¶é—´åºåˆ—åŸºå‡†ï¼Œæ¶µç›–8ä¸ªçœŸå®ä¸–ç•Œé¢†åŸŸï¼š

| Dataset | Domain | Frequency | Length | Dim |
|--------|--------|----------|--------|-----|
| Agriculture | å†œä¸š | Monthly | 496 | 1 |
| Climate | æ°”å€™ | Monthly | 496 | 5 |
| Economy | ç»æµ | Monthly | 423 | 3 |
| Energy | èƒ½æº | Weekly | 1,479 | 9 |
| Environment | ç¯å¢ƒ | Daily | 11,102 | 4 |
| Health | å¥åº· | Weekly | 1,389 | 11 |
| Social Good | ç¤¾ä¼šå…¬ç›Š | Monthly | 900 | 1 |
| Traffic | äº¤é€š | Monthly | 531 | 1 |

> æ–‡æœ¬ä¿¡æ¯æ¥æºäºå†å²æ—¶é—´æ®µå†…çš„ç›¸å…³æŠ¥å‘Šã€æ–°é—»ç­‰ã€‚

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

- **ä»»åŠ¡ç±»å‹**ï¼šå¤šæ­¥é¢„æµ‹ï¼ˆforecasting horizon: 6, 8, 10, 12, 24, 36, 48, 96ï¼‰
- **é¢„å¤„ç†**ï¼š
  - Lookbackçª—å£æ ¹æ®é¢‘ç‡è®¾å®šï¼›
  - æ•°å€¼å½’ä¸€åŒ–ï¼ˆzero-mean, unit-varianceï¼‰ï¼›
  - æ–‡æœ¬è¾“å…¥ä¸ºå‰36ä¸ªåŒºé—´çš„æŠ¥å‘Šæ‹¼æ¥ã€‚
- **æ¨¡å‹å‚æ•°**ï¼š
  - Patchå¤§å°ï¼šP=16ï¼ŒStride=8ï¼›
  - ä½¿ç”¨å†»ç»“çš„BERT-baseä½œä¸ºText Encoderï¼›
  - Fusion Layers: L=6ï¼Œd_model=512ï¼Œ8-head attentionï¼›
  - Diffusion Steps: K=200ï¼Œå™ªå£°è°ƒåº¦ä¸ºquadraticï¼›
  - æ¨ç†ä½¿ç”¨DDIMé‡‡æ ·å™¨ï¼›
  - é»˜è®¤CFGæƒé‡ï¼š`wt=0.5`, `wd=0.8`ï¼›
  - è®­ç»ƒæ—¶dropæ¦‚ç‡ï¼š`puncond_T = puncond_D = 0.1`

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **MSE**: Mean Squared Error
  - **MAE**: Mean Absolute Error
  - æ‰€æœ‰ç»“æœå–ä¸‰æ¬¡è¿è¡Œå¹³å‡å€¼ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

å…±æ¯”è¾ƒå››å¤§ç±»SOTAæ¨¡å‹ï¼š

| ç±»åˆ« | æ–¹æ³• | ç®€è¦è¯´æ˜ |
|------|------|---------|
| **LLM/VLM-based** | CALF, Time-VLM, GPT4MTS | åˆ©ç”¨å¤§è¯­è¨€/è§†è§‰è¯­è¨€æ¨¡å‹å¢å¼ºTSF |
| **Transformer Foundation Models** | Sundial, ROSE, MOIRAI | ä¸“ä¸ºTSè®¾è®¡çš„åŸºç¡€æ¨¡å‹ |
| **CV-inspired Methods** | VisionTS | å°†TSè§†ä¸ºå›¾åƒè¿›è¡Œä¿®å¤é¢„æµ‹ |
| **Generative/Diffusion Models** | MCD-TSF, CSDI | åŸºäºæ‰©æ•£çš„æ¦‚ç‡é¢„æµ‹æ¨¡å‹ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable IIæ‘˜è¦ï¼‰**

åœ¨**8ä¸ªçœŸå®æ•°æ®é›†ä¸Šå¹³å‡è¡¨ç°**ï¼š

| Model | Avg MSE â†“ | Avg MAE â†“ |
|-------|-----------|-----------|
| **UniDiff (Ours)** | **0.213** | **0.294** |
| MCD-TSF (diffusion baseline) | 0.222 | 0.322 |
| Sundial | 0.373 | 0.392 |
| ROSE | 0.290 | 0.336 |
| GPT4MTS | 0.225 | 0.298 |
| CSDI (unimodal diffusion) | 2.096 | 1.048 |

> âœ… UniDiffåœ¨ç»å¤§å¤šæ•°æ•°æ®é›†ä¸Šå–å¾—**SOTAæ€§èƒ½**ï¼Œå°¤å…¶åœ¨Agricultureã€Energyã€Trafficç­‰é¢†åŸŸé¢†å…ˆæ˜¾è‘—ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- ç›¸æ¯”æœ€å¼ºçš„å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹ **MCD-TSF**ï¼š
  - MSEé™ä½çº¦ **4%**ï¼ŒMAEé™ä½çº¦ **8.6%**
  - è¡¨æ˜**ç»Ÿä¸€å¹¶è¡Œèåˆ + è§£è€¦CFG**ä¼˜äºç®€å•çš„æ¡ä»¶æ‹¼æ¥
- ç›¸æ¯”LLM-basedæ–¹æ³•ï¼ˆå¦‚GPT4MTSï¼‰ï¼š
  - æ€»ä½“æ›´ç¨³å®šï¼Œåœ¨éç»æµç±»æ•°æ®ä¸Šä¼˜åŠ¿æ˜æ˜¾
  - éªŒè¯äº†â€œ**ä¸ç ´åæ•°å€¼ç»“æ„**â€çš„è®¾è®¡åˆç†æ€§
- ç›¸æ¯”çº¯æ•°å€¼æ‰©æ•£æ¨¡å‹ **CSDI**ï¼š
  - MSEä¸‹é™è¶…è¿‡ **90%**
  - å¼ºè°ƒäº†**å¤šæ¨¡æ€ä¿¡æ¯æ•´åˆçš„é‡è¦æ€§**

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable IIIï¼‰**

| å˜ä½“ | Avg MSE | Avg MAE | åˆ†æ |
|------|--------|--------|------|
| **Full Model (UniDiff)** | **0.213** | **0.294** | åŸºå‡† |
| w/o Text | 0.347 | 0.394 | æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œè¯´æ˜**æ–‡æœ¬è¯­ä¹‰è‡³å…³é‡è¦** |
| w/o Timestamp | 0.289 | 0.335 | ä¸‹é™æ˜æ˜¾ï¼Œä½“ç°**æ—¶é—´ç»“æ„çš„ä»·å€¼** |
| w/o Both (Unimodal) | 2.096 | 1.048 | é”™è¯¯é£™å‡ï¼Œè¯æ˜**å¤šæ¨¡æ€å¿…è¦æ€§** |
| Sequential Fusion | 0.222 | 0.322 | å·®äºå¹¶è¡Œèåˆï¼ŒéªŒè¯**å¹¶è¡Œè®¾è®¡ä¼˜è¶Šæ€§** |
| Simple Fusion (concat) | 0.290 | 0.336 | è¿œå·®äºcross-attentionï¼Œè¯´æ˜**é«˜çº§èåˆæœºåˆ¶å…³é”®** |
| Coupled CFG | 0.238 | 0.312 | å·®äºè§£è€¦CFGï¼Œè¡¨æ˜**ç‹¬ç«‹æ§åˆ¶æ›´ä¼˜** |

> ğŸ” **å®šé‡åˆ†æç»“è®º**ï¼šæ¯ä¸ªç»„ä»¶éƒ½å¯¹æœ€ç»ˆæ€§èƒ½æœ‰æ˜¾è‘—è´¡çŒ®ï¼Œå°¤å…¶æ˜¯å¤šæ¨¡æ€è¾“å…¥å’Œè§£è€¦CFGã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **å¤šæ¨¡æ€ä¿¡æ¯æ˜¾è‘—æå‡é¢„æµ‹å‡†ç¡®æ€§**  
   ç‰¹åˆ«æ˜¯å½“çªå‘äº‹ä»¶å‘ç”Ÿæ—¶ï¼ˆå¦‚æµæ„Ÿçˆ†å‘ï¼‰ï¼Œæ–‡æœ¬æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯èƒ½å¤Ÿå¸®åŠ©æ¨¡å‹æå‰æ„ŸçŸ¥å¼‚å¸¸ã€‚

2. **å¹¶è¡Œèåˆæœºåˆ¶ä¼˜äºä¸²è¡Œæˆ–æ‹¼æ¥æ–¹å¼**  
   cross-attentionèƒ½åŠ¨æ€åˆ†é…ä¸åŒæ¨¡æ€çš„æ³¨æ„åŠ›æƒé‡ï¼Œé€‚åº”ä¸åŒçš„é¢„æµ‹åœºæ™¯ï¼ˆevent-driven vs pattern-drivenï¼‰ã€‚

3. **è§£è€¦å¼CFGæä¾›æ›´å¼ºçš„æ§åˆ¶åŠ›ä¸é²æ£’æ€§**  
   å…è®¸åœ¨æ¨ç†æ—¶çµæ´»è°ƒæ•´æ–‡æœ¬/æ—¶é—´æˆ³çš„å½±å“ç¨‹åº¦ï¼Œé˜²æ­¢å™ªå£°æ–‡æœ¬è¯¯å¯¼é¢„æµ‹ã€‚

4. **UniDiffå…¼å…·é«˜ç²¾åº¦ä¸é«˜æ•ˆç‡**  
   å¦‚å›¾5æ‰€ç¤ºï¼ŒUniDiffåœ¨ä¿æŒæœ€ä½è¯¯å·®çš„åŒæ—¶ï¼Œè®¡ç®—å¤æ‚åº¦ï¼ˆMACsï¼‰ã€å†…å­˜å ç”¨å’Œæ¨ç†é€Ÿåº¦å‡ä¼˜äºå¤šæ•°SOTAæ¨¡å‹ã€‚

5. **æ—¶é—´æˆ³æƒé‡ Î» åˆ†ææ˜¾ç¤ºå…¶ç§¯æä½œç”¨**  
   å½“ `Î» âˆˆ [0.8, 1.0]` æ—¶æ€§èƒ½æœ€ä½³ï¼Œè¿‡é«˜åè€Œè½»å¾®ä¸‹é™ï¼Œè¯´æ˜éœ€å¹³è¡¡å„æ¨¡æ€è´¡çŒ®ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- å½“å‰ä»…æ•´åˆäº†**æ–‡æœ¬ + æ—¶é—´æˆ³ + æ•°å€¼åºåˆ—**ä¸‰ç§æ¨¡æ€ï¼Œå°šæœªæ‰©å±•è‡³å›¾åƒã€éŸ³é¢‘ç­‰å…¶ä»–å½¢å¼ï¼›
- æ–‡æœ¬ç¼–ç ä¾èµ–é¢„è®­ç»ƒBERTï¼Œå¯èƒ½å—é™äºé¢†åŸŸé€‚é…æ€§ï¼›
- æ¨¡å‹è®­ç»ƒéœ€è¦å¤§é‡å¤šæ¨¡æ€å¯¹é½æ•°æ®ï¼Œåœ¨æŸäº›é¢†åŸŸè·å–æˆæœ¬è¾ƒé«˜ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ‰©å±•è‡³æ›´å¤šæ¨¡æ€ï¼ˆå¦‚å›¾åƒã€è¯­éŸ³ï¼‰ï¼›
- æ¢ç´¢æ›´é«˜æ•ˆçš„è½»é‡åŒ–ç‰ˆæœ¬ä»¥é€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡ï¼›
- ç»“åˆå› æœæ¨ç†æœºåˆ¶ï¼Œæå‡å¯¹å¤–éƒ¨å¹²é¢„çš„è§£é‡Šèƒ½åŠ›ï¼›
- åº”ç”¨äºå®æ—¶å†³ç­–ç³»ç»Ÿï¼ˆå¦‚é‡‘èäº¤æ˜“ã€æ™ºèƒ½äº¤é€šï¼‰ã€‚

---

## æ€»ç»“

âœ… **UniDiff æ˜¯é¦–ä¸ªå°†æ‰©æ•£æ¨¡å‹ä¸å¤šæ¨¡æ€æ—¶é—´åºåˆ—é¢„æµ‹æ·±åº¦ç»“åˆçš„ç»Ÿä¸€æ¡†æ¶**ï¼Œé€šè¿‡**å¹¶è¡Œäº¤å‰æ³¨æ„åŠ›èåˆ**å’Œ**è§£è€¦å¼CFGæœºåˆ¶**ï¼Œå®ç°äº†å¯¹æ–‡æœ¬ã€æ—¶é—´æˆ³å’Œæ•°å€¼åºåˆ—çš„é«˜æ•ˆååŒå»ºæ¨¡ã€‚å®éªŒè¯æ˜å…¶åœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¾¾åˆ°SOTAæ°´å¹³ï¼Œä¸”å…·å¤‡è‰¯å¥½çš„å¯è§£é‡Šæ€§ä¸å®ç”¨æ€§ï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½é¢„æµ‹ç³»ç»Ÿæä¾›äº†å¼ºæœ‰åŠ›çš„èŒƒå¼æ”¯æŒã€‚

</details>

---

### 9. [GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory](https://arxiv.org/abs/2512.07782)

**Authors**: Jiaxu Liu, Yuhe Bai, Christos-Savvas Bouganis  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.07782v1  

#### Abstract
Modern autoregressive models rely on attention, yet the Softmax full attention in Transformers scales quadratically with sequence length. Sliding Window Attention (SWA) achieves linear-time encoding/decoding by constraining the attention pattern, but under an \textit{Associative Memory} interpretati...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGatedFWA: Linear Flash Windowed Attention with Gated Associative Memory

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£è‡ªå›å½’æ¨¡å‹ï¼ˆå¦‚Transformerï¼‰ä¾èµ–äº **Softmax full attention**ï¼Œå…¶è®¡ç®—å¤æ‚åº¦éšåºåˆ—é•¿åº¦å‘ˆ**äºŒæ¬¡æ–¹å¢é•¿**ï¼ˆ$O(N^2)$ï¼‰ï¼Œä¸¥é‡é™åˆ¶äº†é•¿åºåˆ—å»ºæ¨¡çš„æ•ˆç‡ã€‚ä¸ºç¼“è§£æ­¤é—®é¢˜ï¼Œ**Sliding Window Attention (SWA)** è¢«æå‡ºä»¥å®ç°çº¿æ€§æ—¶é—´è§£ç ï¼ˆ$O(Nw)$ï¼‰ï¼Œä½†ä½œè€…é€šè¿‡**å…³è”è®°å¿†ï¼ˆAssociative Memoryï¼‰è§†è§’**åˆ†æå‘ç°ï¼š

- **Softmax Attention**ï¼šç”±äºå½’ä¸€åŒ–æœºåˆ¶ï¼Œæ¯æ­¥çš„è®°å¿†æ›´æ–°è¢«ä¸æ–­ç¼©å°ï¼Œå¯¼è‡´**æ¢¯åº¦æ¶ˆå¤±ï¼ˆgradient vanishingï¼‰**ã€‚
- **SWA**ï¼šé‡‡ç”¨å·®åˆ†å¼æ›´æ–°ï¼ˆdifference-style updateï¼‰ï¼Œå…¶ä¼˜åŒ–ç›®æ ‡åœ¨æ•°å­¦ä¸Šæ˜¯**æ— ç•Œçš„ï¼ˆunboundedï¼‰**ï¼Œå®¹æ˜“å¼•å‘**æ¢¯åº¦ä¸ç¨³å®šï¼ˆgradient instabilityï¼‰** å’Œè®°å¿†çˆ†ç‚¸ã€‚

å› æ­¤ï¼Œè®ºæ–‡æ—¨åœ¨è®¾è®¡ä¸€ç§æ—¢èƒ½ä¿æŒ SWA çš„çº¿æ€§æ•ˆç‡ï¼Œåˆèƒ½ç¨³å®šè®°å¿†æ›´æ–°ã€æ§åˆ¶æ¢¯åº¦æµçš„æ–°æ³¨æ„åŠ›æœºåˆ¶ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šGatedFWA
ä½œè€…æå‡ºäº† **GatedFWA**ï¼ˆGated Flash Windowed Attentionï¼‰ï¼Œä¸€ç§åŸºäº**é—¨æ§å…³è”è®°å¿†**çš„çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

- **é—¨æ§è¡°å‡æœºåˆ¶ï¼ˆMemory-Gated Decayï¼‰**ï¼š
  - ä¸ºæ¯ä¸ª token å’Œ attention head å¼•å…¥ä¸€ä¸ªè½»é‡çº§çš„éè´Ÿé—¨æ§ï¼ˆnon-negative gateï¼‰ã€‚
  - è¯¥é—¨æ§æ²¿åºåˆ—ç´¯ç§¯å½¢æˆä¸€ä¸ª**è¡°å‡åç½®ï¼ˆdecay biasï¼‰**ï¼Œå¹¶æ³¨å…¥åˆ° attention logits ä¸­ã€‚
  - åœ¨å…³è”è®°å¿†æ¡†æ¶ä¸‹ï¼Œè¿™ç›¸å½“äºå¯¹è®°å¿†çŠ¶æ€æ–½åŠ äº†ä¸€ä¸ª**å¯å­¦ä¹ çš„æ”¶ç¼©æ“ä½œï¼ˆlearnable contractionï¼‰**ï¼Œå³ $M_t \leftarrow \exp(-\alpha) M_{t-1} + \cdots$ï¼Œä»è€Œè½¯æ€§åœ°é—å¿˜æ— å…³å†å²ã€‚

- **ç¡¬ä»¶å¯¹é½è®¾è®¡ï¼ˆHardware-Aligned Implementationï¼‰**ï¼š
  - **èåˆé¢„å¤„ç†ï¼ˆFused One-Pass Preprocessingï¼‰**ï¼šé€šè¿‡ä¸€æ¬¡æ‰«æå®Œæˆé—¨æ§è®¡ç®—åŠå…¶å‰ç¼€å’Œï¼Œé¿å…ä¸­é—´å¼ é‡å­˜å‚¨ï¼Œæå‡ I/O æ•ˆç‡ã€‚
  - **FlashAttention å…¼å®¹å†…æ ¸**ï¼šå°†é—¨æ§åç½®åœ¨æ»‘åŠ¨çª—å£æ©ç ä¸‹æ³¨å…¥ FlashAttention æµæ°´çº¿ï¼Œä¿æŒæ•°å€¼ç¨³å®šæ€§ä¸é«˜ååã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | Softmax | SWA | GatedFWA |
|------|--------|-----|---------|
| æ—¶é—´å¤æ‚åº¦ | $O(N^2)$ | $O(Nw)$ | $O(Nw)$ âœ… |
| å†…å­˜å¤æ‚åº¦ | $O(N^2)$ | $O(Nd + Nw)$ | $O(Nd + Nw)$ âœ… |
| æ¢¯åº¦ç¨³å®šæ€§ | âŒ æ¢¯åº¦æ¶ˆå¤± | âŒ æ¢¯åº¦ä¸ç¨³å®š | âœ… å¯æ§æ¢¯åº¦æµ |
| é•¿ç¨‹ä¾èµ–ä¿ç•™ | âš ï¸ å½’ä¸€åŒ–å‰Šå¼± | âš ï¸ å·®åˆ†æ”¾å¤§å™ªå£° | âœ… é—¨æ§é€‰æ‹©æ€§ä¿ç•™ |
| ç¡¬ä»¶å‹å¥½æ€§ | âœ…ï¼ˆFAä¼˜åŒ–åï¼‰ | âœ… | âœ…ï¼ˆå…¼å®¹FAï¼‰ |

æ­¤å¤–ï¼ŒGatedFWA å¯ä½œä¸º **NSAï¼ˆNative Sparse Attentionï¼‰ç­‰å‹ç¼©/é€‰æ‹©æ–¹æ³•ä¸­çš„å±€éƒ¨æ¨¡å—**æ— ç¼æ›¿æ¢ SWAï¼Œè¿›ä¸€æ­¥å¢å¼ºå…¨å±€ä¸Šä¸‹æ–‡åˆ©ç”¨èƒ½åŠ›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è¯­è¨€å»ºæ¨¡åŸºå‡†**ï¼š
  - **WikiText103**ï¼šæ ‡å‡†è¯­è¨€å»ºæ¨¡æ•°æ®é›†ã€‚
  - **OpenWebText**ï¼šå¤§è§„æ¨¡å¼€æ”¾ç½‘é¡µæ–‡æœ¬ï¼Œç”¨äºè®­ç»ƒä¸è¯„ä¼°ã€‚
- **ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°**ï¼š
  - åŒ…æ‹¬ **PiQA, HellaSwag, WinoGrande, ARC-e/c, COPA, OpenBookQA, SciQA, BoolQ** ç­‰å¸¸è¯†æ¨ç†ä¸é—®ç­”ä»»åŠ¡ã€‚
- **å¬å›å¯†é›†å‹ä»»åŠ¡**ï¼š
  - **MQARï¼ˆMulti-Query Associative Recallï¼‰**ï¼šæµ‹è¯•æ¨¡å‹å¯¹é”®å€¼å¯¹è®°å¿†ä¸æ£€ç´¢çš„èƒ½åŠ›ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹è§„æ¨¡**ï¼š120M å’Œ 360M å‚æ•°é‡ã€‚
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼š1024 åˆ° 4096ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **è¯­è¨€å»ºæ¨¡**ï¼šéªŒè¯é›†æŸå¤±ï¼ˆValidation Loss â†“ï¼‰
  - **ä¸‹æ¸¸ä»»åŠ¡**ï¼šå‡†ç¡®ç‡ï¼ˆAccuracy â†‘ï¼‰ï¼Œéƒ¨åˆ†ä»»åŠ¡ä½¿ç”¨å½’ä¸€åŒ–å‡†ç¡®ç‡ï¼ˆacc_normï¼‰
  - **æ•ˆç‡å¯¹æ¯”**ï¼šå‰å‘/åå‘ä¼ æ’­æ—¶é—´ã€ååé‡ï¼ˆtokens/secï¼‰ã€é¢„å¤„ç†å¼€é”€
- **å®ç°ç»†èŠ‚**ï¼š
  - æ‰€æœ‰æ¨¡å‹å‡åŸºäº LLaMA æ¶æ„ä¿®æ”¹ã€‚
  - ä½¿ç”¨ Triton å®ç°é«˜æ•ˆå†…æ ¸ï¼Œæ”¯æŒ FlashAttention é£æ ¼èåˆã€‚
  - å¯¹æ¯”æ–¹æ³•åŒ…æ‹¬ï¼šRetNet, Mamba, RWKV, GLA, Transformer (LLaMA), SWA, SWA+NSA ç­‰ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | ç±»å‹ | æ˜¯å¦çº¿æ€§ |
|--------|------|----------|
| Softmax (FA) | å…¨å±€æ³¨æ„åŠ› | å¦ |
| SWA | å±€éƒ¨æ»‘çª— | æ˜¯ |
| SWA + NSA | æ»‘çª— + å‹ç¼©é€‰æ‹© | æ˜¯ |
| Mamba / GLA / RWKV | SSM æˆ–çº¿æ€§æ³¨æ„åŠ› | æ˜¯ |
| RetNet | å¾ªç¯å¢å¼ºæ³¨æ„åŠ› | æ˜¯ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰è¯­è¨€å»ºæ¨¡æŸå¤±ï¼ˆTab. 1 & Fig. 5ï¼‰
åœ¨ OpenWebText ä¸Šè®­ç»ƒï¼ŒGatedFWA æ˜¾è‘—ä¼˜äºå„ç±»åŸºçº¿ï¼š

| æ¶æ„ | #Param (M) | N=1024 Val Loss | N=4096 Val Loss |
|------|------------|------------------|------------------|
| Transformer (LLaMA) | 124.4 | 3.247 | 3.273 |
| + SWA | 124.4 | 3.248 | 3.274 |
| + SWA + NSA | 125.4 | 3.240 | 3.248 |
| **+ GatedFWA** | **125.1** | **3.237** | **3.255** |
| **+ GatedFWA + NSA** | **126.1** | **3.215** | **3.230** |

> âœ… åœ¨é•¿ä¸Šä¸‹æ–‡ï¼ˆN=4096ï¼‰ä¸‹ï¼ŒGatedFWA + NSA å°†éªŒè¯æŸå¤±ä» 3.273 é™è‡³ **2.842**ï¼ˆ360M æ¨¡å‹ï¼‰ï¼Œæ˜¾è‘—é¢†å…ˆã€‚

#### ï¼ˆ2ï¼‰ä¸‹æ¸¸ä»»åŠ¡è¡¨ç°ï¼ˆTab. 2ï¼‰
åœ¨å¤šä¸ªå¸¸è¯†æ¨ç†ä»»åŠ¡ä¸Šï¼ŒGatedFWA æ¨¡å‹å¹³å‡å‡†ç¡®ç‡æå‡æ˜æ˜¾ï¼š

| æ¶æ„ | å¹³å‡å¾—åˆ† â†‘ |
|------|-----------|
| Transformer (LLaMA) | 50.41 |
| + SWA | 50.28 |
| + SWA + NSA | 51.03 |
| **+ GatedFWA** | **50.98** |
| **+ GatedFWA + NSA** | **51.65** |

> âœ… ç›¸è¾ƒäºåŸºç¡€ Transformerï¼ŒGatedFWA+NSA å®ç° **2.45% çš„ç›¸å¯¹æå‡**ã€‚

#### ï¼ˆ3ï¼‰MQAR å›è°ƒç‡ï¼ˆFig. 8ï¼‰
åœ¨ä¸åŒåºåˆ—é•¿åº¦ï¼ˆ128â€“512ï¼‰å’Œç»´åº¦ï¼ˆ64â€“512ï¼‰ä¸‹çš„å¤šæŸ¥è¯¢å›å¿†ä»»åŠ¡ä¸­ï¼š
- GatedFWA åœ¨æ‰€æœ‰é…ç½®ä¸‹å‡ä¼˜äº SWA å’Œå¤šç§ SSMï¼ˆå¦‚ Mamba, RWKVï¼‰ã€‚
- å³ä½¿åœ¨å°æ¨¡å‹ï¼ˆd=64ï¼‰å’Œé•¿åºåˆ—ï¼ˆN=512ï¼‰ä¸‹ä»ä¿æŒé«˜ recallï¼Œè¡¨æ˜å…¶æ›´å¼ºçš„è®°å¿†ä¿æŒèƒ½åŠ›ã€‚

#### ï¼ˆ4ï¼‰æ•ˆç‡ä¸ååé‡ï¼ˆFig. 10ï¼‰
- **å‰å‘/åå‘é€Ÿåº¦**ï¼šGatedFWA ä¸ SWA æ¥è¿‘ï¼Œåœ¨ N > 64K æ—¶æ¯” FA å¿«çº¦ **30Ã—**ã€‚
- **é¢„å¤„ç†å¼€é”€**ï¼šåœ¨ N=64K ä¸‹ï¼ŒGatedFWA çš„é—¨æ§é¢„å¤„ç†ä»…éœ€ **0.3ms**ï¼Œè¿œä½äº PyTorch åŸºçº¿ï¼ˆ2.9msï¼‰ã€‚
- **ååé‡**ï¼šä¸ SWA+NSA ç›¸å½“ï¼Œä¸”æ¯” FA é«˜å‡º **3.1â€“5.4Ã—**ã€‚

#### ï¼ˆ5ï¼‰æ¶ˆèå®éªŒï¼ˆFig. 9ï¼‰
- å›ºå®š amplitude $\beta=1$ vs. å¯å­¦ä¹  $\beta$ï¼š
  - å¯å­¦ä¹  $\beta$ åœ¨ GatedFWA å’Œ GatedFWA+NSA ä¸Šå‡å¸¦æ¥æ›´ä¼˜æ”¶æ•›ä¸æ›´ä½æŸå¤±ã€‚
  - è¡¨æ˜ amplitude æ§åˆ¶é—¨æ§åˆ‡æ¢é”åº¦ï¼Œæœ‰åŠ©äºé€‚åº”ä¸åŒ token çš„æ³¨æ„åŠ›è·¨åº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä»å…³è”è®°å¿†è§†è§’çœ‹ï¼ŒSoftmax å’Œ SWA åˆ†åˆ«å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±ä¸ä¸ç¨³å®šçš„æœ¬è´¨ç¼ºé™·**ã€‚
2. **GatedFWA é€šè¿‡å¼•å…¥å¯å­¦ä¹ é—¨æ§è¡°å‡ï¼Œå®ç°äº†å¯¹è®°å¿†æ›´æ–°çš„â€œè½¯æ“¦é™¤â€**ï¼Œæ—¢é˜²æ­¢äº† SWA çš„æ— ç•Œå¢é•¿ï¼Œåˆé¿å…äº† Softmax çš„è¿‡åº¦æŠ‘åˆ¶ã€‚
3. **é—¨æ§æœºåˆ¶ä½¿å¾—æ¢¯åº¦è·¯å¾„å¯æ§**ï¼šæ¨¡å‹å¯å­¦ä¹ åœ¨é‡è¦ä½ç½®ä¿ç•™æ¢¯åº¦ï¼Œåœ¨æ— å…³ä½ç½®åˆ‡æ–­ï¼Œå¢å¼ºäº†ä¿¡ç”¨åˆ†é…ï¼ˆcredit assignmentï¼‰ã€‚
4. **GatedFWA å®Œå…¨å…¼å®¹ FlashAttention å’Œ NSA ç­‰ç¨€ç–æ¶æ„**ï¼Œå¯åœ¨ä¸å¢åŠ å¤æ‚åº¦çš„å‰æä¸‹æå‡æ€§èƒ½ã€‚
5. **å®éªŒè¡¨æ˜ GatedFWA åœ¨è¯­è¨€å»ºæ¨¡ã€å¸¸è¯†æ¨ç†ã€é•¿ç¨‹å›å¿†ç­‰ä»»åŠ¡ä¸Šå…¨é¢è¶…è¶Šä¸»æµçº¿æ€§ä¸äºŒæ¬¡æ³¨æ„åŠ›æ–¹æ³•**ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ç”µè·¯å¤æ‚åº¦é™åˆ¶åœ¨ TCâ°**ï¼šå°½ç®¡å¼•å…¥äº†æ•°æ®ä¾èµ–é—¨æ§ï¼Œä½†ç”±äºå…¶æ›´æ–°ä»æ˜¯**å¯¹è§’çŸ©é˜µä¹˜æ³•**ï¼ˆdiagonal gatingï¼‰ï¼Œæ— æ³•è§£å†³éœ€è¦éäº¤æ¢æ“ä½œçš„ NCÂ¹ å®Œå…¨é—®é¢˜ï¼ˆå¦‚ Sâ‚… ç½®æ¢è¿½è¸ªï¼‰ã€‚
- **è¡¨è¾¾åŠ›å—é™äºå†™å…¥-only è®°å¿†æœºåˆ¶**ï¼šç¼ºä¹çœŸæ­£çš„è¯»-å†™äº¤äº’ï¼ˆread-write memoryï¼‰ï¼Œéš¾ä»¥æ¨¡æ‹Ÿå¤æ‚çš„çŠ¶æ€è½¬ç§»ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ç»“åˆ **Delta Rule** ç­‰è¯»å†™è®°å¿†æœºåˆ¶ï¼Œæå‡è‡³ NCÂ¹ å¤æ‚åº¦ç±»ï¼Œæ”¯æŒæ›´å¤æ‚çš„é¡ºåºä¾èµ–å»ºæ¨¡ã€‚
- è®¾è®¡æ”¯æŒéå¯¹è§’ã€éäº¤æ¢çŠ¶æ€è½¬ç§»çš„é«˜æ•ˆå†…æ ¸ï¼Œçªç ´å½“å‰å¹¶è¡ŒåŒ–é™åˆ¶ã€‚
- å°† GatedFWA æ‰©å±•è‡³è§†è§‰-è¯­è¨€ã€äº‹ä»¶æµç­‰å¤šæ¨¡æ€è‡ªå›å½’åœºæ™¯ã€‚

---

> **æ€»ç»“**ï¼šGatedFWA æ˜¯ä¸€ç§å…¼å…·**ç†è®ºæ´å¯Ÿ**ï¼ˆä»å…³è”è®°å¿†è§£é‡Šæ¢¯åº¦é—®é¢˜ï¼‰ä¸**å·¥ç¨‹å®è·µä»·å€¼**ï¼ˆFlashAttention å…¼å®¹ã€ä½å¼€é”€ï¼‰çš„çº¿æ€§æ³¨æ„åŠ›æ–°èŒƒå¼ï¼Œåœ¨ä¿æŒ SWA æ•ˆç‡çš„åŒæ—¶æ˜¾è‘—æå‡äº†è®­ç»ƒç¨³å®šæ€§ä¸é•¿ç¨‹å»ºæ¨¡èƒ½åŠ›ï¼Œæ˜¯å½“å‰é«˜æ•ˆ LLM æ¶æ„ä¸­çš„æœ‰åŠ›å€™é€‰æ–¹æ¡ˆã€‚

</details>

---

### 10. [Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients](https://arxiv.org/abs/2512.06990)

**Authors**: Krishna Arun, Moinak Bhattachrya, Paras Goel  
**Category**: cs.AI  
**Published**: 2025-12-09  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.06990v1  

#### Abstract
Currently, there is a noticeable lack of AI in the medical field to support doctors in treating heterogenous brain tumors such as Glioblastoma Multiforme (GBM), the deadliest human cancer in the world with a five-year survival rate of just 5.1%. This project develops an AI system offering the only e...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³**èƒ¶è´¨æ¯ç»†èƒç˜¤ï¼ˆGlioblastoma Multiforme, GBMï¼‰è¯Šæ–­ä¸æ²»ç–—è§„åˆ’ä¸­ç¼ºä¹é«˜æ•ˆã€ç«¯åˆ°ç«¯AIç³»ç»Ÿæ”¯æŒ**çš„ä¸´åºŠç—›ç‚¹ã€‚å…·ä½“åŒ…æ‹¬ï¼š
- **è¯Šæ–­é˜¶æ®µ**ï¼šä¼ ç»Ÿå¤§å‹æ¨¡å‹ï¼ˆå¦‚ViT-L/16ï¼‰å‚æ•°é‡å·¨å¤§ï¼ˆ>3äº¿ï¼‰ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼ˆçº¦$102,420ï¼‰ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™åœ°åŒºéƒ¨ç½²ã€‚
- **æ²»ç–—é¢„æµ‹é˜¶æ®µ**ï¼šç°æœ‰ç‰©ç†é©±åŠ¨æ¨¡å‹ï¼ˆå¦‚PDEã€Lattice Boltzmannï¼‰éœ€æ•°åè‡³æ•°ç™¾å°æ—¶æ¨¡æ‹Ÿè‚¿ç˜¤ç”Ÿé•¿ï¼Œä¸”æ— æ³•å»ºæ¨¡æ‰‹æœ¯ã€æ”¾ç–—ã€åŒ–ç–—ç­‰å¹²é¢„æªæ–½çš„å½±å“ï¼Œä¸´åºŠå®ç”¨æ€§ä½ã€‚
- **ä¸ªæ€§åŒ–æ²»ç–—è§„åˆ’ç¼ºå¤±**ï¼šç¼ºä¹èƒ½å¤Ÿè”åˆä¼˜åŒ–æ‰‹æœ¯åˆ‡é™¤ä½ç½®å¹¶åŠ¨æ€åé¦ˆè°ƒæ•´çš„æ™ºèƒ½ç³»ç»Ÿã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æå‡ºåä¸º **Brainstorm** çš„é¦–ä¸ª**ç«¯åˆ°ç«¯å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ¡†æ¶**ï¼Œæ¶µç›–è¯Šæ–­ä¸æ²»ç–—ä¸¤å¤§é˜¶æ®µï¼š

#### ï¼ˆ1ï¼‰è¯Šæ–­é˜¶æ®µï¼šåŸºäºåºåˆ—å†³ç­–çš„è½»é‡åŒ–åˆ†ç±»é“¾
- æ„å»ºç”± **5ä¸ªå°å‹CNN/SVMæ¨¡å‹ç»„æˆçš„çº§è”åˆ†ç±»æµæ°´çº¿**ï¼Œé€æ­¥ç¼©å°ç–¾ç—…èŒƒå›´ï¼š
  1. Mass Detection CNN â†’ æ˜¯å¦å­˜åœ¨å¼‚å¸¸è´¨é‡
  2. Tumor Confirmation CNN â†’ æ˜¯å¦ä¸ºè‚¿ç˜¤
  3. nnU-Net Segmentation â†’ åˆ†å‰²æ°´è‚¿ã€å¢å¼ºè‚¿ç˜¤ã€æ ¸å¿ƒåŒºåŸŸ
  4. SVM Malignancy Classifier â†’ è¾“å…¥30é¡¹å®šé‡radiomicç‰¹å¾åˆ¤æ–­è‰¯æ¶æ€§
  5. Multi-class CNN â†’ æœ€ç»ˆåˆ†ç±»ä¸ºGBMã€Meningiomaã€Schwannomaã€Neurocytomaæˆ–å…¶ä»–
- åˆ›æ–°æ€§åœ°é‡‡ç”¨â€œåˆ†è€Œæ²»ä¹‹â€ç­–ç•¥ï¼Œé¿å…å•ä¸€å·¨å‹æ¨¡å‹ã€‚

#### ï¼ˆ2ï¼‰æ²»ç–—è§„åˆ’é˜¶æ®µï¼šç”Ÿæˆå¼MARLé—­ç¯ä¼˜åŒ–ç³»ç»Ÿ
- å¼•å…¥ä¸‰ä¸ªå›¾åƒåˆ°å›¾åƒï¼ˆimage-to-imageï¼‰ç”Ÿæˆæ¨¡å‹ä¾æ¬¡æ¨¡æ‹Ÿæ²»ç–—è¿‡ç¨‹ï¼š
  1. **Resection Model**ï¼šåŸºäºDiffusion Modelé¢„æµ‹æœ¯åMRI
  2. **Radiotherapy Model**ï¼šæå‡ºä¸€ç§æ–°å‹**Spatio-Temporal Vision Transformer**æ¶æ„ï¼Œé¢„æµ‹å¤šæ—¶é—´ç‚¹æ”¾ç–—åè‚¿ç˜¤æ¼”å˜
  3. **Chemotherapy Model**ï¼šå¦ä¸€ä¸ªDiffusion Modelç”ŸæˆåŒ–ç–—åçš„MRI
- ä½¿ç”¨ä¸€ä¸ª**CNNç”Ÿå­˜ç‡è®¡ç®—å™¨**è¯„ä¼°ç”Ÿæˆçš„post-treatment MRIå¯¹åº”çš„é¢„ä¼°ç”Ÿå­˜å¤©æ•°
- è‹¥é¢„æµ‹ç”Ÿå­˜ç‡æœªè¾¾åˆ°åŒ»ç”Ÿè®¾å®šç›®æ ‡Â±15%ï¼Œåˆ™é€šè¿‡**Proximal Policy Optimization (PPO)** åé¦ˆå¾ªç¯è¿­ä»£æœç´¢æ›´ä¼˜çš„åˆ‡é™¤æ–¹æ¡ˆ

#### ï¼ˆ3ï¼‰æ•°æ®å¢å¼ºåˆ›æ–°
- åœ¨é¢„å¤„ç†ä¸­å¼•å…¥**è´´è¿‘çœŸå®åŒ»ç–—åœºæ™¯çš„æ•°æ®å¢å¼ºæŠ€æœ¯**ï¼Œå¦‚ï¼š
  - Random bias fieldï¼ˆæ¨¡æ‹Ÿç£åœºä¸å‡ï¼‰
  - Elastic deformationï¼ˆæ¨¡æ‹Ÿæœ¯ä¸­è„‘ç§»ä½ï¼‰
  - Gaussian noiseï¼ˆæ¨¡æ‹Ÿè€æ—§è®¾å¤‡ä½åˆ†è¾¨ç‡æˆåƒï¼‰
- æ˜¾è‘—æå‡æ¨¡å‹åœ¨éç†æƒ³å½±åƒæ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Brainstormä¼˜åŠ¿ |
|------|----------------|
| **è®¡ç®—æ•ˆç‡** | è¯Šæ–­æ¨¡å‹æ€»å‚æ•°ä»…~20.9Mï¼Œè¾ƒViT-L/16å‡å°‘22.28å€è®¡ç®—æˆæœ¬ |
| **æ¨ç†é€Ÿåº¦** | å•æ¬¡æ²»ç–—é¢„æµ‹ä»…éœ€9.7ç§’ï¼Œè¿œå¿«äºPDEç±»æ¨¡å‹ï¼ˆ31â€“225å°æ—¶ï¼‰ |
| **ä¸´åºŠå®ç”¨æ€§** | æ”¯æŒå®Œæ•´æ²»ç–—å‘¨æœŸå»ºæ¨¡ï¼ˆæ‰‹æœ¯+æ”¾ç–—+åŒ–ç–—ï¼‰ï¼Œè€Œéæ— å¹²é¢„è‡ªç„¶è¿›å±• |
| **å¯åŠæ€§** | è½»é‡åŒ–è®¾è®¡ä½¿å…¶å¯åœ¨å†œæ‘/èµ„æºåŒ®ä¹åŒ»é™¢éƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
ä»The Cancer Imaging Archive (TCIA) æ•´åˆäº†æ¥è‡ª7ä¸ªæƒå¨æ•°æ®åº“çš„å…± **6,560ä¾‹æ‚£è€…T1CE MRIæ‰«æåŠå®šé‡radiomicç‰¹å¾**ï¼Œä¸»è¦åŒ…æ‹¬ï¼š
- **BraTS dataset**ï¼ˆå¤šä¸­å¿ƒè„‘ç˜¤åˆ†å‰²æŒ‘æˆ˜èµ›æ•°æ®ï¼‰
- **ReMIND dataset**ï¼ˆè‚¿ç˜¤è¿›å±•é¢„æµ‹ä¸“ç”¨æ•°æ®é›†ï¼‰
- **Lumiere dataset**ï¼ˆèåˆå¤šæ¨¡æ€æˆåƒï¼‰

æ‰€æœ‰MRIæ ‡å‡†åŒ–ä¸º **64Ã—64Ã—32ä½“ç´ åˆ†è¾¨ç‡**ï¼Œå¹¶è¿›è¡Œå¼ºåº¦å½’ä¸€åŒ–ä¸é«˜æ–¯å»å™ªã€‚

### å®éªŒè®¾ç½®
- **è®­ç»ƒå¹³å°**ï¼šGoogle Colab T4/A100 GPU
- **è®­ç»ƒæ–¹å¼**ï¼šå„æ¨¡å—ç‹¬ç«‹è®­ç»ƒï¼Œè¶…å‚æ•°é’ˆå¯¹ä»»åŠ¡å®šåˆ¶ï¼ˆè§Table 1ï¼‰
- **è¯Šæ–­é˜¶æ®µæŸå¤±å‡½æ•°**ï¼š
  - CNNåˆ†ç±»å™¨ï¼šCross Entropy
  - SVMï¼šHinge Loss
  - nnU-Netåˆ†å‰²ï¼šDice + Cross Entropyæ··åˆæŸå¤±
- **æ²»ç–—é˜¶æ®µæŸå¤±å‡½æ•°**ï¼šå…¨éƒ¨ä½¿ç”¨MSEï¼ˆMean Squared Errorï¼‰ç”¨äºå›¾åƒé‡å»ºä»»åŠ¡
- **ä¼˜åŒ–å™¨**ï¼š
  - CNNåˆ†ç±»å™¨ & ç”Ÿæˆæ¨¡å‹ï¼šAdam
  - nnU-Netï¼šSGDï¼ˆåˆ©äºç»†ç²’åº¦åˆ†å‰²ä»»åŠ¡ï¼‰

### è¯„ä¼°æŒ‡æ ‡
| é˜¶æ®µ | æŒ‡æ ‡ |
|------|------|
| **è¯Šæ–­å‡†ç¡®æ€§** | Confusion Matrixï¼ˆTP/TN/FP/FNï¼‰ã€Accuracy |
| **åˆ†å‰²æ€§èƒ½** | Dice Scoreã€IoUï¼ˆIntersection over Unionï¼‰ |
| **ç”Ÿæˆå›¾åƒè´¨é‡** | SSIMï¼ˆStructural Similarity Index Measureï¼‰ |
| **ç³»ç»Ÿçº§æ¯”è¾ƒ** | è®¡ç®—æ—¶é—´ã€è®­ç»ƒæˆæœ¬ã€äº”å¹´äººç”Ÿå­˜ç‡æå‡ä¼°ç®— |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **è¯Šæ–­æ¨¡å‹å¯¹æ¯”**ï¼š
  - ViT-L/16ï¼ˆ303Må‚æ•°ï¼‰
  - ViT-B/16ï¼ˆ87Mï¼‰
  - R50-ViT-L/16ï¼ˆ23.5Mï¼‰
- **åˆ†å‰²æ¨¡å‹å¯¹æ¯”**ï¼š
  - BraTS 2023å† å†›æ¨¡å‹ï¼ˆGAN-basedï¼‰
  - BraTS 2020ä¼˜èƒœæ¨¡å‹ï¼ˆU-Net-basedï¼‰
- **è‚¿ç˜¤æ¼”åŒ–é¢„æµ‹æ¨¡å‹å¯¹æ¯”**ï¼š
  - Glioma Solverï¼ˆPDE-basedï¼‰
  - Lattice Boltzmannæ–¹æ³•
  - å…¶ä»–PDEæ¡†æ¶

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰è¯Šæ–­æ€§èƒ½ï¼ˆTable 2 & ç»“æœéƒ¨åˆ†ï¼‰
| æ¨¡å‹ | å‡†ç¡®ç‡ | ç‰¹å¼‚æ€§ | æ•æ„Ÿæ€§ |
|------|--------|--------|--------|
| Mass Detection CNN | 94.4% | 96.7% | 92.1% |
| Tumor Confirmation CNN | 91.4% | 90.2% | 92.6% |
| Final Diagnosis CNN | **99.4%** | **99.4%** | **99.4%** |
| Malignancy SVM | 97.5% | 98% | 97% |

> æ³¨ï¼šæœ€ç»ˆå¤šåˆ†ç±»å‡†ç¡®ç‡è¾¾99.4%ï¼Œæ˜¾è‘—ä¼˜äºå•ä¸€å¤§æ¨¡å‹ã€‚

#### ï¼ˆ2ï¼‰åˆ†å‰²æ€§èƒ½ï¼ˆTable 3ï¼‰
| æ¨¡å‹ | Edema Dice | Enhancing Tumor Dice | Tumor Core Dice |
|------|-----------|-----------------------|-----------------|
| **Brainstorm (ours)** | **0.9095** | **0.8795** | **0.8653** |
| BraTS 2023 (GAN) | 0.9005 | 0.8673 | 0.8509 |
| BraTS 2020 (U-Net) | 0.8895 | 0.8506 | 0.8203 |

> æ‰€æœ‰å­åŒºåŸŸåˆ†å‰²è¡¨ç°å‡è¶…è¶Šå½“å‰æœ€ä¼˜æ¨¡å‹ã€‚

#### ï¼ˆ3ï¼‰æ²»ç–—ç”Ÿæˆæ¨¡å‹SSIMå¾—åˆ†
| æ¨¡å‹ | SSIM |
|------|------|
| Resection Diffusion Model | **0.89** |
| Radiotherapy ViT Model | **0.81**ï¼ˆä¸­ä½æ•°ï¼ŒIQR Â±0.03ï¼‰ |
| Chemotherapy Diffusion Model | **0.82** |

> è¡¨æ˜ç”ŸæˆMRIä¸çœŸå®å›¾åƒå…·æœ‰é«˜åº¦ç»“æ„ç›¸ä¼¼æ€§ã€‚

#### ï¼ˆ4ï¼‰ç³»ç»Ÿæ•ˆç‡å¯¹æ¯”ï¼ˆTable 4ï¼‰
| æ¨¡å‹ | å¹³å‡æ¯ä¾‹è€—æ—¶ | æ¨¡æ‹Ÿæ—¶é—´ |
|------|---------------|----------|
| **Brainstorm** | **9.7ç§’** | **9.7ç§’** |
| Glioma Solver | 31å°æ—¶ | 110.5ç§’ |
| PDE Frameworks | 83å°æ—¶ | 300ç§’ |
| Lattice Boltzmann | 225å°æ—¶ | 850ç§’ |

> æ¨ç†é€Ÿåº¦å¿«**ä¸Šä¸‡å€ä»¥ä¸Š**ï¼Œå…·å¤‡å®æ—¶åº”ç”¨æ½œåŠ›ã€‚

#### ï¼ˆ5ï¼‰æˆæœ¬ä¸ç²¾åº¦æƒè¡¡ï¼ˆTable 5ï¼‰
| æ¨¡å‹ | å‚æ•°é‡ | æˆæœ¬ | å‡†ç¡®ç‡ |
|------|--------|------|--------|
| **Brainstorm** | **20.9M** | **~$4,600** | **95.28%** |
| ViT-L/16 | 303.3M | ~$102,420 | 97.08% |
| ViT-B/16 | 87.5M | ~$26,800 | 97.89% |

> Brainstormä»¥ä¸åˆ°4%çš„æˆæœ¬å®ç°æ¥è¿‘é¡¶çº§æ¨¡å‹çš„æ€§èƒ½ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **è®¡ç®—æˆæœ¬é™ä½22.28Ã—**
- **è‚¿ç˜¤è¿›å±•æ¨æ–­æ—¶é—´ç¼©çŸ­113å°æ—¶**
- **DICEåˆ†æ•°å¹³å‡æå‡2.9%**
- **é€‚ç”¨äºéç†æƒ³å½±åƒç¯å¢ƒï¼Œåœ¨ä½è´¨é‡MRIä¸Šä»ä¿æŒé²æ£’æ€§**

### æ¶ˆèå®éªŒç»“æœï¼ˆæ–‡ä¸­éšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»¥ä¸‹åˆ†æä½“ç°äº†å…³é”®ç»„ä»¶ä½œç”¨ï¼š
- **åºåˆ—å†³ç­–æ¡†æ¶ vs å•ä¸€æ¨¡å‹**ï¼šå¤§å¹…é™ä½æˆæœ¬è€Œä¸ç‰ºç‰²ç²¾åº¦
- **çœŸå®ä¸–ç•Œé£æ ¼å¢å¼º**ï¼šæå‡äº†æ¨¡å‹å¯¹ä½è´¨é‡MRIçš„é€‚åº”èƒ½åŠ›ï¼ŒDICEæå‡2.9%
- **Transformerç”¨äºæ”¾ç–—å»ºæ¨¡**ï¼šç›¸æ¯”RNNèƒ½æ›´å¥½æ•æ‰æ—¶ç©ºä¾èµ–å…³ç³»ï¼Œæé«˜é•¿æœŸé¢„æµ‹ç¨³å®šæ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è½»é‡åŒ–çº§è”è¯Šæ–­æ¡†æ¶å¯è¡Œä¸”é«˜æ•ˆ**ï¼šé€šè¿‡å¤šä¸ªå°æ¨¡å‹ä¸²è”å®ç°é«˜ç²¾åº¦è¯Šæ–­ï¼Œæ˜¾è‘—é™ä½è®¡ç®—è´Ÿæ‹…ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚
2. **Spatio-Temporal Vision Transformerå¯æœ‰æ•ˆå»ºæ¨¡æ”¾ç–—å“åº”**ï¼šå…¶è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¼˜äºRNNï¼Œèƒ½æ•æ‰å¤æ‚éçº¿æ€§æ—¶ç©ºå˜åŒ–ã€‚
3. **Diffusion Modelsåœ¨åŒ»å­¦å›¾åƒç”Ÿæˆä¸­ä¼˜äºGANs**ï¼šå°¤å…¶åœ¨å­˜åœ¨å™ªå£°å’Œç±»ä¸å¹³è¡¡æƒ…å†µä¸‹æ›´ç¨³å®šï¼Œé¿å…æ¨¡å¼å´©æºƒã€‚
4. **MARLé—­ç¯ç³»ç»Ÿèƒ½è‡ªåŠ¨æ¢ç´¢æœ€ä¼˜åˆ‡é™¤ç­–ç•¥**ï¼šç»“åˆPPOåé¦ˆæœºåˆ¶ï¼Œå¯æ ¹æ®åŒ»ç”Ÿç›®æ ‡åŠ¨æ€è°ƒæ•´æ²»ç–—è®¡åˆ’ã€‚
5. **çœŸå®åœºæ™¯å¢å¼ºæ˜¾è‘—æå‡æ³›åŒ–èƒ½åŠ›**ï¼šä½¿æ¨¡å‹æ›´é€‚åˆå…¨çƒå¤šæ ·åŒ–åŒ»ç–—ç¯å¢ƒã€‚

### æ–¹æ³•å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡æ ‡æ³¨æ•°æ®**ï¼šå°¤å…¶æ˜¯æœ¯åMRIé…å¯¹æ ·æœ¬ç”¨äºè®­ç»ƒresection diffusion modelå¯èƒ½ç¨€ç¼ºã€‚
- **æ”¾å°„ç»„å­¦ç‰¹å¾éœ€äººå·¥è¾“å…¥**ï¼šç›®å‰ä»éœ€åŒ»ç”Ÿæ‰‹åŠ¨æå–30é¡¹radiomicç‰¹å¾ä¾›SVMä½¿ç”¨ï¼Œå°šæœªå®Œå…¨è‡ªåŠ¨åŒ–ã€‚
- **æœªåœ¨çœŸå®æ‰‹æœ¯ç¯å¢ƒä¸­éªŒè¯**ï¼šç›®å‰ä¸ºç¦»çº¿è¯„ä¼°ï¼Œå°šæ— å‰ç»æ€§ä¸´åºŠè¯•éªŒéªŒè¯å…¶å®é™…ç–—æ•ˆã€‚
- **ä¸ªä½“ç”Ÿç‰©å­¦å·®å¼‚å»ºæ¨¡æœ‰é™**ï¼šå°½ç®¡è€ƒè™‘å¼‚è´¨æ€§ï¼Œä½†ä»åŸºäºç¾¤ä½“ç»Ÿè®¡è§„å¾‹ï¼Œä¸ªæ€§åŒ–ç¨‹åº¦æœ‰å¾…æ·±åŒ–ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **æ‰©å±•è‡³å…¶ä»–å±€éƒ¨ä¾µè¢­æ€§ç™Œç—‡**ï¼šå¦‚ä¹³è…ºç™Œã€èƒ°è…ºç™Œç­‰åŒæ ·éœ€è¦ç»¼åˆæ²»ç–—çš„å®ä½“ç˜¤ã€‚
- **å®ç°å…¨è‡ªåŠ¨åŒ–radiomicç‰¹å¾æå–**ï¼šå°†SVMå‰çš„äººå·¥ç¯èŠ‚æ›¿æ¢ä¸ºç«¯åˆ°ç«¯CNNç‰¹å¾å­¦ä¹ ã€‚
- **å¼€å±•å¤šä¸­å¿ƒå‰ç»æ€§ä¸´åºŠè¯•éªŒ**ï¼šéªŒè¯ç³»ç»Ÿåœ¨çœŸå®è¯Šç–—æµç¨‹ä¸­çš„æœ‰æ•ˆæ€§ä¸å®‰å…¨æ€§ã€‚
- **é›†æˆæ›´å¤šæ²»ç–—æ¨¡æ€**ï¼šå¦‚å…ç–«ç–—æ³•ã€é¶å‘è¯ç‰©ç­‰æ–°å…´æ‰‹æ®µçš„å»ºæ¨¡ã€‚
- **å¼€å‘äº¤äº’å¼å¯è§†åŒ–ç•Œé¢**ï¼šä¾¿äºç¥ç»å¤–ç§‘åŒ»ç”Ÿç›´è§‚ç†è§£AIå»ºè®®å¹¶å‚ä¸å†³ç­–ã€‚

---

> **ç¤¾ä¼šå½±å“å±•æœ›ï¼ˆTable 6ï¼‰**  
> ç ”ç©¶å›¢é˜Ÿå’¨è¯¢å¤šä½ä¸´åºŠåŒ»å¸ˆåé¢„æµ‹ï¼š
> - äº”å¹´äººç”Ÿå­˜ç‡æœ‰æœ›ä» **5.1% æå‡è‡³ 6.0%**ï¼ˆ+0.9%ï¼‰
> - æ¯å¹´å¯é¢å¤–æŒ½æ•‘çº¦ **2,250æ¡ç”Ÿå‘½**
> - å…¨çƒæ‚£è€…è¦†ç›–æ¯”ä¾‹ä»28.7%æå‡è‡³34.9%ï¼Œæ˜¾è‘—æ”¹å–„åŒ»ç–—å…¬å¹³æ€§

ç»¼ä¸Šæ‰€è¿°ï¼Œ**Brainstorm** æ˜¯ä¸€ä¸ªå…¼å…·**é«˜æ€§èƒ½ã€ä½æˆæœ¬ã€å¼ºæ³›åŒ–æ€§å’Œä¸´åºŠå®ç”¨æ€§**çš„ç«¯åˆ°ç«¯AIç³»ç»Ÿï¼Œä¸ºGBMç²¾å‡†æ²»ç–—æä¾›äº†å…¨æ–°èŒƒå¼ï¼Œå…·æœ‰é‡å¤§è½¬åŒ–å‰æ™¯ã€‚

</details>

---

### 11. [PMA-Diffusion: A Physics-guided Mask-Aware Diffusion Framework for TSE from Sparse Observations](https://arxiv.org/abs/2512.06183)

**Authors**: Lindong Liu, Zhixiong Jin, Seongjin Choi  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.06183v1  

#### Abstract
High-resolution highway traffic state information is essential for Intelligent Transportation Systems, but typical traffic data acquired from loop detectors and probe vehicles are often too sparse and noisy to capture the detailed dynamics of traffic flow. We propose PMA-Diffusion, a physics-guided ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPMA-Diffusion: A Physics-guided Mask-Aware Diffusion Framework for TSE from Sparse Observations

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

äº¤é€šçŠ¶æ€ä¼°è®¡ï¼ˆTraffic State Estimation, TSEï¼‰é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
1. **è®­ç»ƒä¾èµ–å®Œæ•´è§‚æµ‹**ï¼šå¤§å¤šæ•°æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚VAEã€Diffusionï¼‰éœ€è¦å®Œæ•´çš„é«˜åˆ†è¾¨ç‡é€Ÿåº¦åœºè¿›è¡Œè®­ç»ƒï¼Œä½†åœ¨ç°å®ä¸­ï¼Œloop detectors å’Œ probe vehicles æä¾›çš„æ•°æ®é«˜åº¦ç¨€ç–ï¼ˆé€šå¸¸ä»…5%-25%å¯è§ï¼‰ï¼Œéš¾ä»¥è·å–å…¨è§‚æµ‹æ•°æ®ã€‚
2. **ç¼ºä¹ä¸ç¡®å®šæ€§å»ºæ¨¡**ï¼šå¤šæ•°æ–¹æ³•åªè¾“å‡ºå•ä¸€ä¼°è®¡å€¼ï¼Œæ— æ³•æä¾›å®Œæ•´çš„åéªŒåˆ†å¸ƒï¼Œé™åˆ¶äº†åœ¨å†³ç­–ç³»ç»Ÿä¸­çš„å¯é æ€§ã€‚
3. **ç‰©ç†çº¦æŸä¸ä¼ æ„Ÿå™¨é…ç½®è€¦åˆè¿‡ç´§**ï¼šç°æœ‰ Physics-Informed Deep Learning (PIDL) æ–¹æ³•å°†è§‚æµ‹æ©ç ï¼ˆmaskï¼‰ç›´æ¥ç¼–ç è¿›æŸå¤±å‡½æ•°ï¼Œå¯¼è‡´æ¨¡å‹å¯¹éƒ¨ç½²æ—¶çš„ä¼ æ„Ÿå™¨å¸ƒå±€å˜åŒ–ä¸é²æ£’ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **PMA-Diffusion**ï¼Œä¸€ä¸ª**ç‰©ç†å¼•å¯¼çš„æ©ç æ„ŸçŸ¥æ‰©æ•£æ¡†æ¶**ï¼Œç”¨äºä»ç¨€ç–è§‚æµ‹ä¸­é‡å»ºé«˜é€Ÿå…¬è·¯é€Ÿåº¦åœºã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†TSEè§†ä¸ºä¸€ä¸ª**è´å¶æ–¯é€†é—®é¢˜**ï¼Œå¹¶è§£è€¦ä¸¤ä¸ªé˜¶æ®µï¼š

- **Mask-Aware Diffusion Prior Training**ï¼šç›´æ¥åœ¨ç¨€ç–è§‚æµ‹ä¸Šè®­ç»ƒæ‰©æ•£å…ˆéªŒï¼ˆdiffusion priorï¼‰ï¼Œæ— éœ€å®Œæ•´æ•°æ®ã€‚
  - **Single-Mask Strategy**ï¼šæŒ‰çœŸå®ä¼ æ„Ÿå™¨è¦†ç›–æ¨¡å¼è¿›è¡Œæ©ç ã€‚
  - **Double-Mask Strategy**ï¼šé¢å¤–å¼•å…¥è¾…åŠ©æ©ç ï¼Œå³ä½¿â€œå§‹ç»ˆå¯è§â€çš„ä½ç½®ä¹Ÿå¶å°”è¢«é®è”½ï¼Œå¢å¼ºæ¨¡å‹å¯¹æ°¸ä¹…ç¼ºå¤±åŒºåŸŸçš„æ³›åŒ–èƒ½åŠ›ã€‚

- **Physics-Guided Posterior Sampling**ï¼šåœ¨æ¨ç†é˜¶æ®µï¼Œé€šè¿‡äº¤æ›¿æ‰§è¡Œä»¥ä¸‹æ­¥éª¤é‡‡æ ·åéªŒåˆ†å¸ƒ $p(V|Y)$ï¼š
  1. **Reverse Diffusion Update**ï¼šåŸºäºå­¦ä¹ åˆ°çš„å…ˆéªŒå»å™ªã€‚
  2. **Observation Projection**ï¼šå°†è§‚æµ‹å€¼ç²¾ç¡®æ³¨å…¥å¯¹åº”ä½ç½®ï¼Œä¿è¯æ•°æ®ä¿çœŸåº¦ã€‚
  3. **Physics-Guided Projection**ï¼šä½¿ç”¨è‡ªé€‚åº”å„å‘å¼‚æ€§å¹³æ»‘ï¼ˆAdaptive Anisotropic Smoothing, AASï¼‰ç®—å­ï¼Œåœ¨æœªè§‚æµ‹åŒºåŸŸæ–½åŠ äº¤é€šæ³¢åŠ¨åŠ›å­¦çº¦æŸï¼ˆå¦‚æ¿€æ³¢ä¼ æ’­æ–¹å‘ï¼‰ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è®­ç»ƒæ•°æ®è¦æ±‚** | ä¸éœ€è¦å®Œæ•´è§‚æµ‹æ•°æ®ï¼Œå¯ç›´æ¥ç”¨ç¨€ç–æ•°æ®è®­ç»ƒï¼Œæ›´è´´è¿‘ç°å®åœºæ™¯ã€‚ |
| **çµæ´»æ€§ä¸é²æ£’æ€§** | æ©ç åœ¨æ¨ç†é˜¶æ®µå¤„ç†ï¼Œè€Œéå›ºåŒ–åœ¨è®­ç»ƒæŸå¤±ä¸­ï¼Œæ”¯æŒä»»æ„ä¼ æ„Ÿå™¨é…ç½®ã€‚ |
| **ç‰©ç†ä¸€è‡´æ€§** | ç‰©ç†çº¦æŸä»¥æ¨¡å—åŒ–æŠ•å½±å½¢å¼åŠ å…¥ï¼Œä¸å½±å“å…ˆéªŒè®­ç»ƒï¼Œä¸”å¯çµæ´»æ›¿æ¢æˆ–æ‰©å±•å…¶ä»–ç‰©ç†æ¨¡å—ï¼ˆå¦‚å®ˆæ’å¾‹ï¼‰ã€‚ |
| **ä¸ç¡®å®šæ€§é‡åŒ–** | æ‰©æ•£æ¨¡å‹å¤©ç„¶æ”¯æŒç”Ÿæˆå¤šä¸ªåˆç†æ ·æœ¬ï¼Œå¯ç”¨äºä¸ç¡®å®šæ€§åˆ†æã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **I-24 MOTION Dataset**ï¼šç”±ç”°çº³è¥¿å·äº¤é€šéƒ¨æä¾›çš„çœŸå®é«˜é€Ÿå…¬è·¯ç›‘æ§æ•°æ®ã€‚
  - è¦†ç›–çº¦4.2è‹±é‡Œï¼Œ276ä¸ªå›ºå®šæ‘„åƒå¤´ï¼Œæä¾›è¿‘ä¹å®Œæ•´çš„è½¦è¾†è½¨è¿¹ã€‚
  - æ•°æ®è¢«è½¬æ¢ä¸º **200Ã—200 çš„æ¬§æ‹‰ç½‘æ ¼**ï¼ˆç©ºé—´æ­¥é•¿ Î”x=100 ftï¼Œæ—¶é—´æ­¥é•¿ Î”t=1 sï¼‰ï¼ŒåŒ…å«å››æ¡è½¦é“çš„é€Ÿåº¦åœºã€‚
  - åˆ’åˆ†æ¯”ä¾‹ï¼š70%è®­ç»ƒã€10%éªŒè¯ã€20%æµ‹è¯•ã€‚

### **å®éªŒè®¾ç½®**

#### **æ¨¡æ‹Ÿç¨€ç–è§‚æµ‹**
- **Loop Detectors**ï¼šå›ºå®šè¡Œæ©ç ï¼Œåˆ†åˆ«æ¨¡æ‹Ÿ 5%ã€15%ã€25% çš„ç©ºé—´è¦†ç›–ç‡ã€‚
- **Probe Vehicles**ï¼šä»çœŸå®è½¨è¿¹ä¸­éšæœºé‡‡æ ·ï¼Œæ¨¡æ‹Ÿä¸åŒå¯†åº¦ï¼ˆÎ» = 0, 5, 15, 25 è¾†è½¦/åˆ†é’Ÿï¼‰ã€‚
- æ€»ä½“å¯è§ç‡ï¼ˆvisibility ratioï¼‰ä½è‡³ **5%**ã€‚

#### **è¯„ä¼°æŒ‡æ ‡ï¼ˆå‡åœ¨æœªè§‚æµ‹åƒç´ ä¸Šè®¡ç®—ï¼‰**
1. **Masked-MSE (2Ã—2)**ï¼šå¯¹é‡å»ºä¸çœŸå®é€Ÿåº¦åœºè¿›è¡Œ 2Ã—2 å¹³å‡æ± åŒ–åè®¡ç®—MSEï¼Œè¡¡é‡ä½é¢‘ç»“æ„å‡†ç¡®æ€§ã€‚
2. **Sobel-MSE**ï¼šä½¿ç”¨Sobelç®—å­æå–æ¢¯åº¦å›¾åè®¡ç®—MSEï¼Œè¯„ä¼°æ¿€æ³¢ã€åœæ­¢-å¯åŠ¨æ³¢ç­‰é«˜é¢‘ç‰¹å¾çš„æ¢å¤è´¨é‡ã€‚
3. **LPIPS**ï¼šåŸºäºé¢„è®­ç»ƒAlexNetçš„æ„ŸçŸ¥ç›¸ä¼¼æ€§åº¦é‡ï¼Œåæ˜ è§†è§‰è´¨é‡å’Œçº¹ç†ä¸€è‡´æ€§ã€‚

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
1. **AAS-only**ï¼šä»…ä½¿ç”¨ç‰©ç†é©±åŠ¨çš„è‡ªé€‚åº”å„å‘å¼‚æ€§å¹³æ»‘ï¼Œæ— æ‰©æ•£æ¨¡å‹ã€‚
2. **RePaint**ï¼šç»å…¸æ‰©æ•£å›¾åƒä¿®å¤æ–¹æ³•ï¼Œäº¤æ›¿åå‘æ‰©æ•£ä¸è§‚æµ‹é‡ç½®ã€‚
3. **Full-obs Model**ï¼šåœ¨å®Œæ•´é€Ÿåº¦åœºä¸Šè®­ç»ƒçš„æ ‡å‡†DDPMï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒã€‚

#### **æ¶ˆèå®éªŒè®¾è®¡**
- å¯¹æ¯”ä¸‰ç§è®­ç»ƒç­–ç•¥ï¼š
  - **Full-obs**ï¼šå®Œæ•´æ•°æ®è®­ç»ƒã€‚
  - **Single-mask**ï¼šçœŸå®æ©ç è®­ç»ƒã€‚
  - **Double-mask**ï¼šåŒå±‚æ©ç è®­ç»ƒã€‚
- å›ºå®šé‡‡æ ·å™¨ä¸º PMA-Diffusionï¼Œè¯„ä¼°ä¸åŒå…ˆéªŒçš„å½±å“ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2 & Table 3ï¼‰**

| è®¾ç½® | æ–¹æ³• | Masked-MSE â†“ | Sobel-MSE â†“ | LPIPS â†“ |
|------|------|--------------|-------------|---------|
| Row=5%, Î»=0 | AAS-only | 0.1463 | 0.0009 | 0.2662 |
| | RePaint (M1) | 0.0172 | 0.0008 | 0.1617 |
| | **PMA-Diffusion (M1)** | **0.0167** | **0.0008** | **0.1768** |
| | RePaint (M3) | 0.2962 | 0.2066 | 0.0008 |
| | **PMA-Diffusion (M3)** | **0.0289** | **0.0008** | **0.1833** |

> æ³¨ï¼šM1=Full-obs, M3=Double-mask

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- åœ¨æœ€æç«¯ç¨€ç–æ¡ä»¶ä¸‹ï¼ˆ5%å›ºå®šæ£€æµ‹å™¨ + æ— probeè½¦ï¼‰ï¼š
  - **PMA-Diffusion (Double-mask)** çš„ Masked-MSE ä»…ä¸º **0.0289**ï¼Œæ˜¾è‘—ä¼˜äº RePaintï¼ˆ0.2962ï¼‰å’Œ AAS-onlyï¼ˆ0.1463ï¼‰ã€‚
  - RePaint åœ¨ Single-mask æˆ– Double-mask å…ˆéªŒä¸‹æ˜“å‡ºç°ä¸¥é‡å¤–æ¨é”™è¯¯ï¼ˆå¦‚M2ä¸‹Masked-MSEé«˜è¾¾7.1959ï¼‰ï¼Œè€Œ PMA-Diffusion é€šè¿‡ç‰©ç†æŠ•å½±æœ‰æ•ˆç¨³å®šé‡å»ºè¿‡ç¨‹ã€‚

- å³ä½¿åœ¨ä»…æœ‰ **5% å¯è§ç‡**çš„æƒ…å†µä¸‹ï¼ŒPMA-Diffusion çš„æ€§èƒ½æ¥è¿‘åœ¨å®Œæ•´æ•°æ®ä¸Šè®­ç»ƒçš„ Full-obs æ¨¡å‹ã€‚

- éšç€è§‚æµ‹å¯†åº¦å¢åŠ ï¼ˆå¦‚Row=25%, Î»=25ï¼‰ï¼ŒPMA-Diffusion å‡ ä¹è¾¾åˆ° Full-obs æ¨¡å‹çš„æ€§èƒ½æ°´å¹³ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

- **Double-mask vs Single-mask**ï¼š
  - Double-mask æ˜¾è‘—æå‡åœ¨ç¨€ç–åŒºåŸŸçš„æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶å½“æŸäº›ä½ç½®é•¿æœŸä¸å¯è§æ—¶ã€‚
  - ä¾‹å¦‚åœ¨ Row=15%, Î»=15 ä¸‹ï¼ŒDouble-mask çš„ Masked-MSE è¾¾åˆ° 0.0014ï¼Œæ¥è¿‘ Full-obs çš„ 0.0016ã€‚

- **ç‰©ç†æŠ•å½±çš„ä½œç”¨**ï¼š
  - åœ¨æ‰€æœ‰é…ç½®ä¸‹ï¼Œæ·»åŠ  AAS æŠ•å½±å‡èƒ½è¿›ä¸€æ­¥é™ä½è¯¯å·®ï¼Œå°¤å…¶æ˜¯åœ¨ç¨€ç–æ¡ä»¶ä¸‹æ•ˆæœæ˜¾è‘—ã€‚
  - ç‰©ç†æŠ•å½±æœ‰æ•ˆæŠ‘åˆ¶äº†æ‰©æ•£è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„éç‰©ç†è§£ï¼ˆå¦‚åå‘ä¼ æ’­çš„æ¿€æ³¢ï¼‰ã€‚

- **åˆ†è¾¨ç‡æ•æ„Ÿæ€§æµ‹è¯•ï¼ˆ64Ã—64 ç½‘æ ¼ï¼‰**ï¼š
  - åœ¨æ›´ä½åˆ†è¾¨ç‡ä¸‹è¶‹åŠ¿ä¸€è‡´ï¼Œä¸”æ•°å€¼æ›´ç¨³å®šã€‚
  - è¡¨æ˜è¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„å°ºåº¦é€‚åº”æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **Mask-Aware Training æ˜¯å¯è¡Œä¸”æœ‰æ•ˆçš„**ï¼š  
   å³ä½¿æ²¡æœ‰å®Œæ•´è§‚æµ‹æ•°æ®ï¼Œä¹Ÿèƒ½é€šè¿‡ Single-mask å’Œ Double-mask ç­–ç•¥æˆåŠŸè®­ç»ƒå‡ºé«˜è´¨é‡çš„ diffusion priorï¼Œå¤§å¹…ç¼©å°ä¸ Full-obs æ¨¡å‹ä¹‹é—´çš„å·®è·ã€‚

2. âœ… **Physics-Guided Sampling æå¤§æå‡äº†é‡å»ºè´¨é‡**ï¼š  
   å°†ç‰©ç†çº¦æŸä½œä¸ºæ¨ç†é˜¶æ®µçš„æŠ•å½±æ“ä½œï¼Œæ—¢èƒ½ä¿æŒæ•°æ®ä¿çœŸåº¦ï¼Œåˆèƒ½å¼•å¯¼æœªè§‚æµ‹åŒºåŸŸç¬¦åˆäº¤é€šåŠ¨åŠ›å­¦è§„å¾‹ï¼Œé¿å…â€œå¹»è§‰â€ç»“æ„ã€‚

3. âœ… **PMA-Diffusion åœ¨æç¨€ç–æ¡ä»¶ä¸‹ä»è¡¨ç°ä¼˜å¼‚**ï¼š  
   å³ä½¿åªæœ‰ **5% å¯è§ç‡**ï¼Œå…¶æ€§èƒ½ä»æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•å’Œçº¯æ‰©æ•£ä¿®å¤æ–¹æ³•ï¼Œæ¥è¿‘å…¨ç›‘ç£æ¨¡å‹çš„è¡¨ç°ã€‚

4. âœ… **æ¨¡å—åŒ–è®¾è®¡å¸¦æ¥é«˜çµæ´»æ€§**ï¼š  
   ç‰©ç†æŠ•å½±å™¨ï¼ˆå¦‚ AASï¼‰å¯ç‹¬ç«‹äºå…ˆéªŒè®­ç»ƒï¼Œæœªæ¥å¯è½»æ¾æ›¿æ¢ä¸ºæ›´å¤æ‚çš„ç‰©ç†æ¨¡å‹ï¼ˆå¦‚å®ˆæ’å¾‹ã€FDä¸€è‡´æ€§ç­‰ï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **å‡è®¾ç®€åŒ–**ï¼š
   - å¿½ç•¥ GPS å»¶è¿Ÿï¼ˆAssumption 1ï¼‰å’Œä¼ æ„Ÿå™¨åç½®ï¼ˆAssumption 2ï¼‰ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€æ˜¾å¼å»ºæ¨¡ã€‚
   - è§‚æµ‹å™ªå£°å‡è®¾ä¸ºé«˜æ–¯ç™½å™ªå£°ï¼Œæœªè€ƒè™‘å¼‚æ–¹å·®æˆ–éé«˜æ–¯ç‰¹æ€§ã€‚

2. **ç‰©ç†å»ºæ¨¡æœ‰é™**ï¼š
   - å½“å‰ä»…ä½¿ç”¨ AAS ä½œä¸ºä»£ç†ç‰©ç†æ¨¡å—ï¼Œæœªæ˜¾å¼å»ºæ¨¡å¯†åº¦ã€æµé‡æˆ–å®ˆæ’æ–¹ç¨‹ã€‚
   - æ— æ³•å¤„ç† ramp flowã€lane change ç­‰å¤æ‚è¾¹ç•Œæ¡ä»¶ã€‚

3. **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼š
   - æ‰©æ•£æ¨¡å‹éœ€æ•°ç™¾æ­¥è¿­ä»£é‡‡æ ·ï¼Œå®æ—¶æ€§ä¸å¦‚ä¼ ç»Ÿæ»¤æ³¢æ–¹æ³•ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•å¤šæ¨¡æ€å»ºæ¨¡**ï¼š
   - åˆ†åˆ«å»ºæ¨¡ loop detector å’Œ probe vehicle çš„å™ªå£°ç‰¹æ€§ä¸åå·®ï¼Œæå‡å¼‚æ„æ•°æ®èåˆèƒ½åŠ›ã€‚

2. **å¼•å…¥æ›´å¼ºç‰©ç†çº¦æŸ**ï¼š
   - è®¾è®¡åŸºäºå®ˆæ’å¾‹ï¼ˆConservation Lawï¼‰ã€åŸºæœ¬å›¾ï¼ˆFundamental Diagramï¼‰çš„æŠ•å½±æ¨¡å—ï¼Œå¹¶é›†æˆåˆ°é‡‡æ ·å¾ªç¯ä¸­ã€‚

3. **æå‡æ¨ç†æ•ˆç‡**ï¼š
   - æ¢ç´¢è’¸é¦ã€åŠ é€Ÿé‡‡æ ·ï¼ˆå¦‚DDIMã€Progressive Distillationï¼‰ç­‰æŠ€æœ¯ï¼Œå®ç°è¿‘å®æ—¶äº¤é€šçŠ¶æ€ä¼°è®¡ã€‚

4. **ç½‘ç»œçº§æ‰©å±•**ï¼š
   - å°†æ–¹æ³•æ¨å¹¿è‡³åŸå¸‚è·¯ç½‘ï¼Œç»“åˆ Network Macroscopic Fundamental Diagram (NMFD) è¿›è¡Œå…¨å±€ä¸€è‡´æ€§çº¦æŸã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PMA-Diffusion æˆåŠŸå®ç°äº†**æ— éœ€å®Œæ•´æ ‡ç­¾çš„æ‰©æ•£å…ˆéªŒå­¦ä¹ **ä¸**ç‰©ç†å¼•å¯¼çš„åéªŒé‡‡æ ·**ç›¸ç»“åˆï¼Œåœ¨æç¨€ç–è§‚æµ‹ä¸‹å®ç°äº†é«˜è´¨é‡ã€ç‰©ç†ä¸€è‡´çš„äº¤é€šçŠ¶æ€é‡å»ºï¼Œä¸ºæ™ºèƒ½äº¤é€šç³»ç»Ÿçš„æ„ŸçŸ¥å±‚æä¾›äº†å¯é çš„æ–°èŒƒå¼ã€‚

</details>

---

### 12. [Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction](https://arxiv.org/abs/2512.07200)

**Authors**: Zhen Huang, Jiaxin Deng, Jiayu Xu, Junbiao Pang, Haitao Yu  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.07200v1  

#### Abstract
In bus arrival time prediction, the process of organizing road infrastructure network data into homogeneous entities is known as segmentation. Segmenting a road network is widely recognized as the first and most critical step in developing an arrival time prediction system, particularly for auto-reg...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿå…¬äº¤åˆ°è¾¾æ—¶é—´é¢„æµ‹ï¼ˆETAï¼‰ç³»ç»Ÿé€šå¸¸é‡‡ç”¨**å‡åŒ€é“è·¯åˆ†æ®µç­–ç•¥**ï¼ˆuniform road segmentationï¼‰ï¼Œå³é€šè¿‡å›ºå®šé—´éš”æ’å€¼æˆ–ä»¥ç«™ç‚¹ä¸ºå•ä½åˆ’åˆ†é“è·¯ã€‚è¿™ç§åšæ³•å¿½ç•¥äº†ä¸åŒè·¯æ®µåœ¨ç‰©ç†ç‰¹æ€§ä¸Šçš„å·®å¼‚ï¼ˆå¦‚äº¤å‰å£ã€å­¦æ ¡åŒºåŸŸã€æ–‘é©¬çº¿ç­‰ï¼‰ï¼Œå¯¼è‡´ï¼š
- å¼•å…¥å¤§é‡å†—ä½™ä¸”ä¿¡æ¯é‡ä½çš„ç‰¹å¾ï¼›
- åœ¨è‡ªå›å½’æ¨¡å‹ä¸­åŠ å‰§**è¯¯å·®ç´¯ç§¯**ï¼ˆerror accumulationï¼‰ï¼›
- é™ä½é¢„æµ‹æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚

è¯¥è®ºæ–‡æŒ‡å‡ºï¼Œå¹¶éæ‰€æœ‰é“è·¯åˆ†æ®µå¯¹é¢„æµ‹åŒç­‰é‡è¦ï¼Œå› æ­¤æå‡ºåº”**åŠ¨æ€é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„éå‡åŒ€é“è·¯æ®µ**ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº**å¼ºåŒ–å­¦ä¹ **ï¼ˆReinforcement Learning, RLï¼‰çš„æ¡†æ¶â€”â€”**Deep Progressive Reinforcement Learning (DPRL)**ï¼Œç”¨äºè‡ªé€‚åº”åœ°å­¦ä¹ æœ€ä¼˜çš„éå‡åŒ€é“è·¯åˆ†æ®µã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†â€œé“è·¯æ®µé€‰æ‹©â€å»ºæ¨¡ä¸ºä¸€ä¸ª**åºåˆ—å†³ç­–è¿‡ç¨‹**ã€‚

#### æ–¹æ³•æ¶æ„ï¼š
- **ä¸¤é˜¶æ®µè§£è€¦è®¾è®¡**ï¼š
  1. **Road Segment Selection Network (RSS-Net)**ï¼šä½¿ç”¨ RL åŠ¨æ€é€‰æ‹©å…³é”®é“è·¯æ®µï¼›
  2. **Linear Regression Model (LRM)**ï¼šåœ¨é€‰å‡ºçš„ç¨€ç–è·¯æ®µä¸Šè¿›è¡Œ ETA é¢„æµ‹ã€‚

- **å¥–åŠ±å‡½æ•°è®¾è®¡**ï¼šè”åˆä¼˜åŒ–é¢„æµ‹ç²¾åº¦ä¸ç‰¹å¾ç¨€ç–æ€§ï¼Œå®šä¹‰å¦‚ä¸‹ä¸‰ç§å¥–åŠ±æœºåˆ¶å¹¶æ¯”è¾ƒæ•ˆæœï¼š
  - **Benchmark-Calibrated Reward (BCR)**
  - **Inverse Error Reward (IER)**
  - **Arrival Time difference Reward (ATR)** â€”â€” æœ€ç»ˆè¡¨ç°æœ€ä½³

- **æ¸è¿›è®­ç»ƒæœºåˆ¶**ï¼šé€šè¿‡è¿­ä»£æ›´æ–°é€‰ä¸­çš„è·¯æ®µä½ç½®ï¼Œé€æ­¥é€¼è¿‘æœ€ä¼˜é…ç½®ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡æå‡** | æ˜¾è‘—å‡å°‘è¾“å…¥ç‰¹å¾æ•°é‡ï¼ˆä»…ä¿ç•™çº¦ 2/3 è·¯æ®µï¼‰ï¼Œæé«˜è®¡ç®—æ•ˆç‡ |
| **é¢„æµ‹æ€§èƒ½** | å³ä½¿ä½¿ç”¨ç®€å•çš„çº¿æ€§æ¨¡å‹ï¼ˆLRMï¼‰ï¼Œä¹Ÿä¼˜äºå¤æ‚çš„æ·±åº¦æ¨¡å‹ï¼ˆå¦‚ LSTMï¼‰ |
| **å¯è§£é‡Šæ€§å¢å¼º** | RSS-Net å¯è¯†åˆ«å‡ºçœŸæ­£å½±å“é¢„æµ‹çš„å…³é”®è·¯æ®µï¼ˆå¦‚ä¿¡å·ç¯ã€å­¦æ ¡å…¥å£ï¼‰ |
| **é¿å…è¯¯å·®ä¼ æ’­** | éè‡ªå›å½’ç»“æ„ + ç¨€ç–åŒ–å‡å°‘äº†è¯¯å·®ç´¯ç§¯é£é™© |

> âœ… æ ¸å¿ƒç†å¿µï¼šâ€œ**Less is More**â€â€”â€”æ›´å°‘ä½†æ›´æœ‰ä»£è¡¨æ€§çš„é“è·¯æ®µåè€Œèƒ½å¸¦æ¥æ›´é«˜é¢„æµ‹ç²¾åº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- æ¥æºäºæ–‡çŒ® [8] çš„çœŸå®å…¬äº¤ GPS æ•°æ®ï¼›
- åŒ—äº¬å¸‚ 6 æ¡å…¬äº¤çº¿è·¯ï¼ˆNo. 14, 60, 74, 110, 421, 563ï¼‰è¿ç»­ 23 å¤©çš„è¿è¥æ•°æ®ï¼›
- å‰ 22 å¤©ç”¨äºè®­ç»ƒï¼Œæœ€å 1 å¤©ä½œä¸ºæµ‹è¯•é›†ï¼›
- æ‰€æœ‰è½¨è¿¹æŒ‰æ¯ 100 ç±³è¿›è¡Œåˆå§‹å‡åŒ€æ’å€¼ç”Ÿæˆé“è·¯æ®µã€‚

---

### å®éªŒè®¾ç½®
- **å¹³å°**ï¼šPyTorch 1.8.0 + CUDA 11.1ï¼ŒNVIDIA RTX 3080 GPUï¼›
- **è¶…å‚æ•°**ï¼š
  - Batch size: 16
  - Optimizer: SGDï¼ˆmomentum=0.9, weight decay=0.0005ï¼‰
  - åˆå§‹å­¦ä¹ ç‡ï¼š1e-3ï¼Œæ¯ 20 è½®è¡°å‡ä¸€æ¬¡
- **åŠ¨ä½œè¿­ä»£æ¬¡æ•°**ï¼šè®¾ä¸º 2ï¼ˆç»éªŒè¯æœ€ä¼˜ï¼‰
- **é€‰æ®µæ¯”ä¾‹**ï¼šä¿ç•™æ€»æ’å€¼ç‚¹çš„ 2/3

---

### è¯„ä¼°æŒ‡æ ‡
- **Mean Absolute Error (MAE)**ï¼ˆå•ä½ï¼šåˆ†é’Ÿï¼‰ï¼š
  $$
  \text{MAE} = \frac{1}{NV}\sum_{i=1}^{N}\sum_{v=1}^{V} |t_{\text{pred}} - t_{\text{true}}|
  $$

---

### å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
| æ–¹æ³• | ç±»å‹ |
|------|------|
| LRM [11] | çº¿æ€§å›å½’æ¨¡å‹ |
| KNN [31] | åŸºäºå†å²ç›¸ä¼¼è½¨è¿¹æœç´¢ |
| KR [11] | æ ¸å›å½’ |
| AMM [33] | åŠ æ³•æ··åˆæ¨¡å‹ï¼ˆéçº¿æ€§ï¼‰ |
| SPB [32] | æ”¯æŒå‘é‡æœº + æ¢é’ˆè½¦æ•°æ® |
| KFP [34] | å¡å°”æ›¼æ»¤æ³¢ |
| MLP [35] | å¤šå±‚æ„ŸçŸ¥æœº |
| LSTM [8] | åºåˆ—æ·±åº¦æ¨¡å‹ï¼ˆSOTAä¹‹ä¸€ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆMAEï¼Œå•ä½ï¼šåˆ†é’Ÿï¼‰

| æ–¹æ³• | 14 | 60 | 110 | 421 | 74 | 563 |
|------|----|----|-----|-----|----|-----|
| **Our (Proposed)** | **0.99** | **1.11** | **1.23** | **1.15** | **1.26** | **0.93** |
| LSTM [8] | 1.55 | 1.50 | 1.70 | 1.28 | 1.38 | 1.19 |
| LRM [11] | 1.58 | 1.58 | 1.72 | 1.30 | 1.52 | 1.26 |

> âœ… æ‰€æœ‰è·¯çº¿å‡å–å¾—**æœ€ä½ MAE**ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

#### æ€§èƒ½æå‡ç¤ºä¾‹ï¼š
- åœ¨ **Route 60** ä¸Šæ¯” LSTM æå‡ **0.39 min**
- åœ¨ **Route 110** ä¸Šæ¯” LSTM æå‡ **0.47 min**
- åœ¨ **Route 563** ä¸Šæ¯” LSTM æå‡ **0.26 min**

> ğŸ’¡ ç‰¹åˆ«å€¼å¾—æ³¨æ„çš„æ˜¯ï¼š**ä¸€ä¸ªç®€å•çš„çº¿æ€§æ¨¡å‹ + æ™ºèƒ½é€‰æ®µ > å¤æ‚éçº¿æ€§æ¨¡å‹ï¼ˆLSTMï¼‰**

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ä¸åŒåˆ†æ®µé€‰æ‹©ç­–ç•¥å¯¹æ¯”ï¼ˆTable IIï¼‰

| æ–¹æ³• | æè¿° | å¹³å‡ MAE |
|------|------|--------|
| **ALL** | ä½¿ç”¨å…¨éƒ¨æ’å€¼ç‚¹ | 1.51 |
| **RS**ï¼ˆRandom Selectionï¼‰ | éšæœºé€‰å– 2/3 è·¯æ®µ | 1.91 |
| **RL**ï¼ˆOursï¼‰ | RL è‡ªé€‚åº”é€‰æ‹© | **1.11** |

> â—è¯´æ˜ï¼š**å¹¶éè¶Šå¤šè¶Šå¥½**ï¼Œéšæœºåˆ å‡åè€Œæ›´å·®ï¼›åªæœ‰æ™ºèƒ½é€‰æ‹©æ‰èƒ½æå‡æ€§èƒ½ã€‚

#### ï¼ˆ2ï¼‰å¥–åŠ±å‡½æ•°æ¯”è¾ƒï¼ˆTable IIIï¼‰

| å¥–åŠ±ç­–ç•¥ | Route 110 | Route 563 |
|---------|----------|----------|
| BCR | 1.79 | 1.19 |
| IER | 1.67 | 1.12 |
| **ATR**ï¼ˆOursï¼‰ | **1.23** | **0.93** |

> âœ… **ATR** æ•ˆæœæœ€å¥½ï¼Œå› å…¶æä¾›ç¨³å®šå¯†é›†çš„åé¦ˆä¿¡å·ã€‚

#### ï¼ˆ3ï¼‰æ˜¯å¦ä½¿ç”¨äºŒå…ƒæ©ç ï¼ˆBinary Maskï¼‰ï¼ˆTable IVï¼‰

| æ–¹æ³• | 110 | 563 |
|------|-----|-----|
| RSS-Net w/o S (æ— æ©ç ) | 1.98 | 1.11 |
| **RSS-Net w/ S**ï¼ˆå¸¦æ©ç ï¼‰ | **1.23** | **0.93** |

> âœ… äºŒå…ƒæ©ç æå¤§æå‡äº†æ¨¡å‹æ„ŸçŸ¥å·²é€‰èŠ‚ç‚¹çš„èƒ½åŠ›ã€‚

#### ï¼ˆ4ï¼‰åŠ¨ä½œè¿­ä»£æ¬¡æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆTable Vï¼‰
| è¿­ä»£æ¬¡æ•° | MAEï¼ˆå¹³å‡ï¼‰ |
|--------|------------|
| 2 | **1.11** |
| 4 | 1.13 |
| 6 | 1.16 |
| 8 | 1.18 |

> âœ… å°‘æ•°å‡ æ¬¡ç²¾ç»†è°ƒæ•´ä¼˜äºå¤šæ¬¡å¤§å¹…è·³è·ƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **éå‡åŒ€é“è·¯åˆ†æ®µæ˜¾è‘—ä¼˜äºå‡åŒ€åˆ†æ®µ**ï¼šç‰©ç†æ„ä¹‰æ˜ç¡®çš„å…³é”®è·¯æ®µï¼ˆå¦‚çº¢ç»¿ç¯ã€å­¦æ ¡é—¨å£ï¼‰æ¯”ä¸»å¹²é“ä¸­é—´çš„æ™®é€šè·¯æ®µæ›´å…·é¢„æµ‹ä»·å€¼ã€‚
2. âœ… **â€œLess is Moreâ€ æˆç«‹**ï¼šé€šè¿‡ RL ç²¾å‡†ç­›é€‰å…³é”®è·¯æ®µåï¼Œå³ä½¿ä½¿ç”¨ç®€å•çº¿æ€§æ¨¡å‹ä¹Ÿèƒ½è¶…è¶Šå¤æ‚æ·±åº¦æ¨¡å‹ã€‚
3. âœ… **ç‰¹å¾è´¨é‡ > ç‰¹å¾æ•°é‡**ï¼šç›²ç›®å¢åŠ æ’å€¼ç‚¹ä¼šå¼•å…¥å™ªå£°å¹¶åŠ å‰§è¯¯å·®ä¼ æ’­ï¼Œè€Œé«˜è´¨é‡ç¨€ç–è¡¨ç¤ºæ›´åˆ©äºæ³›åŒ–ã€‚
4. âœ… **RSS-Net å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šåœ¨é•¿çŸ­è·ç¦»ã€åŸå¸‚åŠŸèƒ½åŒºå„å¼‚çš„å¤šæ¡è·¯çº¿ä¸Šå‡ä¿æŒç¨³å®šé¢†å…ˆã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¨¡å‹ä¾èµ–é¢„å®šä¹‰çš„å€™é€‰æ’å€¼ç‚¹é›†åˆï¼Œå°šæœªå®ç°å®Œå…¨ç«¯åˆ°ç«¯çš„æ®µè½ç”Ÿæˆï¼›
- æœªèåˆå®æ—¶å¤–éƒ¨å› ç´ ï¼ˆå¦‚å¤©æ°”ã€çªå‘äº‹ä»¶ï¼‰ï¼›
- çº¿æ€§é¢„æµ‹å™¨é™åˆ¶äº†å¯¹é•¿ç¨‹éçº¿æ€§ä¾èµ–çš„å»ºæ¨¡èƒ½åŠ›ï¼Œå°¤å…¶åœ¨é•¿é€”è·¯çº¿ä¸­æå‡ç©ºé—´å—é™ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. å°† RSS-Net æ‰©å±•è‡³**é«˜é€Ÿå…¬è·¯ ETA é¢„æµ‹**åœºæ™¯ï¼›
2. å¼•å…¥**å®æ—¶ä¸Šä¸‹æ–‡ä¿¡æ¯**ï¼ˆtraffic flow, weatherï¼‰æ„å»º test-time adaptation æ¡†æ¶ï¼›
3. æ¢ç´¢â€œ**prediction as generation**â€èŒƒå¼ï¼Œç»“åˆç”Ÿæˆå¼ AI è¿›è¡Œäº¤é€šç½‘ç»œå»ºæ¨¡ï¼›
4. æ¨å¹¿è‡³å…¶ä»–äº¤é€šé¢„æµ‹ä»»åŠ¡ï¼ˆå¦‚ç½‘çº¦è½¦ã€å…±äº«å•è½¦åˆ°è¾¾æ—¶é—´é¢„æµ‹ï¼‰ã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–ä¸”é«˜æ•ˆçš„å…¬äº¤åˆ°è¾¾æ—¶é—´é¢„æµ‹æ¡†æ¶ï¼Œé€šè¿‡**å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„é“è·¯æ®µé€‰æ‹©æœºåˆ¶**ï¼Œå®ç°äº†â€œç”¨æ›´å°‘ã€å¾—æ›´å¤šâ€çš„ç›®æ ‡ã€‚å®éªŒè¯æ˜ï¼Œ**åˆç†çš„ç‰¹å¾é€‰æ‹©æ¯”å¤æ‚çš„æ¨¡å‹ç»“æ„æ›´é‡è¦**ï¼Œä¸ºæ™ºèƒ½äº¤é€šç³»ç»Ÿä¸­çš„æ•°æ®è¡¨ç¤ºä¸æ¨¡å‹è®¾è®¡æä¾›äº†æ–°çš„è§†è§’ã€‚

> ğŸ”— å¼€æºåœ°å€ï¼š[https://github.com/pangjunbiao/Less-is-More](https://github.com/pangjunbiao/Less-is-More)

</details>

---

### 13. [Parallel Algorithms for Combined Regularized Support Vector Machines: Application in Music Genre Classification](https://arxiv.org/abs/2512.07463)

**Authors**: Rongmei Liang, Zizheng Liu, Xiaofei Wu, Jingwen Tu  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.07463v1  

#### Abstract
In the era of rapid development of artificial intelligence, its applications span across diverse fields, relying heavily on effective data processing and model optimization. Combined Regularized Support Vector Machines (CR-SVMs) can effectively handle the structural information among data features, ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**åˆ†å¸ƒå¼å­˜å‚¨çš„å¤§è§„æ¨¡æ•°æ®**ä¸­ï¼Œ**Combined Regularized Support Vector Machines (CR-SVMs)** ç¼ºä¹é«˜æ•ˆå¹¶è¡Œç®—æ³•çš„é—®é¢˜ã€‚ä¼ ç»Ÿçš„SVMæ¨¡å‹åœ¨å¤„ç†é«˜ç»´ã€ç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚éŸ³ä¹ä¿¡å·ï¼‰æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ç‰¹å¾é—´çš„ç»„ç»“æ„ï¼ˆgroup structureï¼‰å’Œæ—¶é—´è¿ç»­æ€§ç­‰å…ˆéªŒä¿¡æ¯ï¼Œä¸”ç°æœ‰ç®—æ³•åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹æ•ˆç‡ä½ä¸‹ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
1. **æå‡ºç»Ÿä¸€ä¼˜åŒ–æ¡†æ¶**ï¼šåŸºäºå…±è¯†ç»“æ„ï¼ˆconsensus structureï¼‰ï¼Œæ„å»ºäº†ä¸€ä¸ªé€‚ç”¨äºå¤šç§æŸå¤±å‡½æ•°ï¼ˆloss functionsï¼‰å’Œç»„åˆæ­£åˆ™é¡¹ï¼ˆcombined regularization termsï¼‰çš„é€šç”¨ä¼˜åŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¯æ‰©å±•è‡³éå‡¸æ­£åˆ™é¡¹ï¼ˆå¦‚SCADã€MCPï¼‰ï¼Œå…·æœ‰å¼ºå¯æ‰©å±•æ€§ã€‚
2. **è®¾è®¡åˆ†å¸ƒå¼å¹¶è¡ŒADMMç®—æ³•**ï¼šå¼€å‘äº†ä¸€ç§åŸºäº**åˆ†å¸ƒå¼å¹¶è¡Œäº¤æ›¿æ–¹å‘ä¹˜å­æ³•ï¼ˆdistributed parallel ADMMï¼‰** çš„ç®—æ³•ï¼Œç”¨äºé«˜æ•ˆæ±‚è§£åˆ†å¸ƒå¼å­˜å‚¨ä¸‹çš„CR-SVMsã€‚
3. **å¼•å…¥Gaussian back-substitutionä¿è¯æ”¶æ•›**ï¼šç”±äºSVMä¸­çš„æˆªè·é¡¹ $ \beta_0 $ å¯¼è‡´æ— æ³•è½¬åŒ–ä¸ºä¸¤å—ADMMï¼Œæœ¬æ–‡é‡‡ç”¨ä¸‰å—ADMMï¼Œå¹¶é€šè¿‡**Gaussian back-substitution**æŠ€æœ¯ç¡®ä¿ç®—æ³•æ”¶æ•›ï¼Œå®ç°æ”¹è¿›çš„æ¬¡çº¿æ€§æ”¶æ•›ç‡ã€‚
4. **æå‡ºSGL-SVMæ¨¡å‹**ï¼šé¦–æ¬¡ç³»ç»Ÿåœ°æå‡ºäº†**ç¨€ç–ç»„å¥—ç´¢æ”¯æŒå‘é‡æœºï¼ˆSparse Group Lasso SVM, SGL-SVMï¼‰**ï¼Œèƒ½å¤Ÿåœ¨ç»„çº§åˆ«å’Œä¸ªä½“ç‰¹å¾çº§åˆ«åŒæ—¶å®ç°ç¨€ç–æ€§ï¼Œç‰¹åˆ«é€‚ç”¨äºå…·æœ‰è‡ªç„¶åˆ†ç»„ç»“æ„çš„æ•°æ®ï¼ˆå¦‚éŸ³ä¹ç‰¹å¾ï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é€šç”¨æ€§å¼º**ï¼šæå‡ºçš„ç®—æ³•æ¡†æ¶å¯å…¼å®¹54ç§ä¸åŒçš„CR-SVMæ¨¡å‹ï¼ˆ6ç§æŸå¤±å‡½æ•° Ã— 9ç§æ­£åˆ™ç»„åˆï¼‰ï¼Œæ— éœ€ä¸ºæ¯ç§æ¨¡å‹å•ç‹¬è®¾è®¡ç®—æ³•ã€‚
- **è®¡ç®—å¤æ‚åº¦ç‹¬ç«‹äºæ­£åˆ™é¡¹ä¸æŸå¤±å‡½æ•°**ï¼šç†è®ºåˆ†æè¡¨æ˜ï¼Œç®—æ³•çš„è®¡ç®—å¤æ‚åº¦ä¸å—å…·ä½“æ­£åˆ™é¡¹æˆ–æŸå¤±å‡½æ•°å½±å“ï¼Œä½“ç°äº†é«˜åº¦çš„æ™®é€‚æ€§ã€‚
- **é€‚ç”¨äºéå‡¸æ­£åˆ™åŒ–**ï¼šèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†SCADã€MCPç­‰éå‡¸æ­£åˆ™é¡¹ï¼Œå‡å°‘å‚æ•°ä¼°è®¡åå·®ã€‚
- **æ”¶æ•›æ€§ä¿éšœ**ï¼šé€šè¿‡Gaussian back-substitutionè§£å†³äº†å¤šå—ADMMçš„æ”¶æ•›éš¾é¢˜ï¼Œæå‡äº†ç®—æ³•ç¨³å®šæ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
1. **åˆæˆæ•°æ®ï¼ˆSynthetic Dataï¼‰**ï¼š
   - æ•°æ®åˆ†å¸ƒï¼šæ¥è‡ªä¸¤ä¸ªå¤šå…ƒæ­£æ€åˆ†å¸ƒ $ N(\mu_+, \Sigma) $ å’Œ $ N(\mu_-, \Sigma) $
   - ç‰¹å¾ç»´åº¦ $ p = 500 $ æˆ– $ 1000 $
   - æ ·æœ¬æ•°é‡ $ n = 200,000 $ æˆ– $ 500,000 $
   - å¼•å…¥20%æ ‡ç­¾å™ªå£°ä»¥æµ‹è¯•é²æ£’æ€§

2. **çœŸå®æ•°æ®é›†ï¼šFMAï¼ˆFree Music Archivï¼‰**
   - æ¥æºï¼šGitHubå…¬å¼€éŸ³ä¹åˆ†ææ•°æ®é›†ï¼ˆhttps://github.com/mdeff/fmaï¼‰
   - å­é›†ï¼š`fma_small`ï¼Œå…±8ä¸ªæµæ´¾ï¼Œæ¯ç±»1000ä¸ªéŸ³é¢‘æ ·æœ¬ï¼Œæ€»è®¡8000æ¡
   - ç‰¹å¾æ€»æ•°ï¼š1036ç»´ï¼Œåˆ†ä¸º7ä¸ªç‰©ç†æ„ä¹‰æ˜ç¡®çš„ç»„ï¼š
     - æ—¶é—´åŸŸç‰¹å¾ï¼ˆ16ï¼‰
     - é¢‘è°±ç‰¹å¾ï¼ˆ32ï¼‰
     - MFCCç‰¹å¾ï¼ˆ160ï¼‰
     - Chromaç‰¹å¾ï¼ˆ96ï¼‰
     - Tonnetzç‰¹å¾ï¼ˆ48ï¼‰
     - Echonestç‰¹å¾ï¼ˆ518ï¼‰
     - å…¶ä»–ç‰¹å¾ï¼ˆ166ï¼‰

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **å¹¶è¡Œç¯å¢ƒ**ï¼šå°†æ•°æ®åˆ’åˆ†ä¸º $ K=2,4,\dots,20 $ ä¸ªå­å—ï¼Œæ¨¡æ‹Ÿåˆ†å¸ƒå¼è®­ç»ƒ
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **åˆ†ç±»å‡†ç¡®ç‡ï¼ˆCAR / Accuracyï¼‰**ï¼šè®­ç»ƒé›†ä¸æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡
  - **è®¡ç®—æ—¶é—´ï¼ˆCTï¼‰**
  - **è¿­ä»£æ¬¡æ•°ï¼ˆNIï¼‰**
  - **é€‰ä¸­çœŸå®ç‰¹å¾æ•°ï¼ˆNTSFï¼‰**
  - **ç¨€ç–æ€§ï¼ˆSparsityï¼‰**ï¼šé›¶ç³»æ•°æ¯”ä¾‹
- **å‚æ•°é€‰æ‹©**ï¼šä½¿ç”¨SVMä¿¡æ¯å‡†åˆ™ï¼ˆSVMICï¼‰è‡ªåŠ¨é€‰æ‹©æ­£åˆ™å‚æ•° $ \lambda_1, \lambda_2 $

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **QPADM-slack**ï¼ˆGuan et al., 2020ï¼‰
- **QPADM-slack(GB)**ï¼ˆWu et al., 2025bï¼‰
- **M-QPADM-slack(GB)**ï¼ˆWu et al., 2025bï¼‰

æ‰€æœ‰åŸºçº¿å‡ç»“åˆSCAD-SVMè¿›è¡Œæ¯”è¾ƒï¼Œè€Œæœ¬æ–‡æ–¹æ³•ä½¿ç”¨SGL-SVMã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table 7 & Table 8ï¼‰

#### åœ¨åˆæˆæ•°æ®ä¸Šï¼ˆ$ (n,p)=(500000,1000) $ï¼‰ï¼š
| æ–¹æ³• | CAR (%) | CT (s) | NI | NTSF |
|------|---------|--------|----|-------|
| **PADMM (æœ¬æ–‡)** | **97.2** | **1.942** | **40.1** | **10.8** |
| QPADM-slack | 96.5 | 2.010 | 44.7 | 11.1 |
| QPADM-slack(GB) | 96.8 | 1.980 | 44.5 | 11.0 |

- **PADMMåœ¨å‡†ç¡®æ€§ã€é€Ÿåº¦ã€è¿­ä»£æ¬¡æ•°ä¸Šå…¨é¢ä¼˜äºåŸºçº¿**
- æ‰€æœ‰æ–¹æ³•éšç€ $ K $ å¢åŠ ï¼ŒCARç•¥æœ‰ä¸‹é™ï¼ŒCTé™ä½ï¼ŒNIä¸Šå‡ â€”â€” è¿™æ˜¯å…±è¯†ç»“æ„å¸¦æ¥çš„å›ºæœ‰ trade-off

#### åœ¨FMAçœŸå®æ•°æ®ä¸Šï¼ˆå¹³å‡100æ¬¡è¿è¡Œï¼‰ï¼š
| $ K $ | æ–¹æ³• | Sparsity (%) | Train Acc (%) | Test Acc (%) |
|-------|------|--------------|---------------|--------------|
| 2 | **PADMM** | **90.38** | **99.32** | **97.27** |
|     | QPADM-slack(GB) | 85.99 | 95.14 | 92.96 |
|     | QPADM-slack | 83.64 | 93.38 | 92.00 |
| 20 | **PADMM** | **89.57** | **98.34** | **96.27** |
|     | QPADM-slack(GB) | 76.26 | 88.64 | 85.35 |
|     | QPADM-slack | 71.46 | 87.67 | 85.18 |

- **PADMMåœ¨æ‰€æœ‰ $ K $ ä¸‹å‡ä¿æŒæœ€é«˜å‡†ç¡®ç‡ä¸ç¨€ç–æ€§**
- å³ä½¿åœ¨ $ K=20 $ æ—¶ï¼ŒPADMMä»ç»´æŒçº¦96.3%æµ‹è¯•å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼ˆ~85%ï¼‰

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **åˆ†ç±»æ€§èƒ½æ›´ä¼˜**ï¼šPADMMåœ¨è®­ç»ƒå’Œæµ‹è¯•é›†ä¸Šå‡å–å¾—æ›´é«˜å‡†ç¡®ç‡ï¼Œè¯´æ˜å…¶æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚
- **æ¨¡å‹æ›´ç¨€ç–**ï¼šSparsityé«˜å‡ºçº¦5â€“18ä¸ªç™¾åˆ†ç‚¹ï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹å¯è§£é‡Šæ€§å’Œå‹ç¼©å­˜å‚¨ã€‚
- **æ”¶æ•›æ›´å¿«**ï¼šæ‰€éœ€è¿­ä»£æ¬¡æ•°æ›´å°‘ï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡æ•°æ®ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚
- **é€šä¿¡å¼€é”€æ›´ä½**ï¼šé€šè¿‡å±€éƒ¨è®¡ç®— $ c_k $ å¹¶èšåˆï¼Œå‡å°‘äº†ä¸­å¿ƒèŠ‚ç‚¹çš„é€šä¿¡è´Ÿæ‹…ã€‚

### æ¶ˆèå®éªŒä¸ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆæ— æ˜¾å¼æ¶ˆèè¡¨ï¼Œä½†æœ‰æ·±å…¥åˆ†æï¼‰
- **ç‰¹å¾ç»„é‡è¦æ€§æ’åº**ï¼ˆåŸºäºSGL-SVMç³»æ•°ç»å¯¹å€¼ä¹‹å’Œï¼‰ï¼š
  1. **MFCCç‰¹å¾ç»„**ï¼ˆæœ€é‡è¦ï¼‰
  2. **é¢‘è°±ç‰¹å¾ç»„**
  3. **Chromaç‰¹å¾ç»„**
  4. å…¶ä½™å››ç»„ï¼ˆTonnetz, Echonest, æ—¶é—´åŸŸ, å…¶ä»–ï¼‰è´¡çŒ®æå°ï¼Œå¯å¿½ç•¥

> **å…³é”®å‘ç°**ï¼šå½“æœºå™¨å†…å­˜æœ‰é™æ—¶ï¼Œä»…æ”¶é›†ä¸Šè¿°å‰ä¸‰ç»„ç‰¹å¾å³å¯å®ç°é«˜æ•ˆçš„éŸ³ä¹åˆ†ç±»ï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´å¹¶ä¿æŒé«˜æ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **SGL-SVMèƒ½æœ‰æ•ˆæ•æ‰éŸ³ä¹ç‰¹å¾çš„åŒé‡ç¨€ç–æ€§**ï¼šæ—¢èƒ½åœ¨ç»„å±‚é¢ç­›é€‰é‡è¦ç‰¹å¾ç±»åˆ«ï¼ˆå¦‚MFCCï¼‰ï¼Œä¹Ÿèƒ½åœ¨ç»„å†…è¯†åˆ«å…³é”®é¢„æµ‹å˜é‡ï¼Œå¢å¼ºæ¨¡å‹å¯è§£é‡Šæ€§ã€‚
2. **æ‰€æå¹¶è¡ŒADMMç®—æ³•å…·å¤‡é«˜å¯é æ€§ã€ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§**ï¼šåœ¨åˆæˆä¸çœŸå®æ•°æ®ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶é€‚åˆå¤„ç†å¤§è§„æ¨¡ã€é«˜ç»´ã€ç»“æ„åŒ–çš„éŸ³ä¹æ•°æ®ã€‚
3. **ç®—æ³•å¤æ‚åº¦ä¸ä¾èµ–äºæ­£åˆ™é¡¹ä¸æŸå¤±å‡½æ•°å½¢å¼**ï¼šéªŒè¯äº†æ‰€ææ¡†æ¶çš„é«˜åº¦é€šç”¨æ€§ã€‚
4. **MFCCæ˜¯éŸ³ä¹æµæ´¾åˆ†ç±»ä¸­æœ€å…³é”®çš„ç‰¹å¾ç»„**ï¼Œå…¶æ¬¡æ˜¯é¢‘è°±å’ŒChromaç‰¹å¾ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ç®—æ³•ä¸»è¦é¢å‘**å‡¸æŸå¤±å‡½æ•°**ï¼ˆå¦‚hinge lossï¼‰ï¼Œå¯¹éå‡¸æŸå¤±å‡½æ•°çš„æ”¯æŒå°šæœªæ¶µç›–ã€‚
- éšç€å­æœºå™¨æ•°é‡ $ K $ å¢åŠ ï¼Œç”±äºå…±è¯†çº¦æŸçš„å­˜åœ¨ï¼Œåˆ†ç±»ç²¾åº¦ä¼šç¼“æ…¢ä¸‹é™ï¼Œå­˜åœ¨æ€§èƒ½å¤©èŠ±æ¿ã€‚
- å®éªŒå—é™äºç¡¬ä»¶å†…å­˜ï¼Œæœ€å¤šä»…æ”¯æŒçº¦20å°å¹¶è¡Œæœºå™¨ï¼Œæ›´å¤§è§„æ¨¡å¹¶è¡Œæ•ˆæœæœªå……åˆ†éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. å°†æ¡†æ¶æ‰©å±•è‡³**éå‡¸æŸå¤±å‡½æ•°**ï¼ˆå¦‚bounded concave lossï¼‰åœºæ™¯ã€‚
2. æ¢ç´¢åœ¨**å™ªå£°æˆ–ç¼ºå¤±æ•°æ®**æ¡ä»¶ä¸‹çš„é²æ£’æ€§ä¸æ”¶æ•›æ€§è´¨ã€‚
3. ç»“åˆ**éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰æˆ–åŠ é€ŸæŠ€æœ¯**ï¼ˆå¦‚Nesterov momentumï¼‰è¿›ä¸€æ­¥æå‡æ”¶æ•›é€Ÿåº¦ã€‚
4. åº”ç”¨äº**å¤šæ ‡ç­¾ä»»åŠ¡**ï¼ˆmulti-label tasksï¼‰ï¼Œå¦‚éŸ³ä¹è‡ªåŠ¨æ‰“æ ‡ï¼ˆmusic auto-taggingï¼‰ã€‚
5. æ¨å¹¿åˆ°å…¶ä»–å…·æœ‰ç»“æ„åŒ–ç‰¹å¾çš„é¢†åŸŸï¼Œå¦‚ç”Ÿç‰©ä¿¡æ¯å­¦ã€é¥æ„Ÿå›¾åƒåˆ†æç­‰ã€‚

> **ä»£ç å¼€æº**ï¼šä½œè€…å·²å°†å®Œæ•´Rä»£ç å‘å¸ƒäº GitHubï¼š[https://github.com/xfwu1016/PADMM-for-Svms](https://github.com/xfwu1016/PADMM-for-Svms)ï¼Œä¾¿äºå¤ç°ä¸åº”ç”¨ã€‚

</details>

---

### 14. [Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents](https://arxiv.org/abs/2512.06716)

**Authors**: Zhibo Liang, Tianze Hu, Zaiye Chen, Mingjie Tang  
**Category**: cs.AI  
**Published**: 2025-12-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.06716v1  

#### Abstract
Autonomous Large Language Model (LLM) agents exhibit significant vulnerability to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources, exploiting fundamental trade-offs between security and functionality in existing defense mechanism...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹ **Large Language Model (LLM) agents** åœ¨è‡ªä¸»æ‰§è¡Œä»»åŠ¡æ—¶é¢ä¸´çš„ä¸¥é‡å®‰å…¨å¨èƒâ€”â€”**é—´æ¥æç¤ºæ³¨å…¥æ”»å‡»ï¼ˆIndirect Prompt Injection, IPIï¼‰**ã€‚è¿™ç±»æ”»å‡»é€šè¿‡æ±¡æŸ“å¤–éƒ¨ä¿¡æ¯æºï¼ˆå¦‚ç½‘é¡µã€æ–‡ä»¶ã€é‚®ä»¶ç­‰ï¼‰ï¼Œè¯±å¯¼ agent æ‰§è¡Œæ¶æ„æ“ä½œï¼ˆå¦‚æ•°æ®æ³„éœ²ã€æœªç»æˆæƒçš„å·¥å…·è°ƒç”¨ï¼‰ï¼Œä»è€Œåç¦»ç”¨æˆ·åŸå§‹æ„å›¾ã€‚

ç°æœ‰é˜²å¾¡æœºåˆ¶å­˜åœ¨æ ¹æœ¬æ€§ç¼ºé™·ï¼š
- **Runtime checks** åªèƒ½æ£€æµ‹å•æ­¥è¡Œä¸ºï¼Œæ— æ³•è¯†åˆ«é•¿ç¨‹æ¶æ„è®¡åˆ’ï¼›
- **Architectural defenses** å¼€é”€å¤§æˆ–é™åˆ¶åŠŸèƒ½ï¼›
- **Training-time alignment** éš¾ä»¥æ³›åŒ–åˆ°æ–°å‹æˆ–ä¼˜åŒ–å‹æ”»å‡»ï¼›
- å¤šæ•°æ–¹æ³•æ˜¯**ç¢ç‰‡åŒ–çš„ï¼ˆfragmentedï¼‰**ï¼Œç¼ºä¹å¯¹æ•´ä¸ªä»»åŠ¡ç”Ÿå‘½å‘¨æœŸçš„ç«¯åˆ°ç«¯å®Œæ•´æ€§ä¿éšœã€‚

å› æ­¤ï¼Œå½“å‰æ–¹æ³•åœ¨ **å®‰å…¨æ€§ã€åŠŸèƒ½æ€§ã€æ•ˆç‡** ä¹‹é—´è¢«è¿«åšå‡ºå¤šç»´å¦¥åã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„å…¨å‘¨æœŸè®¤çŸ¥ç›‘ç£æ¡†æ¶ â€”â€” **Cognitive Control Architecture (CCA)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> â€œæ— è®ºå¤šä¹ˆéšè”½çš„ IPI æ”»å‡»ï¼Œåªè¦è¿½æ±‚æ¶æ„ç›®æ ‡ï¼Œæœ€ç»ˆéƒ½ä¼šåœ¨è¡Œä¸ºè½¨è¿¹ä¸Šè¡¨ç°å‡ºå¯æ£€æµ‹çš„åå·®ã€‚â€

åŸºäºæ­¤æ´å¯Ÿï¼ŒCCA æ„å»ºäº†ä¸€ä¸ªåŒå±‚ååŒé˜²å¾¡ç³»ç»Ÿï¼š

#### âœ… Pillar I: **Intent Graph**ï¼ˆä¸»åŠ¨æ§åˆ¶æµä¸æ•°æ®æµå®Œæ•´æ€§ï¼‰
- åœ¨ä»»åŠ¡å¼€å§‹å‰ï¼Œæ ¹æ®ç”¨æˆ·ç›®æ ‡ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„ **Directed Acyclic Graph (DAG)**ï¼Œç§°ä¸º *Intent Graph*ã€‚
- å›¾ä¸­æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªåˆæ³•çš„å·¥å…·è°ƒç”¨ï¼ˆtool callï¼‰ï¼Œè¾¹è¡¨ç¤ºæ‰§è¡Œé¡ºåºã€‚
- è¿è¡Œæ—¶å¯¹æ¯ä¸€æ­¥è¿›è¡ŒåŒé‡éªŒè¯ï¼š
  - **Control-Flow Check**ï¼šåŠ¨ä½œæ˜¯å¦ç¬¦åˆé¢„å®šä¹‰çš„æ‹“æ‰‘åºåˆ—ï¼Ÿ
  - **Data-Flow Integrity Check**ï¼šå‚æ•°æ¥æºæ˜¯å¦åˆæ³•ï¼Ÿä»…å…è®¸æ¥è‡ªç”¨æˆ·è¾“å…¥æˆ–ä¸Šæ¸¸å¯ä¿¡èŠ‚ç‚¹è¾“å‡ºï¼Œç¦æ­¢ä»å¯èƒ½è¢«æ±¡æŸ“çš„ä¸Šä¸‹æ–‡ä¸­æå–ã€‚

è¿™å®ç°äº†**ä½å¼€é”€ã€å®æ—¶çš„ç»“æ„æ€§é˜²æŠ¤**ï¼Œè¿‡æ»¤æ‰æ˜æ˜¾çš„è§„åˆ’åå·®ã€‚

#### âœ… Pillar II: **Tiered Adjudicator**ï¼ˆåˆ†çº§è£å†³å™¨ï¼Œç”¨äºé«˜ä¿çœŸå¼‚å¸¸åˆ¤å®šï¼‰
- å½“åŠ¨ä½œåç¦» Intent Graph æ—¶è§¦å‘ã€‚
- å¼•å…¥å¤šç»´åº¦è¯„åˆ†æœºåˆ¶ â€”â€” **Intent Alignment Score (Salign)**ï¼Œç»¼åˆå››ä¸ªå­åˆ†æ•°åŠ æƒè®¡ç®—ï¼š
  1. **Semantic Alignment (Ssem)**ï¼šè¯­ä¹‰ç›¸å…³æ€§ï¼ˆä¸ç”¨æˆ·ç›®æ ‡çš„ç›¸ä¼¼åº¦ï¼‰
  2. **Causal Contribution (Scausal)**ï¼šé€»è¾‘å¿…è¦æ€§ï¼ˆè¯¥åŠ¨ä½œæ˜¯å¦çœŸæ­£æœ‰åŠ©äºè¾¾æˆç›®æ ‡ï¼Ÿç”± LLM åˆ¤æ–­ï¼‰
  3. **Source Provenance (Sprov)**ï¼šæ¥æºå¯ä¿¡åº¦ï¼ˆè§¦å‘è¯¥åŠ¨ä½œçš„ä¿¡æ¯æºæ˜¯å¦å¯é ï¼ŸåŠ¨æ€æ›´æ–°ä¿¡ä»»åˆ†ï¼‰
  4. **Inherent Action Risk Score (Srisk)**ï¼šå›ºæœ‰é£é™©å€¼ï¼ˆé¢„å…ˆè®¾å®šé«˜å±æ“ä½œçš„é£é™©ç­‰çº§ï¼Œå¦‚ `transfer_money` = 1.0ï¼‰

æœ€ç»ˆå†³ç­–åŸºäºæ€»åˆ†å†³å®šï¼šæ‰¹å‡†ã€é˜»æ–­æˆ–è¯¢é—®ç”¨æˆ·ã€‚

æ­¤å¤–ï¼ŒCCA æ”¯æŒ **åŠ¨æ€å›¾æ›´æ–°ï¼ˆdynamic graph updateï¼‰**ï¼šå½“è£å†³å™¨ç¡®è®¤æŸæ¬¡â€œåç¦»â€å®ä¸ºåˆç†è°ƒæ•´åï¼Œä¼šå°†æ–°è·¯å¾„åŠ å…¥ Intent Graphï¼Œå®ç°å®‰å…¨è¾¹ç•Œä¸‹çš„çµæ´»é€‚åº”ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | CCA çš„ä¼˜åŠ¿ |
|------|-----------|
| **å®‰å…¨æ€§** | æ˜¾è‘—é™ä½æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰ï¼Œå°¤å…¶å¯¹æŠ—å¤æ‚æ¡ä»¶æ€§æ”»å‡»ï¼ˆå¦‚ Important Messagesï¼‰ |
| **åŠŸèƒ½æ€§** | åœ¨æ— æ”»å‡»åœºæ™¯ä¸‹ä¿æŒæ¥è¿‘åŸå§‹ agent çš„ä»»åŠ¡å®Œæˆç‡ï¼ˆBUï¼‰ï¼Œè¿œä¼˜äºå…¶ä»–é˜²å¾¡æ–¹æ³• |
| **æ•ˆç‡** | åˆ†å±‚è®¾è®¡é¿å…é¢‘ç¹è°ƒç”¨æ˜‚è´µçš„ LLM æ¨ç†ï¼Œtoken æ¶ˆè€—ä»…ä¸º MELON çš„ ~1/3.3 |
| **ç³»ç»Ÿæ€§** | é¦–æ¬¡å®ç°ä»â€œäº‹åæ ¡éªŒâ€åˆ°â€œå…¨ç”Ÿå‘½å‘¨æœŸè®¤çŸ¥ç›‘ç£â€çš„èŒƒå¼è½¬å˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **AgentDojo**ï¼šä¸€ä¸ªåŠ¨æ€ã€æœ‰çŠ¶æ€çš„ benchmarkï¼ŒåŒ…å« 97 ä¸ªå¤šè½®ä»»åŠ¡ï¼Œæ¶µç›– emailã€bankingã€workspaceã€travel ç­‰å¤šä¸ªé¢†åŸŸã€‚
- ä½¿ç”¨ç¡®å®šæ€§ä»£ç è¯„ä¼°ï¼ˆdeterministic code evaluationï¼‰ï¼Œé€‚åˆæµ‹è¯•å…¨å±€ç›‘ç£èƒ½åŠ›ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### âœ… æ¨¡å‹é…ç½®
- **ä¸» agent æ¨¡å‹**ï¼šDeepSeek-V3.1 å’Œ Kimi K2
- **Adjudicator æ¨¡å‹**ï¼šå›ºå®šä¸º DeepSeek-V3.1
- æ¸©åº¦è®¾ä¸º 0.0 ä¿è¯å¯å¤ç°æ€§

#### âœ… æ”»å‡»ç±»å‹ï¼ˆå…±å››ç§ IPI æ”»å‡»ï¼‰
1. **Direct**ï¼šç›´æ¥åµŒå…¥æ¶æ„æŒ‡ä»¤
2. **Ignore Prev**ï¼šè¦æ±‚å¿½ç•¥å…ˆå‰æŒ‡ä»¤
3. **System Msg**ï¼šä¼ªè£…æˆç³»ç»Ÿçº§æç¤º
4. **Important Messages**ï¼šä¼ªè£…æˆç”¨æˆ·å‘å‡ºçš„é‡è¦æ¶ˆæ¯ï¼ˆæœ€éšè”½ã€æœ€éš¾é˜²å¾¡ï¼‰

#### âœ… åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| Prompt Engineering | Repeat Prompt, Spotlight |
| å¤–éƒ¨åˆ†ç±»å™¨ | DeBERTa classifier |
| SOTA Runtime Verification | MELON |
| æ— é˜²å¾¡ | No Defense |

#### âœ… è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Attack Success Rate (ASR, â†“)** | æ”»å‡»è€…ç›®æ ‡è¾¾æˆçš„æ¯”ä¾‹ |
| **Benign Utility (BU, â†‘)** | æ— æ”»å‡»æ—¶ä»»åŠ¡æˆåŠŸå®Œæˆç‡ |
| **Utility Under Attack (UA, â†‘)** | å­˜åœ¨æ”»å‡»æ—¶ä»æ­£ç¡®å®Œæˆä»»åŠ¡ä¸”æœªæ‰§è¡Œæ¶æ„æ“ä½œçš„æ¯”ä¾‹ |
| **API å¼€é”€ / Token ä½¿ç”¨é‡** | è¡¡é‡è¿è¡Œæ•ˆç‡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰**

| æ–¹æ³• | å¹³å‡ ASR (%) | UA (%) | BU (%) |
|------|-------------|--------|--------|
| No Defense | 11.99 | 81.67 | 89.69 |
| DeBERTa | 2.27 | 42.97 | 53.61 |
| MELON (SOTA) | **0.16** | 43.76 | 72.16 |
| **CCA (Ours)** | **0.34** | **86.43** | **87.63** |

> ğŸ” **è§£è¯»**ï¼š
> - CCA å°†å¹³å‡ ASR ä» 11.99% é™è‡³ **0.34%**ï¼Œæ”»å‡»ç¼“è§£ç‡è¾¾ **>97%**
> - åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„ **Important Messages** æ”»å‡»ä¸­ï¼ŒCCA ASR = **0.84%**ï¼Œæ˜¾è‘—ä¼˜äº Spotlight (42.78%) å’Œ MELON (0.63%)
> - CCA çš„ UA è¾¾åˆ° **86.43%**ï¼Œå‡ ä¹æ˜¯ MELON (43.76%) çš„ä¸¤å€ï¼Œè¯´æ˜å…¶åœ¨é˜²å¾¡åŒæ—¶æå¤§ä¿ç•™äº†åŠŸèƒ½æ€§

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **å®‰å…¨æ€§æ–¹é¢**ï¼š
  - CCA ä¸ MELON åŒå±é¡¶çº§é˜²å¾¡æ°´å¹³ï¼ˆASR < 1%ï¼‰
  - ä½†åœ¨æœ€éš¾çš„ Important Messages æ”»å‡»ä¸­ï¼ŒCCA è¡¨ç°æ›´ç¨³å®š

- **åŠŸèƒ½æ€§æ–¹é¢**ï¼š
  - CCA çš„ BU ä»…ä¸‹é™ 2.06%ï¼Œè€Œ MELON ä¸‹é™ 19.6%ï¼ŒDeBERTa ä¸‹é™ 40.2%
  - CCA æˆåŠŸè§£å†³äº†â€œå®‰å…¨ vs åŠŸèƒ½â€çš„ç»å…¸ trade-off

- **æ•ˆç‡æ–¹é¢**ï¼ˆFigure 4bï¼‰ï¼š
  - CCA å¹³å‡æ¯ä»»åŠ¡æ¶ˆè€—çº¦ **3857 tokens**
  - MELON æ¶ˆè€—é«˜è¾¾ **12772 tokens**ï¼ˆçº¦ä¸º CCA çš„ 3.3 å€ï¼‰
  - æ•ˆç‡æå‡ä¸»è¦å¾—ç›Šäº Layer 1 çš„è½»é‡çº§ Intent Graph éªŒè¯ï¼Œä»…åœ¨å¿…è¦æ—¶æ‰å¯ç”¨ Layer 2 çš„ LLM è£å†³

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

#### âœ… æ¨¡å‹æ— å…³æ€§æµ‹è¯•ï¼ˆTable 2ï¼‰
ä½¿ç”¨ Kimi K2 æ›¿æ¢ä¸»æ¨¡å‹ï¼š
- ASR ä» 29.50% â†’ **0.53%**
- UA ä» 74.18% â†’ **82.51%**ï¼ˆç”šè‡³é«˜äºæ— é˜²å¾¡ï¼ï¼‰
â†’ è¯æ˜ CCA å…·å¤‡è‰¯å¥½çš„ **model-agnostic robustness**

#### âœ… ç»„ä»¶é‡è¦æ€§åˆ†æï¼ˆTable 3 & Figure 3ï¼‰

| é…ç½® | ASR (%) | UA (%) |
|------|--------|--------|
| Full CCA | **0.53** | **82.51** |
| w/o S_causal | 4.95 | 66.49 |
| w/o S_risk | 1.58 | 81.98 |
| w/o S_prov | 1.48 | 83.46 |
| w/o S_sem | 0.74 | 83.56 |

> ğŸ” **å‘ç°**ï¼š
> - ç§»é™¤ **S_causal** å¯¼è‡´æ€§èƒ½å´©æºƒï¼Œè¯´æ˜å› æœæ¨ç†æ˜¯æ ¸å¿ƒæ”¯æŸ±
> - ç§»é™¤å…¶ä»–ç»„ä»¶è™½å¯¹å¹³å‡ UA å½±å“è¾ƒå°ï¼Œä½†ä¼šå¯¼è‡´æ›´å¤šä½åˆ†å¼‚å¸¸æ¡ˆä¾‹ï¼ˆoutliersï¼‰ï¼Œå½±å“é²æ£’æ€§
> - æ‰€æœ‰ç»„ä»¶å…±åŒä½œç”¨ä½¿ Salign åˆ†å¸ƒæ›´å¹³æ»‘ã€æ›´å…·åˆ¤åˆ«åŠ›ï¼Œé¿å…â€œä¿¡æ¯æ‚¬å´–â€ï¼ˆinformation cliffï¼‰

#### âœ… åŠ¨æ€å›¾æ›´æ–°æ¶ˆèï¼ˆTable 8ï¼‰
- å…³é—­åŠ¨æ€æ›´æ–°åï¼ŒUA ä» 86.47% â†’ 84.19%
- å®‰å…¨æ€§ä¸å˜ï¼ˆASR â‰ˆ 0.7%ï¼‰
â†’ è¯å®åŠ¨æ€å›¾æ›´æ–°å¯¹ç»´æŒä¸Šä¸‹æ–‡è¿è´¯æ€§å’Œä»»åŠ¡æˆåŠŸç‡è‡³å…³é‡è¦

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **IPI æ”»å‡»çš„æœ¬è´¨æ˜¯è¡Œä¸ºè½¨è¿¹çš„å¯æ£€æµ‹åå·®**ï¼Œå¯é€šè¿‡æ§åˆ¶æµ + æ•°æ®æµè”åˆç›‘æ§æœ‰æ•ˆæ•æ‰ã€‚
2. **Intent Graph + Tiered Adjudicator çš„åŒå±‚æ¶æ„** å®ç°äº†å®‰å…¨æ€§ã€åŠŸèƒ½æ€§ã€æ•ˆç‡ä¸‰è€…çš„ç»Ÿä¸€ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿ trade-offã€‚
3. **Causal Contribution åˆ†ææ˜¯è£å†³æœºåˆ¶çš„æ ¸å¿ƒ**ï¼Œä»…é è¯­ä¹‰åŒ¹é…ä¸è¶³ä»¥åº”å¯¹é«˜çº§ä¼ªè£…æ”»å‡»ã€‚
4. **åŠ¨æ€å›¾æ›´æ–°æœºåˆ¶å¢å¼ºäº†ç³»ç»Ÿçš„çµæ´»æ€§ä¸å®ç”¨æ€§**ï¼Œå…è®¸ agent åœ¨å®‰å…¨å‰æä¸‹é€‚åº”ç¯å¢ƒå˜åŒ–ã€‚
5. CCA åœ¨å¤šç§ LLM æ¶æ„ï¼ˆåŒ…æ‹¬å¼€æºä¸ API æ¨¡å‹ï¼‰ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œå…·å¤‡è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä»»åŠ¡éœ€å¯åˆ†è§£ä¸ºæ˜ç¡®çš„ Intent Graph**ï¼šå¯¹äºé«˜åº¦å¼€æ”¾ã€æ¢ç´¢æ€§å¼ºçš„ä»»åŠ¡ï¼ˆå¦‚è‡ªç”±åˆ›ä½œã€ç§‘ç ”æ¢ç´¢ï¼‰ï¼Œéš¾ä»¥æå‰æ„å»ºå®Œæ•´è®¡åˆ’ã€‚
2. **Inherent Action Risk Score (Srisk) æ˜¯é™æ€çš„**ï¼šæœªè€ƒè™‘å‚æ•°ä¾èµ–çš„é£é™©å˜åŒ–ï¼ˆä¾‹å¦‚ `send_email` å‘ç»™è°ï¼Ÿé‡‘é¢å¤šå¤§ï¼Ÿï¼‰ã€‚
3. **Source Provenance Score åœ¨çŸ­ä»»åŠ¡ä¸­ç®€åŒ–ä¸ºé™æ€å€¼**ï¼šæœªèƒ½å……åˆ†å‘æŒ¥å…¶åŠ¨æ€å­¦ä¹ æ½œåŠ›ã€‚
4. **ä¾èµ–é«˜è´¨é‡çš„ Intent Graph ç”Ÿæˆèƒ½åŠ›**ï¼šè‹¥åˆå§‹è§„åˆ’é”™è¯¯ï¼Œå¯èƒ½å¯¼è‡´è¯¯åˆ¤ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **åŠ¨æ€å›¾ç”Ÿæˆä¸æ¼”åŒ–æœºåˆ¶**ï¼šæ”¯æŒåœ¨è¿è¡Œä¸­è‡ªåŠ¨æ‰©å±•å’Œä¿®æ­£ Intent Graphï¼Œé€‚ç”¨äºå¼€æ”¾å¼ä»»åŠ¡ã€‚
2. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é£é™©è¯„åˆ†æ¨¡å‹**ï¼šå¼€å‘å‚æ•°æ•æ„Ÿçš„åŠ¨æ€ Sriskï¼Œç»“åˆ argument å†…å®¹è¯„ä¼°çœŸå®å±å®³ã€‚
3. **å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„ä¿¡ä»»æ›´æ–°æœºåˆ¶**ï¼šè®© Sprov èƒ½åœ¨é•¿æœŸäº¤äº’ä¸­æŒç»­ä¼˜åŒ–ã€‚
4. **é›†æˆæ›´å¤šæ¨¡æ€è¾“å…¥**ï¼ˆå¦‚å›¾åƒã€è¯­éŸ³ï¼‰ä¸‹çš„ CCA æ‰©å±•ã€‚
5. æ¢ç´¢ CCA åœ¨ multi-agent åä½œåœºæ™¯ä¸­çš„åº”ç”¨ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> CCA æå‡ºäº†ä¸€ç§ç³»ç»Ÿæ€§çš„å…¨ç”Ÿå‘½å‘¨æœŸç›‘ç£æ¡†æ¶ï¼Œé¦–æ¬¡å®ç°äº† LLM agent åœ¨é¢å¯¹å¤æ‚ IPI æ”»å‡»æ—¶â€œæ—¢å®‰å…¨åˆä¸å¤±æ•ˆã€æ—¢é«˜æ•ˆåˆä¸è„†å¼±â€çš„ç†æƒ³å¹³è¡¡ï¼Œä¸ºæ„å»ºå¯ä¿¡è‡ªä¸»æ™ºèƒ½ä½“æä¾›äº†åšå®æ¶æ„è“å›¾ã€‚

</details>

---

### 15. [Enhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization](https://arxiv.org/abs/2512.07478)

**Authors**: Zhuoran Zhuang, Ye Chen, Jianghao Su, Chao Luo, Luhui Liu, Xia Zeng  
**Category**: cs.CL  
**Published**: 2025-12-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.07478v1  

#### Abstract
Large Language Models (LLMs) empowered with Tool-Integrated Reasoning (TIR) can iteratively plan, call external tools, and integrate returned information to solve complex, long-horizon reasoning tasks. Agentic Reinforcement Learning (Agentic RL) optimizes such models over full tool-interaction traje...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEnhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **Agentic Reinforcement Learning (Agentic RL)** åœ¨ **Tool-Integrated Reasoning (TIR)** åœºæ™¯ä¸­é¢ä¸´çš„ä¸¤å¤§æŒ‘æˆ˜ï¼š
1. **ç¨€ç–ä¸”éæŒ‡å¯¼æ€§å¥–åŠ±**ï¼ˆSparse and non-instructive rewardsï¼‰ï¼šä¼ ç»ŸåŸºäºæœ€ç»ˆç­”æ¡ˆæ­£ç¡®æ€§çš„äºŒå…ƒï¼ˆ0-1ï¼‰å¥–åŠ±ä¿¡å·æ— æ³•ä¸ºä¸­é—´æ­¥éª¤æä¾›æœ‰æ•ˆåé¦ˆï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡ä½ã€æ”¶æ•›æ…¢ã€‚
2. **GRPO ä¸­çš„æ¢¯åº¦é€€åŒ–é—®é¢˜**ï¼ˆGradient degradation in GRPOï¼‰ï¼šå½“ä¸€ä¸ª rollout ç»„å†…æ‰€æœ‰æ ·æœ¬è·å¾—ç›¸åŒå¥–åŠ±æ—¶ï¼Œå…¶ä¼˜åŠ¿å‡½æ•°ï¼ˆadvantageï¼‰ä¸ºé›¶ï¼Œå¯¼è‡´æ¢¯åº¦æ›´æ–°å¤±æ•ˆï¼Œè®­ç»ƒä¸ç¨³å®šä¸”æ ·æœ¬åˆ©ç”¨ç‡ä½ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡ºä¸¤ç§äº’è¡¥çš„æŠ€æœ¯æ¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼š

#### âœ… **Progressive Reward Shaping (PRS)**
- **æ€æƒ³æ¥æº**ï¼šå—è¯¾ç¨‹å­¦ä¹ ï¼ˆcurriculum learningï¼‰å¯å‘ï¼Œè®¾è®¡åˆ†é˜¶æ®µã€æ¸è¿›å¼çš„å¥–åŠ±æœºåˆ¶ã€‚
- **æ ¸å¿ƒæœºåˆ¶**ï¼š
  - é¦–å…ˆé¼“åŠ±æ¨¡å‹æŒæ¡åŸºç¡€èƒ½åŠ›ï¼ˆå¦‚ç”Ÿæˆå¯è§£æçš„å·¥å…·è°ƒç”¨æ ¼å¼ï¼‰ï¼›
  - å†é€æ­¥ä¼˜åŒ–æ›´å¤æ‚çš„ä»»åŠ¡ç›®æ ‡ï¼ˆå¦‚äº‹å®å‡†ç¡®æ€§ã€ç­”æ¡ˆè´¨é‡ï¼‰ã€‚
- **å…·ä½“å®ç°**ï¼š
  - **çŸ­ç­”æ¡ˆ QA**ï¼šå¼•å…¥ **length-aware BLEU**ï¼Œé¿å…å¯¹ç®€çŸ­ä½†æ­£ç¡®çš„ç­”æ¡ˆè¿›è¡Œä¸å…¬å¹³æƒ©ç½šã€‚
  - **é•¿ç­”æ¡ˆ QA**ï¼šç»“åˆ **LLM-as-a-Judge** è¯„åˆ†ï¼Œé˜²æ­¢æ¨¡å‹é€šè¿‡â€œå¥–åŠ±é»‘å®¢â€ï¼ˆreward hackingï¼‰ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†é”™è¯¯çš„å†…å®¹ã€‚

#### âœ… **Value-based Sampling Policy Optimization (VSPO)**
- **æ”¹è¿›å¯¹è±¡**ï¼šåœ¨ GRPO åŸºç¡€ä¸Šæå‡ºçš„å¢å¼ºå‹ç­–ç•¥ä¼˜åŒ–ç®—æ³•ã€‚
- **æ ¸å¿ƒæœºåˆ¶**ï¼š
  1. **Value-based Sampling**ï¼šè¯†åˆ«å¹¶æ›¿æ¢æ‰ä½ä»·å€¼ï¼ˆé›¶ä¼˜åŠ¿ï¼‰æ ·æœ¬ï¼Œä¼˜å…ˆé‡‡æ ·å…·æœ‰é«˜â€œå­¦ä¹ ä»·å€¼â€çš„ promptã€‚å­¦ä¹ ä»·å€¼ç”±ä»»åŠ¡éš¾åº¦ï¼ˆä¸æœ€ä¼˜è¡¨ç°å·®è·ï¼‰å’Œç­–ç•¥ä¸ç¡®å®šæ€§ï¼ˆreward varianceï¼‰å…±åŒå†³å®šã€‚
  2. **Value Smoothing Clipping**ï¼šå¯¹é‡å¤é‡‡æ ·çš„é«˜ä»·å€¼æ ·æœ¬è¿›è¡Œä¼˜åŠ¿å€¼å¹³æ»‘è£å‰ªï¼Œé˜²æ­¢å…¶ä¸»å¯¼æ¢¯åº¦æ›´æ–°ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ä¼˜åŠ¿ |
|------|------|
| **PRS vs Binary Reward** | æä¾›å¯†é›†ã€é˜¶æ®µæ€§åé¦ˆï¼Œæ˜¾è‘—åŠ å¿«æ”¶æ•›é€Ÿåº¦ï¼Œå‡å°‘æ— æ•ˆæ¢ç´¢ |
| **VSPO vs PPO / GRPO / CISPO** | æ›´é«˜çš„æ ·æœ¬æ•ˆç‡ã€æ›´å¼ºçš„è®­ç»ƒç¨³å®šæ€§ã€æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œæ›´é«˜çš„æœ€ç»ˆæ€§èƒ½ |
| **PRS + VSPO è”åˆä½¿ç”¨** | æ˜¾è‘—æå‡æ³›åŒ–èƒ½åŠ›å’Œè·¨é¢†åŸŸé€‚åº”æ€§ï¼Œåœ¨å¤šç§ QA ä»»åŠ¡ä¸Šå‡å–å¾— SOTA è¡¨ç° |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
#### ğŸ”¹ **Long-Form QA**
- æ¥æºäºç”Ÿäº§ç³»ç»Ÿçš„ä¸“æœ‰æ•°æ®ï¼ŒåŒ…å«ä¸‰ç±»æŸ¥è¯¢ï¼š
  - `Qsimple`ï¼šå•ä¸ªæ–‡æœ¬é—®é¢˜
  - `Qmultim`ï¼šå›¾æ–‡æ··åˆæŸ¥è¯¢ï¼ˆå«å›¾åƒ URLï¼‰
  - `Qmultiq`ï¼šåŒ…å«å¤šä¸ªå­é—®é¢˜çš„å¤æ‚æŸ¥è¯¢
- å‚è€ƒç­”æ¡ˆç”±äººå·¥åŸºäºå†…éƒ¨çŸ¥è¯†åº“æ ‡æ³¨ã€‚
- SFT æ•°æ®é€šè¿‡ **Qwen3-235B-A22B** çš„çŸ¥è¯†è’¸é¦ç”Ÿæˆï¼Œå¹¶ç»è¿‡è§„åˆ™è¿‡æ»¤å’Œ LLM-as-a-Judge æ¸…æ´—ã€‚

#### ğŸ”¹ **Short-Form QA**
- ä½¿ç”¨ 7 ä¸ªå…¬å¼€åŸºå‡†æ•°æ®é›†ï¼š
  - é€šç”¨é—®ç­”ï¼šNQ, TriviaQA, PopQA
  - å¤šè·³é—®ç­”ï¼šHotpotQA, 2WikiMultiHopQA, Musique, Bamboogle
- è®­ç»ƒé›†ï¼šåˆå¹¶ NQ å’Œ HotpotQA çš„è®­ç»ƒé›†
- æµ‹è¯•é›†ï¼šå…¨éƒ¨ 7 ä¸ªæ•°æ®é›†çš„æµ‹è¯•/éªŒè¯é›†ï¼Œç”¨äºè¯„ä¼°åŸŸå†…ä¸åŸŸå¤–æ€§èƒ½

---

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - çŸ­ç­”æ¡ˆä»»åŠ¡ï¼šQwen2.5-7B-Instruct
  - é•¿ç­”æ¡ˆä»»åŠ¡ï¼šQwen3-14B
- **è®­ç»ƒæ¡†æ¶**ï¼šTrinity-RFT
- **è¶…å‚æ•°**ï¼š
  - Rollout æ•°é‡ï¼š5
  - å­¦ä¹ ç‡ï¼š1e-6
  - æ¸©åº¦ & top_pï¼šå‡ä¸º 1.0
  - KL ç³»æ•° Î²ï¼š0.001ï¼Œclip ratio Îµï¼š0.2
- **ç¡¬ä»¶**ï¼šå•èŠ‚ç‚¹ 8Ã—H100 GPUï¼Œå¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹å’Œ FSDP CPU å¸è½½ä»¥èŠ‚çœæ˜¾å­˜

---

### è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ç±»å‹ | è¯„ä¼°æ–¹å¼ |
|--------|---------|
| **Long-Form QA** | ä½¿ç”¨ **Qwen3-235B-A22B-Instruct-2507** ä½œä¸º LLM Judgeï¼Œåˆ¤æ–­å›å¤æ˜¯å¦ä¸å‚è€ƒç­”æ¡ˆè¯­ä¹‰ä¸€è‡´ï¼ˆMatch/Mismatchï¼‰ |
| **Short-Form QA** | ä½¿ç”¨ **Exact Match (EM)** æŒ‡æ ‡ï¼Œè¡¡é‡é¢„æµ‹ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆå®Œå…¨åŒ¹é…çš„æ¯”ä¾‹ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | å¯¹æ¯”æ–¹æ³• |
|------|----------|
| **Policy Optimization** | PPO, GRPO, CISPO, SFT-only |
| **Reward Design** | Rule-based 0-1 rewardï¼ˆåŸºäº EM æˆ– LLM åˆ¤å®šï¼‰ |
| **å¼ºå‚è€ƒæ¨¡å‹** | Qwen3-235B-A22Bï¼ˆä»…ç”¨äº Long-Form QA æ€§èƒ½ä¸Šé™å‚è€ƒï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ”¹ Long-Form QA ç»“æœï¼ˆè§ Table 1ï¼‰
| æ–¹æ³• | Qsimple | Qmultiq | Qmultim | å¹³å‡æå‡ï¼ˆvs untrainedï¼‰ |
|------|--------|--------|--------|---------------------|
| untrained | 0.6025 | 0.400 | 0.500 | â€” |
| SFT-only | 0.700 | 0.575 | 0.400 | â€” |
| GRPO | 0.700 | 0.575 | 0.475 | â€” |
| PPO | 0.6625 | 0.700 | 0.550 | â€” |
| CISPO | 0.6875 | 0.4875 | 0.400 | â€” |
| **VSPO** | **0.7125** | **0.725** | **0.550** | **+18.26%, +81.24%, +10%** |

âœ… **VSPO åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡ä¼˜äºå…¶ä»– RL æ–¹æ³•**ï¼Œå°¤å…¶åœ¨å¤šå­é—®é¢˜ï¼ˆQmultiqï¼‰ä¸Šè¡¨ç°çªå‡ºã€‚

---

### ğŸ”¹ Short-Form QA ç»“æœï¼ˆè§ Table 2ï¼‰
| æ–¹æ³• | Avg Score |
|------|---------|
| Direct Inference | 0.181 |
| SFT | 0.207 |
| PPO+EM | 0.385 |
| GRPO+EM | 0.396 |
| VSPO+EM | 0.397 |
| PPO+PRS | 0.396 |
| GRPO+PRS | 0.410 |
| **VSPO+PRS** | **0.419** |

ğŸ“Œ **å…³é”®å‘ç°**ï¼š
- æ‰€æœ‰ä½¿ç”¨ **PRS** çš„æ–¹æ³•éƒ½ä¼˜äºå¯¹åº” EM å¥–åŠ±ç‰ˆæœ¬ â†’ **PRS æœ‰æ•ˆ**
- æ‰€æœ‰ä½¿ç”¨ **VSPO** çš„æ–¹æ³•è¡¨ç°ç¨³å®šä¸”é¢†å…ˆ â†’ **VSPO æ›´é«˜æ•ˆç¨³å®š**
- **VSPO+PRS ç»„åˆè¾¾åˆ°æœ€é«˜å¹³å‡å¾—åˆ† 0.419**

---

### ğŸ”¹ æ¶ˆèå®éªŒç»“æœï¼ˆè§ Table 4ï¼‰
| é…ç½® | Qsimple | Qmultiq | Qmultim |
|------|--------|--------|--------|
| w/o sample, w/o clipï¼ˆâ‰ˆGRPOï¼‰ | 0.700 | 0.575 | 0.475 |
| random sample, w/o clip | 0.460 | 0.160 | 0.100 |
| value-based sample, w/o clip | 0.450 | 0.175 | 0.300 |
| random sample, w/clip | 0.500 | 0.300 | 0.025 |
| **value-based sample, w/clipï¼ˆVSPOï¼‰** | **0.7125** | **0.725** | **0.550** |

âœ… **ç»“è®º**ï¼š
- ç¼ºå°‘ **value smoothing clipping** ä¼šå¯¼è‡´ä¸¥é‡è®­ç»ƒä¸ç¨³å®šï¼ˆKL divergence å¼‚å¸¸å‡é«˜ï¼‰
- **random sampling** å³ä½¿åŠ  clipping ä¹Ÿæ— æ³•å¸¦æ¥æ€§èƒ½å¢ç›Š
- **åªæœ‰ value-based sampling + clipping çš„ç»„åˆæ‰èƒ½å®ç°æœ€ä½³æ€§èƒ½**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **PRS æ˜¾è‘—æ”¹å–„å­¦ä¹ è¿‡ç¨‹**ï¼š
   - åˆ†é˜¶æ®µå¥–åŠ±å¼•å¯¼æ¨¡å‹å…ˆå­¦ä¼šâ€œæ€ä¹ˆåšâ€ï¼Œå†è¿½æ±‚â€œåšå¾—å¥½â€ã€‚
   - åœ¨çŸ­ç­”æ¡ˆä»»åŠ¡ä¸­ï¼Œlength-aware BLEU é¿å…äº†å¯¹ç®€æ´æ­£ç¡®ç­”æ¡ˆçš„è¯¯ç½šã€‚
   - åœ¨é•¿ç­”æ¡ˆä»»åŠ¡ä¸­ï¼ŒLLM-as-a-Judge æŠ‘åˆ¶äº† reward hackingï¼Œæå‡äº†äº‹å®ä¸€è‡´æ€§ã€‚

2. **VSPO è§£å†³äº† GRPO çš„æ¢¯åº¦é€€åŒ–é—®é¢˜**ï¼š
   - é€šè¿‡åŠ¨æ€æ›¿æ¢ä½ä»·å€¼æ ·æœ¬ï¼Œç¡®ä¿æ¯ä¸ª batch éƒ½åŒ…å«æœ‰æ•ˆæ¢¯åº¦ä¿¡å·ã€‚
   - value-based sampling èšç„¦äºâ€œæœ€éš¾ä¸”æœ€ä¸ç¡®å®šâ€çš„ä»»åŠ¡ï¼Œæœ€å¤§åŒ–å­¦ä¹ æ”¶ç›Šã€‚
   - value smoothing clipping ä¿è¯äº†é‡å¤é‡‡æ ·çš„ç¨³å®šæ€§ï¼Œé¿å…è¿‡æ‹Ÿåˆé«˜ä»·å€¼ promptã€‚

3. **PRS + VSPO å…·æœ‰ååŒæ•ˆåº”**ï¼š
   - å¯†é›†å¥–åŠ± + é«˜æ•ˆé‡‡æ · = æ›´å¿«æ”¶æ•› + æ›´é«˜æ€§èƒ½ + æ›´å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
   - åœ¨çŸ­å½¢å¼å’Œé•¿å½¢å¼ QA ä¸Šå‡è¶…è¶Š PPOã€GRPOã€CISPO å’Œ SFT-onlyã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡å‚è€ƒç­”æ¡ˆå’Œ LLM Judge**ï¼šLLM-as-a-Judge çš„å¯é æ€§ä¼šå½±å“ PRS çš„æœ‰æ•ˆæ€§ï¼Œå¯èƒ½å­˜åœ¨ä¸»è§‚åå·®ã€‚
2. **è®¡ç®—å¼€é”€å¢åŠ **ï¼šVSPO éœ€è¦é¢å¤–è®¡ç®—ä»»åŠ¡ä»·å€¼åˆ†æ•°ï¼Œè™½ç„¶ä»ä¼˜äº DAPO ç­‰åŠ¨æ€é‡‡æ ·æ–¹æ³•ï¼Œä½†åœ¨å¤§è§„æ¨¡éƒ¨ç½²æ—¶éœ€æƒè¡¡æˆæœ¬ã€‚
3. **å½“å‰éªŒè¯é›†ä¸­åœ¨ QA ä»»åŠ¡**ï¼šå°½ç®¡ä½œè€…å£°ç§°æ–¹æ³•å…·æœ‰ä¸€èˆ¬æ€§ï¼Œä½†ä»éœ€åœ¨æ›´å¤š TIR åœºæ™¯ï¼ˆå¦‚è§„åˆ’ã€å†³ç­–ã€ä»£ç ç”Ÿæˆï¼‰ä¸­è¿›ä¸€æ­¥éªŒè¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. å°† PRS å’Œ VSPO åº”ç”¨äºæ›´å¹¿æ³›çš„ **Agentic RAG** å’Œ **multi-agent systems**ã€‚
2. æ¢ç´¢è‡ªåŠ¨æ„å»º curriculum çš„æœºåˆ¶ï¼Œå®ç° reward stage çš„è‡ªé€‚åº”è°ƒæ•´ã€‚
3. è®¾è®¡è½»é‡åŒ–ç‰ˆæœ¬çš„ VSPOï¼Œé™ä½åœ¨çº¿è®­ç»ƒä¸­çš„è®¡ç®—è´Ÿæ‹…ã€‚
4. ç»“åˆ offline RL æˆ– preference modeling è¿›ä¸€æ­¥æå‡æ ·æœ¬æ•ˆç‡ã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡ç³»ç»Ÿåœ°è§£å†³äº† Agentic RL åœ¨ TIR åœºæ™¯ä¸‹çš„ä¸¤ä¸ªæ ¸å¿ƒç“¶é¢ˆâ€”â€”**ç¨€ç–å¥–åŠ±**å’Œ**æ¢¯åº¦é€€åŒ–**ï¼Œæå‡ºäº† **PRS** å’Œ **VSPO** ä¸¤é¡¹å…³é”®æŠ€æœ¯ã€‚å®éªŒè¯æ˜ï¼ŒäºŒè€…è”åˆä½¿ç”¨å¯åœ¨å¤šä¸ª QA åŸºå‡†ä¸Šå®ç°ç¨³å®šä¸”æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€é²æ£’çš„ LLM-based agent æä¾›äº†ä¸€å¥—å¯æ¨å¹¿çš„æ–¹æ³•è®ºæ¡†æ¶ã€‚

</details>

---

### 16. [Bridging Code Graphs and Large Language Models for Better Code Understanding](https://arxiv.org/abs/2512.07666)

**Authors**: Zeqi Chen, Zhaoyang Chu, Yi Gui, Feng Guo, Yao Wan, Chuan Shi  
**Category**: cs.CL  
**Published**: 2025-12-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.07666v1  

#### Abstract
Large Language Models (LLMs) have demonstrated remarkable performance in code intelligence tasks such as code generation, summarization, and translation. However, their reliance on linearized token sequences limits their ability to understand the structural semantics of programs. While prior studies...

---

### 17. [gp2Scale: A Class of Compactly-Supported Non-Stationary Kernels and Distributed Computing for Exact Gaussian Processes on 10 Million Data Points](https://arxiv.org/abs/2512.06143)

**Authors**: Marcus M. Noack, Mark D. Risser, Hengrui Luo, Vardaan Tekriwal, Ronald J. Pandolfi  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.06143v1  

#### Abstract
Despite a large corpus of recent work on scaling up Gaussian processes, a stubborn trade-off between computational speed, prediction and uncertainty quantification accuracy, and customizability persists. This is because the vast majority of existing methodologies exploit various levels of approximat...

---

### 18. [Optimizing LLMs Using Quantization for Mobile Execution](https://arxiv.org/abs/2512.06490)

**Authors**: Agatsya Yadav, Renta Chintala Bhargavi  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.06490v1  

#### Abstract
Large Language Models (LLMs) offer powerful capabilities, but their significant size and computational requirements hinder deployment on resource-constrained mobile devices. This paper investigates Post-Training Quantization (PTQ) for compressing LLMs for mobile execution. We apply 4-bit PTQ using t...

---

### 19. [KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models](https://arxiv.org/abs/2512.06727)

**Authors**: Sourjya Roy, Shrihari Sridharan, Surya Selvam, Anand Raghunathan  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.06727v1  

#### Abstract
As Large Language Models (LLMs) scale in size and context length, the memory requirements of the key value (KV) cache have emerged as a major bottleneck during autoregressive decoding. The KV cache grows with sequence length and embedding dimension, often exceeding the memory footprint of the model ...

---

### 20. [LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding](https://arxiv.org/abs/2512.06982)

**Authors**: Yu Yu, Qian Xie, Nairen Cao, Li Jin  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.06982v1  

#### Abstract
Designing state encoders for reinforcement learning (RL) with multiple information sources -- such as sensor measurements, time-series signals, image observations, and textual instructions -- remains underexplored and often requires manual design. We formalize this challenge as a problem of composit...

---

### 21. [PlantBiMoE: A Bidirectional Foundation Model with SparseMoE for Plant Genomes](https://arxiv.org/abs/2512.07113)

**Authors**: Kepeng Lin, Qizhe Zhang, Rui Wang, Xuehai Hu, Wei Xu  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.07113v1  

#### Abstract
Understanding the underlying linguistic rules of plant genomes remains a fundamental challenge in computational biology. Recent advances including AgroNT and PDLLMs have made notable progress although, they suffer from excessive parameter size and limited ability to model the bidirectional nature of...

---

### 22. [PINE: Pipeline for Important Node Exploration in Attributed Networks](https://arxiv.org/abs/2512.07244)

**Authors**: Elizaveta Kovtun, Maksim Makarenko, Natalia Semenova, Alexey Zaytsev, Semen Budennyy  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.07244v1  

#### Abstract
A graph with semantically attributed nodes are a common data structure in a wide range of domains. It could be interlinked web data or citation networks of scientific publications. The essential problem for such a data type is to determine nodes that carry greater importance than all the others, a t...

---

### 23. [LightSearcher: Efficient DeepSearch via Experiential Memory](https://arxiv.org/abs/2512.06653)

**Authors**: Hengzhi Lan, Yue Yu, Li Qian, Li Peng, Jie Wu, Wei Liu, Jian Luan, Ting Bai  
**Category**: cs.AI  
**Published**: 2025-12-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.06653v1  

#### Abstract
DeepSearch paradigms have become a core enabler for deep reasoning models, allowing them to invoke external search tools to access up-to-date, domain-specific knowledge beyond parametric boundaries, thereby enhancing the depth and factual reliability of reasoning. Building upon this foundation, rece...

---

### 24. [BitStopper: An Efficient Transformer Attention Accelerator via Stage-fusion and Early Termination](https://arxiv.org/abs/2512.06457)

**Authors**: Huizheng Wang, Hongbin Wang, Shaojun Wei, Yang Hu, Shouyi Yin  
**Category**: cs.LG  
**Published**: 2025-12-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.06457v1  

#### Abstract
Attention-based large language models (LLMs) have transformed modern AI applications, but the quadratic cost of self-attention imposes significant compute and memory overhead. Dynamic sparsity (DS) attention mitigates this, yet its hardware efficiency is limited by the added prediction stage and the...

---

### 25. [ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment](https://arxiv.org/abs/2512.06196)

**Authors**: Charlie Masters, Marta Grze\'skiewicz, Stefano V. Albrecht  
**Category**: cs.AI  
**Published**: 2025-12-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.06196v1  

#### Abstract
As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model ...

---

### 26. [GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols](https://arxiv.org/abs/2512.06404)

**Authors**: Mohammad Soleymanibrojeni, Roland Aydin, Diego Guedes-Sobrinho, Alexandre C. Dias, Maur\'icio J. Piotrowski, Wolfgang Wenzel, Celso Ricardo Caldeira R\^ego  
**Category**: cs.AI  
**Published**: 2025-12-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.06404v1  

#### Abstract
Predictive atomistic simulations have propelled materials discovery, yet routine setup and debugging still demand computer specialists. This know-how gap limits Integrated Computational Materials Engineering (ICME), where state-of-the-art codes exist but remain cumbersome for non-experts. We address...

---

### 27. [DoVer: Intervention-Driven Auto Debugging for LLM Multi-Agent Systems](https://arxiv.org/abs/2512.06749)

**Authors**: Ming Ma, Jue Zhang, Fangkai Yang, Yu Kang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang  
**Category**: cs.AI  
**Published**: 2025-12-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.06749v1  

#### Abstract
Large language model (LLM)-based multi-agent systems are challenging to debug because failures often arise from long, branching interaction traces. The prevailing practice is to leverage LLMs for log-based failure localization, attributing errors to a specific agent and step. However, this paradigm ...

---

### 28. [JT-DA: Enhancing Data Analysis with Tool-Integrated Table Reasoning Large Language Models](https://arxiv.org/abs/2512.06859)

**Authors**: Ce Chi, Xing Wang, Zhendong Wang, Xiaofan Liu, Ce Li, Zhiyan Song, Chen Zhao, Kexin Yang, Boshen Shi, Jingjing Yang, Chao Deng, Junlan Feng  
**Category**: cs.AI  
**Published**: 2025-12-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.06859v1  

#### Abstract
In this work, we present JT-DA-8B (JiuTian Data Analyst 8B), a specialized large language model designed for complex table reasoning tasks across diverse real-world scenarios. To address the lack of high-quality supervision in tabular reasoning scenarios, we construct a comprehensive and diverse tra...

---

### 29. [ClinNoteAgents: An LLM Multi-Agent System for Predicting and Interpreting Heart Failure 30-Day Readmission from Clinical Notes](https://arxiv.org/abs/2512.07081)

**Authors**: Rongjia Zhou, Chengzhuo Li, Carl Yang, Jiaying Lu  
**Category**: cs.AI  
**Published**: 2025-12-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.07081v1  

#### Abstract
Heart failure (HF) is one of the leading causes of rehospitalization among older adults in the United States. Although clinical notes contain rich, detailed patient information and make up a large portion of electronic health records (EHRs), they remain underutilized for HF readmission risk analysis...

---

### 30. [ProSocialAlign: Preference Conditioned Test Time Alignment in Language Models](https://arxiv.org/abs/2512.06515)

**Authors**: Somnath Banerjee, Sayan Layek, Sayantan Adak, Mykola Pechenizkiy, Animesh Mukherjee, Rima Hazra  
**Category**: cs.CL  
**Published**: 2025-12-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.06515v1  

#### Abstract
Current language model safety paradigms often fall short in emotionally charged or high-stakes settings, where refusal-only approaches may alienate users and naive compliance can amplify risk. We propose ProSocialAlign, a test-time, parameter-efficient framework that steers generation toward safe, e...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
