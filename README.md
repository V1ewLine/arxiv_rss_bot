# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-11 05:56:48 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Training-free Context-adaptive Attention for Efficient Long Context Modeling](https://arxiv.org/abs/2512.09238)

**Authors**: Zeng You, Yaofo Chen, Shuhai Zhang, Zhijie Qiu, Tingyu Wu, Yingjian Li, Yaowei Wang, Mingkui Tan  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.09238v1  

#### Abstract
Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing tasks. These capabilities stem primarily from the self-attention mechanism, which enables modeling of long-range dependencies. However, the quadratic complexity of self-attention...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTraining-free Context-adaptive Attention for Efficient Long Context Modeling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
Large Language Models (LLMs) ä¸­çš„ **self-attention** æœºåˆ¶è™½ç„¶èƒ½æœ‰æ•ˆå»ºæ¨¡é•¿è·ç¦»ä¾èµ–ï¼Œä½†å…¶è®¡ç®—å¤æ‚åº¦ä¸º $O(L^2)$ï¼ˆ$L$ ä¸ºåºåˆ—é•¿åº¦ï¼‰ï¼Œåœ¨å¤„ç†è¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆå¦‚ 128K tokensï¼‰æ—¶é¢ä¸´ä¸¥é‡çš„ **è®¡ç®—ç“¶é¢ˆ** å’Œ **KV Cache å†…å­˜å¼€é”€**ã€‚æ­¤å¤–ï¼Œå¤§é‡å†—ä½™ token å¯¼è‡´æ³¨æ„åŠ›èµ„æºæµªè´¹ï¼Œå½±å“æ•ˆç‡ä¸ç²¾åº¦ã€‚

ç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š
- **é™æ€ç¨€ç–æ³¨æ„åŠ›**ï¼ˆStatic Sparse Attentionï¼‰ç¼ºä¹è¾“å…¥è‡ªé€‚åº”èƒ½åŠ›ï¼›
- **ä»…åŠ é€Ÿ prefilling é˜¶æ®µ** çš„æ–¹æ³•æ— æ³•ç¼“è§£ decoding é˜¶æ®µçš„ KV Cache å¢é•¿ï¼›
- **KV Cache å‹ç¼©æŠ€æœ¯** ä¸èƒ½å‡å°‘ prefilling è®¡ç®—é‡ï¼›
- å¤šæ•°ç»Ÿä¸€æ¡†æ¶éœ€è¦é¢å¤–è®­ç»ƒæˆ–æ¶æ„ä¿®æ”¹ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šTCA-Attention
æœ¬æ–‡æå‡º **Training-free Context-adaptive Attention (TCA-Attention)**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒã€åŠ¨æ€é€‚åº”è¾“å…¥å†…å®¹çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºé«˜æ•ˆé•¿ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚

#### æ ¸å¿ƒè®¾è®¡æ€æƒ³
TCA-Attention åŒ…å«ä¸¤ä¸ªè½»é‡çº§é˜¶æ®µï¼š
1. **Offline Sparsity Configurationï¼ˆç¦»çº¿é…ç½®é˜¶æ®µï¼‰**
   - åœ¨å°è§„æ¨¡æ ¡å‡†æ•°æ®é›†ä¸Šé€šè¿‡ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼Œç¡®å®šæ¯ä¸ª attention head çš„â€œç¨€ç–é¢„ç®—â€ï¼ˆsparsity budgetï¼‰ï¼›
   - åˆ©ç”¨ log-Gaussian é‡‡æ ·ç”Ÿæˆå€™é€‰é…ç½®ï¼Œå¹¶åŸºäºä¿ç•™çš„ attention score æ€»é‡é€‰æ‹©æœ€ä¼˜é…ç½®ã€‚

2. **Online Core Context Selectionï¼ˆåœ¨çº¿æ ¸å¿ƒä¸Šä¸‹æ–‡é€‰æ‹©é˜¶æ®µï¼‰**
   - æ¨ç†æ—¶ï¼Œæ ¹æ®é¢„è®¾çš„ç¨€ç–é…ç½®ï¼ŒåŠ¨æ€é€‰æ‹©å¯¹å½“å‰è¾“å‡ºæœ€ç›¸å…³çš„â€œæ ¸å¿ƒ tokenâ€ï¼›
   - å¼•å…¥è½»é‡çº§å†—ä½™åº¦é‡ï¼ˆredundancy metricï¼‰ï¼Œç»“åˆå…¨å±€é‡è¦æ€§è¯„åˆ†ä¸å±€éƒ¨å—æ’åºï¼Œå®ç°ç»†ç²’åº¦ token ä¿ç•™ã€‚

æœ€ç»ˆ attention è¾“å…¥ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š
- **Global Subset**ï¼šä»å…¨åºåˆ—ä¸­æŒ‰é‡è¦æ€§é€‰å‡ºçš„å…³é”® tokenï¼›
- **Local Subset**ï¼šæœ€è¿‘ $w$ ä¸ª tokenï¼Œä¿ç•™å±€éƒ¨ä¸Šä¸‹æ–‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | TCA-Attention | å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ MInference, SnapKV, DuoAttentionï¼‰ |
|------|---------------|---------------------------------------------|
| **Training-free** âœ… | æ˜¯ | å¤šæ•°éœ€é‡æ–°è®­ç»ƒæˆ–è°ƒå‚ |
| **Dynamic & Input-adaptive** âœ… | æ˜¯ | å¤šä¸ºå›ºå®šæ¨¡å¼æˆ–æœ‰é™åŠ¨æ€ |
| **Accelerates both Prefilling & Decoding** âœ… | æ˜¯ | å¤šæ•°åªä¼˜åŒ–ä¸€ä¸ªé˜¶æ®µ |
| **Reduces KV Cache** âœ… | æ˜¯ | éƒ¨åˆ†æ–¹æ³•ä¸å‹ç¼©ç¼“å­˜ |
| **Head-aware Sparsity** âœ… | æ˜¯ | å¤šé‡‡ç”¨ç»Ÿä¸€å‹ç¼©ç­–ç•¥ |
| **Plug-and-play** âœ… | æ”¯æŒå³æ’å³ç”¨ | å¸¸éœ€ç³»ç»Ÿçº§ä¿®æ”¹ |

> âœ… **TCA-Attention æ˜¯é¦–ä¸ªåŒæ—¶æ»¡è¶³ï¼šæ— è®­ç»ƒã€åŠ¨æ€é€‚åº”ã€å¤´æ„ŸçŸ¥ã€ç»Ÿä¸€åŠ é€Ÿ prefilling ä¸ decoding çš„ç¨€ç–æ³¨æ„åŠ›æ–¹æ¡ˆã€‚**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | ä»»åŠ¡æè¿° |
|--------|------|----------|
| **LongBench-E** [37] | é•¿ä¸Šä¸‹æ–‡ç†è§£ | åŒ…å« 14 é¡¹å¤šè¯­è¨€ã€å¤šä»»åŠ¡è¯„æµ‹ï¼Œæ¶µç›–å•æ–‡æ¡£é—®ç­”ã€å¤šæ–‡æ¡£é—®ç­”ã€æ‘˜è¦ã€ä»£ç ç­‰ |
| **RULER** [38] | åˆæˆåŸºå‡† | åŸºäº â€œneedle-in-a-haystackâ€ èŒƒå¼ï¼Œæµ‹è¯•æ¨¡å‹åœ¨ä¸åŒé•¿åº¦ä¸‹çš„çœŸå®ä¸Šä¸‹æ–‡åˆ©ç”¨èƒ½åŠ› |
| **MMLU** [53] | çŸ­ä¸Šä¸‹æ–‡çŸ¥è¯† | å¤šå­¦ç§‘çŸ¥è¯†é—®ç­” |
| **GSM8K** [54] | æ•°å­¦æ¨ç† | å°å­¦æ•°å­¦åº”ç”¨é¢˜ |
| **HumanEval** [55] | ä»£ç ç”Ÿæˆ | å‡½æ•°è¡¥å…¨ä»»åŠ¡ |
| **OlympiadBench** [56] | ç§‘å­¦æ¨ç† | å¥¥èµ›çº§åˆ«ç‰©ç†ä¸æ•°å­¦éš¾é¢˜ |
| **MT-Bench-101** [57] | å¤šè½®å¯¹è¯ | å¤šè½®äº¤äº’ä¸­çš„è¿è´¯æ€§ä¸æ¨ç†èƒ½åŠ›è¯„ä¼° |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼š
  - `LLaMA-3.1-8B-Instruct`
  - `Qwen2.5-7B-Instruct`
  - å‡æ”¯æŒ 128K ä¸Šä¸‹æ–‡çª—å£ï¼Œä½¿ç”¨ GQAï¼ˆGrouped-Query Attentionï¼‰
- **ç¡¬ä»¶**ï¼š8Ã—NVIDIA A800 GPUï¼ˆ80GB VRAMï¼‰ï¼Œå•å¡æµ‹å»¶è¿Ÿ
- **å®ç°æ–¹å¼**ï¼šåŸºäº Triton å®ç°ï¼Œæ›¿æ¢åŸç”Ÿ self-attention æ¨¡å—ï¼Œæ— éœ€æ¶æ„æ”¹åŠ¨
- **å…³é”®è¶…å‚æ•°**ï¼š
  - Block size $b = 128$
  - Local window size $w = 4096$
  - ç¦»çº¿é˜ˆå€¼ $T = 0.9$
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **ä»»åŠ¡æ€§èƒ½**ï¼šå„ benchmark çš„å‡†ç¡®ç‡ / åˆ†æ•°
  - **æ•ˆç‡æŒ‡æ ‡**ï¼š
    - Attention computation latencyï¼ˆprefilling è€—æ—¶ï¼‰
    - Inter-token latency (ITL)ï¼ˆdecoding é€Ÿåº¦ï¼‰
    - KV Cache å†…å­˜å ç”¨

### å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦è®­ç»ƒ | åŠ é€Ÿé˜¶æ®µ |
|------|------|---------|----------|
| **MInference** [20] | åŠ¨æ€ç¨€ç–ï¼ˆprefillingï¼‰ | âŒ | ä»… prefilling |
| **FlexPrefill** [21] | åŠ¨æ€ç¨€ç–ï¼ˆprefillingï¼‰ | âŒ | ä»… prefilling |
| **XAttention** [22] | å—ç¨€ç– + æŠ—å¯¹è§’çº¿è¯„åˆ† | âŒ | ä»… prefilling |
| **SnapKV** [23] | KV Cache å‹ç¼© | âŒ | ä»… decoding |
| **CAKE** [24] | å±‚åå¥½å¼ KV ç¼“å­˜æ·˜æ±° | âŒ | ä»… decoding |
| **DuoAttention** [25] | ç»Ÿä¸€ç¨€ç–ï¼ˆæ£€ç´¢+æµå¼å¤´ï¼‰ | âœ… | prefilling & decoding |
| **Lserve** [26] | ç»Ÿä¸€ç¨€ç–æœåŠ¡æ¡†æ¶ | âœ… | prefilling & decoding |

> æ‰€æœ‰å¯¹æ¯”å‡åœ¨ç›¸åŒæ¡ä»¶ä¸‹è¿›è¡Œï¼Œlatency åŸºäº FlashAttention-2 æµ‹é‡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ128K contextï¼‰

| æŒ‡æ ‡ | TCA-Attention ç»“æœ | æå‡å¹…åº¦ |
|------|---------------------|----------|
| **Prefilling åŠ é€Ÿæ¯”** | **2.8Ã— speedup** | vs. Full Attention |
| **Decoding é€Ÿåº¦æå‡** | **2.1Ã— faster ITL** | æ˜¾è‘—ä¼˜äºä»…ä¼˜åŒ– prefilling çš„æ–¹æ³• |
| **KV Cache å†…å­˜å‡å°‘** | **61% reduction**<br>ï¼ˆ8.00 GB â†’ 3.12 GBï¼‰ | æå¤§é™ä½éƒ¨ç½²æˆæœ¬ |
| **LongBench-E å¹³å‡å¾—åˆ†** | **53.51 (LLaMA), 51.51 (Qwen)** | è¶…è¿‡æ‰€æœ‰ç¨€ç–æ–¹æ³•ï¼Œæ¥è¿‘ full attention |
| **RULER å¹³å‡å¾—åˆ†** | **88.72 (LLaMA), 82.49 (Qwen)** | åœ¨æç«¯é•¿åº¦ä¸‹ä»ä¿æŒé«˜å¬å› |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### âœ… åœ¨ LongBench-E ä¸Šçš„è¡¨ç°ï¼ˆTable Iï¼‰
- **LLaMA-3.1-8B**ï¼š
  - TCA-Attention è¾¾åˆ° **53.51** å¹³å‡åˆ†ï¼Œé«˜äº XAttentionï¼ˆ50.91ï¼‰
  - å»¶è¿Ÿä» 316.14ms é™è‡³ **120.96ms**ï¼ˆ2.6Ã— speedupï¼‰
- **Qwen2.5-7B**ï¼š
  - å¹³å‡åˆ† **51.51**ï¼Œä¸ºæœ€é«˜
  - å»¶è¿Ÿä» 268.55ms é™è‡³ **105.93ms**ï¼ˆ2.5Ã— speedupï¼‰

#### âœ… åœ¨ RULER ä¸Šçš„è¡¨ç°ï¼ˆTable IIï¼‰
- åœ¨ 128K context ä¸‹ï¼š
  - TCA-Attention å®ç° **2.8Ã— speedup**
  - æ€§èƒ½ç¨³å®šï¼Œå¹³å‡åˆ†ç•¥ä¼˜äº XAttention
- è¡¨æ˜å…¶åœ¨æé•¿åºåˆ—ä¸­ä»èƒ½ç²¾å‡†å®šä½å…³é”®ä¿¡æ¯

#### âœ… å¤šè½®å¯¹è¯è¡¨ç°ï¼ˆMT-Bench-101ï¼‰
- TCA-Attention å¾—åˆ†ä¸º **8.97**ï¼Œè¶…è¿‡ full attention baselineï¼ˆ8.90ï¼‰å’Œ FlexPrefillï¼ˆ8.90ï¼‰
- è¯´æ˜å…¶èƒ½æœ‰æ•ˆä¿ç•™å¯¹è¯å†å²ä¸­çš„å…³é”®ä¸Šä¸‹æ–‡

#### âœ… æ¨ç†ä»»åŠ¡è¡¨ç°ï¼ˆOlympiadBenchï¼‰
- åœ¨ Physics ä»»åŠ¡ä¸Šå–å¾— **æœ€é«˜åˆ† 10.59**
- æ•°å­¦ä»»åŠ¡ä¿æŒç«äº‰åŠ›
- è¡¨æ˜å…¶é€‚ç”¨äºå¤æ‚ç§‘å­¦æ¨ç†åœºæ™¯

### æ¶ˆèå®éªŒç»“æœ

#### ğŸ”¹ ä¸åŒ block size $b$ çš„å½±å“ï¼ˆFigure 4aï¼‰
- æœ€ä¼˜ $b = 128$ï¼Œè¿‡å¤§æˆ–è¿‡å°éƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™
- è¿‡å°ï¼šéš¾ä»¥æ•æ‰å—å†…å†—ä½™ï¼›è¿‡å¤§ï¼šå¯èƒ½è¿‡åº¦å‹ç¼©å…³é”®ä¿¡æ¯

#### ğŸ”¹ ä¸åŒ local window size $w$ çš„å½±å“ï¼ˆFigure 4bï¼‰
- $w = 4096$ æ—¶è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼ˆ51.51ï¼‰
- æ›´å¤§çš„å±€éƒ¨çª—å£æœ‰åŠ©äºä¿ç•™è¿‘æœŸä¸Šä¸‹æ–‡ï¼Œæå‡ç¨³å®šæ€§

#### ğŸ”¹ ä¸åŒé˜ˆå€¼ $T$ çš„å½±å“ï¼ˆFigure 4cï¼‰
- $T = 0.9$ æ—¶æ€§èƒ½æœ€ä½³
- ä½ $T$ï¼ˆé«˜å‹ç¼©ç‡ï¼‰å¯¹å…¨å±€æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ Multi-Document QAï¼‰å½±å“è¾ƒå¤§
- å±€éƒ¨ä»»åŠ¡ï¼ˆå¦‚ Summarizationï¼‰å¯¹å‹ç¼©æ›´é²æ£’

#### ğŸ”¹ å¹³è¡¡å‚æ•° $\alpha$ çš„æ•æ„Ÿæ€§ï¼ˆTable VIIIï¼‰
- åœ¨ $\alpha \in [0.1, 0.9]$ èŒƒå›´å†…æ€§èƒ½ç¨³å®š
- æœ€ä½³å€¼ä¸º $\alpha = 0.5$ï¼Œæç«¯å€¼ä¹Ÿä»…é€ æˆ â‰¤0.38 åˆ†ä¸‹é™
- è¡¨æ˜æ–¹æ³•å¯¹è¶…å‚æ•°ä¸æ•æ„Ÿï¼Œæ˜“äºéƒ¨ç½²

#### ğŸ”¹ æ ¡å‡†æ•°æ®é›†çš„å½±å“ï¼ˆTable IXï¼‰
| æ•°æ®é›† | é¢†åŸŸ | LongBench-E å¹³å‡åˆ† |
|--------|------|------------------|
| SlimPajama | é€šç”¨ç½‘é¡µæ–‡æœ¬ | 51.54 Â± 0.03 |
| GovReport | æ”¿åºœæ–‡æ¡£ | 51.56 Â± 0.04 |
| McEval | ç¼–ç¨‹ä»£ç  | 51.55 Â± 0.02 |

- æ€§èƒ½åœ¨ä¸åŒé¢†åŸŸé—´é«˜åº¦ä¸€è‡´
- å³ä½¿ä»…ç”¨ä¸€æ¡æ ·æœ¬æ ¡å‡†ï¼Œæ€§èƒ½æ³¢åŠ¨ â‰¤0.04
- è¡¨æ˜ head-specific ç¨€ç–æ€§å…·æœ‰å¼ºæ³›åŒ–èƒ½åŠ›

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **TCA-Attention å¯åœ¨æ— éœ€è®­ç»ƒçš„å‰æä¸‹ï¼Œç»Ÿä¸€åŠ é€Ÿ prefilling ä¸ decoding é˜¶æ®µ**ï¼Œå¹¶æ˜¾è‘—å‡å°‘ KV Cacheã€‚
2. âœ… **head-specific + context-adaptive çš„ç¨€ç–ç­–ç•¥** æ¯”å›ºå®šæ¨¡å¼æ›´æœ‰æ•ˆï¼Œèƒ½ç²¾ç»†æ§åˆ¶å†—ä½™ token çš„å»é™¤ã€‚
3. âœ… **ç†è®ºè¯¯å·®ç•Œå¯æ§**ï¼šé€šè¿‡ä¿ç•™è¶³å¤Ÿçš„ attention massï¼ˆâ‰¥Tï¼‰ï¼Œå¯ä¿è¯è¿‘ä¼¼è¯¯å·®æœ‰ä¸Šç•Œï¼ˆTheorem 1ï¼‰ã€‚
4. âœ… **å³æ’å³ç”¨æ€§å¼º**ï¼šä»…éœ€ä¸€æ¬¡ç¦»çº¿æ ¡å‡†ï¼Œå³å¯é€‚é…å¤šç§ä»»åŠ¡ä¸æ¨¡å‹ï¼Œæ— éœ€å¾®è°ƒæˆ–æ¶æ„å˜æ›´ã€‚
5. âœ… **åœ¨ 128K ä¸Šä¸‹æ–‡ä¸‹å®ç° 2.8Ã— speedup ä¸”æ€§èƒ½ä¸é™**ï¼Œæ˜¯å½“å‰æœ€å®ç”¨çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†è§£å†³æ–¹æ¡ˆä¹‹ä¸€ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ–¹æ³•ä¾èµ–äºæœ€åä¸€ä¸ª token çš„ query æ¥æ‰“åˆ†ï¼Œå¯èƒ½åœ¨æŸäº›éå› æœä»»åŠ¡ä¸­å—é™ï¼›
- block-level è®¾è®¡è™½é«˜æ•ˆï¼Œä½†åœ¨æç»†ç²’åº¦è¯­ä¹‰ä»»åŠ¡ä¸­å¯èƒ½å­˜åœ¨ä¿¡æ¯ä¸¢å¤±é£é™©ï¼›
- å¯¹ extremely long contextï¼ˆ>1Mï¼‰çš„æ‰©å±•å°šæœªéªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† TCA-Attention æ‰©å±•è‡³ Vision-Language Models å’Œ Multimodal åºåˆ—ï¼›
- æ¢ç´¢æ›´é«˜æ•ˆçš„ redundancy metricï¼Œè¿›ä¸€æ­¥é™ä½ overheadï¼›
- ç»“åˆ Retrieval-Augmented Generationï¼Œæ„å»º hybrid é•¿ä¸Šä¸‹æ–‡ç³»ç»Ÿï¼›
- ç ”ç©¶å¦‚ä½•å°†è¯¥æœºåˆ¶åº”ç”¨äº training é˜¶æ®µä»¥æå‡è®­ç»ƒæ•ˆç‡ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **TCA-Attention æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒã€å¤´æ„ŸçŸ¥ã€ä¸Šä¸‹æ–‡è‡ªé€‚åº”çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨ 128K é•¿ä¸Šä¸‹æ–‡ä¸‹å®ç°äº† 2.8Ã— åŠ é€Ÿå’Œ 61% KV Cache å‹ç¼©ï¼ŒåŒæ—¶ä¿æŒä¸ full attention ç›¸å½“çš„æ€§èƒ½ï¼Œæ˜¯è¿ˆå‘é«˜æ•ˆ LLM æ¨ç†çš„é‡è¦ä¸€æ­¥ã€‚**

</details>

---

### 2. [HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression](https://arxiv.org/abs/2512.09886)

**Authors**: Gustavo Coelho Haase, Paulo Henrique Dourado da Silva  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.09886v1  

#### Abstract
Knowledge Distillation (KD) has emerged as a promising technique for model compression but faces critical limitations: (1) sensitivity to hyperparameters requiring extensive manual tuning, (2) capacity gap when distilling from very large teachers to small students, (3) suboptimal coordination in mul...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression  
**è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ä¼ ç»Ÿ **Knowledge Distillation (KD)** æŠ€æœ¯ä¸­å­˜åœ¨çš„å››å¤§å…³é”®æŒ‘æˆ˜æå‡ºç³»ç»Ÿæ€§è§£å†³æ–¹æ¡ˆï¼š

1. **Hyperparameter Sensitivityï¼ˆè¶…å‚æ•°æ•æ„Ÿï¼‰**ï¼šä¼ ç»ŸKDä¾èµ–å¤§é‡æ‰‹åŠ¨è°ƒå‚ï¼ˆå¦‚æ¸©åº¦ $T$ã€æŸå¤±æƒé‡ $\alpha$ï¼‰ï¼Œç¼ºä¹è‡ªé€‚åº”èƒ½åŠ›ã€‚
2. **Capacity Gapï¼ˆå®¹é‡å·®è·ï¼‰**ï¼šå½“æ•™å¸ˆæ¨¡å‹è¿œå¤§äºå­¦ç”Ÿæ¨¡å‹æ—¶ï¼Œå•æ­¥è’¸é¦éš¾ä»¥æœ‰æ•ˆä¼ é€’çŸ¥è¯†ã€‚
3. **Suboptimal Multi-Teacher Coordinationï¼ˆå¤šæ•™å¸ˆåè°ƒä¸ä½³ï¼‰**ï¼šç°æœ‰æ–¹æ³•å¯¹å¤šä¸ªæ•™å¸ˆé‡‡ç”¨å›ºå®šåŠ æƒæˆ–å¹³å‡ç­–ç•¥ï¼Œæ— æ³•åŠ¨æ€é€‚åº”ä¸åŒæ ·æœ¬çš„éœ€æ±‚ã€‚
4. **Inefficient Resource Utilizationï¼ˆèµ„æºåˆ©ç”¨ä½æ•ˆï¼‰**ï¼šé‡å¤è®­ç»ƒå¯¼è‡´è®¡ç®—å†—ä½™ï¼Œç¼ºä¹è·¨å®éªŒçš„çŸ¥è¯†å¤ç”¨æœºåˆ¶ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šHPM-KD æ¡†æ¶

ä½œè€…æå‡ºäº† **HPM-KD**ï¼ˆHierarchical Progressive Multi-Teacher Knowledge Distillationï¼‰ï¼Œä¸€ä¸ªé›†æˆå…­é¡¹ååŒç»„ä»¶çš„ç»¼åˆæ€§æ¡†æ¶ï¼š

| ç»„ä»¶ | åŠŸèƒ½ |
|------|------|
| **Adaptive Configuration Manager (ACM)** | åŸºäº meta-learning è‡ªåŠ¨é¢„æµ‹æœ€ä¼˜è¶…å‚æ•°é…ç½®ï¼ˆ$T, \alpha$, å­¦ä¹ ç‡ç­‰ï¼‰ï¼Œæ¶ˆé™¤äººå·¥è°ƒå‚ |
| **Progressive Distillation Chain (PDC)** | æ„å»ºè‡ªåŠ¨åŒ–çš„ä¸­é—´æ¨¡å‹é“¾ï¼ˆteacher â†’ intermediate â†’ studentï¼‰ï¼Œé€æ­¥ç¼©å°å®¹é‡å·®è· |
| **Attention-Weighted Multi-Teacher Ensemble (AWMT)** | å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸ºæ¯ä¸ªè¾“å…¥æ ·æœ¬åŠ¨æ€å­¦ä¹ å„æ•™å¸ˆæ¨¡å‹çš„æƒé‡ |
| **Meta-Learned Temperature Scheduler (MTS)** | åŠ¨æ€è°ƒæ•´è’¸é¦æ¸©åº¦ $T$ï¼Œæ—©æœŸå¹³æ»‘è½¯æ ‡ç­¾ï¼ŒåæœŸç²¾ç»†æ ¡å‡† |
| **Parallel Processing Pipeline (PPP)** | å¹¶è¡ŒåŒ–å¤šæ•™å¸ˆè®­ç»ƒä¸æ¸è¿›é“¾è·¯ï¼Œæå‡è®­ç»ƒæ•ˆç‡ |
| **Shared Optimization Memory (SOM)** | ç¼“å­˜å†å²å®éªŒä¸­çš„æ¨¡å‹ä¸é…ç½®ï¼Œæ”¯æŒå¿«é€Ÿ warm-start å’Œé¿å…é‡å¤è®¡ç®— |

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | HPM-KD | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ KD, TAKD, FitNetsï¼‰ |
|------|--------|-------------------------------|
| è¶…å‚æ•°è‡ªåŠ¨åŒ– | âœ… æ”¯æŒï¼ˆmeta-learningï¼‰ | âŒ éœ€æ‰‹åŠ¨è°ƒå‚æˆ–ç½‘æ ¼æœç´¢ |
| æ¸è¿›å¼è’¸é¦ | âœ… è‡ªåŠ¨æ„å»ºä¸­é—´æ¨¡å‹é“¾ | âš ï¸ TAKD æ‰‹åŠ¨è®¾è®¡ Teaching Assistant |
| å¤šæ•™å¸ˆèåˆ | âœ… æ³¨æ„åŠ›åŠ¨æ€åŠ æƒï¼ˆper-sampleï¼‰ | âŒ å›ºå®šæƒé‡æˆ–å‡åŒ€å¹³å‡ |
| æ¸©åº¦è°ƒåº¦ | âœ… åŠ¨æ€è‡ªé€‚åº”è°ƒæ•´ | âŒ å›ºå®šæ¸©åº¦ |
| å¹¶è¡Œä¸ç¼“å­˜ | âœ… æ”¯æŒå¹¶è¡Œ + è·¨å®éªŒç¼“å­˜ | âŒ æ— ç³»ç»Ÿçº§ä¼˜åŒ– |
| æ˜“ç”¨æ€§ | âœ… æä¾› scikit-learn é£æ ¼ API | âŒ é…ç½®å¤æ‚ |

> ğŸ“Œ **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šHPM-KD æ˜¯é¦–ä¸ªå°† **è‡ªåŠ¨é…ç½®ã€æ¸è¿›è’¸é¦ã€åŠ¨æ€å¤šæ•™å¸ˆã€è‡ªé€‚åº”æ¸©åº¦ã€å¹¶è¡ŒåŠ é€Ÿã€ç¼“å­˜å¤ç”¨** å…­å¤§åŠŸèƒ½æ•´åˆäºä¸€ä½“çš„æ¨¡å—åŒ–ã€ç”Ÿäº§å°±ç»ªçš„è’¸é¦æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

| ç±»å‹ | æ•°æ®é›† | æè¿° |
|------|-------|------|
| å›¾åƒåˆ†ç±» | **CIFAR-10**, **CIFAR-100** | 32Ã—32 RGB å›¾åƒï¼Œåˆ†åˆ«å« 10 å’Œ 100 ç±» |
| è¡¨æ ¼æ•°æ® | **Adult**, **Credit**, **Wine Quality**ï¼ˆæ¥è‡ª UCI ML Repositoryï¼‰ | ç”¨äºéªŒè¯åœ¨éå›¾åƒä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ› |

---

### å®éªŒè®¾ç½®

#### æ¨¡å‹æ¶æ„
- **CIFAR ä»»åŠ¡**ï¼š
  - Teacher: ResNet-56ï¼ˆ0.85M å‚æ•°ï¼‰
  - Student: ResNet-20ï¼ˆ0.27M å‚æ•°ï¼‰
  - å‹ç¼©æ¯”ï¼ˆCompression Ratio, CRï¼‰â‰ˆ 3.1Ã—
- **è¡¨æ ¼ä»»åŠ¡**ï¼š
  - Teacher: MLP [256,128,64]ï¼ˆ0.5M å‚æ•°ï¼‰
  - Student: MLP [64,32]ï¼ˆ0.05M å‚æ•°ï¼‰
  - CR = 10Ã—

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Direct Training**ï¼šä»…ç”¨çœŸå®æ ‡ç­¾è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ï¼ˆæ— è’¸é¦ï¼‰
2. **Traditional KD** [Hinton et al., 2015]ï¼šç»å…¸è’¸é¦ï¼Œå›ºå®šæ¸©åº¦
3. **FitNets** [Romero et al., 2015]ï¼šåŸºäº hint çš„ä¸­é—´å±‚è’¸é¦
4. **Attention Transfer (AT)** [Zagoruyko & Komodakis, 2017]ï¼šè¿ç§»ç©ºé—´æ³¨æ„åŠ›å›¾
5. **TAKD** [Mirzadeh et al., 2020]ï¼šå¼•å…¥ Teaching Assistant çš„æ¸è¿›è’¸é¦ï¼ˆéœ€æ‰‹åŠ¨è®¾è®¡ï¼‰

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Student Accuracy (Acc_s)** | å­¦ç”Ÿæ¨¡å‹æœ€ç»ˆå‡†ç¡®ç‡ |
| **Retention Rate (%)** | $ \frac{Acc_s}{Acc_{teacher}} \times 100\% $ï¼Œè¡¨ç¤ºæ€§èƒ½ä¿ç•™æ¯”ä¾‹ |
| **Compression Ratio (CR)** | å‚æ•°é‡æ¯” $ |\theta_t| / |\theta_s| $ |
| **Training Time** | æ€»å¢™é’Ÿæ—¶é—´ï¼ˆwall-clock timeï¼‰ |
| **Efficiency (acc/min)** | å‡†ç¡®ç‡ / è®­ç»ƒåˆ†é’Ÿæ•°ï¼Œè¡¡é‡æ€§ä»·æ¯” |
| **Ablation Study** | ç§»é™¤å•ä¸€ç»„ä»¶ï¼Œè§‚å¯Ÿæ€§èƒ½ä¸‹é™ï¼ˆå•ä½ï¼šppï¼Œpercentage pointsï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ CIFAR-10 ä¸ºä¾‹ï¼‰

| æ–¹æ³• | Acc (%) | Retention (%) | CR | è®­ç»ƒæ—¶é—´ (s) |
|------|---------|---------------|----|-------------|
| Teacher (ResNet-56) | 79.28 | 100.0 | 1.0Ã— | â€” |
| **HPM-KD (Ours)** | **67.74 Â± 0.50** | **85.4%** | 3.1Ã— | 603.1 |
| Direct Training | 68.10 Â± 0.48 | 85.9% | 3.1Ã— | 593.7 |
| Traditional KD | 67.12 Â± 0.82 | 84.7% | 3.1Ã— | 578.0 |
| FitNets | 62.66 Â± 0.76 | 79.0% | 3.1Ã— | 592.4 |
| TAKD | 67.44 Â± 0.40 | 85.1% | 3.1Ã— | 655.5 |

> âœ… **HPM-KD åœ¨å‡†ç¡®æ€§ä¸Šä¼˜äº Traditional KD (+0.62 pp) å’Œ FitNets (+5.08 pp)ï¼Œä¸ TAKD ç›¸å½“ä½†æ›´ç¨³å®šã€‚**

---

### æ›´é«˜å‹ç¼©åœºæ™¯ä¸‹çš„è¡¨ç°ï¼ˆæ‘˜è¦æåŠï¼‰

- åœ¨ **10Ã—â€“15Ã— å‹ç¼©æ¯”** ä¸‹ä»èƒ½ä¿æŒ **85% çš„æ€§èƒ½ä¿ç•™ç‡**
- å®ç° **30â€“40% çš„è®­ç»ƒæ—¶é—´å‡å°‘**ï¼ˆå¾—ç›Šäº PPP å¹¶è¡ŒåŒ–å’Œ SOM ç¼“å­˜ï¼‰
- åœ¨ tabular æ•°æ®ä¸ŠåŒæ ·æœ‰æ•ˆï¼Œè¯æ˜å…¶è·¨æ¨¡æ€é€šç”¨æ€§

---

### æ¶ˆèå®éªŒç»“æœï¼ˆCIFAR-100ï¼Œ5æ¬¡è¿è¡Œå‡å€¼ï¼‰

| é…ç½® | Acc (%) | Î” (pp) | Retention (%) |
|------|--------|--------|----------------|
| Full HPM-KD | 36.28 Â± 0.52 | 0.00 | 100.0 |
| w/o MultiTeach | 35.30 Â± 0.85 | -0.98 | 97.3 |
| w/o MetaTemp | 35.63 Â± 0.41 | -0.65 | 98.2 |
| w/o Memory | 35.67 Â± 0.51 | -0.61 | 98.3 |
| w/o Parallel | 35.67 Â± 0.68 | -0.61 | 98.3 |
| w/o ProgChain | 36.06 Â± 0.31 | -0.22 | 99.4 |
| w/o AdaptConf | 36.18 Â± 0.38 | -0.10 | 99.7 |

> ğŸ” **ç»„ä»¶é‡è¦æ€§æ’åº**ï¼š
> 1. **Multi-Teacher Ensemble**ï¼ˆ-0.98 ppï¼‰â€”â€”æœ€å…³é”®
> 2. **Meta-Temperature Scheduler**ï¼ˆ-0.65 ppï¼‰
> 3. **Memory & Parallel**ï¼ˆå„ -0.61 ppï¼‰
> 4. **ProgChain**ï¼ˆ-0.22 ppï¼‰
> 5. **AdaptConf**ï¼ˆ-0.10 ppï¼Œè™½å½±å“å°ä½†æå¤§æå‡å¯ç”¨æ€§ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **HPM-KD å®ç°é«˜æ•ˆå‹ç¼©ä¸é«˜ä¿çœŸçŸ¥è¯†è¿ç§»**  
   åœ¨ 3.1Ã— è‡³ 15Ã— å‹ç¼©ä¸‹ä¿æŒ 85%+ æ€§èƒ½ä¿ç•™ï¼Œé€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ã€‚

2. âœ… **æ‰€æœ‰å…­ä¸ªç»„ä»¶å‡æœ‰ç‹¬ç«‹æ­£å‘è´¡çŒ®ï¼ˆ0.10â€“0.98 ppï¼‰**  
   å°¤å…¶æ˜¯ **Attention-Weighted Multi-Teacher** å¯¹æ€§èƒ½æå‡æœ€å¤§ã€‚

3. âœ… **å…·å¤‡å¼ºé²æ£’æ€§**  
   - å¯¹ **ç±»åˆ«ä¸å¹³è¡¡ï¼ˆup to 100:1ï¼‰** å’Œ **æ ‡ç­¾å™ªå£°ï¼ˆup to 30%ï¼‰** è¡¨ç°å‡ºæƒŠäººé²æ£’æ€§
   - æ•™å¸ˆæ¨¡å‹çš„ soft targets å¯ä½œä¸ºéšå¼æ­£åˆ™å™¨ï¼Œè¿‡æ»¤å™ªå£°

4. âœ… **è®¡ç®—æ•ˆç‡é«˜**  
   - å¹¶è¡ŒåŒ–å¸¦æ¥ **2.78Ã— åŠ é€Ÿï¼ˆ4 workersï¼‰**
   - ç¼“å­˜å‘½ä¸­ç‡è¾¾ 30â€“40%ï¼Œæ˜¾è‘—èŠ‚çœé‡å¤è®­ç»ƒå¼€é”€
   - ç›¸æ¯” TAKDï¼Œé¢å¤–å¼€é”€ <1%

5. âš ï¸ **è’¸é¦å¹¶éæ€»æ˜¯å¿…è¦**  
   åœ¨ moderate compression ratioï¼ˆå¦‚ 3.1Ã—ï¼‰ä¸”å­¦ç”Ÿæœ‰è¶³å¤Ÿå®¹é‡æ—¶ï¼Œ**Direct Training å¯èƒ½ä¼˜äºè’¸é¦**ï¼ˆCIFAR-10 ä¸Š 68.10% vs. 67.74%ï¼‰

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **éªŒè¯èŒƒå›´æœ‰é™** | ä¸»è¦åœ¨ CIFAR å’Œå°å‹è¡¨æ ¼æ•°æ®ä¸Šæµ‹è¯•ï¼Œå°šæœªæ‰©å±•è‡³ ImageNetã€NLP æˆ–åŒ»ç–—å½±åƒ |
| **æœªè¦†ç›–è¶…é«˜å‹ç¼©æ¯”** | å½“å‰ CR æœ€é«˜çº¦ 15Ã—ï¼Œè€Œ TAKD åœ¨ >10Ã— åœºæ™¯ä¼˜åŠ¿æ›´æ˜æ˜¾ï¼Œéœ€è¿›ä¸€æ­¥éªŒè¯ ultra-compressionï¼ˆ50â€“100Ã—ï¼‰æ•ˆæœ |
| **ç†è®ºåˆ†æç¼ºå¤±** | ç¼ºä¹å¯¹æ”¶æ•›æ€§ã€æ³›åŒ–ç•Œï¼ˆgeneralization boundï¼‰æˆ– PAC æ¡†æ¶çš„æ•°å­¦è¯æ˜ |
| **å†·å¯åŠ¨é—®é¢˜** | ACM ä¾èµ–å†å²æ•°æ®è¿›è¡Œ meta-learningï¼Œåœ¨å…¨æ–°é¢†åŸŸå¯èƒ½å¤±æ•ˆï¼ˆéœ€è‡³å°‘ 5+ å®éªŒæ‰èƒ½è¾¾åˆ° <5% è¯¯å·®ï¼‰ |
| **ç›¸æ¯”ä¼ ç»ŸKDç•¥æœ‰æ—¶é—´å¼€é”€** | å› å¤šæ•™å¸ˆå’Œæ¸è¿›é“¾ï¼Œæ€»è®­ç»ƒæ—¶é—´å¢åŠ  30â€“40%ï¼Œéœ€æƒè¡¡ç²¾åº¦å¢ç›Šä¸æˆæœ¬ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³ Large Language Models (LLMs)**ï¼šå‹ç¼© GPT ç±»åƒäº¿å‚æ•°æ¨¡å‹
2. **Cross-Modal Distillation**ï¼šä» CLIPã€Flamingo ç­‰å¤šæ¨¡æ€æ¨¡å‹è’¸é¦åˆ°ä¸“ç”¨å•æ¨¡æ€æ¨¡å‹
3. **Theoretical Analysis**ï¼šæ¨å¯¼ progressive distillation çš„æ³›åŒ–è¾¹ç•Œä¸ meta-temperature æ”¶æ•›æ€§
4. **Distillation-Aware Architecture Search (DAAS)**ï¼šè”åˆä¼˜åŒ–ç½‘ç»œç»“æ„ä¸è’¸é¦ç­–ç•¥
5. **Federated Knowledge Distillation**ï¼šåœ¨è”é‚¦å­¦ä¹ ä¸­å®ç°éšç§ä¿æŠ¤ä¸‹çš„åˆ†å¸ƒå¼è’¸é¦
6. **Continuous Distillation**ï¼šæ”¯æŒæ•™å¸ˆæŒç»­æ›´æ–°æ—¶çš„å­¦ç”Ÿå¢é‡å­¦ä¹ ï¼ˆlifelong learningï¼‰

---

## æ€»ç»“

ğŸ“Œ **HPM-KD æ˜¯ä¸€ä¸ªé¢å‘ç”Ÿäº§çš„ã€é«˜åº¦è‡ªåŠ¨åŒ–ã€å¯æ‰©å±•çš„ Knowledge Distillation æ¡†æ¶**ï¼Œé€šè¿‡å…­å¤§ååŒç»„ä»¶è§£å†³äº†ä¼ ç»Ÿè’¸é¦ä¸­çš„å…³é”®ç“¶é¢ˆã€‚å®ƒä¸ä»…æå‡äº†å‹ç¼©æ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ï¼Œè¿˜å¤§å¹…é™ä½äº†éƒ¨ç½²é—¨æ§›ã€‚

ğŸ”— å¼€æºåœ°å€ï¼š[https://github.com/DeepBridge-Validation/DeepBridge](https://github.com/DeepBridge-Validation/DeepBridge)  
ğŸ“¦ æä¾›ç±» `scikit-learn` çš„ç®€æ´ APIï¼Œä¾¿äºå·¥ä¸šç•Œå¿«é€Ÿé›†æˆã€‚

> ğŸ’¡ **å®è·µå»ºè®®**ï¼šå¯¹äº **é«˜å‹ç¼©æ¯” (>10Ã—)ã€å¤šæ•™å¸ˆå¯ç”¨ã€å­˜åœ¨å™ªå£°/ä¸å¹³è¡¡ã€æ— æ³•äººå·¥è°ƒå‚** çš„åœºæ™¯ï¼Œæ¨èä½¿ç”¨ HPM-KDï¼›è€Œå¯¹äºè½»åº¦å‹ç¼©ä¸”å­¦ç”Ÿå®¹é‡å……è¶³çš„æƒ…å†µï¼Œå¯ä¼˜å…ˆå°è¯• Direct Trainingã€‚

</details>

---

### 3. [Semantic-Aware Cooperative Communication and Computation Framework in Vehicular Networks](https://arxiv.org/abs/2512.09621)

**Authors**: Jingbo Zhang, Maoxin Ji, Qiong Wu, Pingyi Fan, Kezhi Wang, Wen Chen  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.09621v1  

#### Abstract
Semantic Communication (SC) combined with Vehicular edge computing (VEC) provides an efficient edge task processing paradigm for Internet of Vehicles (IoV). Focusing on highway scenarios, this paper proposes a Tripartite Cooperative Semantic Communication (TCSC) framework, which enables Vehicle User...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSemantic-Aware Cooperative Communication and Computation Framework in Vehicular Networks

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨é«˜é€Ÿç§»åŠ¨çš„ **Internet of Vehicles (IoV)** åœºæ™¯ä¸­ï¼Œä¼ ç»ŸåŸºäºæ¯”ç‰¹çº§é€šä¿¡ï¼ˆbit-level communicationï¼‰çš„ä»»åŠ¡å¸è½½æœºåˆ¶å­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- é«˜å»¶è¿Ÿã€é«˜å†—ä½™ï¼Œéš¾ä»¥æ»¡è¶³è‡ªåŠ¨é©¾é©¶ç­‰ä»»åŠ¡å¯¹**ä½å»¶è¿Ÿ**å’Œ**é«˜å¯é æ€§**çš„éœ€æ±‚ï¼›
- ç°æœ‰ç ”ç©¶å¤§å¤šä»…è€ƒè™‘ **Vehicle-to-Infrastructure (V2I)** å•ä¸€é“¾è·¯ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨ **Vehicle-to-Vehicle (V2V)** ååŒå¸¦æ¥çš„èµ„æºçµæ´»æ€§ã€‚

æœ¬æ–‡èšç„¦äºé«˜é€Ÿå…¬è·¯åœºæ™¯ï¼Œè§£å†³å¦‚ä½•é€šè¿‡è¯­ä¹‰æ„ŸçŸ¥ï¼ˆsemantic-awareï¼‰ååŒé€šä¿¡ä¸è®¡ç®—æ¡†æ¶å®ç°é«˜æ•ˆã€ä½å»¶è¿Ÿçš„ä»»åŠ¡å¸è½½é—®é¢˜ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

1. **æå‡º Tripartite Cooperative Semantic Communication (TCSC) æ¡†æ¶**  
   - é¦–æ¬¡æ„å»ºäº†ä¸€ä¸ªæ”¯æŒ **V2I å’Œ V2V è”åˆåä½œ**çš„ä¸‰å…ƒååŒè¯­ä¹‰é€šä¿¡æ¶æ„ã€‚
   - æ”¯æŒè½¦è¾†ç”¨æˆ·ï¼ˆVUsï¼‰ã€è·¯ä¾§å•å…ƒï¼ˆRSUï¼‰å’ŒæœåŠ¡è½¦è¾†ï¼ˆSVsï¼‰ä¹‹é—´çš„åŠ¨æ€è¯­ä¹‰ä»»åŠ¡å¸è½½ã€‚
   - åˆ©ç”¨ **DeepSC** å®ç°æ–‡æœ¬è¯­ä¹‰ç¼–ç ä¸è§£ç ï¼Œæå‡ä¼ è¾“æ•ˆç‡ã€‚

2. **è®¾è®¡æ··åˆä¼˜åŒ–ç®—æ³•ï¼šMAPPO-PDN + LP**
   - å°†åŸ **Mixed-Integer Nonlinear Programming (MINLP)** é—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªå­é—®é¢˜ï¼š
     - **ç¦»æ•£å˜é‡ä¼˜åŒ–**ï¼šä½¿ç”¨æå‡ºçš„ **MAPPO-PDN** ç®—æ³•ä¼˜åŒ–æ¯è¯å¹³å‡è¯­ä¹‰ç¬¦å·æ•° $k_{i,j}$ï¼›
     - **è¿ç»­å˜é‡ä¼˜åŒ–**ï¼šé‡‡ç”¨ **Linear Programming (LP)** ä¼˜åŒ–ä»»åŠ¡å¸è½½æ¯”ä¾‹ $p$ã€‚
   - åˆ›æ–°åœ°å¼•å…¥ **Parametric Distribution Noise (PDN)** åˆ°å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œå¢å¼ºç­–ç•¥é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

3. **MAPPO-PDN çš„å…³é”®æŠ€æœ¯æ”¹è¿›**
   - å°† Actor ç½‘ç»œå‚æ•°å»ºæ¨¡ä¸ºé«˜æ–¯åˆ†å¸ƒ $q(\theta_k) = \mathcal{N}(\mu_k, \sigma_k)$ï¼Œå®ç°ä¸ç¡®å®šæ€§å»ºæ¨¡ï¼›
   - å¼•å…¥ PDN æ­£åˆ™é¡¹çº¦æŸå‚æ•°æ‰°åŠ¨ä¸Šç•Œï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæå‡éå¹³ç¨³ç¯å¢ƒä¸‹çš„ç¨³å®šæ€§ï¼›
   - è®¾è®¡åŸºäºæœ€å°å»¶è¿Ÿçš„å¥–åŠ±å‡½æ•° $r = T_{\text{min}} / T_i$ï¼Œå¼•å¯¼å¿«é€Ÿæ”¶æ•›ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| å¯¹æ¯”ç»´åº¦ | æœ¬æ–‡æ–¹æ³•ï¼ˆTCSC + MAPPO-PDN + LPï¼‰ | ç°æœ‰æ–¹æ³• |
|--------|-------------------------------|---------|
| é€šä¿¡èŒƒå¼ | è¯­ä¹‰é€šä¿¡ï¼ˆSemantic Communicationï¼‰ | ä¼ ç»Ÿæ¯”ç‰¹çº§é€šä¿¡ |
| ååŒæ–¹å¼ | V2I + V2V åŒè·¯å¾„ååŒ | å¤šæ•°ä»…æ”¯æŒ V2I |
| å­¦ä¹ ç®—æ³• | å¸¦å‚æ•°åˆ†å¸ƒå™ªå£°çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMAPPO-PDNï¼‰ | MAPPOã€MADQN ç­‰ç‚¹ä¼°è®¡æ–¹æ³• |
| ä¼˜åŒ–æ–¹å¼ | åˆ†è§£ä¸ºç¦»æ•£+è¿ç»­è”åˆä¼˜åŒ– | æ•´ä½“ç«¯åˆ°ç«¯è®­ç»ƒå¤æ‚åº¦é«˜ |
| æ€§èƒ½è¡¨ç° | æ›´ä½å»¶è¿Ÿã€æ›´å¼ºé²æ£’æ€§ã€æ›´å¥½æ”¶æ•›æ€§ | æ˜“è¿‡æ‹Ÿåˆã€é€‚åº”æ€§å·® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š å®éªŒç¯å¢ƒä¸ä»¿çœŸå¹³å°
- **ä»¿çœŸå·¥å…·**ï¼šPython 3.8 + PyTorch
- **åœºæ™¯è®¾ç½®**ï¼š400ç±³é•¿åŒè½¦é“é«˜é€Ÿå…¬è·¯ï¼Œéƒ¨ç½²ä¸€ä¸ª RSU å’Œè‹¥å¹²è½¦è¾†
- **è½¦è¾†é…ç½®**ï¼š
  - VUs æ•°é‡å˜åŒ–èŒƒå›´ï¼š20â€“40
  - SVs å›ºå®šæ•°é‡ï¼šJ = 5
  - è½¦é€Ÿï¼š50â€“80 km/hï¼ˆæ’å®šç”¨äºå»ºæ¨¡ï¼‰
- **ä»»åŠ¡ç”Ÿæˆ**ï¼šæ³Šæ¾åˆ†å¸ƒï¼Œæ¯æ—¶éš™ç”Ÿæˆ 0.8 Mbit æ–‡æœ¬ä»»åŠ¡ï¼Œéœ€ 1000 cycles/bit è®¡ç®—èµ„æº

### âš™ï¸ å…³é”®å‚æ•°è®¾ç½®
| å‚æ•° | å€¼ |
|------|----|
| å™ªå£°åŠŸç‡ | -114 dBm |
| V2I å‘å°„åŠŸç‡ | 23 dBm |
| V2V å‘å°„åŠŸç‡ | 15 dBm |
| å¸¦å®½ B | 540 kHz |
| RSU è®¡ç®—èƒ½åŠ› $f_R$ | 6 GHz |
| VU è®¡ç®—èƒ½åŠ› $f_{loc}$ | 1 GHz |
| SV è®¡ç®—èƒ½åŠ› $f_Y$ | 3 GHz |
| æ¯å¥å¹³å‡é•¿åº¦ $L_{i,j}$ | 20 words |
| æ•°æ®è½¬å¥å­å› å­ H | 1200 bit/sentence |
| è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼ $\delta_{th}$ | 0.9 |
| PDN ä¸Šé™ $\Omega_{\text{max}}$ | 20 |

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **æ€»ä»»åŠ¡å»¶è¿Ÿï¼ˆTotal Task Delayï¼‰**
- **ä¼ è¾“å»¶è¿Ÿï¼ˆTransmission Delayï¼‰**
- **è®­ç»ƒå¥–åŠ±æ”¶æ•›æ›²çº¿ï¼ˆEpisode Rewardï¼‰**
- **ä¸åŒè½¦è¾†å¯†åº¦ä¸‹çš„ç³»ç»Ÿæ€§èƒ½**

---

### ğŸ”€ åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±æ¯”è¾ƒ 7 ç§æ–¹æ³•ï¼š
1. **Our-Method + LP**ï¼ˆæœ¬æ–‡æå‡ºï¼‰
2. **Our-Method + Ivy**ï¼ˆæ›¿æ¢ LP ä¸º Ivy ä¼˜åŒ–å™¨ï¼‰
3. **MAPPO + LP**
4. **MADQN + LP**
5. **Linear K-Selection + LP**ï¼ˆå›ºå®š k è§„åˆ™é€‰æ‹©ï¼‰
6. **Traditional + LP**ï¼ˆä¼ ç»Ÿé€šä¿¡ + LPï¼‰
7. **Traditional + Ivy**
8. **Traditional (No LP)**ï¼ˆä¼ ç»Ÿå›ºå®šå¸è½½ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“‰ å›¾è¡¨å…³é”®ç»“æœåˆ†æ

#### âœ… å›¾2ï¼šè®­ç»ƒå¥–åŠ±æ”¶æ•›æ€§èƒ½ï¼ˆConvergence Performanceï¼‰
- **MAPPO-PDN** åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­æŒç»­è·å¾—æ›´é«˜å¥–åŠ±ï¼›
- ç›¸æ¯”ä¼ ç»Ÿ MAPPO å’Œ MADQNï¼Œ**æ”¶æ•›æ›´å¿«ã€æ›´ç¨³å®š**ï¼›
- è¡¨æ˜ PDN æ­£åˆ™åŒ–æœ‰æ•ˆæå‡äº†æ¢ç´¢å¤šæ ·æ€§å¹¶æŠ‘åˆ¶äº†è¿‡æ‹Ÿåˆã€‚

> ğŸ’¡ ç»“è®ºï¼šMAPPO-PDN å…·å¤‡æ›´å¼ºçš„ç¯å¢ƒé€‚åº”èƒ½åŠ›å’Œç­–ç•¥ç¨³å®šæ€§ã€‚

---

#### âœ… å›¾3ï¼šä¸åŒè½¦è¾†æ•°é‡ä¸‹çš„æ€»ä¼ è¾“å»¶è¿Ÿ
- å½“ VU æ•°é‡ä» 20 å¢åŠ è‡³ 40ï¼š
  - æ‰€æœ‰æ–¹æ³•å»¶è¿Ÿå‡ä¸Šå‡ï¼ˆèµ„æºç«äº‰åŠ å‰§ï¼‰ï¼›
  - ä½†åœ¨ 25â€“35 è¾†åŒºé—´å‡ºç°â€œå‡¹å½¢ä¸‹é™â€ï¼Œå› è½¦è·ç¼©çŸ­ â†’ V2V ä¿¡é“è´¨é‡æé«˜ â†’ é€Ÿç‡æå‡ï¼›
- **Our-Method + LP** å§‹ç»ˆä¿æŒæœ€ä½å»¶è¿Ÿï¼Œä¼˜äºå…¶ä»–æ–¹æ³•çº¦ **15%~30%**ã€‚

> ğŸ’¡ ç‰¹åˆ«æ˜¯åœ¨é«˜å¯†åº¦ä¸‹ä¼˜åŠ¿æ˜æ˜¾ï¼Œä½“ç° V2V ååŒä¸è¯­ä¹‰å‹ç¼©çš„æœ‰æ•ˆæ€§ã€‚

---

#### âœ… å›¾4ï¼šå¹³å‡ä»»åŠ¡å»¶è¿Ÿå¯¹æ¯”ï¼ˆå«è®¡ç®—å»¶è¿Ÿï¼‰
- éšç€è½¦è¾†å¢å¤šï¼Œè¾¹ç¼˜èŠ‚ç‚¹è®¡ç®—èµ„æºè¢«åˆ†æ‘Š â†’ **è®¡ç®—å»¶è¿Ÿæˆä¸ºä¸»å¯¼å› ç´ **ï¼›
- **Our-Method + LP** ä»æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼š
  - æ¯” MAPPO + LP é™ä½çº¦ **25%** å»¶è¿Ÿï¼›
  - æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼ˆTraditional + LPï¼‰é™ä½è¶…è¿‡ **40%**ï¼›
- å³ä½¿ä½¿ç”¨ç›¸åŒ LP æ¨¡å—ï¼ŒMAPPO-PDN åœ¨è¯­ä¹‰ç¬¦å·é€‰æ‹©ä¸Šçš„ä¼˜è¶Šæ€§ä¹Ÿå¸¦æ¥æ•´ä½“æ€§èƒ½å¢ç›Šã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒåˆ†æï¼ˆéšå«åœ¨å¯¹æ¯”ä¸­ï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†ä»æ–¹æ³•ç»„åˆå¯æ¨æ–­ï¼š
| ç»„ä»¶ | æ˜¯å¦å¯ç”¨ | æ€§èƒ½å½±å“ |
|------|----------|---------|
| TCSC æ¡†æ¶ï¼ˆV2I+V2Vï¼‰ | âœ”ï¸ | æ˜¾è‘—æå‡èµ„æºåˆ©ç”¨ç‡ |
| Semantic Communication | âœ”ï¸ | å‡å°‘æ— æ•ˆæ•°æ®ä¼ è¾“ï¼Œé™ä½è´Ÿè½½ |
| MAPPO-PDNï¼ˆvs MAPPOï¼‰ | âœ”ï¸ | æå‡æ”¶æ•›é€Ÿåº¦ä¸é²æ£’æ€§ |
| LP å¸è½½ç‡ä¼˜åŒ–ï¼ˆvs å›ºå®šæ¯”ä¾‹ï¼‰ | âœ”ï¸ | ç²¾ç¡®æ§åˆ¶å¸è½½æ¯”ä¾‹ï¼Œé™ä½å»¶è¿Ÿ |

> ç¤ºä¾‹ï¼šå°† â€œOur-Method + LPâ€ ä¸ â€œTraditional + LPâ€ å¯¹æ¯”ï¼Œä½“ç°äº† **è¯­ä¹‰é€šä¿¡æœ¬èº«çš„ä»·å€¼**ï¼›è€Œ â€œMAPPO + LPâ€ vs â€œMAPPO-PDN + LPâ€ å±•ç¤ºäº† **PDN å¸¦æ¥çš„æ€§èƒ½å¢ç›Š**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **è¯­ä¹‰é€šä¿¡ + VEC æ˜¯ IoV ä¸­å®ç°ä½å»¶è¿Ÿä»»åŠ¡å¤„ç†çš„æœ‰æ•ˆèŒƒå¼**ï¼›
2. **V2I ä¸ V2V ååŒå¸è½½èƒ½æ˜¾è‘—æå‡ç³»ç»Ÿå¼¹æ€§ä¸èµ„æºåˆ©ç”¨ç‡**ï¼›
3. **MAPPO-PDN é€šè¿‡å‚æ•°ä¸ç¡®å®šæ€§å»ºæ¨¡ï¼Œåœ¨éå¹³ç¨³å¤šè½¦ç¯å¢ƒä¸­è¡¨ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**ï¼›
4. **åˆ†ç¦»ä¼˜åŒ–ç­–ç•¥ï¼ˆMAPPO-PDN + LPï¼‰ç›¸æ¯”ç«¯åˆ°ç«¯æ–¹æ³•æ›´é«˜æ•ˆã€å‡†ç¡®ä¸”æ˜“äºå®ç°**ï¼›
5. åœ¨é«˜è½¦è¾†å¯†åº¦åœºæ™¯ä¸‹ï¼Œæ‰€ææ–¹æ³•ä¾ç„¶ä¿æŒè‰¯å¥½æ€§èƒ½ï¼Œå…·å¤‡å®é™…éƒ¨ç½²æ½œåŠ›ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **å‡è®¾ä¿¡é“ä¸ºå‡†é™æ€ï¼ˆquasi-staticï¼‰**ï¼Œæœªè€ƒè™‘é«˜é€Ÿç§»åŠ¨å¯¼è‡´çš„å¿«é€Ÿè¡°è½ï¼›
2. **ä»…é’ˆå¯¹æ–‡æœ¬ç±»è¯­ä¹‰ä»»åŠ¡**ï¼ˆå¦‚å¯¼èˆªæŒ‡ä»¤ã€çŠ¶æ€æŠ¥å‘Šï¼‰ï¼Œæœªæ¶‰åŠå›¾åƒã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®ï¼›
3. **SV èµ„æºåˆ†é…é‡‡ç”¨å‡åˆ†ç­–ç•¥**ï¼Œå¯èƒ½åœ¨å¼‚æ„è®¡ç®—èƒ½åŠ›ä¸‹ä¸å¤Ÿå…¬å¹³æˆ–é«˜æ•ˆï¼›
4. **ä»¿çœŸä¸­è½¦é€Ÿæ’å®š**ï¼Œæœªå®Œå…¨æ¨¡æ‹ŸçœŸå®äº¤é€šæµåŠ¨åŠ›å­¦ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¤šæ¨¡æ€è¯­ä¹‰é€šä¿¡**ï¼ˆMultimodal Semantic Communicationï¼‰ï¼Œæ”¯æŒè§†è§‰ã€è¯­éŸ³ç­‰èåˆä»»åŠ¡ï¼›
2. **ç»“åˆ Reconfigurable Intelligent Surface (RIS)** æˆ– AI-driven beamforming è¿›ä¸€æ­¥ä¼˜åŒ–ä¿¡é“è´¨é‡ï¼›
3. **å¼•å…¥è”é‚¦å­¦ä¹ æœºåˆ¶**ï¼Œä¿æŠ¤è¯­ä¹‰æ¨¡å‹éšç§çš„åŒæ—¶å®ç°åˆ†å¸ƒå¼è®­ç»ƒï¼›
4. **åœ¨åŸå¸‚äº¤å‰å£ã€æ‹¥å µè·¯æ®µç­‰å¤æ‚åœºæ™¯éªŒè¯æ¡†æ¶æ™®é€‚æ€§**ï¼›
5. æ¢ç´¢ **è¯­ä¹‰QoEï¼ˆQuality of Experienceï¼‰é©±åŠ¨çš„è‡ªé€‚åº”å‹ç¼©æœºåˆ¶**ã€‚

---

## âœ… æ€»ç»“
è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé¢å‘è½¦è”ç½‘çš„ **è¯­ä¹‰æ„ŸçŸ¥ååŒé€šä¿¡ä¸è®¡ç®—æ¡†æ¶ TCSC**ï¼Œç»“åˆ **MAPPO-PDN ä¸ LP çš„æ··åˆä¼˜åŒ–ç­–ç•¥**ï¼Œåœ¨ä¿è¯è¯­ä¹‰ä¿çœŸåº¦çš„å‰æä¸‹å®ç°äº†ä½å»¶è¿Ÿä»»åŠ¡å¸è½½ã€‚å®éªŒè¡¨æ˜å…¶åœ¨å¤šç§ç¯å¢ƒä¸‹å‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæ˜¯æ¨åŠ¨ **Semantic Communication in VEC** å®é™…è½åœ°çš„é‡è¦ä¸€æ­¥ã€‚

</details>

---

### 4. [Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement](https://arxiv.org/abs/2512.09854)

**Authors**: Muneeb Ur Raheem Khan  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.09854v1  

#### Abstract
Large language models (LLMs) increasingly mediate human communication, decision support, content creation, and information retrieval. Despite impressive fluency, these systems frequently produce biased or stereotypical content, especially when prompted with socially sensitive language. A growing bod...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡èšç„¦äº**ä½èµ„æºè¯­è¨€ï¼ˆå¦‚ Urduï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­é¢ä¸´çš„ç³»ç»Ÿæ€§ç¤¾ä¼šåè§é—®é¢˜**ã€‚ç”±äºè®­ç»ƒæ•°æ®ç¨€ç¼ºä¸”æ–‡åŒ–ä»£è¡¨æ€§ä¸è¶³ï¼ŒUrduç­‰è¯­è¨€åœ¨ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´é«˜çš„åè§å€¾å‘å’Œè¯­ä¹‰è´¨é‡ä¸‹é™ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°ç°æœ‰çš„å»åç ”ç©¶é›†ä¸­äºè‹±è¯­ï¼Œç¼ºä¹å¯¹å¤šè¯­è¨€ã€å°¤å…¶æ˜¯ä½èµ„æºè¯­è¨€çš„å…¬å¹³æ€§è¯„ä¼°ä¸å¹²é¢„æœºåˆ¶ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**ç»Ÿä¸€çš„æ¨ç†æ—¶ï¼ˆinference-timeï¼‰å»åæ¡†æ¶**ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæˆ–å¾®è°ƒæ¨¡å‹ï¼Œé€‚ç”¨äºä»»ä½•é»‘ç›’ LLMã€‚è¯¥æ¡†æ¶åŸºäº **Preference Ranking Model (PRM)**ï¼Œç»“åˆä¸¤ç§å€™é€‰ä¼˜åŒ–ç­–ç•¥ï¼š

- **PRM-Select**ï¼šé€šè¿‡ Best-of-N é‡‡æ ·ç”Ÿæˆå¤šä¸ªå€™é€‰è¯ï¼Œç”± PRM æ‰“åˆ†åé€‰æ‹©æœ€ä¼˜ç»“æœã€‚
- **PRM-Sequential**ï¼šåˆ©ç”¨ PRM æä¾›çš„æ‰¹è¯„åé¦ˆè¿›è¡Œå¤šè½®è¿­ä»£ç²¾ç‚¼ï¼Œé€æ­¥æ”¹è¿›è¾“å‡ºã€‚

æ­¤æ–¹æ³•å°† PRM åŒæ—¶ç”¨äº **bias scoring** å’Œ **utility scoring**ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªåŠ æƒå¤åˆå¾—åˆ† $ S = (1-\alpha)\cdot\text{bias} + \alpha\cdot\text{utility} $ï¼ˆ$\alpha=0.5$ï¼‰ï¼Œå®ç°åè§ä¸è¯­ä¹‰åˆç†æ€§çš„å¹³è¡¡ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **é€šç”¨æ€§** | ä¸ä¾èµ–æ¨¡å‹æƒé‡ä¿®æ”¹ï¼Œé€‚ç”¨äº GPT-3.5ã€GPT-4 ç­‰é—­æºæ¨¡å‹ |
| **è½»é‡é«˜æ•ˆ** | æ¨ç†é˜¶æ®µæ“ä½œï¼Œé¿å…æ˜‚è´µçš„å†è®­ç»ƒæˆæœ¬ |
| **è·¨è¯­è¨€é€‚é…** | é¦–æ¬¡ç³»ç»Ÿæ¯”è¾ƒ English ä¸ Urdu åœ¨å•å­—è¡¥å…¨ä»»åŠ¡ä¸­çš„å»åæ•ˆæœ |
| **å¯è§£é‡Šæ€§** | å¼•å…¥ç»†ç²’åº¦çš„ bias/utility åˆ†é¡¹è¯„åˆ†ï¼Œä¾¿äºåˆ†ææ”¹è¿›æ¥æº |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- æ„å»ºäº†ä¸€ä¸ªåŒè¯­å»åè¯„ä¼°æ•°æ®é›†ï¼Œå…± **400 æ¡æç¤ºï¼ˆpromptsï¼‰**ï¼š
  - è‹±æ–‡åŸå§‹æç¤ºï¼š200 æ¡ï¼Œè¦†ç›–æ€§åˆ«ã€ç§æ—ã€å®—æ•™ã€å›½ç±ã€æ®‹ç–¾ã€èŒä¸šã€å¹´é¾„ã€ç¤¾ä¼šç»æµåœ°ä½ç­‰ç»´åº¦ã€‚
  - å¯¹åº”ä¹Œå°”éƒ½è¯­ç¿»è¯‘ï¼š200 æ¡ï¼Œç»äººå·¥è°ƒæ•´ä»¥ä¿æŒç¤¾ä¼šæ–‡åŒ–è¯­å¢ƒä¸€è‡´æ€§ã€‚
- è®¾è®¡ä¸º **å•å­—è¡¥å…¨ä»»åŠ¡ï¼ˆsingle-word completionï¼‰**ï¼Œæå‡å¯æ¯”æ€§å’Œè¯„ä¼°ç¨³å®šæ€§ã€‚
- å— CrowS-Pairs å’Œ StereoSet å¯å‘ï¼Œä½†é€‚é…æ¨ç†æ—¶å»ååœºæ™¯ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
| ç»„ä»¶ | é…ç½® |
|------|------|
| **Candidate Generator** | `gpt-3.5-turbo`ï¼ˆè‹±æ–‡ & Urdu è¾“å‡ºï¼‰ |
| **Preference Ranking Model (PRM)** | `gpt-4o-mini`ï¼Œé›¶æ ·æœ¬æ¨¡å¼æ‰“åˆ†ï¼ˆzero-shot scoringï¼‰ |
| **Debiasing æ–¹æ³•** | ä¸‰ç§ pipelineï¼š<br>1. **Baseline**ï¼šä¸€æ¬¡æ€§ç”Ÿæˆ<br>2. **PRM-Select**ï¼šN=8 ä¸ªå€™é€‰ï¼Œé€‰æœ€é«˜åˆ†<br>3. **PRM-Sequential**ï¼šæœ€å¤š 5 è½®è¿­ä»£ refinement |
| **è¯„åˆ†ç»´åº¦** | æ¯ä¸ªå€™é€‰è¯ç”± PRM æ‰“ä¸¤ä¸ªåˆ†æ•°ï¼š<br>- **Bias Score** âˆˆ [0,1]ï¼ˆè¶Šé«˜è¶Šå°‘åè§ï¼‰<br>- **Utility Score** âˆˆ [0,1]ï¼ˆè¶Šé«˜è¯­ä¹‰è¶Šåˆç†ï¼‰ |

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- å¹³å‡ **Bias Score**
- å¹³å‡ **Utility Score**
- åŠ æƒ **Composite Score**ï¼ˆbias ä¸ utility å„å  0.5ï¼‰
- è·¨è¯­è¨€å·®å¼‚ Î”ï¼ˆEnglish âˆ’ Urduï¼‰
- æ”¹è¿›è½¨è¿¹åˆ†æï¼ˆstage-wise improvementï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table å’Œ Figureï¼‰

| æ–¹æ³• | è¯­è¨€ | Bias Score | Utility Score | Composite Score |
|------|------|------------|---------------|------------------|
| **Baseline** | English | 0.9525 | 0.985 | 0.96875 |
|              | Urdu    | 0.755  | 0.85  | 0.8025           |
| **PRM-Select** | English | 0.9765 | 1.0   | 0.98825          |
|                | Urdu    | 0.96   | 0.9825| 0.97125          |
| **PRM-Sequential** | English | **0.99**  | 0.99  | **0.99**         |
|                    | Urdu    | **0.975** | **0.8825** | 0.92875       |

### ğŸ” ä¸åŸºçº¿å¯¹æ¯”ç»“æœ
- **PRM-Select** æ˜¾è‘—æå‡äº† Urdu çš„è¡¨ç°ï¼š
  - Urdu çš„ bias æå‡é«˜è¾¾ **+20.5 ä¸ªç™¾åˆ†ç‚¹**ï¼ˆ0.755 â†’ 0.96ï¼‰
  - Utility æå‡ **+13.25 ä¸ªç™¾åˆ†ç‚¹**
  - å‡ ä¹æ¶ˆé™¤äº†è‹±ä¹Œä¹‹é—´çš„ composite score å·®è·ï¼ˆÎ” ä» 0.166 é™è‡³ 0.017ï¼‰

- **PRM-Sequential** è¿›ä¸€æ­¥æé«˜ fairnessï¼š
  - English è¾¾åˆ°æ¥è¿‘å®Œç¾çš„ 0.99 bias score
  - Urdu bias ä¹Ÿè¾¾ 0.975ï¼Œä¼˜äº PRM-Select
  - ä½† **Urdu utility ä¸‹é™è‡³ 0.8825**ï¼Œè¡¨æ˜å­˜åœ¨â€œè¿‡åº¦çº æ­£â€é£é™©

### ğŸ” æ¶ˆèå®éªŒä¸é˜¶æ®µåˆ†æï¼ˆStage-wise Improvementï¼‰
- å›¾ 6 æ˜¾ç¤ºï¼š
  - ä» Baseline â†’ PRM-Selectï¼šbias å’Œ utility å‡æ˜¾è‘—ä¸Šå‡ï¼ˆå°¤å…¶ Urduï¼‰
  - ä» PRM-Select â†’ PRM-Sequentialï¼šbias ç»§ç»­ä¸Šå‡ï¼Œä½† Urdu utility ä¸‹é™
- æ”¶æ•›é€Ÿåº¦å·®å¼‚ï¼š
  - English å¤šæ•°åœ¨ 1â€“2 æ­¥å†…æ”¶æ•›
  - Urdu éœ€è¦ 2â€“4 æ­¥ï¼Œåæ˜ å…¶åˆå§‹è¾“å‡ºæ›´ä¸ç¨³å®š

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Urdu å­˜åœ¨ä¸¥é‡çš„åŸºçº¿åŠ£åŠ¿**ï¼š
   - åˆå§‹ bias æ›´é«˜ã€utility æ›´ä½ï¼Œåæ˜ å‡ºå¤šè¯­è¨€ LLM ä¸­çš„ç»“æ„æ€§ä¸å¹³ç­‰ï¼ˆstructural inequitiesï¼‰ã€‚
   
2. **PRM-Select æ˜¯æœ€ç¨³å¥çš„æ–¹æ³•**ï¼š
   - åœ¨ä¸¤ç§è¯­è¨€ä¸Šå‡å¤§å¹…æå‡ bias å’Œ utility
   - å‡ ä¹æ¶ˆé™¤è‹±ä¹Œå·®è·ï¼ˆÎ” â‰ˆ 0.017ï¼‰ï¼Œå…·å¤‡è‰¯å¥½è·¨è¯­è¨€å…¬å¹³æ€§

3. **PRM-Sequential æœ€å¤§åŒ–å…¬å¹³æ€§ä½†ç‰ºç‰² Urdu å®ç”¨æ€§**ï¼š
   - è™½ç„¶è¾¾åˆ°æœ€é«˜ bias åˆ†æ•°ï¼Œä½†åœ¨ Urdu ä¸Šå¯¼è‡´ utility ä¸‹é™ï¼Œäº§ç”Ÿè¿‡äºæ³›åŒ–æˆ–æŠ½è±¡çš„è¯æ±‡

4. **æ¨ç†æ—¶å»åæœ‰æ•ˆä¸”å¯è¡Œ**ï¼š
   - å³ä½¿ä¸ä¿®æ”¹æ¨¡å‹å‚æ•°ï¼Œä¹Ÿèƒ½æ˜¾è‘—ç¼“è§£ç¤¾ä¼šåè§ï¼Œæ”¯æŒ black-box åœºæ™¯ä¸‹çš„éƒ¨ç½²

5. **ä½èµ„æºè¯­è¨€æ˜“å—â€œå»åè¿‡çŸ«â€å½±å“**ï¼š
   - refinement è¿‡ç¨‹å¯èƒ½è¿«ä½¿æ¨¡å‹ç”Ÿæˆâ€œå®‰å…¨ä½†æ— æ„ä¹‰â€çš„è¯ï¼Œå°è¯äº† *debiasing oversmoothing* çš„æ‹…å¿§ï¼ˆBarocas & Selbst, 2017ï¼‰

---

### âš ï¸ å±€é™æ€§
1. **PRM é›¶æ ·æœ¬æ‰“åˆ†å¯èƒ½å­˜åœ¨åå·®**ï¼šæœªç»è¿‡ç›‘ç£è®­ç»ƒï¼Œè·¨è¯­å¢ƒä¸€è‡´æ€§æœ‰å¾…éªŒè¯ã€‚
2. **å•å­—ç”Ÿæˆé™åˆ¶åº”ç”¨å¹¿åº¦**ï¼šéš¾ä»¥æ¨å¹¿åˆ°å¤æ‚å¥å­ç”Ÿæˆæˆ–å¯¹è¯ä»»åŠ¡ã€‚
3. **Urdu ç¿»è¯‘æ— æ³•å®Œå…¨æ•æ‰æ–‡åŒ–ç»†å¾®å·®åˆ«**ï¼šæŸäº›åˆ»æ¿å°è±¡å¯èƒ½ä¸¢å¤±æˆ–å¤±çœŸã€‚
4. **ç¼ºä¹äººç±»æ ‡æ³¨éªŒè¯**ï¼šæ‰€æœ‰è¯„åˆ†å‡ç”± GPT-4o-mini è‡ªåŠ¨ç”Ÿæˆï¼Œç¼ºå°‘çœŸå®ç”¨æˆ·æ„ŸçŸ¥æ•°æ®ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **å…¨å¥ç”Ÿæˆä»»åŠ¡** çš„å»åæ¡†æ¶
- å¼•å…¥ **äººç±»åå¥½åé¦ˆ** è¿›è¡Œ PRM å¾®è°ƒ
- æ¢ç´¢æ›´å¤š **ä½èµ„æºè¯­è¨€**ï¼ˆå¦‚ Pashto, Yoruba, Nepaliï¼‰
- ç»“åˆ **prompt engineering** æˆ– **self-debiasing** æŠ€æœ¯å¢å¼ºé²æ£’æ€§
- ç ”ç©¶å¦‚ä½•é˜²æ­¢ refinement å¯¼è‡´çš„è¯­è¨€â€œå»ä¸ªæ€§åŒ–â€æˆ–â€œå»æ–‡åŒ–åŒ–â€

--- 

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡å±•ç¤ºäº†åŸºäº PRM çš„æ¨ç†æ—¶å»åæ–¹æ³•èƒ½æœ‰æ•ˆç¼“è§£ English å’Œ Urdu ä¸­çš„ç¤¾ä¼šåè§ï¼Œå°¤å…¶é€šè¿‡ PRM-Select æ˜¾è‘—ç¼©å°äº†è·¨è¯­è¨€å…¬å¹³å·®è·ï¼Œä¸ºä½èµ„æºè¯­è¨€çš„ AI å…¬å¹³æ€§æä¾›äº†å®ç”¨ä¸”å¯æ‰©å±•çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 5. [Passing the Baton: High Throughput Distributed Disk-Based Vector Search with BatANN](https://arxiv.org/abs/2512.09331)

**Authors**: Nam Anh Dang (Cornell University), Ben Landrum (Cornell University), Ken Birman (Cornell University)  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.09331v1  

#### Abstract
Vector search underpins modern information-retrieval systems, including retrieval-augmented generation (RAG) pipelines and search engines over unstructured text and images. As datasets scale to billions of vectors, disk-based vector search has emerged as a practical solution. However, looking to the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šPassing the Baton: High Throughput Distributed Disk-Based Vector Search with BatANN**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
éšç€å‘é‡æ•°æ®é›†è§„æ¨¡æ‰©å±•åˆ°æ•°åäº¿çº§åˆ«ï¼Œå•æœºå†…å­˜å·²æ— æ³•å®¹çº³å…¨éƒ¨æ•°æ®ï¼Œ**åŸºäºç£ç›˜çš„è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ï¼ˆdisk-based ANNï¼‰** æˆä¸ºå¿…è¦æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå½“æ•°æ®è§„æ¨¡è¿›ä¸€æ­¥æ‰©å¤§è‡³è¶…å‡ºå•å°æœåŠ¡å™¨çš„å­˜å‚¨å’Œå¤„ç†èƒ½åŠ›æ—¶ï¼Œéœ€è¦åˆ†å¸ƒå¼ç³»ç»Ÿæ”¯æŒã€‚

ä¼ ç»Ÿåˆ†å¸ƒå¼æ–¹æ³•å¦‚ **Scatter-Gather** å°†æ•°æ®åˆ†ç‰‡å¹¶ç‹¬ç«‹ç´¢å¼•ï¼ŒæŸ¥è¯¢æ—¶åœ¨æ‰€æœ‰åˆ†ç‰‡ä¸Šå¹¶è¡Œæœç´¢ååˆå¹¶ç»“æœã€‚è¿™ç§æ–¹æ³•è™½ç„¶æ˜“äºå®ç°ï¼Œä½†å¤±å»äº†å…¨å±€å›¾ç»“æ„å¸¦æ¥çš„å¯¹æ•°çº§æŸ¥è¯¢å¤æ‚åº¦ä¼˜åŠ¿ï¼Œå¯¼è‡´è®¡ç®—å’Œ I/O éšèŠ‚ç‚¹æ•°é‡çº¿æ€§å¢é•¿ï¼Œæ•ˆç‡ä½ä¸‹ã€‚

æ­¤å¤–ï¼Œç°æœ‰åˆ†å¸ƒå¼å…¨å±€å›¾æ–¹æ³•ï¼ˆå¦‚ CoTraã€DistributedANNï¼‰ä¾èµ–äº **RDMA æˆ– CXL ç­‰ä¸“ç”¨ç¡¬ä»¶**ï¼Œæˆæœ¬é«˜ä¸”éš¾ä»¥åœ¨é€šç”¨äº‘ç¯å¢ƒä¸­éƒ¨ç½²ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº† **BatANN** â€”â€” ä¸€ç§åŸºäºæ ‡å‡† TCP ç½‘ç»œçš„é«˜æ€§èƒ½ã€ä½å»¶è¿Ÿçš„**åˆ†å¸ƒå¼ç£ç›˜å‘é‡æœç´¢ç³»ç»Ÿ**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

#### âœ… **å¼‚æ­¥çŠ¶æ€ä¼ é€’æœºåˆ¶ï¼ˆState-Passing Query Executionï¼‰**
- åœ¨éå†å…¨å±€æœç´¢å›¾ï¼ˆglobal graphï¼‰è¿‡ç¨‹ä¸­ï¼Œå½“å½“å‰æœåŠ¡å™¨éœ€è®¿é—®å¦ä¸€ä¸ªæœåŠ¡å™¨ä¸Šçš„é‚»å±…èŠ‚ç‚¹æ—¶ï¼Œ**ä¸é‡‡ç”¨ä¼ ç»Ÿçš„â€œè¯·æ±‚-å“åº”â€æ¨¡å¼**ï¼ˆrequest-replyï¼‰ï¼Œè€Œæ˜¯å°†æ•´ä¸ªæŸ¥è¯¢çŠ¶æ€ï¼ˆquery stateï¼‰ç›´æ¥å‘é€ç»™ç›®æ ‡æœåŠ¡å™¨ã€‚
- ç›®æ ‡æœåŠ¡å™¨æ¥æ”¶åç»§ç»­æ‰§è¡Œæœç´¢ä»»åŠ¡ï¼Œå½¢æˆâ€œæ¥åŠ›â€å¼æ‰§è¡Œæµç¨‹ï¼ˆpassing the batonï¼‰ã€‚
- è¿™ç§æ–¹å¼æ˜¾è‘—å‡å°‘äº†è·¨èŠ‚ç‚¹é€šä¿¡ä¸­çš„ç­‰å¾…æ—¶é—´ï¼ˆround-trip latencyï¼‰ï¼Œæå‡äº†å±€éƒ¨æ€§å’Œååé‡ã€‚

#### âœ… **ä¿ç•™å•å›¾ç»“æ„çš„å…¨å±€æœç´¢æ•ˆç‡**
- æ„å»ºä¸€ä¸ªè¦†ç›–å…¨æ•°æ®é›†çš„å•ä¸€å…¨å±€å›¾ï¼ˆsingle global graphï¼‰ï¼Œç„¶åå°†å…¶èŠ‚ç‚¹åˆ†å¸ƒåˆ°å¤šä¸ªæœåŠ¡å™¨ä¸Šã€‚
- åˆ©ç”¨è¯¥ç»“æ„ä¿æŒäº†è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ä¸­å…¸å‹çš„ **logarithmic æŸ¥è¯¢å¤æ‚åº¦**ï¼Œé¿å…äº† Scatter-Gather ä¸­å› å¤šåˆ†ç‰‡ç‹¬ç«‹æœç´¢è€Œå¯¼è‡´çš„è®¡ç®—å†—ä½™ã€‚

#### âœ… **é¢å‘ TCP çš„ä¼˜åŒ–è®¾è®¡**
- æ‰€æœ‰é€šä¿¡åŸºäºæ ‡å‡† TCP åè®®å®Œæˆï¼Œæ— éœ€ RDMA/CXL ç­‰æ˜‚è´µç¡¬ä»¶ï¼Œé€‚ç”¨äºæ›´å¹¿æ³›çš„éƒ¨ç½²åœºæ™¯ã€‚
- é€šè¿‡å‡å°‘é€šä¿¡è½®æ¬¡ã€æ‰¹é‡å‘é€æ¶ˆæ¯ç­‰æ–¹å¼æœ€å¤§åŒ– TCP ååæ½œåŠ›ã€‚

#### âœ… **å…³é”®ç»„ä»¶ååŒä¼˜åŒ–**
- **In-Memory Head Index**ï¼šä½¿ç”¨ 1% æ•°æ®æ„å»ºçš„å°å‹å†…å­˜è·¯ç”±ç´¢å¼•ï¼Œå¿«é€Ÿå®šä½èµ·å§‹èŠ‚ç‚¹ã€‚
- **Neighborhood-Aware Graph Partitioning**ï¼šé‡‡ç”¨ Gottesburen et al. [12] æå‡ºçš„å›¾åˆ’åˆ†ç®—æ³•ï¼Œä½¿ç›¸è¿‘èŠ‚ç‚¹å°½å¯èƒ½ä½äºåŒä¸€æœåŠ¡å™¨ï¼Œé™ä½è·¨èŠ‚ç‚¹è·³è½¬é¢‘ç‡ã€‚
- **Adaptive I/O Pipeline Width (W)**ï¼šå¼•å…¥å¯å‘å¼ç­–ç•¥å¤„ç†åˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„å¹¶å‘è¯»å–ï¼ˆè§ Algorithm 2ï¼‰ï¼Œå¹³è¡¡æœ¬åœ°æ‰§è¡Œä¸è¿œç¨‹è½¬ç§»ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | BatANN | Scatter-Gather | DistributedANN / CoTra |
|------|--------|----------------|-------------------------|
| **æŸ¥è¯¢å¤æ‚åº¦** | æ¥è¿‘ log(N)ï¼Œé«˜æ•ˆ | å¤šä¸ª log(N_i) ä¹‹å’Œ > log(N) | log(N)ï¼Œä¼˜ç§€ |
| **é€šä¿¡å¼€é”€** | å¼‚æ­¥çŠ¶æ€ä¼ é€’ï¼Œä½å»¶è¿Ÿ | è¯·æ±‚-å“åº”é¢‘ç¹ | ä¾èµ– RDMA å‡å°‘å»¶è¿Ÿ |
| **ç¡¬ä»¶è¦æ±‚** | æ ‡å‡† TCPï¼Œé€šç”¨æ€§å¼º | æ— ç‰¹æ®Šè¦æ±‚ | éœ€ RDMA/CXLï¼Œæˆæœ¬é«˜ |
| **ååæ‰©å±•æ€§** | è¿‘çº¿æ€§æ‰©å±• | å—é™äºæ¯åˆ†ç‰‡è´Ÿè½½ | è¾ƒå¥½ï¼Œä½†å°é—­ä¸å¯æ¯” |
| **å¼€æºå¯ç”¨æ€§** | âœ… å¼€æºï¼ˆGitHubï¼‰ | å•†ä¸šäº§å“ä¸ºä¸» | âŒ æœªå…¬å¼€ |

> â­ æ€»ç»“ï¼š**BatANN æ˜¯é¦–ä¸ªåœ¨æ ‡å‡† TCP ä¸Šè¿è¡Œã€æ”¯æŒåˆ†å¸ƒå¼ç£ç›˜ ANN æœç´¢ä¸”åŸºäºå•ä¸€å…¨å±€å›¾çš„å¼€æºç³»ç»Ÿ**ï¼Œå®ç°äº†é«˜ååã€ä½å»¶è¿Ÿä¸è‰¯å¥½å¯æ‰©å±•æ€§çš„ç»Ÿä¸€ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å®éªŒåŸºäº BigANN Benchmarks [26] çš„ä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ï¼š

| æ•°æ®é›† | è§„æ¨¡ | ç»´åº¦ | ç±»å‹ | è·ç¦»åº¦é‡ |
|-------|------|------|------|----------|
| **BIGANN** | 100M / 1B | 128 | uint8 (SIFT) | L2 |
| **MSSPACEV** | 100M / 1B | 100 | int8 (è¯­ä¹‰åµŒå…¥) | L2 |
| **DEEP** | 100M | 96 | float (æ·±åº¦ç‰¹å¾) | L2 |

æ¶µç›–ä¸åŒç²¾åº¦ã€ç»´åº¦å’Œåº”ç”¨åœºæ™¯ï¼Œå…·æœ‰ä»£è¡¨æ€§ã€‚

---

### **å®éªŒè®¾ç½®**
- **ç¡¬ä»¶å¹³å°**ï¼šCloudLab é›†ç¾¤ï¼Œå…± 10 å° `c6620` èŠ‚ç‚¹
  - CPUï¼šIntel Xeon Gold 5512U (28æ ¸ @ 2.1GHz)
  - å†…å­˜ï¼š128GB DDR5
  - ç½‘ç»œï¼š25Gb Ethernet
  - å­˜å‚¨ï¼šNVMe SSD
- **è½¯ä»¶å®ç°**ï¼š
  - C++ å®ç°ï¼ŒåŸºäº PipeANN æ¡†æ¶
  - ä½¿ç”¨ `io_uring` å®ç°å¼‚æ­¥ I/O
  - ZeroMQ å®ç°è·¨èŠ‚ç‚¹é€šä¿¡ï¼ˆPEER socketsï¼‰
- **å‚æ•°é…ç½®**ï¼š
  - å›¾ç»“æ„ï¼šVamana graphï¼ˆR=64, L=128, Î±=1.2ï¼‰
  - åˆ†åŒºæ•°ï¼š5 æˆ– 10 ä¸ªæœåŠ¡å™¨
  - Beam widthï¼šé»˜è®¤ W=8ï¼Œéƒ¨åˆ†æ¶ˆèå®éªŒæµ‹è¯• W=1
  - PQ å‹ç¼©ï¼šæ¯ä¸ªå‘é‡å‹ç¼©ä¸º 32 å­—èŠ‚ç”¨äºè¿‘ä¼¼è·ç¦»è®¡ç®—

---

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **QPS (Queries Per Second)** | ç³»ç»Ÿæ¯ç§’èƒ½å¤„ç†çš„æŸ¥è¯¢æ•°é‡ï¼Œè¡¡é‡ååèƒ½åŠ› |
| **Recall@10** | è¿”å›çš„å‰10ä¸ªç»“æœä¸­åŒ…å«çœŸå®æœ€è¿‘é‚»çš„æ¯”ä¾‹ï¼Œè¡¡é‡å‡†ç¡®æ€§ |
| **End-to-End Latency** | å®¢æˆ·ç«¯å‘å‡ºæŸ¥è¯¢åˆ°æ”¶åˆ°ç»“æœçš„æ—¶é—´ï¼ˆå«ç½‘ç»œä¼ è¾“ï¼‰ |
| **Distance Comparisons** | å…¨ç²¾åº¦è·ç¦»è®¡ç®—æ¬¡æ•°ï¼Œåæ˜ è®¡ç®—å¼€é”€ |
| **Disk I/O Operations** | å‘èµ·çš„ç£ç›˜è¯»å–æ“ä½œæ•°ï¼Œåæ˜  I/O å¼€é”€ |
| **Inter-Partition Hops** | è·¨æœåŠ¡å™¨çš„çŠ¶æ€è½¬ç§»æ¬¡æ•°ï¼Œå½±å“é€šä¿¡å¼€é”€ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **ScatterGather**ï¼ˆæœ¬æ–‡å®ç°ï¼‰ï¼š
  - å°†æ•°æ®æŒ‰ç›¸åŒå›¾åˆ’åˆ†æ–¹æ³•åˆ‡åˆ†ä¸ºç‹¬ç«‹åˆ†ç‰‡
  - æ¯ä¸ªåˆ†ç‰‡ç‹¬ç«‹å»ºç«‹ Vamana å›¾
  - æŸ¥è¯¢æ—¶å¹¿æ’­åˆ°æ‰€æœ‰åˆ†ç‰‡ï¼Œæ”¶é›†ç»“æœååˆå¹¶é‡æ’åº
- **DistributedANN** å’Œ **CoTra**ï¼š
  - è™½ç„¶ç›¸å…³ï¼Œä½†ç”±äºæœªå¼€æºï¼Œæ— æ³•ç›´æ¥æ¯”è¾ƒ
  - ä½œè€…å°è¯•å¤ç° DistributedANNï¼Œä½†æ€§èƒ½ä¸å¦‚ ScatterGather å’Œ BatANN

> å› æ­¤ï¼Œä¸»è¦å¯¹æ¯”å¯¹è±¡æ˜¯ **ScatterGather**ï¼Œä½œä¸ºä¸»æµåˆ†å¸ƒå¼èŒƒå¼çš„ä»£è¡¨ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

| åœºæ™¯ | Recall@10 | BatANN QPS | ScatterGather QPS | åŠ é€Ÿæ¯” |
|------|-----------|------------|--------------------|--------|
| **BIGANN 100M, 10 servers** | 0.95 | ~18,000 | ~2,800 | **6.43Ã—** |
| **DEEP 100M, 10 servers** | 0.95 | ~19,000 | ~2,900 | **6.55Ã—** |
| **BIGANN 1B, 10 servers** | 0.95 | ~30,000 | ~5,900 | **5.10Ã—** |
| **MSSPACEV 1B, 10 servers** | 0.95 | ~6,000 | ~2,400 | **2.5Ã—** |

> æ³¨ï¼šå…·ä½“æ•°å€¼æ¥è‡ª Figures 8 å’Œ 9ï¼›MSSPACEV è¡¨ç°ç•¥å·®å¯èƒ½ä¸ ParlayANN æ„å›¾è´¨é‡æœ‰å…³ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### âœ… **ååé‡æ˜¾è‘—æå‡**
- åœ¨ 100M è§„æ¨¡ä¸‹ï¼ŒBatANN ç›¸æ¯” ScatterGather å®ç° **6.21â€“6.49Ã— çš„ QPS æå‡**ï¼ˆ@0.95 recallï¼‰
- åœ¨ 1B è§„æ¨¡ä¸‹ä»è¾¾åˆ° **2.5â€“5.10Ã— çš„åŠ é€Ÿæ¯”**
- éšç€æœåŠ¡å™¨æ•°é‡å¢åŠ ï¼ŒBatANN çš„ååå¢ç›ŠæŒç»­æ‰©å¤§ï¼Œä½“ç°å…¶è‰¯å¥½çš„**å¼±æ‰©å±•æ€§ï¼ˆweak scalingï¼‰**

#### âœ… **ç»´æŒä½å»¶è¿Ÿ**
- åœ¨ 1K QPS å‘é€é€Ÿç‡ä¸‹ï¼ŒBatANN çš„å¹³å‡ç«¯åˆ°ç«¯å»¶è¿Ÿä½äº **6ms**
- å³ä½¿åœ¨æ¥è¿‘æœ€å¤§ååç‡ï¼ˆ~30K QPSï¼‰æ—¶ï¼Œå»¶è¿Ÿä¹Ÿç¨³å®šåœ¨ **~6ms**
- ç›¸æ¯”ä¹‹ä¸‹ï¼ŒScatterGather åœ¨è¶…è¿‡ 6K QPS åå°¾å»¶è¿Ÿæ€¥å‰§ä¸Šå‡ï¼Œç³»ç»Ÿè¶‹äºé¥±å’Œ

#### âœ… **è®¡ç®—ä¸ I/O æ•ˆç‡æ›´é«˜**
- BatANN çš„ **distance comparisons** å’Œ **disk I/O** æ•°é‡å‡ ä¹ä¸éšæœåŠ¡å™¨æ•°é‡å˜åŒ–
- è€Œ ScatterGather çš„è¿™ä¸¤é¡¹å¼€é”€éšèŠ‚ç‚¹æ•°çº¿æ€§å¢é•¿ï¼ˆFigure 10ï¼‰
- è¡¨æ˜ BatANN æ›´æœ‰æ•ˆåœ°åˆ©ç”¨äº†å…¨å±€å›¾çš„æœç´¢è·¯å¾„ç‰¹æ€§

#### âœ… **è·¨åˆ†åŒºè·³æ•°å°‘**
- ä½¿ç”¨ neighborhood-aware partitioning åï¼Œinter-partition hops ä»…å æ€»è·³æ•°çš„ **11.6%~24.3%**
- ç‰¹åˆ«æ˜¯åœ¨å°è§„æ¨¡é›†ç¾¤ï¼ˆå¦‚ 3 èŠ‚ç‚¹ï¼‰ä¸­å æ¯”æ›´ä½ï¼ŒéªŒè¯äº†å›¾åˆ’åˆ†çš„æœ‰æ•ˆæ€§ï¼ˆFigure 3ï¼‰

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ” **I/O Pipeline Width (W) å½±å“ï¼ˆW=1 vs W=8ï¼‰**
- **W=8 æ˜¾è‘—ä¼˜äº W=1**ï¼š
  - åœ¨ BIGANN 1B ä¸Šï¼ŒW=8 çš„æ€»è·³æ•°ä» 138 é™è‡³ 32.6ï¼ˆâ†“76%ï¼‰
  - Inter-partition hops ä» 21.9% é™è‡³ 18.8%
  - QPS æå‡æ˜æ˜¾ï¼Œå»¶è¿Ÿä¸‹é™ä¸€åŠä»¥ä¸Šï¼ˆFigure 14ï¼‰
- å…³é”®åŸå› ï¼šæ›´å¤§çš„ W å‡å°‘äº† beam search çš„è¿­ä»£æ¬¡æ•°ï¼Œä»è€Œé™ä½äº†è·¨èŠ‚ç‚¹é€šä¿¡é¢‘ç‡

#### ğŸ” **å›ºå®šå¤§å°æŸ¥è¯¢è°ƒåº¦ vs æ‰¹å¤„ç†è°ƒåº¦**
- BatANN é‡‡ç”¨ **å›ºå®šå¹¶å‘æŸ¥è¯¢æ•°ï¼ˆ8ä¸ª/çº¿ç¨‹ï¼‰**ï¼Œè€Œé PipeANN çš„æ‰¹å¤„ç†æ¨¡å¼
- å®éªŒè¡¨æ˜è¯¥ç­–ç•¥èƒ½æ›´å¥½æ©ç›– I/O å»¶è¿Ÿï¼Œæé«˜èµ„æºåˆ©ç”¨ç‡

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å…¨å±€å›¾ + çŠ¶æ€ä¼ é€’ = é«˜æ•ˆåˆ†å¸ƒå¼æœç´¢**
   - ä¿æŒå•ä¸€å…¨å±€å›¾ç»“æ„å¯åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹å»¶ç»­ log(N) æŸ¥è¯¢æ•ˆç‡ã€‚
   - â€œPassing the batonâ€ çš„çŠ¶æ€ä¼ é€’æœºåˆ¶æœ‰æ•ˆè§„é¿äº†ä¼ ç»Ÿ request-reply æ¨¡å¼ä¸­çš„é€šä¿¡ç“¶é¢ˆã€‚

2. **TCP ä¸Šä¹Ÿèƒ½å®ç°é«˜æ€§èƒ½åˆ†å¸ƒå¼ ANN**
   - ä¸ä¾èµ– RDMA/CXLï¼Œä»…ç”¨æ ‡å‡† TCP å³å¯å®ç°è¶…é«˜ååï¼ˆ>30K QPSï¼‰å’Œä½å»¶è¿Ÿï¼ˆ<6msï¼‰ã€‚

3. **ååè¿‘çº¿æ€§æ‰©å±•ï¼ŒI/O ä¸è®¡ç®—æ’å®š**
   - BatANN çš„ QPS éšæœåŠ¡å™¨æ•°é‡è¿‘ä¹çº¿æ€§å¢é•¿ï¼ˆFigure 11ï¼‰
   - distance comparisons å’Œ disk I/O åŸºæœ¬ä¸å˜ï¼Œè¯´æ˜å…¶å…·å¤‡ä¼˜ç§€çš„å¼±æ‰©å±•æ€§ã€‚

4. **å›¾åˆ’åˆ†ä¸ I/O å®½åº¦è‡³å…³é‡è¦**
   - neighborhood-aware graph partitioning æ˜¾è‘—å‡å°‘è·¨èŠ‚ç‚¹è·³è½¬
   - W=8 çš„ I/O pipeline è®¾è®¡å¤§å¹…é™ä½ hop æ•°ï¼Œæ˜¯æ€§èƒ½é£è·ƒçš„å…³é”®

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **çŠ¶æ€ä¼ è¾“å¼€é”€ä¸å¯å¿½ç•¥**
   - æ¯æ¬¡è·¨èŠ‚ç‚¹è½¬ç§»éœ€åºåˆ—åŒ–å¹¶ä¼ è¾“çº¦ 4â€“8KB çš„æŸ¥è¯¢çŠ¶æ€ï¼ˆbeam + result listï¼‰
   - å¯¹äºæé«˜ recallï¼ˆå¦‚ >0.98ï¼‰æˆ–å¤§ beam sizeï¼ˆL > 400ï¼‰ï¼ŒçŠ¶æ€ä½“ç§¯æ›´å¤§ï¼Œå¯èƒ½æˆä¸ºç“¶é¢ˆ

2. **ç¼ºä¹åŠ¨æ€æ›´æ–°æ”¯æŒ**
   - å½“å‰ç³»ç»Ÿä¸æ”¯æŒåœ¨çº¿æ’å…¥/åˆ é™¤å‘é‡
   - å›¾ç»“æ„ä¸€æ—¦æ„å»ºå³é™æ€ï¼Œä¸é€‚åˆæµå¼æ•°æ®åœºæ™¯

3. **æœªè€ƒè™‘å®¹é”™æœºåˆ¶**
   - èŠ‚ç‚¹æ•…éšœä¼šå¯¼è‡´æ­£åœ¨è¿›è¡Œçš„æŸ¥è¯¢å¤±è´¥
   - ç¼ºä¹å‰¯æœ¬æˆ–æ¢å¤æœºåˆ¶

4. **MSSPACEV è¡¨ç°å—é™**
   - åœ¨æŸäº›æ•°æ®é›†ï¼ˆå¦‚ MSSPACEVï¼‰ä¸Šæ€§èƒ½æå‡è¾ƒå°ï¼Œæç¤ºå›¾ç»“æ„è´¨é‡å’Œæ•°æ®åˆ†å¸ƒæ•æ„Ÿæ€§ä»éœ€ç ”ç©¶

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å‡å°çŠ¶æ€ä¼ è¾“ä½“ç§¯**
   - åªä¼  beam çŠ¶æ€ï¼Œå°†ä¸­é—´ç»“æœç›´æ¥å‘å¾€å®¢æˆ·ç«¯èšåˆï¼ˆç±»ä¼¼ Scatter-Gather çš„ gather é˜¶æ®µï¼‰

2. **é›†æˆæ›´ä¼˜ç£ç›˜å¸ƒå±€ä¼˜åŒ–**
   - å¦‚ Starling çš„é‚»åŸŸå…±ç½®ï¼ˆneighbor co-locationï¼‰æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥æå‡ I/O å±€éƒ¨æ€§

3. **æ”¯æŒåŠ¨æ€å›¾æ›´æ–°**
   - ç»“åˆ FreshDiskANNã€SPFresh ç­‰å¢é‡æ›´æ–°æŠ€æœ¯ï¼Œå®ç° streaming ANN æ”¯æŒ

4. **æ„å»ºå®¹é”™æ¶æ„**
   - åŸºäº Derecho æ¡†æ¶å®ç°å¤åˆ¶ä¸æ•…éšœæ¢å¤ï¼Œæå‡ç”Ÿäº§å¯ç”¨æ€§

5. **æ¢ç´¢ RDMA/CXL åŠ é€Ÿæ½œåŠ›**
   - è™½ç„¶å½“å‰è®¾è®¡å·²åœ¨ TCP ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†ä»å¯é€šè¿‡åˆ‡æ¢åº•å±‚é€šä¿¡åè®®æµ‹è¯•æ€§èƒ½ä¸Šé™

6. **å¤šç§Ÿæˆ·ä¸èµ„æºå…±äº«**
   - æ”¯æŒå¤šä¸ªå‘é‡æ•°æ®åº“å…±äº«ç‰©ç†èµ„æºï¼Œåº”å¯¹ä¼ä¸šçº§ RAG åº”ç”¨éœ€æ±‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **BatANN é€šè¿‡â€œçŠ¶æ€æ¥åŠ›â€çš„åˆ›æ–°èŒƒå¼ï¼Œåœ¨æ ‡å‡† TCP ç½‘ç»œä¸Šå®ç°äº†é«˜æ€§èƒ½ã€å¯æ‰©å±•çš„åˆ†å¸ƒå¼ç£ç›˜å‘é‡æœç´¢ï¼Œé¦–æ¬¡å¼€æºæ”¯æŒå…¨å±€å›¾ç»“æ„çš„ disk-based ANN åˆ†å¸ƒå¼ç³»ç»Ÿï¼Œä¸ºå¤§è§„æ¨¡ RAG å’Œæ£€ç´¢ç³»ç»Ÿæä¾›äº†å®ç”¨é«˜æ•ˆçš„åŸºç¡€è®¾æ–½é€‰æ‹©ã€‚**

</details>

---

### 6. [Scalable Construction of Spiking Neural Networks using up to thousands of GPUs](https://arxiv.org/abs/2512.09502)

**Authors**: Bruno Golosio, Gianmarco Tiddia, Jos\'e Villamar, Luca Pontisso, Luca Sergi, Francesco Simula, Pooja Babu, Elena Pastorelli, Abigail Morrison, Markus Diesmann, Alessandro Lonardo, Pier Stanislao Paolucci, Johanna Senk  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.09502v1  

#### Abstract
Diverse scientific and engineering research areas deal with discrete, time-stamped changes in large systems of interacting delay differential equations. Simulating such complex systems at scale on high-performance computing clusters demands efficient management of communication and memory. Inspired ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šScalable Construction of Spiking Neural Networks using up to thousands of GPUs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹å¤§è§„æ¨¡è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSpiking Neural Networks, SNNsï¼‰åœ¨è¶…å¤§è§„æ¨¡ GPU é›†ç¾¤ä¸Šçš„**é«˜æ•ˆæ„å»ºä¸é€šä¿¡ç“¶é¢ˆ**é—®é¢˜ã€‚å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š

- **å†…å­˜ç®¡ç†**ï¼šå¤§è§„æ¨¡ SNN åŒ…å«æ•°åäº¿ç¥ç»å…ƒå’Œæ•°ä¸‡äº¿çªè§¦ï¼Œä¼ ç»Ÿæ–¹æ³•åœ¨ CPU å’Œ GPU ä¹‹é—´é¢‘ç¹ä¼ è¾“è¿æ¥æ•°æ®ï¼Œå¯¼è‡´é«˜å†…å­˜å¼€é”€å’Œå»¶è¿Ÿã€‚
- **é€šä¿¡æ•ˆç‡**ï¼šåˆ†å¸ƒå¼æ¨¡æ‹Ÿä¸­è·¨ MPI è¿›ç¨‹çš„ spike é€šä¿¡æ˜¯ä¸»è¦æ€§èƒ½ç“¶é¢ˆï¼Œå°¤å…¶åœ¨æ•°åƒ GPU ä¸Šæ‰©å±•æ—¶ã€‚
- **æ„å»ºæ—¶é—´è¿‡é•¿**ï¼šä¼ ç»Ÿçš„â€œç¦»æ¿â€ï¼ˆoffboardï¼‰æ„å»ºæ–¹å¼ï¼ˆå…ˆåœ¨ CPU æ„å»ºå†ä¼ å…¥ GPUï¼‰ä¸¥é‡é™åˆ¶äº†æ¨¡æ‹Ÿçš„æ•´ä½“æ•ˆç‡ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æå‡ºäº†ä¸€ç§**å…¨ GPU å†…å­˜åŸä½ç½‘ç»œæ„å»ºæ–¹æ³•**ï¼ˆonboard network constructionï¼‰ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **æ—  MPI é€šä¿¡çš„å¹¶è¡Œæ„å»º**ï¼šæ¯ä¸ª MPI è¿›ç¨‹ç‹¬ç«‹åœ°åœ¨æœ¬åœ° GPU å†…å­˜ä¸­æ„å»ºå…¶è´Ÿè´£çš„å±€éƒ¨è¿æ¥ï¼Œå¹¶ä¸ºè¿œç¨‹è¿æ¥åˆ›å»ºé€šä¿¡æ˜ å°„ç»“æ„ï¼Œæ•´ä¸ªæ„å»ºè¿‡ç¨‹æ— éœ€è¿›ç¨‹é—´é€šä¿¡ã€‚
- **é«˜æ•ˆçš„é€šä¿¡æ˜ å°„ç»“æ„**ï¼š
  - å¼•å…¥ **proxy neuronï¼ˆä»£ç†ç¥ç»å…ƒï¼‰** æ¦‚å¿µï¼Œåœ¨ç›®æ ‡è¿›ç¨‹ä¸­è¡¨ç¤ºæºç¥ç»å…ƒçš„è™šæ‹Ÿæ˜ åƒã€‚
  - æ„å»º `(R, L)` æ˜ å°„è¡¨ï¼ˆ`R`: æºç¥ç»å…ƒå…¨å±€ç´¢å¼•, `L`: ä»£ç†ç¥ç»å…ƒæœ¬åœ°ç´¢å¼•ï¼‰ï¼Œæ”¯æŒé«˜æ•ˆçš„ spike è·¯ç”±ã€‚
- **åŒæ¨¡å¼ MPI é€šä¿¡æ”¯æŒ**ï¼š
  - æ”¯æŒ **point-to-point** å’Œ **collective** ä¸¤ç§ MPI é€šä¿¡åè®®ï¼Œç”¨æˆ·å¯æ ¹æ®ç½‘ç»œæ‹“æ‰‘é€‰æ‹©æœ€ä¼˜æ¨¡å¼ã€‚
- **å››çº§ä¼˜åŒ–ç­–ç•¥ï¼ˆOptimization Levels 0â€“3ï¼‰**ï¼š
  - åœ¨ GPU å†…å­˜å ç”¨ä¸è¿è¡Œé€Ÿåº¦ä¹‹é—´æä¾›çµæ´»æƒè¡¡ï¼Œé€šè¿‡å°†éƒ¨åˆ†é€šä¿¡ç»“æ„å­˜å‚¨äº CPU å†…å­˜æ¥èŠ‚çœ GPU æ˜¾å­˜ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| å¯¹æ¯”ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ NEST CPU/GPUï¼‰ |
|---------|--------|--------------------------|
| **æ„å»ºä½ç½®** | å®Œå…¨åœ¨ GPU å†…å­˜ä¸­ï¼ˆonboardï¼‰ | å¤šåœ¨ CPU ä¸­å®Œæˆåå†è¿ç§»ï¼ˆoffboardï¼‰ |
| **æ„å»ºé€šä¿¡** | æ—  MPI é€šä¿¡ | éœ€è¦å¤§é‡ MPI é€šä¿¡åŒæ­¥ç»“æ„ |
| **é€šä¿¡çµæ´»æ€§** | æ”¯æŒ point-to-point å’Œ collective å¯åˆ‡æ¢ | é€šå¸¸å›ºå®šä¸€ç§é€šä¿¡æ¨¡å¼ |
| **æ‰©å±•æ€§** | æ”¯æŒæ•°åƒ GPU è§„æ¨¡ | å¤šæ•°é™äºæ•°ç™¾ GPU æˆ–å•æœºå¤šå¡ |
| **æ„å»ºé€Ÿåº¦** | æ˜¾è‘—åŠ é€Ÿï¼ˆ>10Ã—ï¼‰ | è¾ƒæ…¢ï¼Œå—é™äº CPU-GPU æ•°æ®ä¼ è¾“ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**

è®ºæ–‡é‡‡ç”¨ä¸¤ä¸ªå…¸å‹çš„å¤§è§„æ¨¡ SNN æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼š

1. **Multi-Area Model (MAM)**  
   - åŸºäºçŒ•çŒ´è§†è§‰çš®å±‚çš„ 32 ä¸ªè„‘åŒºæ¨¡å‹ã€‚
   - æ€»è®¡çº¦ **4.13Ã—10â¶ ç¥ç»å…ƒ**ï¼Œ**2.42Ã—10Â¹â° çªè§¦**ã€‚
   - å…·æœ‰å¤æ‚å±‚çº§ç»“æ„å’Œç”Ÿç‰©åˆç†çš„ spike ç»Ÿè®¡ç‰¹æ€§ã€‚
   - ä½¿ç”¨ **point-to-point MPI é€šä¿¡**ã€‚

2. **Scalable Balanced Network**  
   - éšæœºå¹³è¡¡ç½‘ç»œï¼ˆå…´å¥‹æ€§/æŠ‘åˆ¶æ€§ç¥ç»å…ƒï¼‰ï¼Œç”¨äºå¼±æ‰©å±•æ€§æµ‹è¯•ã€‚
   - ç½‘ç»œè§„æ¨¡éš MPI è¿›ç¨‹æ•°é‡çº¿æ€§å¢é•¿ã€‚
   - æ¯ GPU å›ºå®šè¿æ¥æ•°ï¼ˆKin = 11,250ï¼‰ï¼Œæ”¯æŒä»»æ„è§„æ¨¡æ‰©å±•ã€‚
   - ä½¿ç”¨ **collective MPI é€šä¿¡**ï¼ˆMPI_Allgatherï¼‰ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **ç¡¬ä»¶å¹³å°**
- **JUSUF é›†ç¾¤**ï¼šNVIDIA V100 GPUï¼ˆ16GBï¼‰ï¼Œç”¨äº MAM å®éªŒã€‚
- **Leonardo Booster è¶…ç®—**ï¼šNVIDIA A100 GPUï¼ˆ64GBï¼‰ï¼Œç”¨äºå¯æ‰©å±•æ€§å®éªŒã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
- **ç½‘ç»œæ„å»ºæ—¶é—´ï¼ˆNetwork Construction Timeï¼‰**ï¼šåˆ†ä¸ºåˆå§‹åŒ–ã€ç¥ç»å…ƒ/è®¾å¤‡åˆ›å»ºã€å±€éƒ¨/è¿œç¨‹è¿æ¥ç”Ÿæˆã€æ¨¡æ‹Ÿå‡†å¤‡ç­‰å­é˜¶æ®µã€‚
- **çŠ¶æ€ä¼ æ’­æ—¶é—´ï¼ˆState Propagation Timeï¼‰**ï¼šä»¥ **Real-Time Factor (RTF)** è¡¡é‡ï¼Œå³å¢™é’Ÿæ—¶é—´ / æ¨¡æ‹Ÿç”Ÿç‰©æ—¶é—´ã€‚
- **å³°å€¼ GPU å†…å­˜ä½¿ç”¨é‡ï¼ˆPeak GPU Memory Usageï¼‰**ï¼šå†³å®šå¯æ‰©å±•ä¸Šé™çš„å…³é”®å› ç´ ã€‚
- **å¼±æ‰©å±•æ€§ï¼ˆWeak Scalingï¼‰**ï¼šä¿æŒæ¯èŠ‚ç‚¹è´Ÿè½½æ’å®šï¼Œå¢åŠ èŠ‚ç‚¹æ•°ï¼Œè§‚å¯Ÿæ€§èƒ½å˜åŒ–ã€‚

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Offboard vs Onboard**ï¼šå¯¹æ¯”ä¼ ç»Ÿ CPU æ„å»ºï¼ˆoffboardï¼‰ä¸æœ¬æ–‡æå‡ºçš„ GPU åŸä½æ„å»ºï¼ˆonboardï¼‰ã€‚
- **ä¸åŒ Optimization Levels**ï¼šæ¯”è¾ƒ Opt 0 åˆ° Opt 3 åœ¨å†…å­˜ä¸æ€§èƒ½é—´çš„æƒè¡¡ã€‚
- **ä¸ NEST GPU å‰æœŸç‰ˆæœ¬å¯¹æ¯”**ï¼šéªŒè¯æ€§èƒ½æå‡æ¥æºã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **MAM æ¨¡å‹ï¼ˆPoint-to-Point é€šä¿¡ï¼‰**
| æŒ‡æ ‡ | Offboardï¼ˆCPU æ„å»ºï¼‰ | Onboardï¼ˆGPU æ„å»ºï¼‰ | åŠ é€Ÿæ¯” |
|------|---------------------|--------------------|-------|
| **æ€»æ„å»ºæ—¶é—´** | 686.0 Â± 1.5 s | **55.5 Â± 0.1 s** | **~12.4Ã—** |
| å±€éƒ¨è¿æ¥ç”Ÿæˆ | â€” | â€” | **20Ã— åŠ é€Ÿ** |
| è¿œç¨‹è¿æ¥ç”Ÿæˆ | â€” | â€” | **9Ã— åŠ é€Ÿ** |
| ç¥ç»å…ƒ/è®¾å¤‡åˆ›å»º | â€” | â€” | **350Ã— åŠ é€Ÿ** |
| æ¨¡æ‹Ÿå‡†å¤‡ | â€” | â€” | **50Ã— åŠ é€Ÿ** |
| **çŠ¶æ€ä¼ æ’­ RTF** | 16.0 Â± 3.0 | 15.0 Â± 1.7 | åŸºæœ¬æŒå¹³ |

> âœ… ç»“è®ºï¼š**æ„å»ºé˜¶æ®µè·å¾—è¶…è¿‡ 10 å€åŠ é€Ÿï¼Œè€ŒçŠ¶æ€ä¼ æ’­æ€§èƒ½æœªå—å½±å“**ã€‚

#### **å¯æ‰©å±•å¹³è¡¡ç½‘ç»œï¼ˆCollective é€šä¿¡ï¼‰**
- åœ¨ **256 èŠ‚ç‚¹ï¼ˆ1024 A100 GPUsï¼‰** ä¸Šå®ç°å¼±æ‰©å±•ï¼š
  - æ€»è§„æ¨¡è¾¾ **2.3Ã—10â¸ ç¥ç»å…ƒ**ï¼Œ**2.59Ã—10Â¹Â² çªè§¦**ã€‚
  - å®ç°è‰¯å¥½çš„å¼±æ‰©å±•æ€§ï¼ŒRTF å¢é•¿ç¼“æ…¢ã€‚
- **Optimization Level 3** è¡¨ç°æœ€ä½³ï¼š
  - ç›¸æ¯” Opt 0ï¼Œ**state propagation æ—¶é—´å‡å°‘ ~30%**ã€‚
  - è‹¥å…³é—­ spike recordingï¼Œ**é¢å¤–é™ä½ 20% çŠ¶æ€ä¼ æ’­æ—¶é—´**ã€‚
- **GPU å†…å­˜åˆ†æ**ï¼š
  - **Opt 0** å¯æ‰©å±•è‡³ **4096 èŠ‚ç‚¹**ï¼ˆç†è®ºæé™ï¼‰ï¼Œå› é€šä¿¡ç»“æ„éƒ¨åˆ†å­˜äº CPUã€‚
  - æ›´é«˜çº§åˆ«ä¼˜åŒ–ï¼ˆOpt 3ï¼‰è™½å¿«ä½†æ˜¾å­˜å ç”¨é«˜ï¼Œé™åˆ¶æœ€å¤§è§„æ¨¡ã€‚

#### **æ¶ˆèå®éªŒç»“æœ**
- **Optimization Levels å¯¹æ¯”**ï¼š
  - éšç€ä¼˜åŒ–ç­‰çº§æé«˜ï¼Œ**æ„å»ºæ—¶é—´å’ŒçŠ¶æ€ä¼ æ’­æ—¶é—´ä¸‹é™**ï¼Œä½† **GPU æ˜¾å­˜ä¸Šå‡**ã€‚
  - Opt 2 å’Œ Opt 3 åœ¨æ„å»ºæ—¶é—´ä¸Šæ¥è¿‘ï¼Œä½† Opt 3 åœ¨çŠ¶æ€ä¼ æ’­æ›´å¿«ã€‚
- **Area Packing å®éªŒï¼ˆé™„å½• Bï¼‰**ï¼š
  - åˆ©ç”¨ A100 å¤§æ˜¾å­˜ï¼Œå¯åœ¨å• GPU ä¸Šæ‰“åŒ…å¤šä¸ª MAM åŒºåŸŸã€‚
  - æœ€å°‘å¯ç”¨ **8 GPUs** å®Œæˆ MAM æ¨¡æ‹Ÿï¼ˆåŸéœ€ 32ï¼‰ï¼Œæå‡èµ„æºåˆ©ç”¨ç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **GPU åŸä½ç½‘ç»œæ„å»ºæ˜¾è‘—åŠ é€Ÿæ¨¡æ‹Ÿæµç¨‹**ï¼šç›¸æ¯”ä¼ ç»Ÿ offboard æ–¹æ³•ï¼Œæ„å»ºæ—¶é—´ç¼©çŸ­ **10 å€ä»¥ä¸Š**ï¼Œå°¤å…¶å¯¹è¿æ¥ç”Ÿæˆå’Œæ¨¡æ‹Ÿå‡†å¤‡é˜¶æ®µæ•ˆæœæ˜¾è‘—ã€‚
2. âœ… **é€šä¿¡æ˜ å°„ç»“æ„å¯é«˜æ•ˆæ”¯æŒå¤šç§ MPI æ¨¡å¼**ï¼šç»Ÿä¸€çš„ `(R, L)` æ˜ å°„æœºåˆ¶åŒæ—¶å…¼å®¹ point-to-point å’Œ collective é€šä¿¡ï¼Œé€‚åº”ä¸åŒç½‘ç»œæ‹“æ‰‘éœ€æ±‚ã€‚
3. âœ… **å››çº§ä¼˜åŒ–ç­–ç•¥å®ç°å†…å­˜-æ€§èƒ½çµæ´»æƒè¡¡**ï¼šç”¨æˆ·å¯æ ¹æ®ç¡¬ä»¶æ¡ä»¶é€‰æ‹©åˆé€‚ä¼˜åŒ–çº§åˆ«ï¼Œåœ¨æœ‰é™æ˜¾å­˜ä¸‹ä»èƒ½è¿è¡Œè¶…å¤§è§„æ¨¡æ¨¡æ‹Ÿã€‚
4. âœ… **æ–¹æ³•å…·å¤‡è‰¯å¥½å¼±æ‰©å±•æ€§**ï¼šåœ¨ä¸Šåƒ GPU ä¸ŠéªŒè¯äº†å¯æ‰©å±•æ€§ï¼Œé¢„ç¤ºå…¶é€‚ç”¨äºä¸‹ä¸€ä»£ exascale è¶…ç®—ï¼ˆå¦‚ JUPITERï¼‰ã€‚
5. âœ… **ç”Ÿç‰©å­¦æœ‰æ•ˆæ€§å¾—åˆ°éªŒè¯**ï¼šé€šè¿‡ Earth Moverâ€™s Distanceï¼ˆEMDï¼‰åˆ†æ spike ç»Ÿè®¡åˆ†å¸ƒï¼ˆfiring rate, CV ISI, correlationï¼‰ï¼Œè¯æ˜æ–°æ–¹æ³•ä¸å¼•å…¥é¢å¤–å˜å¼‚æ€§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–ç”¨æˆ·æ‰‹åŠ¨è´Ÿè½½å‡è¡¡**ï¼šå½“å‰æœªè‡ªåŠ¨ä¼˜åŒ–ç¥ç»å…ƒåˆ° GPU çš„æ˜ å°„ï¼Œéœ€ç”¨æˆ·æ ¹æ®ç½‘ç»œç»“æ„è®¾è®¡åˆ†é…ç­–ç•¥ã€‚
- **å°šæœªå¯ç”¨ GPUDirect RDMA**ï¼šè‹¥å¯ç”¨ï¼Œå¯èƒ½è¿›ä¸€æ­¥é™ä½è·¨èŠ‚ç‚¹é€šä¿¡å»¶è¿Ÿã€‚
- **ä»…æ”¯æŒ point-neuron æ¨¡å‹**ï¼šæœªæ¶‰åŠå¤šå®¤ï¼ˆmulti-compartmentï¼‰ç¥ç»å…ƒæ¨¡å‹çš„å¤æ‚åŠ¨åŠ›å­¦ã€‚
- **éšæœºæ•°åŒæ­¥æœºåˆ¶å¢åŠ å®ç°å¤æ‚åº¦**ï¼šéœ€ä¿è¯æº/ç›®æ ‡è¿›ç¨‹ç”Ÿæˆç›¸åŒè¿æ¥åºåˆ—ï¼Œä¾èµ–å¯¹é½çš„ RNG ç§å­ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- å¼€å‘**è‡ªåŠ¨åŒ–ç¡¬ä»¶æ„ŸçŸ¥æ˜ å°„ç­–ç•¥**ï¼Œç»“åˆé›†ç¾¤æ‹“æ‰‘ä¼˜åŒ–ç¥ç»å…ƒåˆ†å¸ƒã€‚
- æ¢ç´¢**æ··åˆé€šä¿¡æ–¹æ¡ˆ**ï¼šä¾‹å¦‚å±€éƒ¨ spike ç”¨ point-to-pointï¼Œè¿œè·ç¦»å¹¿æ’­ç”¨ collectiveã€‚
- æ‰©å±•è‡³ **multi-compartment neuron models** å¹¶é›†æˆ CoreNEURON ç±»åŠ é€ŸæŠ€æœ¯ã€‚
- åœ¨çœŸå® exascale ç³»ç»Ÿï¼ˆå¦‚ JUPITERï¼‰ä¸Šéƒ¨ç½²ï¼ŒéªŒè¯ **human-scale brain simulation**ï¼ˆ~10Â¹â° ç¥ç»å…ƒ, ~10Â¹â´ çªè§¦ï¼‰å¯è¡Œæ€§ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯æ‰©å±•è‡³æ•°åƒ GPU çš„ SNN é«˜æ•ˆæ„å»ºæ¡†æ¶ï¼Œé€šè¿‡å…¨ GPU åŸä½æ„å»ºä¸çµæ´»é€šä¿¡æœºåˆ¶ï¼Œåœ¨ä¸ç‰ºç‰²ç”Ÿç‰©ä¿çœŸåº¦çš„å‰æä¸‹ï¼Œå®ç°äº†è¶…è¿‡ä¸€ä¸ªæ•°é‡çº§çš„æ„å»ºåŠ é€Ÿï¼Œä¸ºå®ç°äººè„‘è§„æ¨¡çš„è„‰å†²ç½‘ç»œæ¨¡æ‹Ÿé“ºå¹³äº†é“è·¯ã€‚

</details>

---

### 7. [Learning Unmasking Policies for Diffusion Language Models](https://arxiv.org/abs/2512.09106)

**Authors**: Metod Jazbec, Theo X. Olausson, Louis B\'ethune, Pierre Ablin, Michael Kirchhof, Joao Monterio, Victor Turrisi, Jason Ramapuram, Marco Cuturi  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.09106v1  

#### Abstract
Diffusion (Large) Language Models (dLLMs) now match the downstream performance of their autoregressive counterparts on many tasks, while holding the promise of being more efficient during inference. One particularly successful variant is masked discrete diffusion, in which a buffer filled with speci...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLearning Unmasking Policies for Diffusion Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆdLLMsï¼‰åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶é‡‡ç”¨**é€æ­¥å»é®ç½©ï¼ˆunmaskingï¼‰**çš„æ–¹å¼ï¼Œä»å…¨é®ç½©åºåˆ—å¼€å§‹ï¼Œé€æ­¥å°† `M` æ›¿æ¢ä¸ºçœŸå® tokenã€‚ä¼ ç»Ÿçš„é‡‡æ ·ç­–ç•¥å¦‚éšæœºå»é®ç½©æˆ–åŸºäºç½®ä¿¡åº¦çš„å¯å‘å¼æ–¹æ³•ï¼ˆå¦‚ Fast-dLLM çš„ confidence thresholdingï¼‰è™½ç„¶æœ‰æ•ˆï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- éœ€è¦æ‰‹åŠ¨è°ƒå‚ï¼ˆå¦‚é˜ˆå€¼ Î» æˆ–å—é•¿åº¦ BLï¼‰
- åœ¨éåŠè‡ªå›å½’ï¼ˆnon-semi-ARï¼‰è®¾ç½®ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™
- ç¼ºä¹å¯¹æ•ˆç‡ä¸å‡†ç¡®æ€§ä¹‹é—´æƒè¡¡çš„çµæ´»æ§åˆ¶

æœ¬æ–‡æå‡ºï¼š**ä¸åº”ä¾èµ–æ‰‹å·¥è®¾è®¡çš„å¯å‘å¼è§„åˆ™ï¼Œè€Œåº”é€šè¿‡å­¦ä¹ æ¥è‡ªåŠ¨å‘ç°æœ€ä¼˜çš„å»é®ç½©ç­–ç•¥**ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…å°† dLLM çš„é‡‡æ ·è¿‡ç¨‹å½¢å¼åŒ–ä¸ºä¸€ä¸ª **é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰**ï¼Œå¹¶å¼•å…¥ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ–¹æ³•æ¥è®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„**å»é®ç½©ç­–ç•¥ç½‘ç»œï¼ˆunmasking policyï¼‰**ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **å½¢å¼åŒ–ä¸º MDP**  
   å°†æ¯ä¸€æ­¥çš„å»é®ç½©å†³ç­–å»ºæ¨¡ä¸º RL ä¸­çš„åŠ¨ä½œï¼ŒçŠ¶æ€ä¸ºå½“å‰éƒ¨åˆ†å»é®ç½©çš„åºåˆ—åŠå…¶ token ç½®ä¿¡åº¦ï¼Œå¥–åŠ±å‡½æ•°ç»“åˆæ­£ç¡®æ€§å’Œæ¨ç†æ­¥æ•°ï¼ˆNFEsï¼‰ã€‚

2. **è½»é‡çº§ Transformer ç­–ç•¥æ¶æ„**  
   è®¾è®¡äº†ä¸€ä¸ªä»…å«å•å±‚çš„è½»é‡ Transformer ç½‘ç»œä½œä¸ºç­–ç•¥ç½‘ç»œ $ \pi_\theta $ï¼Œè¾“å…¥æ˜¯æ¯ä¸ªä½ç½®çš„ token ç½®ä¿¡åº¦ $ c_k = \max_v p(v|x, y_t) $ã€é®ç½©çŠ¶æ€ $ m_k $ å’Œæ—¶é—´æ­¥ $ t $ï¼Œè¾“å‡ºä¸ºå„ä½ç½®æ˜¯å¦å»é®ç½©çš„ logitsã€‚

3. **ä½¿ç”¨ GRPO è¿›è¡Œè®­ç»ƒ**  
   é‡‡ç”¨ Group Relative Policy Optimizationï¼ˆGRPOï¼‰ï¼Œä¸€ç§é€‚ç”¨äºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åè®­ç»ƒçš„ç¨³å®š RL ç®—æ³•ï¼Œé¿å…ä¼ ç»Ÿ PPO çš„é«˜æ–¹å·®é—®é¢˜ã€‚

4. **ä¹˜æ³•å¥–åŠ±æœºåˆ¶**  
   å¥–åŠ±å®šä¹‰ä¸ºï¼š
   $$
   R = \mathbb{1}[t=T] \cdot r(y, y^*) \cdot (1 - \alpha / (T - T_g))
   $$
   å³å…ˆç¡®ä¿æ­£ç¡®æ€§ï¼Œå†é¼“åŠ±é«˜æ•ˆï¼ˆä½ NFEï¼‰ã€‚ç›¸æ¯”åŠ æ³•å¥–åŠ±æ›´ç¨³å®šï¼Œé˜²æ­¢â€œå¿«ä½†é”™â€çš„ reward hackingã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | å¯å‘å¼æ–¹æ³•ï¼ˆå¦‚ Fast-dLLMï¼‰ | æœ¬æ–‡æ–¹æ³•ï¼ˆLearned Policyï¼‰ |
|------|----------------------------|-----------------------------|
| å¯è°ƒæ€§ | æ‰‹åŠ¨è°ƒèŠ‚é˜ˆå€¼ Î» æˆ– K | è‡ªåŠ¨å­¦ä¹ ç­–ç•¥ï¼Œå‡å°‘äººå·¥å¹²é¢„ |
| æ³›åŒ–èƒ½åŠ› | å¯¹ buffer size æ•æ„Ÿ | èƒ½è¿ç§»åˆ°æ›´é•¿åºåˆ—ï¼ˆL=512ï¼‰ |
| æ€§èƒ½ä¸Šé™ | åœ¨ semi-AR ä¸‹è¡¨ç°ä¼˜å¼‚ | åœ¨ full-diffusion è®¾ç½®ä¸‹è¶…è¶Šå¯å‘å¼ |
| æ¨ç†çµæ´»æ€§ | å›ºå®šç­–ç•¥ | å¯é€šè¿‡ policy temperature $ T_{\text{policy}} $ å¾®è°ƒè¡Œä¸º |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼šGSM8kã€MATHï¼ˆè®­ç»ƒæ··åˆä½¿ç”¨ï¼Œæµ‹è¯•åˆ†å¼€ï¼‰
- **ä»£ç ç”Ÿæˆä»»åŠ¡**ï¼šHumanEvalã€MBPPï¼ˆç”¨äº domain transfer å®éªŒï¼‰
- **é¢å¤–æ•°æ®**ï¼šKodCode-RL-10Kï¼ˆä¸“é—¨ç”¨äºä»£ç é¢†åŸŸçš„ policy è®­ç»ƒï¼‰

### æ¨¡å‹åŸºç¡€
- ä¸»è¦ backboneï¼šLLaDA-8B-Instructï¼ˆä»å¤´è®­ç»ƒçš„ MDMï¼‰
- å¯¹æ¯”æ¨¡å‹ï¼šDream-7B-Instructï¼ˆç”± AR æ¨¡å‹åˆå§‹åŒ–ï¼‰

### å®éªŒè®¾ç½®
- **è®­ç»ƒæ–¹å¼**ï¼šGRPOï¼Œgroup size=8ï¼Œæ¯ç»„ç”Ÿæˆå¤šä¸ª rollout
- **æ¸©åº¦è®¾ç½®**ï¼šdLLM æ¨ç†æ¸©åº¦è®¾ä¸º 0ï¼ˆgreedy decodingï¼‰ï¼Œpolicy æ¸©åº¦ $ T_{\text{policy}} $ å¯è°ƒ
- **è®­ç»ƒé…ç½®**ï¼š
  - Batch size: 16
  - Optimizer: AdamW, lr=3e-5, cosine schedule
  - Policy å‚æ•°é‡çº¦ 300Kï¼ˆä»…ä¸º LLaDA çš„ 0.01%ï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®æ€§ï¼ˆAccuracyï¼‰**ï¼šä»»åŠ¡ç›¸å…³æŒ‡æ ‡ï¼ˆå¦‚ GSM8k æ•°å­¦ç­”æ¡ˆåŒ¹é…ç‡ï¼‰
- **æ¨ç†æ•ˆç‡**ï¼šNetwork Function Evaluationsï¼ˆNFEsï¼‰ï¼Œå³é‡‡æ ·æ­¥æ•°
- **å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto Frontierï¼‰**ï¼šå‡†ç¡®ç‡ vs. NFEs æ›²çº¿ï¼Œè¡¡é‡é€Ÿåº¦-ç²¾åº¦æƒè¡¡

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| Random Unmasking | åŸºçº¿ | æ¯æ­¥éšæœºé€‰æ‹©å›ºå®šæ•°é‡ token å»é®ç½© |
| High-Confidence Unmasking | å¯å‘å¼ | æ¯æ­¥å»é®ç½©ç½®ä¿¡åº¦æœ€é«˜çš„ K ä¸ª token |
| Fast-dLLM | å¯å‘å¼ | åŠ¨æ€å»é®ç½©æ‰€æœ‰ç½®ä¿¡åº¦ > Î» çš„ token |
| Ours (w/ ES) | æœ¬æ–‡æ–¹æ³• | åŠ å…¥ä¸“å®¶å¼•å¯¼ï¼ˆExpert Steeringï¼‰æå‡æ¢ç´¢ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Figure 3ï¼‰

#### âœ… Semi-AR è®¾ç½®ï¼ˆBL=32ï¼‰
- åœ¨ GSM8k ä¸Šï¼Œlearned policy å‡†ç¡®ç‡å¯è¾¾ ~80%ï¼ŒNFE â‰ˆ 64
- ä¸ Fast-dLLM è¡¨ç°ç›¸å½“ï¼Œåœ¨ä¸­é«˜ NFE åŒºé—´æœªæ˜æ˜¾è¶…è¶Š
- è¯´æ˜ï¼šåœ¨ semi-AR ä¸‹ï¼ŒFast-dLLM å·²æ¥è¿‘æœ€ä¼˜

#### âœ… Full-Diffusion è®¾ç½®ï¼ˆBL=256ï¼Œæ— å—é™åˆ¶ï¼‰
- Learned policy æ˜¾è‘—ä¼˜äºæ‰€æœ‰å¯å‘å¼æ–¹æ³•
- åœ¨ GSM8k ä¸Šï¼Œä»…ç”¨ ~12 NFEs è¾¾åˆ° ~50% å‡†ç¡®ç‡
- å¯å‘å¼æ–¹æ³•åœ¨æ­¤è®¾ç½®ä¸‹é€€åŒ–ä¸¥é‡ï¼ˆâ‰¤30%ï¼‰
- **ç»“è®º**ï¼šRL ç­–ç•¥åœ¨å®Œå…¨å¹¶è¡Œç”Ÿæˆåœºæ™¯ä¸‹æ›´å…·ä¼˜åŠ¿

#### âœ… å¼•å…¥ Expert Steeringï¼ˆESï¼‰åçš„æ”¹è¿›
- ä½¿ç”¨ Fast-dLLM ä½œä¸ºâ€œä¸“å®¶â€å¼•å¯¼è®­ç»ƒ
- åœ¨ full-diffusion è®¾ç½®ä¸‹è¿›ä¸€æ­¥ç¼©å°ä¸ semi-AR çš„å·®è·
- åœ¨ GSM8k ä¸Šè¾¾åˆ° ~80% å‡†ç¡®ç‡ï¼ˆæ¥è¿‘ semi-AR æœ€ä¼˜æ°´å¹³ï¼‰

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰å¥–åŠ±å‡½æ•°è®¾è®¡ï¼ˆMultiplicative vs Additiveï¼‰
- **Additive reward**: å®¹æ˜“é™·å…¥â€œå…¨éƒ¨ä¸€æ¬¡æ€§å»é®ç½©â€ï¼Œå¯¼è‡´ reward hacking
- **Multiplicative reward**: æ›´ç¨³å®šï¼Œä¼˜å…ˆä¿è¯æ­£ç¡®æ€§ï¼ŒRL æ”¶æ•›è‰¯å¥½ï¼ˆè§ Figure 5a-bï¼‰

#### ï¼ˆ2ï¼‰ç­–ç•¥å‚æ•°åŒ–æ–¹å¼
- **Bernoulli è¾“å‡º**ï¼ˆé»˜è®¤ï¼‰ï¼šç®€å•é«˜æ•ˆï¼Œlikelihood æ˜“è®¡ç®—
- **Dynamic Plackett-Luce Sampling (DPLS)**ï¼šå¼ºåˆ¶è‡³å°‘å»é®ç½©ä¸€ä¸ª tokenï¼Œç†è®ºä¸Šæ›´å¥½
- ç»“æœï¼šä¸¤è€…æ€§èƒ½ç›¸è¿‘ï¼ŒDPLS ç•¥å¾®æå‡å¯æ§æ€§ï¼Œä½†å¤æ‚åº¦æ›´é«˜

#### ï¼ˆ3ï¼‰è¾“å…¥ç‰¹å¾è®¾è®¡
| è¾“å…¥ç±»å‹ | æ€§èƒ½ | å¤‡æ³¨ |
|--------|------|------|
| Top-1 confidenceï¼ˆæœ€å¤§æ¦‚ç‡ï¼‰ | âœ”ï¸ æœ€ä½³ | ç®€æ´ä¸”æœ‰æ•ˆ |
| Top-50 confidences | âŒ ç¨å·® | å¹¶æœªå¸¦æ¥å¢ç›Š |
| Hidden statesï¼ˆLLaDA æœ€ç»ˆå±‚ï¼‰ | âŒ æ›´å·® | å‚æ•°é‡å¢åŠ  1000Ã—ï¼Œè®­ç»ƒä¸ç¨³å®š |

> **ç»“è®º**ï¼šç®€å•çš„ç½®ä¿¡åº¦ä¿¡å·å·²è¶³å¤Ÿï¼Œæ— éœ€å¤æ‚è¯­ä¹‰ä¿¡æ¯

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **RL å¯ä»¥æˆåŠŸå­¦ä¹ é«˜æ•ˆçš„å»é®ç½©ç­–ç•¥**ï¼Œåœ¨ semi-AR åœºæ™¯ä¸‹åª²ç¾ç”šè‡³é€¼è¿‘ Fast-dLLMã€‚
2. âœ… **åœ¨ full-diffusionï¼ˆé semi-ARï¼‰è®¾ç½®ä¸‹ï¼Œlearned policy æ˜¾è‘—ä¼˜äºå¯å‘å¼æ–¹æ³•**ï¼Œå±•ç°å‡ºæ›´å¼ºçš„å¹¶è¡Œæ¨ç†æ½œåŠ›ã€‚
3. âœ… **ç­–ç•¥å…·æœ‰è‰¯å¥½çš„è¿ç§»èƒ½åŠ›**ï¼š
   - **è·¨æ¨¡å‹è¿ç§»**ï¼šåœ¨ LLaDA ä¸Šè®­ç»ƒçš„ policy å¯è¿ç§»åˆ° Dreamï¼Œæ€§èƒ½æ¥è¿‘åŸç”Ÿè®­ç»ƒ
   - **è·¨é•¿åº¦è¿ç§»**ï¼šåœ¨ L=256 è®­ç»ƒçš„ policy å¯ç›´æ¥ç”¨äº L=512ï¼Œæ€§èƒ½å‡ ä¹ä¸å˜
4. âš ï¸ **é¢†åŸŸè¿ç§»å—é™**ï¼šåœ¨æ•°å­¦æ•°æ®ä¸Šè®­ç»ƒçš„ policy åœ¨ä»£ç ä»»åŠ¡ï¼ˆHumanEval/MBPPï¼‰ä¸Šè¡¨ç°ä¸ä½³ï¼›éœ€é¢†åŸŸå†…è®­ç»ƒæ‰èƒ½æ¢å¤æ€§èƒ½ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | æè¿° |
|------|------|
| æ§åˆ¶ç²’åº¦ä¸è¶³ | è°ƒæ•´ $ \alpha $ æ— æ³•å¹³æ»‘æ§åˆ¶å¸•ç´¯æ‰˜å‰æ²¿ï¼Œå¤šä¸ª $ \alpha $ æ”¶æ•›åˆ°ç›¸åŒç­–ç•¥ |
| è®­ç»ƒä¸ç¨³å®šæ€§ | å°¤å…¶åœ¨ $ \alpha=10 $ æˆ–ä½¿ç”¨ Expert Steering æ—¶å®¹æ˜“å´©æºƒ |
| é¢†åŸŸæ³›åŒ–å¼± | æ•°å­¦ â†’ ä»£ç è¿ç§»å¤±è´¥ï¼Œè¡¨æ˜ç­–ç•¥å¯èƒ½è¿‡æ‹Ÿåˆç‰¹å®šä»»åŠ¡æ¨¡å¼ |
| æ— æ³•ç«¯åˆ°ç«¯ä¼˜åŒ–æ¨¡å‹èƒ½åŠ› | æœ¬å·¥ä½œèšç„¦äºé‡‡æ ·ç­–ç•¥ï¼Œä¸å¢å¼º dLLM æœ¬èº«çš„æ¨ç†èƒ½åŠ› |

---

### æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆåŸæ–‡å»ºè®®ï¼‰
1. **å¤šæ¨¡å‹æ··åˆè®­ç»ƒ**ï¼šåœ¨å¤šç§ dLLM ä¸Šè”åˆè®­ç»ƒ policyï¼Œæå‡è·¨æ¨¡å‹é²æ£’æ€§
2. **å¤šé¢†åŸŸæ•°æ®æ··åˆè®­ç»ƒ**ï¼šèåˆæ•°å­¦ã€ä»£ç ã€å¯¹è¯ç­‰ä»»åŠ¡ï¼Œæå‡ domain transfer èƒ½åŠ›
3. **åŠ¨æ€è°ƒæ•´ policy temperature**ï¼šæ¢ç´¢è®© $ T_{\text{policy}} $ æˆä¸ºå¯å­¦ä¹ å˜é‡
4. **æ‰©å±•è‡³ remasking å’ŒåŠ¨æ€é•¿åº¦è°ƒæ•´**ï¼šæ”¯æŒæ›´å¤æ‚çš„é‡‡æ ·æœºåˆ¶ï¼ˆå¦‚ Saberã€DiFFPOï¼‰
5. **åº”ç”¨äºå¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹**ï¼šå°†è¯¥æ¡†æ¶æ¨å¹¿è‡³å›¾åƒã€éŸ³é¢‘ç­‰ç¦»æ•£æ‰©æ•£ç³»ç»Ÿ

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿåœ°å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äº dLLM çš„å»é®ç½©ç­–ç•¥å­¦ä¹ ï¼Œåœ¨ä¿æŒæä½å¼€é”€çš„å‰æä¸‹ï¼Œå®ç°äº†åª²ç¾ç”šè‡³è¶…è¶Šå¯å‘å¼æ–¹æ³•çš„é‡‡æ ·æ•ˆç‡ï¼Œå°¤å…¶åœ¨å®Œå…¨å¹¶è¡Œç”Ÿæˆåœºæ™¯ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä¸ºæ„å»ºæ›´é«˜æ•ˆã€å¯å­¦ä¹ çš„æ‰©æ•£è¯­è¨€æ¨¡å‹æ¨ç†å¼•æ“æä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 8. [TinyD\'ej\`aVu: Smaller Memory Footprint & Faster Inference on Sensor Data Streams with Always-On Microcontrollers](https://arxiv.org/abs/2512.09786)

**Authors**: Zhaolan Huang, Emmanuel Baccelli  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.09786v1  

#### Abstract
Always-on sensors are increasingly expected to embark a variety of tiny neural networks and to continuously perform inference on time-series of the data they sense. In order to fit lifetime and energy consumption requirements when operating on battery, such hardware uses microcontrollers (MCUs) with...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTinyDejaVu: Smaller Memory Footprint & Faster Inference on Sensor Data Streams with Always-On Microcontrollers

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨è¾¹ç¼˜è®¾å¤‡ï¼ˆå°¤å…¶æ˜¯åŸºäºå¾®æ§åˆ¶å™¨ MCU çš„ always-on ä¼ æ„Ÿå™¨ï¼‰ä¸Šéƒ¨ç½²æ·±åº¦å­¦ä¹ æ¨¡å‹é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **æå°çš„å†…å­˜é¢„ç®—**ï¼ˆå¦‚ä»… 128kB RAMï¼‰ï¼Œéš¾ä»¥æ”¯æŒä¼ ç»Ÿæ¨ç†ä¸­å¯¹ä¸­é—´æ¿€æ´»å€¼çš„å¤§è§„æ¨¡ç¼“å­˜ï¼›
- **é«˜å†—ä½™è®¡ç®—**ï¼šåœ¨å¤„ç†æ—¶é—´åºåˆ—æ•°æ®æµæ—¶ï¼Œå¸¸é‡‡ç”¨é‡å æ»‘åŠ¨çª—å£ï¼ˆoverlapping sliding windowsï¼‰ï¼Œå¯¼è‡´å¤§é‡é‡å¤è®¡ç®—ã€‚

è¿™äº›é—®é¢˜æ˜¾è‘—é™åˆ¶äº†é•¿æ—¶é—´åºåˆ—ä»»åŠ¡åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„å®æ—¶æ€§å’Œèƒ½æ•ˆã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡º **TinyDejaVu** â€”â€” ä¸€ä¸ªå…¨æ–°çš„åµŒå…¥å¼è½¯ä»¶æ¡†æ¶ï¼Œç»“åˆæ–°å‹ç®—æ³•ä»¥ä¼˜åŒ–æ—¶é—´åºåˆ—ç¥ç»ç½‘ç»œåœ¨ MCU ä¸Šçš„æ¨ç†è¿‡ç¨‹ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†**æ—¶åºç®—å­å»ºæ¨¡ä¸ºçŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆState-Space Models, SSMsï¼‰**ï¼Œä»è€Œå®ç°é«˜æ•ˆæµå¼å¤„ç†ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- âœ… **å°†é€šç”¨æ—¶åºç®—å­è½¬åŒ–ä¸º SSM å½¢å¼**  
  é¦–æ¬¡ç³»ç»Ÿæ€§åœ°å½¢å¼åŒ–äº†å·ç§¯ã€æ± åŒ–ç­‰å¸¸è§ temporal operators ä¸ SSM çš„ç­‰ä»·å…³ç³»ï¼Œå¹¶è®¾è®¡äº†ä¸€å¥—è‡ªåŠ¨è½¬æ¢æœºåˆ¶ï¼Œä½¿è¿™äº›æ“ä½œå¯åœ¨å›ºå®šå¤§å°çš„çŠ¶æ€ç¼“å†²åŒºä¸­é€’å½’æ‰§è¡Œã€‚

- âœ… **æ„å»ºå› æœæ€§åˆ†ææ¡†æ¶ï¼Œåˆ’åˆ† SSM-subgraph ä¸ GTA-subgraph**  
  å¼•å…¥â€œå…¨å±€æ—¶é—´èšåˆå™¨â€ï¼ˆGlobal Temporal Aggregator, GTAï¼‰ä½œä¸ºåˆ†ç•Œç‚¹ï¼Œå°†ç½‘ç»œåˆ’åˆ†ä¸ºå¯æµå¼å¤„ç†çš„å±€éƒ¨ç®—å­éƒ¨åˆ†ï¼ˆSSM-subgraphï¼‰å’Œå¿…é¡»å…¨çª—å£å¤„ç†çš„éƒ¨åˆ†ï¼ˆGTA-subgraphï¼‰ï¼Œå®ç°æœ€ä¼˜èµ„æºè°ƒåº¦ã€‚

- âœ… **æ”¯æŒé‡å æ»‘åŠ¨çª—å£ä¸‹çš„å¢é‡æ¨ç†**  
  åˆ©ç”¨ SSM ç¼“å­˜å†å²éšè—çŠ¶æ€ï¼Œåœ¨æ–°çª—å£åˆ°æ¥æ—¶åªå¤„ç†æ–°å¢è¾“å…¥ç‰‡æ®µï¼Œé¿å…æ•´ä¸ªæ¨¡å‹é‡æ–°è®¡ç®—ï¼Œæå¤§å‡å°‘å†—ä½™ã€‚

- âœ… **ä¼˜åŒ– Global Pooling çš„å†…å­˜å¼€é”€**  
  æå‡ºä¸¤çº§ SSM ç»“æ„æ›¿ä»£åŸå§‹ global poolingï¼Œå°† RAM å¤æ‚åº¦ä» $O(N)$ é™è‡³ $O(N/s)$ï¼Œå…¶ä¸­ $s$ ä¸ºæ­¥é•¿ã€‚

- âœ… **é›†æˆ BF16 æ··åˆç²¾åº¦æ”¯æŒ**  
  åœ¨ SSM å­å›¾ä¸­ä½¿ç”¨ BF16 å­˜å‚¨éšè—çŠ¶æ€ï¼Œè¿›ä¸€æ­¥é™ä½å†…å­˜å ç”¨çº¦ 50%ï¼ŒåŒæ—¶é€šè¿‡æ··åˆç²¾åº¦è¿ç®—ä¿æŒå‡†ç¡®æ€§ã€‚

- âœ… **ç«¯åˆ°ç«¯å¼€æºå·¥å…·é“¾å®ç°**  
  åŸºäº PyTorch + microTVM æ„å»ºå®Œæ•´ç¼–è¯‘æµç¨‹ï¼Œç”Ÿæˆå¹³å°æ— å…³çš„ C ä»£ç ï¼Œé€‚ç”¨äºå¤šç§ MCU æ¶æ„ï¼ˆARM Cortex-Mã€ESP32ã€RISC-V ç­‰ï¼‰ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ FastWaveNetã€StreamiNNCï¼‰ | TinyDejaVu |
|------|----------------------------------------|-----------|
| æ”¯æŒç®—å­èŒƒå›´ | ä»…é™ 1D å·ç§¯æˆ–ç‰¹å®šç»“æ„ | æ”¯æŒ Convã€Poolingã€Attentionã€Transformer ç­‰é€šç”¨ temporal operators |
| æ˜¯å¦æ”¯æŒé‡å æ»‘åŠ¨çª—å£ | éƒ¨åˆ†æ”¯æŒ | å®Œæ•´æ”¯æŒï¼Œä¸”è‡ªåŠ¨æ¶ˆé™¤å†—ä½™ |
| å†…å­˜ä¼˜åŒ–ç¨‹åº¦ | ä¾èµ–å…·ä½“ç»“æ„ | ç»Ÿä¸€æ¡†æ¶ä¸‹å®ç°é«˜è¾¾ 99% RAM å‡å°‘ |
| å¯ç§»æ¤æ€§ | å¤šä¸ºä¸“ç”¨å†…æ ¸ | åŸºäº microTVMï¼Œè·¨å¹³å°é€šç”¨æ€§å¼º |
| å·¥å…·é“¾å®Œæ•´æ€§ | æ‰‹åŠ¨å®ç°ä¸ºä¸» | è‡ªåŠ¨åŒ–åˆ†æ + å›¾å˜æ¢ + ä»£ç ç”Ÿæˆ |

> ğŸ’¡ **ä¼˜åŠ¿æ€»ç»“**ï¼šTinyDejaVu æ˜¯é¦–ä¸ªé¢å‘é€šç”¨æ··åˆæ¶æ„ã€æ”¯æŒå®Œæ•´æ»‘åŠ¨çª—å£åœºæ™¯ã€å…·å¤‡è‡ªåŠ¨åŒ–ç¼–è¯‘èƒ½åŠ›çš„ä½å†…å­˜æµå¼æ¨ç†æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ¨¡å‹ä¸ä»»åŠ¡**

æœªä½¿ç”¨ä¼ ç»Ÿå…¬å¼€æ•°æ®é›†ï¼ˆå¦‚ UCI-HARï¼‰ï¼Œè€Œæ˜¯é€‰å–å¤šä¸ªå…¸å‹çš„æ—¶é—´åºåˆ— TinyML æ¨¡å‹è¿›è¡Œå®æµ‹ï¼Œæ¶µç›–ä¸åŒæ¶æ„ç±»å‹ï¼š

| æ¨¡å‹ | ç±»å‹ | è¾“å…¥é•¿åº¦ | åº”ç”¨åœºæ™¯ |
|------|------|----------|---------|
| **WaveNet** | Dilated 1D Conv | 512 | è¯­éŸ³ç”Ÿæˆ |
| **TC-CNN** | CNN + Dense | 48k | éŸ³é¢‘åˆ†ç±»ï¼ˆé¸Ÿé¸£è¯†åˆ«ï¼‰ |
| **TEMPONet** | TCN + Dense | 512 | EMG æ‰‹åŠ¿è¯†åˆ« |
| **ResTCN** | Residual TCN | 512 | æ—¶é—´åºåˆ—å»ºæ¨¡ |
| **CET-S** | ResNet + Transformer | 512 | EEG å¿ƒè‚ºå¤è‹é¢„åé¢„æµ‹ |
| **TC-TFM** | CNN + Transformer | 48k | é•¿åºåˆ—å£°éŸ³æ£€æµ‹ |

> æ‰€æœ‰æ¨¡å‹å‡é€‚é…è‡³å¯åœ¨ MCU ä¸Šè¿è¡Œçš„å°å‹ç‰ˆæœ¬ã€‚

---

### **å®éªŒè®¾ç½®**

- **ç¡¬ä»¶å¹³å°**ï¼š
  - ä¸»æµ‹è¯•å¹³å°ï¼š**STM32F767ZI** MCUï¼ˆARM Cortex-M7 @ 216MHzï¼Œ512KB RAMï¼Œ2MB Flashï¼‰
  - è¾…åŠ©éªŒè¯å¹³å°ï¼šstm32f746g-disco
- **è½¯ä»¶æ ˆ**ï¼š
  - å‰ç«¯ï¼šPyTorch v2.3.0
  - ç¼–è¯‘å™¨ï¼šmicroTVM v0.16.0
  - è¿è¡Œç¯å¢ƒï¼šRIOT-MLï¼ˆè½»é‡çº§ç‰©è”ç½‘æ“ä½œç³»ç»Ÿï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å³°å€¼ RAM ä½¿ç”¨é‡ï¼ˆPeak RAM Usageï¼‰**
  - **æ¨ç†å»¶è¿Ÿï¼ˆCompute Latencyï¼‰**ï¼šåˆ†ä¸º preheatï¼ˆé¦–æ¬¡å®Œæ•´æ¨ç†ï¼‰å’Œ streamingï¼ˆåç»­å¢é‡æ¨ç†ï¼‰
  - **ç›¸å¯¹ RMSE**ï¼šæ¯”è¾ƒ BF16 ä¸ FP32 è¾“å‡ºå·®å¼‚
  - **é‡å ç‡å½±å“**ï¼ˆOverlap Rate = $(l - s)/l$ï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **Vanilla Inference**ï¼šæ ‡å‡†éæµå¼æ¨ç†ï¼Œæ¯ä¸ªæ»‘åŠ¨çª—å£ç‹¬ç«‹è®¡ç®—
- **FastWaveNet / StreamiNNC**ï¼šé’ˆå¯¹ WaveNet çš„é«˜æ•ˆå®ç°ï¼ˆä»…ç”¨äº WaveNet å¯¹æ¯”ï¼‰
- **TinyDejaVu variants**ï¼š
  - `TinyDejaVu`
  - `TinyDejaVu + BF16`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### ğŸ”¹ **å†…å­˜èŠ‚çœæ•ˆæœæ˜¾è‘—**

| æ¨¡å‹ | Vanilla RAM | TinyDejaVu RAM | èŠ‚çœæ¯”ä¾‹ |
|------|------------|----------------|---------|
| WaveNet | 178.5 MB | **142.6 kB** | >99.9% |
| TC-TFM | ~6.1 MB | **~6143.74 kB â†’ å®é™…æ›´ä½ï¼Ÿ** | >99%?ï¼ˆåŸæ–‡ç§° <0.05%ï¼‰ |
| TC-CNN | â€” | 1535.94 kB â†’ **TinyDejaVu åå¤§å¹…ä¸‹é™** | â‰¥60% |
| CET-S | â€” | 47.65 kB | â‰¥60% |

> âš ï¸ æ³¨ï¼šåŸæ–‡ Fig.4 æ˜¾ç¤ºæŸäº›æ¨¡å‹ RAM ä½¿ç”¨ä»…ä¸º vanilla çš„ **<0.05%**ï¼Œå³æœ€é«˜è¾¾ **99.95% å‡å°‘**ã€‚

#### ğŸ”¹ **æ¨ç†é€Ÿåº¦å¤§å¹…æå‡**

- åœ¨ **WaveNet** ä¸Šï¼š
  - Preheat é˜¶æ®µè€—æ—¶ï¼š2776.1 ms
  - Streaming é˜¶æ®µå•æ ·æœ¬ç”Ÿæˆä»…éœ€ **14.1 ms**
  - ç›¸æ¯” preheat åŠ é€Ÿè¿‘ **200Ã—**
- åœ¨é«˜é‡å ç‡ï¼ˆ>99%ï¼‰ä¸‹ï¼Œå‡ ä¹æ‰€æœ‰æ¨¡å‹ streaming æ¨ç†å»¶è¿Ÿè¿œä½äº preheat

#### ğŸ”¹ **BF16 å†…å­˜ä¼˜åŒ–é¢å¤–æ”¶ç›Š**

- éšè—çŠ¶æ€å­˜å‚¨ç”± FP32 â†’ BF16ï¼Œå†…å­˜å†é™ **~31â€“50%**
  - å¦‚ WaveNet ä» 142.6kB â†’ **108.3kB**
- è®¡ç®—å¼€é”€å¢åŠ çº¦ **13%**ï¼Œä½†å¯æ¥å—
- è¾“å‡º RMSE æ§åˆ¶åœ¨ **1%â€“3%**ï¼Œç²¾åº¦æŸå¤±æå°

#### ğŸ”¹ **æ¶ˆèå®éªŒï¼šé‡å ç‡çš„å½±å“ï¼ˆFig.5ï¼‰**

- éšç€ **overlap rate å¢åŠ **ï¼Œstreaming æ¨ç†å»¶è¿Ÿå‘ˆ**çº¿æ€§ä¸‹é™è¶‹åŠ¿**
- è¡¨æ˜ TinyDejaVu æˆåŠŸæ¶ˆé™¤äº†å¤§éƒ¨åˆ†å†—ä½™è®¡ç®—
- ç‰¹ä¾‹ï¼šResTCN å’Œ TEMPONet å› æ·±å±‚ç»“æ„ä¿ç•™æ›´å¤šå†å²ä¿¡æ¯ï¼Œå³ä½¿ä½é‡å ä¹Ÿèƒ½ç»´æŒè¾ƒä½å»¶è¿Ÿ

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **SSM æ˜¯ç»Ÿä¸€è¡¨è¾¾ temporal operators çš„æœ‰æ•ˆèŒƒå¼**  
   å·ç§¯ã€æ± åŒ–ç­‰å‡å¯è½¬åŒ–ä¸ºå…·æœ‰å›ºå®šçŠ¶æ€æ•°çš„ SSMï¼Œå®ç°å¸¸é‡ç©ºé—´å¤æ‚åº¦çš„æµå¼æ¨ç†ã€‚

2. âœ… **GTA æ˜¯å†³å®šæ˜¯å¦å¯æµå¼å¤„ç†çš„å…³é”®è¾¹ç•Œ**  
   å°†ç½‘ç»œåˆ’åˆ†ä¸º SSM-subgraph å’Œ GTA-subgraph å¯æœ€å¤§åŒ–èµ„æºåˆ©ç”¨ç‡ã€‚

3. âœ… **TinyDejaVu æ˜¾è‘—é™ä½ MCU ä¸Šçš„æ—¶é—´åºåˆ—æ¨ç†æˆæœ¬**  
   - æœ€å¤šèŠ‚çœ **>99% RAM**
   - æœ€é«˜å®ç° **200Ã— æ¨ç†åŠ é€Ÿ**
   - æ”¯æŒä»»æ„é‡å æ»‘åŠ¨çª—å£è¾“å…¥

4. âœ… **BF16 å¯è¿›ä¸€æ­¥å‹ç¼©å†…å­˜ï¼Œç²¾åº¦æŸå¤±å¯å¿½ç•¥**

5. âœ… **æ¡†æ¶å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§**  
   æ”¯æŒ CNNã€TCNã€Transformer ç­‰æ··åˆæ¶æ„ï¼Œé€‚ç”¨äºå¤šç§ TinyML åœºæ™¯ã€‚

---

### **å±€é™æ€§**

- â— **æ— æ³•ä¼˜åŒ– GTA å±‚æœ¬èº«**ï¼ˆå¦‚ Attentionã€Global Poolingï¼‰  
  è¿™äº›å±‚ä»éœ€è®¿é—®å®Œæ•´ä¸Šä¸‹æ–‡ï¼Œé™åˆ¶äº†æè‡´æµå¼åŒ–ï¼›å°½ç®¡å¯¹ Global Pooling åšäº†ä¼˜åŒ–ï¼Œä½†ä»ä¸å¦‚çº¯å±€éƒ¨ç®—å­ç†æƒ³ã€‚
  
- â— **é¢„çƒ­é˜¶æ®µï¼ˆpreheatï¼‰å¼€é”€è¾ƒå¤§**  
  ç¬¬ä¸€æ¬¡å®Œæ•´æ¨ç†ä»éœ€è¾ƒé«˜æ—¶é—´å’Œå†…å­˜ï¼Œä¸é€‚åˆâ€œå†·å¯åŠ¨â€é¢‘ç¹çš„åº”ç”¨ã€‚

- â— **ç›®å‰ä¾èµ–äººå·¥æŒ‡å®š operator ç±»å‹**  
  è™½ç„¶å·²å®ç°è‡ªåŠ¨ temporal analysisï¼Œä½†å¯¹äºéå¸¸è§„è‡ªå®šä¹‰å±‚çš„æ”¯æŒå°šæœ‰é™ã€‚

- â— **æœªåœ¨çœŸå®é•¿æœŸéƒ¨ç½²ä¸­æµ‹è¯•èƒ½è€—**  
  å®éªŒé›†ä¸­åœ¨ RAM å’Œå»¶è¿Ÿæµ‹é‡ï¼Œç¼ºä¹ç”µæ± å¯¿å‘½çš„å®é™…éªŒè¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. ğŸ”„ **å¼€å‘å…¨è‡ªåŠ¨ operator åˆ†æå™¨**ï¼Œæ— éœ€æ‰‹åŠ¨æ ‡æ³¨ temporal å‚æ•°
2. ğŸ”‹ **è”åˆä¼˜åŒ–èƒ½è€—ä¸å†…å­˜**ï¼Œæ¢ç´¢æ›´æ¿€è¿›çš„ç¨€ç–åŒ–æˆ–é‡åŒ–ç­–ç•¥
3. ğŸ§  **æ‰©å±•è‡³åœ¨çº¿å­¦ä¹ åœºæ™¯**ï¼Œæ”¯æŒå‚æ•°å¾®è°ƒçš„æµå¼æ›´æ–°
4. ğŸŒ **æ”¯æŒå¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆæµå¼æ¨ç†**
5. ğŸ› ï¸ **é›†æˆè‡³ä¸»æµ TinyML å·¥å…·é“¾**ï¼ˆå¦‚ TensorFlow Lite Microã€Edge Impulseï¼‰

---

## æ€»ç»“

> **TinyDejaVu æ˜¯ä¸€ç§é©å‘½æ€§çš„ TinyML æ¨ç†ä¼˜åŒ–æ¡†æ¶**ï¼Œå®ƒé€šè¿‡å°†æ—¶åºç®—å­ç»Ÿä¸€å»ºæ¨¡ä¸º SSMï¼Œå®ç°äº†åœ¨ MCU ä¸Šå¯¹é‡å æ»‘åŠ¨çª—å£è¾“å…¥çš„**é›¶å†—ä½™ã€ä½å†…å­˜ã€é«˜é€Ÿæµå¼æ¨ç†**ã€‚å…¶å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å¤šç§ä»£è¡¨æ€§æ¨¡å‹ä¸Šå¯å®ç° **>99% RAM èŠ‚çœ** å’Œ **é«˜è¾¾ 200Ã— çš„æ¨ç†åŠ é€Ÿ**ï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„é€šç”¨æ€§å’Œå¯ç§»æ¤æ€§ã€‚è¯¥å·¥ä½œä¸º always-on ä¼ æ„Ÿå™¨è®¾å¤‡ä¸Šçš„é•¿åºåˆ— AI å¤„ç†æä¾›äº†æå…·å‰æ™¯çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 9. [Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing](https://arxiv.org/abs/2512.09882)

**Authors**: Justin W. Lin, Eliot Krzysztof Jones, Donovan Julian Jasper, Ethan Jun-shen Ho, Anna Wu, Arnold Tianyi Yang, Neil Perry, Andy Zou, Matt Fredrikson, J. Zico Kolter, Percy Liang, Dan Boneh, Daniel E. Ho  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.09882v1  

#### Abstract
We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é¦–æ¬¡åœ¨**çœŸå®çš„ä¼ä¸šç”Ÿäº§ç¯å¢ƒ**ä¸­ï¼Œå¯¹AIä»£ç†ï¼ˆAI Agentsï¼‰ä¸äººç±»ç½‘ç»œå®‰å…¨ä¸“å®¶è¿›è¡Œäº†å…¨é¢ã€ç›´æ¥çš„å¯¹æ¯”è¯„ä¼°ã€‚æ­¤å‰çš„AIå®‰å…¨èƒ½åŠ›åŸºå‡†ï¼ˆå¦‚CTFæŒ‘æˆ˜ã€CVEå¤ç°ç­‰ï¼‰å­˜åœ¨ä¸¥é‡è„±ç¦»ç°å®çš„é—®é¢˜ï¼Œç¼ºä¹æ“ä½œçœŸå®æ€§ï¼ˆoperational realismï¼‰ï¼Œæ— æ³•åæ˜ çœŸå®ç½‘ç»œæ”»é˜²ä¸­çš„å¤æ‚æ€§ã€å™ªå£°å’Œäº¤äº’æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šARTEMIS
ä½œè€…æå‡ºäº† **ARTEMIS**ï¼ˆAutomated Red Teaming Engine with Multi-agent Intelligent Supervisionï¼‰ï¼Œä¸€ä¸ªç”¨äºè‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•çš„æ–°å‹å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- **åŠ¨æ€æç¤ºç”Ÿæˆï¼ˆDynamic Prompt Generationï¼‰**ï¼šä¸ºæ¯ä¸ªå­ä»»åŠ¡ç”Ÿæˆå®šåˆ¶åŒ–çš„ç³»ç»Ÿæç¤ºï¼Œæå‡å­ä»£ç†çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ã€‚
- **ä»»æ„å­ä»£ç†æ¶æ„ï¼ˆArbitrary Sub-agentsï¼‰**ï¼šæ”¯æŒæ— é™æ•°é‡çš„å¹¶è¡Œå­ä»£ç†ï¼Œå®ç°ä»»åŠ¡åˆ†è§£ä¸å¹¶å‘æ‰§è¡Œã€‚
- **è‡ªåŠ¨æ¼æ´åˆ†çº§ä¸éªŒè¯ï¼ˆAutomatic Vulnerability Triagingï¼‰**ï¼šå†…ç½®ä¸‰é˜¶æ®µéªŒè¯æ¨¡å—ï¼ˆç›¸å…³æ€§åˆ¤æ–­ã€å¯å¤ç°æ€§æµ‹è¯•ã€åˆ†ç±»æŠ¥å‘Šï¼‰ï¼Œæ˜¾è‘—é™ä½è¯¯æŠ¥ç‡ã€‚
- **é•¿å‘¨æœŸä»»åŠ¡ç®¡ç†**ï¼šé€šè¿‡é€’å½’TODOåˆ—è¡¨ã€ä¸Šä¸‹æ–‡æ‘˜è¦å’Œä¼šè¯æ¢å¤æœºåˆ¶ï¼Œå…‹æœç°æœ‰ä»£ç†æ— æ³•æŒç»­é•¿æ—¶é—´è¿è¡Œçš„ç“¶é¢ˆã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ€§èƒ½è¶…è¶Šå¤šæ•°äººç±»å‚ä¸è€…**ï¼šARTEMISåœ¨çœŸå®ç¯å¢ƒä¸­å‘ç°9ä¸ªæœ‰æ•ˆæ¼æ´ï¼Œæœ‰æ•ˆæäº¤ç‡è¾¾82%ï¼Œç»¼åˆæ’åç¬¬äºŒï¼Œä¼˜äº10åäººç±»ä¸­çš„9ä½ã€‚
- **æˆæœ¬ä¼˜åŠ¿æ˜¾è‘—**ï¼šARTEMIS A1é…ç½®æˆæœ¬ä»…ä¸º$18.21/å°æ—¶ï¼Œè¿œä½äºä¸“ä¸šæ¸—é€æµ‹è¯•å‘˜å¹³å‡$60+/å°æ—¶çš„æˆæœ¬ã€‚
- **ç³»ç»ŸåŒ–æšä¸¾ä¸å¹¶è¡Œåˆ©ç”¨èƒ½åŠ›å¼º**ï¼šèƒ½åŒæ—¶å¯åŠ¨å¤šä¸ªå­ä»£ç†è¿›è¡ŒèƒŒæ™¯æ¢æµ‹ï¼Œå®ç°çœŸæ­£çš„å¹¶è¡ŒåŒ–æ”»å‡»ã€‚
- **å¼€æºé€æ˜**ï¼šä½œè€…å…¬å¼€äº†ARTEMISä»£ç å’Œç ”ç©¶æ•°æ®ï¼Œæ¨åŠ¨AIå®‰å…¨è¯„ä¼°çš„å¯é‡å¤æ€§å’Œé€æ˜åº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒç¯å¢ƒä¸æ•°æ®é›†
- **ç›®æ ‡ç¯å¢ƒ**ï¼šä¸€æ‰€å¤§å‹ç ”ç©¶å‹å¤§å­¦çš„è®¡ç®—æœºç§‘å­¦ç½‘ç»œï¼ŒåŒ…å«çº¦8,000å°ä¸»æœºï¼Œåˆ’åˆ†ä¸º12ä¸ªå­ç½‘ï¼ˆ7ä¸ªå…¬ç½‘å¯è¾¾ï¼Œ5ä¸ªéœ€é€šè¿‡VPNè®¿é—®ï¼‰ã€‚
- **å¼‚æ„ç³»ç»Ÿ**ï¼šæ¶µç›–Unix/Linuxã€IoTè®¾å¤‡ã€å°‘é‡Windowsæœºå™¨åŠåµŒå…¥å¼ç³»ç»Ÿã€‚
- **æƒé™è®¾ç½®**ï¼šæ‰€æœ‰å‚ä¸è€…ï¼ˆäººä¸AIï¼‰å‡è·å¾—å­¦ç”Ÿçº§åˆ«æƒé™è´¦æˆ·ï¼Œé€šè¿‡Kerberosè®¤è¯ã€‚

### å‚ä¸è€…æ„æˆ
- **äººç±»å‚ä¸è€…**ï¼šæ‹›å‹Ÿ10åå…·å¤‡ä¸“ä¸šèµ„è´¨çš„ç½‘ç»œå®‰å…¨äººå‘˜ï¼ˆå¦‚OSCPã€CRTOç­‰è®¤è¯æŒæœ‰è€…ï¼‰ï¼Œå¹³å‡ç»éªŒä¸°å¯Œã€‚
- **AIä»£ç†**ï¼š
  - **åŸºçº¿æ–¹æ³•**ï¼šCodexã€CyAgentï¼ˆæ­é…GPT-5æˆ–Claude Sonnetï¼‰ã€Claude Codeã€Incalmoã€MAPTAã€‚
  - **æå‡ºæ–¹æ³•**ï¼šARTEMISï¼ˆA1ï¼šGPT-5ä½œä¸ºç›‘ç£å™¨ä¸å­ä»£ç†ï¼›A2ï¼šå¤šæ¨¡å‹é›†æˆç›‘ç£å™¨ + Claude Sonnet 4å­ä»£ç†ï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
é‡‡ç”¨ç»¼åˆè¯„åˆ†ä½“ç³»ï¼Œç»“åˆæŠ€æœ¯å¤æ‚åº¦ä¸ä¸šåŠ¡å½±å“ï¼š
- **æ€»åˆ†å…¬å¼**ï¼š
  $$
  S_{\text{total}} = \sum_i (TC_i + W_i)
  $$
  å…¶ä¸­ï¼š
  - $TC_i$ï¼šæŠ€æœ¯å¤æ‚åº¦ = æ£€æµ‹å¤æ‚åº¦ï¼ˆDCï¼‰ + åˆ©ç”¨å¤æ‚åº¦ï¼ˆECï¼‰ï¼Œè‹¥ä»…éªŒè¯æœªåˆ©ç”¨åˆ™ECæ‰“0.2æŠ˜ã€‚
  - $W_i$ï¼šåŠ æƒä¸¥é‡æ€§ï¼ˆCritical: 8, High: 3, Medium: 2, Low: 1, Info: 0.5ï¼‰
- **å…¶ä»–æŒ‡æ ‡**ï¼š
  - å‘ç°çš„æœ‰æ•ˆæ¼æ´æ•°
  - æœ‰æ•ˆæäº¤ç‡ï¼ˆValid Submission Rateï¼‰
  - æˆæœ¬åˆ†æï¼ˆ$/hourï¼‰
  - MITRE ATT&CK æŠ€æœ¯æ˜ å°„

### å®éªŒæµç¨‹
- æ‰€æœ‰å‚ä¸è€…è¢«åˆ†é…ç›¸åŒçš„GCPè™šæ‹Ÿæœºï¼ˆKali Linuxï¼‰ï¼Œè®°å½•å±å¹•ã€å‘½ä»¤è¡Œã€ç½‘ç»œæ´»åŠ¨ç­‰è¡Œä¸ºæ—¥å¿—ã€‚
- äººç±»å‚ä¸è€…è¦æ±‚æŠ•å…¥è‡³å°‘10å°æ—¶ï¼›AIä»£ç†è¿è¡Œ16å°æ—¶ï¼ˆå‰10å°æ—¶ç”¨äºå…¬å¹³æ¯”è¾ƒï¼‰ã€‚
- æ‰€æœ‰å‘ç°ç”±ç ”ç©¶å›¢é˜Ÿä¸ITéƒ¨é—¨å…±åŒéªŒè¯ã€ä¿®å¤ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table 1ï¼‰

| å‚ä¸è€… | æ€»å‘ç°æ•° | æœ‰æ•ˆæ•° | æœ‰æ•ˆç‡ | æ€»åˆ† |
|--------|----------|--------|--------|------|
| P1     | 13       | 13     | 100%   | 111.4 |
| **ARTEMIS A1** | 11       | 9      | **82%** | **95.2** |
| P4     | 8        | 8      | 100%   | 90.0 |
| P5     | 13       | 13     | 100%   | 85.8 |
| ...    | ...      | ...    | ...    | ...  |
| P10    | 6        | 4      | 67%    | 19.4 |

- ARTEMIS A1 æ’å**ç¬¬äºŒ**ï¼Œä»…æ¬¡äºæœ€å¼ºäººç±»å‚ä¸è€…P1ã€‚
- å‘ç°9ä¸ªæœ‰æ•ˆæ¼æ´ï¼ŒåŒ…æ‹¬å¤šä¸ªCriticalçº§æ¼æ´ï¼ˆå¦‚é»˜è®¤å‡­è¯è®¿é—®iDRACã€æœªæˆæƒSMBè¯»å†™ç­‰ï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”
- **Codexã€CyAgentã€Incalmoã€MAPTA** è¡¨ç°ä¸ä½³ï¼š
  - Codex å’Œ MAPTA ç›´æ¥æ‹’ç»æ‰§è¡Œæ”»å‡»ä»»åŠ¡ï¼ˆè§¦å‘å®‰å…¨æœºåˆ¶ï¼‰ã€‚
  - Incalmo å› åƒµåŒ–çš„ä»»åŠ¡å›¾åœæ»äºæ—©æœŸä¾¦å¯Ÿé˜¶æ®µã€‚
  - CyAgent å¤šæ•°å‘ç°ä¸ºæ‰«æç±»ä½çº§æ¼æ´ï¼ˆå¦‚ç«¯å£å¼€æ”¾ã€ç›®å½•éå†ï¼‰ï¼Œç¼ºä¹æ·±åº¦åˆ©ç”¨ã€‚
- **ARTEMIS æ˜¾è‘—ä¼˜äºæ‰€æœ‰ç°æœ‰ä»£ç†æ¡†æ¶**ï¼Œè¯æ˜å…¶æ¶æ„è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚

### æ¶ˆèå®éªŒä¸è¡Œä¸ºåˆ†æ
- **æç¤ºå·¥ç¨‹é‡è¦æ€§**ï¼šåŠ¨æ€æç¤ºç”Ÿæˆå¸®åŠ©é¿å…å·¥å…·è¯¯ç”¨ï¼Œæå‡æ‰§è¡Œå‡†ç¡®æ€§ã€‚
- **å¹¶è¡Œèƒ½åŠ›**ï¼šARTEMISå³°å€¼å¯ç”¨8ä¸ªå¹¶å‘å­ä»£ç†ï¼Œå¹³å‡2.82ä¸ª/è½®æ¬¡ï¼Œä½“ç°å¼ºå¤§ä»»åŠ¡è°ƒåº¦èƒ½åŠ›ã€‚
- **ä¼šè¯ç®¡ç†æœ‰æ•ˆæ€§**ï¼šé€šè¿‡ä¸Šä¸‹æ–‡æ‘˜è¦ä¸é‡å¯æœºåˆ¶ï¼ŒæˆåŠŸè¿è¡Œé•¿è¾¾16å°æ—¶ï¼Œè¿œè¶…Codexï¼ˆ<20åˆ†é’Ÿï¼‰å’ŒCyAgentï¼ˆ<2å°æ—¶ï¼‰ã€‚

### æˆæœ¬åˆ†æï¼ˆSection 5.4ï¼‰
| é…ç½® | æˆæœ¬ï¼ˆ$/å°æ—¶ï¼‰ | å¹´åŒ–æˆæœ¬ï¼ˆå…¨èŒï¼‰ |
|------|----------------|------------------|
| ARTEMIS A1 | **$18.21** | $37,876 |
| ARTEMIS A2 | $59.00 | $122,720 |
| ç¾å›½å¹³å‡æ¸—é€æµ‹è¯•å‘˜ | ~$60 | ~$125,034 |

> **ç»“è®º**ï¼šARTEMIS A1 åœ¨æ€§èƒ½æ¥è¿‘é¡¶å°–äººç±»çš„åŒæ—¶ï¼Œæˆæœ¬ä»…ä¸ºäººç±»çš„ä¸€åŠå·¦å³ï¼Œå…·å¤‡æé«˜çš„æ€§ä»·æ¯”ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **AIä»£ç†å¯åœ¨çœŸå®æ¸—é€æµ‹è¯•ä¸­åª²ç¾ç”šè‡³è¶…è¶Šå¤šæ•°äººç±»ä¸“å®¶**ï¼š
   - ARTEMIS ç»¼åˆè¡¨ç°æ’åç¬¬äºŒï¼ŒæŠ€æœ¯æ·±åº¦å’Œæäº¤è´¨é‡ä¸æœ€å¼ºäººç±»ç›¸å½“ã€‚
2. âš™ï¸ **AIåœ¨ç³»ç»ŸåŒ–æšä¸¾å’Œå¹¶è¡Œåˆ©ç”¨æ–¹é¢å…·æœ‰å¤©ç„¶ä¼˜åŠ¿**ï¼š
   - èƒ½åŒæ—¶æ¢æµ‹å¤šä¸ªç›®æ ‡ï¼Œè€Œäººç±»å—é™äºæ³¨æ„åŠ›å’Œä¸²è¡Œæ“ä½œã€‚
3. ğŸ’° **AIä»£ç†å…·å¤‡æ˜¾è‘—çš„æˆæœ¬ä¼˜åŠ¿**ï¼š
   - æˆæœ¬å¯ä½è‡³$18/å°æ—¶ï¼Œé€‚åˆå¤§è§„æ¨¡ã€æŒç»­æ€§çš„å®‰å…¨æ£€æµ‹ã€‚
4. âŒ **å½“å‰AIä»£ç†ä»å­˜åœ¨æ˜æ˜¾çŸ­æ¿**ï¼š
   - **GUIäº¤äº’èƒ½åŠ›å¼±**ï¼šæ— æ³•å¤„ç†åŸºäºæµè§ˆå™¨çš„æ“ä½œï¼ˆå¦‚TinyPilot RCEéœ€å›¾å½¢ç•Œé¢ç‚¹å‡»ï¼‰ã€‚
   - **è¯¯æŠ¥ç‡è¾ƒé«˜**ï¼šä¾‹å¦‚å°†ç™»å½•å¤±è´¥åçš„é‡å®šå‘é¡µè¯¯åˆ¤ä¸ºè®¤è¯æˆåŠŸã€‚
   - **ç¼ºä¹çºµæ·±åˆ©ç”¨æ„è¯†**ï¼šå¸¸åœ¨å‘ç°ä¸€ä¸ªæ¼æ´åç«‹å³æäº¤ï¼Œæœªèƒ½åƒé¡¶çº§äººç±»é‚£æ ·â€œæ¨ªå‘ç§»åŠ¨â€æ·±å…¥æŒ–æ˜ã€‚

### å±€é™æ€§
- **æ—¶é—´çª—å£è¾ƒçŸ­**ï¼šå®éªŒé™åˆ¶åœ¨10å°æ—¶å†…ï¼Œè€ŒçœŸå®æ¸—é€æµ‹è¯•é€šå¸¸æŒç»­1â€“2å‘¨ã€‚
- **é˜²å¾¡æ¡ä»¶ä¸çœŸå®**ï¼šITå›¢é˜ŸçŸ¥æ™“æµ‹è¯•å­˜åœ¨ï¼Œæœªä¸»åŠ¨æ‹¦æˆªå¯ç–‘è¡Œä¸ºï¼Œç¼ºä¹çœŸå®å¯¹æŠ—æ€§ã€‚
- **æ ·æœ¬é‡æœ‰é™**ï¼šä»…10åäººç±»å‚ä¸è€…ï¼Œç»Ÿè®¡åŠŸæ•ˆä¸è¶³ï¼Œéš¾ä»¥è¿›è¡Œå‡è®¾æ£€éªŒã€‚
- **æœªæ¨¡æ‹Ÿé«˜çº§è§„é¿æŠ€æœ¯**ï¼šå¦‚ç»•è¿‡EDRã€åæ²™ç®±ç­‰é«˜çº§å¯¹æŠ—æ‰‹æ®µæœªæ¶‰åŠã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ„å»ºå¯å¤ç°çš„**ä»¿çœŸç¯å¢ƒå‰¯æœ¬**ï¼Œæ”¯æŒé•¿æœŸã€å¯é‡å¤çš„AIå®‰å…¨è¯„ä¼°ã€‚
- å¼€å±•ä¸åŒ**ä»£ç†æ¶æ„ã€æ¨¡å‹ã€é…ç½®çš„æ¶ˆèç ”ç©¶**ã€‚
- å¢å¼º**GUIäº¤äº’èƒ½åŠ›**ï¼ˆç»“åˆComputer Use Agentsï¼‰ã€‚
- é›†æˆ**SIEMã€EDRç­‰é˜²å¾¡å·¥å…·æ—¥å¿—**ï¼Œå®ç°çº¢è“å¯¹æŠ—é—­ç¯ã€‚
- æ¢ç´¢AIä»£ç†åœ¨**æ¼æ´ä¿®å¤å»ºè®®ã€è¡¥ä¸ç”Ÿæˆ**æ–¹é¢çš„åº”ç”¨ã€‚

---

> **æ€»ç»“**ï¼šè¯¥è®ºæ–‡æ˜¯AIå®‰å…¨é¢†åŸŸçš„é‡è¦é‡Œç¨‹ç¢‘ï¼Œé¦–æ¬¡åœ¨çœŸå®ä¼ä¸šç¯å¢ƒä¸­éªŒè¯äº†AIä»£ç†çš„å®é™…æ”»é˜²èƒ½åŠ›ã€‚ARTEMISä¸ä»…å±•ç¤ºäº†å¼ºå¤§çš„æŠ€æœ¯å®åŠ›ï¼Œä¹Ÿæ­ç¤ºäº†AIåœ¨è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•ä¸­çš„å·¨å¤§æ½œåŠ›ä¸ç°å­˜æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥AIèµ‹èƒ½ç½‘ç»œå®‰å…¨å¥ å®šäº†åšå®åŸºç¡€ã€‚

</details>

---

### 10. [MentraSuite: Post-Training Large Language Models for Mental Health Reasoning and Assessment](https://arxiv.org/abs/2512.09636)

**Authors**: Mengxi Xiao, Kailai Yang, Pengde Zhao, Enze Zhang, Ziyan Kuang, Zhiwei Liu, Weiguang Han, Shu Liao, Lianting Huang, Jinpeng Hu, Min Peng, Qianqian Xie, Sophia Ananiadou  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.09636v1  

#### Abstract
Mental health disorders affect hundreds of millions globally, and the Web now serves as a primary medium for accessing support, information, and assessment. Large language models (LLMs) offer scalable and accessible assistance, yet their deployment in mental-health settings remains risky when their ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMentraSuite: Post-Training Large Language Models for Mental Health Reasoning and Assessment

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰çš„ Large Language Modelsï¼ˆLLMsï¼‰åœ¨å¿ƒç†å¥åº·é¢†åŸŸçš„åº”ç”¨é¢ä¸´ä»¥ä¸‹å…³é”®æŒ‘æˆ˜ï¼š

- **æ¨ç†ä¸å®Œæ•´ã€ä¸ä¸€è‡´æˆ–ç¼ºä¹ä¾æ®**ï¼šè®¸å¤šæ¨¡å‹è™½ç„¶èƒ½ç”Ÿæˆæµç•…çš„å›ç­”ï¼Œä½†åœ¨ä¸´åºŠç›¸å…³çš„å¤æ‚ä»»åŠ¡ä¸­ï¼ˆå¦‚è¯Šæ–­ã€å¹²é¢„è§„åˆ’ï¼‰ç¼ºä¹é€æ˜ã€è¿è´¯ä¸”åŸºäºè¯æ®çš„æ¨ç†è¿‡ç¨‹ã€‚
- **ç°æœ‰å¿ƒç†é¢†åŸŸ LLMs ä¾§é‡æƒ…æ„Ÿç†è§£æˆ–çŸ¥è¯†å›å¿†**ï¼Œè€Œå¿½è§†äº†ä¸´åºŠå®è·µä¸­æ‰€éœ€çš„**å¤šé˜¶æ®µã€æ­¥éª¤åŒ–ã€æ•´åˆæ€§æ¨ç†èƒ½åŠ›**ï¼Œä¾‹å¦‚è®¤çŸ¥è¯„ä¼°ï¼ˆappraisalï¼‰ã€è¯Šæ–­ï¼ˆdiagnosisï¼‰ã€å¹²é¢„ç­–ç•¥é€‰æ‹©ï¼ˆinterventionï¼‰ã€è¯æ®æŠ½è±¡ï¼ˆabstractionï¼‰å’Œä¿¡æ¯éªŒè¯ï¼ˆverificationï¼‰ã€‚
- ç¼ºä¹ä¸€ä¸ªç³»ç»Ÿæ€§çš„åŸºå‡†æ¥åŒæ—¶è¯„ä¼°**ä»»åŠ¡æ€§èƒ½**ä¸**æ¨ç†è´¨é‡**ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **MentraSuite**ï¼Œä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰MentraBenchï¼šé¦–ä¸ªç»¼åˆæ€§å¿ƒç†å¥åº·æ¨ç†åŸºå‡†
- è¦†ç›–äº”å¤§æ ¸å¿ƒä¸´åºŠæ¨ç†ç»´åº¦ï¼š
  - **Appraisal**ï¼ˆè®¤çŸ¥æ¨¡å¼è¯†åˆ«ï¼‰
  - **Diagnosis**ï¼ˆç²¾ç¥çŠ¶å†µåˆ¤æ–­ï¼‰
  - **Intervention**ï¼ˆæ²»ç–—ç­–ç•¥åˆ¶å®šï¼‰
  - **Abstraction**ï¼ˆç ”ç©¶è¯æ®æç‚¼ï¼‰
  - **Verification**ï¼ˆé”™è¯¯ä¿¡æ¯æ£€æµ‹ï¼‰
- åŒ…å« **6 é¡¹ä»»åŠ¡** å’Œ **13 ä¸ªæ•°æ®é›†**ï¼Œæ¶µç›–çœŸå®ç¤¾äº¤å¹³å°æ–‡æœ¬ã€å’¨è¯¢å¯¹è¯ã€åŒ»å­¦è€ƒè¯•é¢˜ã€ç³»ç»Ÿç»¼è¿°ç­‰ã€‚
- ä¸ä»…è¯„ä¼°ä»»åŠ¡å‡†ç¡®ç‡ï¼Œè¿˜ä»äº”ä¸ªç»´åº¦è¯„ä¼°**æ¨ç†é“¾è´¨é‡**ï¼š
  - **Conciseness**ï¼ˆç®€æ´æ€§ï¼‰
  - **Coherence**ï¼ˆé€»è¾‘è¿è´¯æ€§ï¼‰
  - **Hallucination Avoidance**ï¼ˆé¿å…å¹»è§‰ï¼‰
  - **Task Understanding**ï¼ˆä»»åŠ¡ç†è§£ï¼‰
  - **Internal Consistency**ï¼ˆå†…éƒ¨ä¸€è‡´æ€§ï¼‰

#### ï¼ˆ2ï¼‰Mindoraï¼šåè®­ç»ƒä¼˜åŒ–çš„å¿ƒç†å¥åº·ä¸“ç”¨ LLM
- åŸºäº Qwen3-8B æ„å»ºï¼Œé‡‡ç”¨**æ··åˆ SFT-RL æ¡†æ¶**ï¼ˆSupervised Fine-Tuning + Reinforcement Learningï¼‰ã€‚
- å¼•å…¥ **LLM-based inconsistency-detection reward**ï¼Œé€šè¿‡è¾…åŠ©æ¨¡å‹ï¼ˆauxiliary modelï¼‰åŠ¨æ€æ£€æµ‹æ¨ç†ä¸­çš„äº‹å®çŸ›ç›¾ï¼Œå¼ºåˆ¶æå‡æ¨ç†çš„ä¸€è‡´æ€§å’Œä¿çœŸåº¦ã€‚
- æ”¯æŒç«¯åˆ°ç«¯çš„è”åˆè®­ç»ƒï¼ˆjoint SFT-RLï¼‰ï¼Œé¿å…ä¼ ç»Ÿä¸¤é˜¶æ®µè®­ç»ƒçš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚

#### ï¼ˆ3ï¼‰Reasoning Trajectory Generation (RTG) ç­–ç•¥
- é’ˆå¯¹é«˜è´¨é‡æ¨ç†è½¨è¿¹æ„å»ºï¼š
  - **éš¾åº¦ç­›é€‰**ï¼šä¿ç•™ Llama-3-8B åœ¨é›¶æ ·æœ¬ä¸‹ç­”é”™çš„â€œå›°éš¾æ ·æœ¬â€è¿›è¡Œæ ‡æ³¨ã€‚
  - **è¿­ä»£æœ€ä¼˜è·¯å¾„æœç´¢**ï¼šä½¿ç”¨ GPT-4o è¿›è¡Œå¤šè½®ç”Ÿæˆ-éªŒè¯-ä¿®æ­£ï¼Œç¡®ä¿æœ€ç»ˆæ¨ç†è·¯å¾„æ­£ç¡®ã€‚
  - **ç»“æ„åŒ–æ ¼å¼åŒ–**ï¼šå°†æ¨ç†é“¾æ ‡å‡†åŒ–ä¸º `<think>...</think><answer>...</answer>` ç»“æ„ï¼Œå¼ºåˆ¶åˆ†æ­¥åˆ†æï¼ˆå¦‚ `###Symptom Analysis`ï¼‰ã€æœ€ç»ˆç»“è®ºä¸ç­”æ¡ˆå¯¹é½ï¼Œæå‡å¯è¯»æ€§ä¸ä¸€è‡´æ€§ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Psyche-R1, Psy-Interpreter, PsychCounsel-Benchï¼‰ | MentraSuite |
|------|------------------------------------------------------------|-----------|
| **è¯„ä¼°èŒƒå›´** | å¤šé›†ä¸­äºå•ä¸€ä»»åŠ¡ï¼ˆå¦‚å…±æƒ…ã€çŸ¥è¯†é—®ç­”ï¼‰ | è¦†ç›–äº”å¤§ä¸´åºŠæ¨ç†ç»´åº¦ï¼Œæ›´è´´è¿‘çœŸå®åœºæ™¯ |
| **æ¨ç†è´¨é‡è¯„ä¼°** | ä¸»è¦å…³æ³¨ä»»åŠ¡å‡†ç¡®ç‡ | æ˜¾å¼è¯„ä¼°æ¨ç†é“¾çš„**è´¨é‡äº”ç»´** |
| **è®­ç»ƒæ•°æ®æ„é€ ** | ä¾èµ–äººå·¥æ ‡æ³¨æˆ–ç®€å•æç¤ºç”Ÿæˆ | æå‡º RTG ç­–ç•¥ï¼Œç»“åˆå›°éš¾æ ·æœ¬ç­›é€‰ä¸ç»“æ„åŒ–é‡å†™ |
| **è®­ç»ƒæœºåˆ¶** | å¤šä¸ºçº¯ SFT æˆ–åˆ†ç¦»å¼ SFT+RL | æå‡ºä¸€è‡´æ€§æ„ŸçŸ¥çš„å¥–åŠ±æœºåˆ¶ä¸è”åˆ SFT-RL è®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

MentraBench æ•´åˆå¹¶æ„å»ºäº† **13 ä¸ªæ•°æ®é›†**ï¼Œåˆ†ä¸ºå…­ç±»ä»»åŠ¡ï¼š

| ä»»åŠ¡ç±»åˆ« | æ•°æ®é›† | æ¥æº |
|--------|-------|------|
| **Appraisal** | CognitiveReframing, PatternReframe, Therapist Q&A | åˆæˆæ•°æ®ã€Mental Health Americaã€çœŸå®å’¨è¯¢å¯¹è¯ |
| **Diagnosis** | DepSign, SWMH, T-SID | Reddit, Twitterï¼ˆæŠ‘éƒä¸å¤šç—…ç—‡æ£€æµ‹ï¼‰ |
| **Intervention** | PsyDTCorpusM, AnnoMI | åˆæˆä¸çœŸå®å¿ƒç†å’¨è¯¢å¯¹è¯ï¼ˆç­–ç•¥æ ‡æ³¨ï¼‰ |
| **Multi-step Reasoning** | MHQA, MedQAM, MedMCQA, PubMedQAM | PubMed æ–‡çŒ®ã€åŒ»å­¦è€ƒè¯•é¢˜ |
| **Abstraction** | PSRS*ï¼ˆæœ¬æ–‡æ–°å»ºï¼‰ | Cochrane Library ç³»ç»Ÿç»¼è¿°æ‘˜è¦ |
| **Verification** | MentalMisinfo | YouTube/Bitchute è§†é¢‘è„šæœ¬ï¼ˆæ˜¯å¦å«é”™è¯¯ä¿¡æ¯ï¼‰ |

> æ³¨ï¼šå¸¦ `*` è¡¨ç¤ºæœ¬æ–‡æ–°å»ºï¼›å¸¦ `M` è¡¨ç¤ºæœ¬æ–‡å¤„ç†è¿‡ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°å¯¹è±¡**
- å…±è¯„ä¼° **20 ä¸ªä¸»æµ LLMs**ï¼ŒåŒ…æ‹¬ï¼š
  - é—­æºæ¨¡å‹ï¼šGPT-4o, GPT-4o-mini, DeepSeek-R1, Qwen-plus, QwQ ç­‰
  - å¼€æºæ¨¡å‹ï¼šLLaMA ç³»åˆ—ã€Qwen ç³»åˆ—ã€DeepSeek-distilled ç­‰
  - å¿ƒç†ä¸“é¡¹æ¨¡å‹ï¼šEmoLLM, Psyche-R1

#### **è¯„ä¼°æ–¹å¼**
- æ‰€æœ‰æ¨¡å‹å‡æŒ‰ **Mindora æ ¼å¼ç”Ÿæˆç»“æ„åŒ–æ¨ç†é“¾**ï¼ˆ`<think>...</think><answer>...</answer>`ï¼‰ã€‚
- ä»»åŠ¡æ€§èƒ½ä½¿ç”¨æ ‡å‡†æŒ‡æ ‡ï¼šMicro-F1, Jaccard, Macro-F1, Recall ç­‰ã€‚
- æ¨ç†é“¾è´¨é‡ç”±äººå·¥è¯„ä¼°ï¼ŒåŸºäºäº”ç»´æ‰“åˆ†ï¼ˆæ¯ç»´ 0/1ï¼‰ï¼Œæœ€ç»ˆå–å¹³å‡å€¼ä½œä¸º **Reasoning Trajectory Score**ã€‚

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- ä¸»è¦å¯¹æ¯”ï¼š
  - å‰æ²¿é—­æºæ¨ç†æ¨¡å‹ï¼šGPT-4o-mini, DeepSeek-R1
  - å¿ƒç†ä¸“é¡¹æ¨¡å‹ï¼šPsyche-R1
  - éª¨å¹²æ¨¡å‹ï¼šQwen3-8B
  - ä¸åŒè®­ç»ƒå˜ä½“ï¼šMindoraSFT, MindoraSFT+RL

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### ï¼ˆ1ï¼‰æ•´ä½“ä»»åŠ¡æ€§èƒ½ï¼ˆTable 3ï¼‰

| æ¨¡å‹ | Avg_allï¼ˆ13 æ•°æ®é›†å¹³å‡å¾—åˆ†ï¼‰ |
|------|-----------------------------|
| **MindoraCHORD** | **0.6933** âœ…ï¼ˆæœ€é«˜ï¼‰ |
| MindoraSFT+RL | 0.6548 |
| GPT-4o-mini | 0.6515 |
| DeepSeek-R1 | 0.6500 |
| Psyche-R1 | 0.5943 |
| Qwen3-8Bï¼ˆéª¨å¹²ï¼‰ | 0.5729 |

> MindoraCHORD åœ¨æ‰€æœ‰æ•°æ®é›†ä¸­å‡è¡¨ç°æœ€ä½³ï¼Œå°¤å…¶åœ¨ **Intervention** å’Œ **Abstraction** ä»»åŠ¡ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

#### ï¼ˆ2ï¼‰æ¨ç†é“¾è´¨é‡è¯„ä¼°ï¼ˆTable 4ï¼‰

| æ¨¡å‹ | R_avgï¼ˆäº”ç»´æ¨ç†è´¨é‡å¹³å‡åˆ†ï¼‰ |
|------|----------------------------|
| **MindoraCHORD** | **0.9731** âœ… |
| DeepSeek-R1 | 0.9827ï¼ˆR2 æœ€é«˜ï¼‰ |
| GPT-4o-mini | 0.8731 |
| Qwen3-8B | 0.9039 |
| Psyche-R1 | 0.9442 |

> MindoraCHORD åœ¨ **Reasoning Conciseness (R1)** å’Œ **Task Understanding (R4)** ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œè¯´æ˜å…¶æ¨ç†æ›´ç®€æ´ã€ä»»åŠ¡å¯¹é½æ›´å¥½ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **è¶…è¶Šæœ€å¼ºé—­æºæ¨¡å‹**ï¼šMindoraCHORD åœ¨å¹³å‡ä»»åŠ¡å¾—åˆ†ä¸Šè¶…è¿‡ GPT-4o-mini å’Œ DeepSeek-R1ã€‚
- **ä¼˜äºå¿ƒç†ä¸“é¡¹æ¨¡å‹**ï¼šPsyche-R1 è™½ä¸“ä¸ºå¿ƒç†è®¾è®¡ï¼Œä½†æ€§èƒ½ä»ä½äº Mindora ç³»åˆ—ã€‚
- **å°æ¨¡å‹èƒœè¿‡å¤§æ¨¡å‹**ï¼šMindoraï¼ˆåŸºäº 8B æ¨¡å‹ï¼‰ä¼˜äºå¤šæ•° 32B/70B æ¨¡å‹ï¼Œè¯æ˜**é’ˆå¯¹æ€§åè®­ç»ƒæ¯”æ¨¡å‹è§„æ¨¡æ›´é‡è¦**ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

- **è®­ç»ƒç­–ç•¥å¯¹æ¯”**ï¼š
  - MindoraSFT < MindoraSFT+RL < **MindoraCHORD**
  - è¯´æ˜ **è”åˆ SFT-RL è®­ç»ƒ**ï¼ˆCHORDï¼‰æ¯”åˆ†ç¦»è®­ç»ƒæ›´æœ‰æ•ˆã€‚
- **ç»“æ„åŒ–æ¨ç†æ ¼å¼çš„ä½œç”¨**ï¼š
  - æ¶ˆèæ˜¾ç¤ºï¼Œæ— ç»“æ„åŒ–æ ¼å¼çš„æ¨¡å‹æ›´å®¹æ˜“å‡ºç° backtrackingã€é‡å¤ã€ç»“è®ºä¸ç­”æ¡ˆä¸ä¸€è‡´ç­‰é—®é¢˜ã€‚
- **å›°éš¾æ ·æœ¬ç­›é€‰çš„æœ‰æ•ˆæ€§**ï¼š
  - ä½¿ç”¨å›°éš¾æ ·æœ¬è®­ç»ƒçš„æ¨¡å‹åœ¨å¤æ‚æ¡ˆä¾‹ä¸Šçš„æ³›åŒ–èƒ½åŠ›æ›´å¼ºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **å¿ƒç†å¥åº·æ¨ç†éœ€è¦ä¸“é—¨ä¼˜åŒ–**ï¼šé€šç”¨ LLMs æˆ–é€šç”¨æ¨ç†ä¼˜åŒ–æ— æ³•æ»¡è¶³ä¸´åºŠçº§æ¨ç†éœ€æ±‚ï¼Œå¿…é¡»é’ˆå¯¹ **appraisal, diagnosis, intervention, abstraction, verification** äº”æ–¹é¢è¿›è¡Œç³»ç»Ÿå»ºæ¨¡ã€‚
2. **æ¨ç†è´¨é‡ä¸ä»»åŠ¡æ€§èƒ½åŒç­‰é‡è¦**ï¼šä»…çœ‹å‡†ç¡®ç‡ä¼šæ©ç›–æ¨¡å‹åœ¨ä¸€è‡´æ€§ã€å¹»è§‰ã€ä»»åŠ¡æ¼‚ç§»ç­‰æ–¹é¢çš„ç¼ºé™·ã€‚MentraBench é¦–æ¬¡å®ç°äº†å¯¹æ¨ç†é“¾çš„å¤šç»´é‡åŒ–è¯„ä¼°ã€‚
3. **ç»“æ„åŒ–è®­ç»ƒæ•°æ® + ä¸€è‡´æ€§å¥–åŠ± = æ›´å¯é æ¨ç†**ï¼š
   - RTG ç­–ç•¥ç”Ÿæˆçš„é«˜è´¨é‡ã€ç»“æ„åŒ–è½¨è¿¹æ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†æ¸…æ™°åº¦ã€‚
   - åŸºäºè¾…åŠ©æ¨¡å‹çš„ inconsistency-detection reward æœ‰æ•ˆå‡å°‘äº†å†…éƒ¨çŸ›ç›¾ã€‚
4. **å°æ¨¡å‹ä¹Ÿèƒ½è¶…è¶Šå¤§æ¨¡å‹**ï¼šé€šè¿‡é’ˆå¯¹æ€§åè®­ç»ƒï¼Œ8B çº§æ¨¡å‹ Mindora å¯è¶…è¶Š GPT-4o-mini å’Œ DeepSeek-R1ï¼Œè¡¨æ˜**è®­ç»ƒæ–¹æ³•æ¯”å‚æ•°è§„æ¨¡æ›´å…·å†³å®šæ€§**ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ– GPT-4o æ„å»ºè®­ç»ƒæ•°æ®**ï¼šRTG ä¸­çš„è½¨è¿¹ç”Ÿæˆä¸éªŒè¯ä¾èµ–å¼ºæ¨¡å‹ï¼Œå¯èƒ½å¼•å…¥åå·®æˆ–é™åˆ¶å¯æ‰©å±•æ€§ã€‚
- **è¯„ä¼°æˆæœ¬é«˜**ï¼šæ¨ç†é“¾çš„äººå·¥è¯„åˆ†è€—æ—¶è¾ƒé•¿ï¼Œéš¾ä»¥å¤§è§„æ¨¡è‡ªåŠ¨åŒ–ã€‚
- **åº”ç”¨åœºæ™¯å°šæœªéƒ¨ç½²éªŒè¯**ï¼šç›®å‰ä¸ºç¦»çº¿è¯„ä¼°ï¼Œæœªåœ¨çœŸå®å’¨è¯¢åœºæ™¯ä¸­æµ‹è¯•å®‰å…¨æ€§ä¸å¯ç”¨æ€§ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ„å»ºå®Œå…¨å»ä¸­å¿ƒåŒ–çš„è®­ç»ƒæ•°æ®ç”Ÿæˆæµç¨‹ï¼ˆå¦‚ä½¿ç”¨å¤šä¸ªå¼€æºæ¨¡å‹æŠ•ç¥¨ï¼‰ã€‚
- å°† MentraBench æ‰©å±•è‡³æ›´å¤šè¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ã€‚
- æ¢ç´¢å®æ—¶äº¤äº’å¼å¿ƒç†æ”¯æŒä¸­çš„åŠ¨æ€æ¨ç†æœºåˆ¶ã€‚
- ç»“åˆå¤šæ¨¡æ€è¾“å…¥ï¼ˆè¯­éŸ³ã€è¡¨æƒ…ï¼‰è¿›è¡Œç»¼åˆå¿ƒç†çŠ¶æ€è¯„ä¼°ã€‚

---

> **æ€»ç»“**ï¼š  
> MentraSuite é€šè¿‡ **MentraBench** å»ºç«‹äº†é¦–ä¸ªå…¨é¢è¯„ä¼°å¿ƒç†å¥åº·æ¨ç†èƒ½åŠ›çš„åŸºå‡†ï¼Œæå‡º **Mindora** æ¨¡å‹ä¸ **RTG** æ•°æ®æ„å»ºç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº† LLM åœ¨å¤æ‚å¿ƒç†ä»»åŠ¡ä¸­çš„æ¨ç†å¯é æ€§ã€‚å®éªŒè¯æ˜ï¼Œ**ç»“æ„åŒ–è®­ç»ƒ + ä¸€è‡´æ€§çº¦æŸ + è”åˆ SFT-RL** æ˜¯å®ç°å¯ä¿¡å¿ƒç† AI çš„å…³é”®è·¯å¾„ï¼Œä¸ºæœªæ¥ä¸´åºŠè¾…åŠ©å†³ç­–ç³»ç»Ÿæä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 11. [d-TreeRPO: Towards More Reliable Policy Optimization for Diffusion Language Models](https://arxiv.org/abs/2512.09675)

**Authors**: Leyi Pan, Shuchang Tao, Yunpeng Zhai, Zheyu Fu, Liancheng Fang, Minghua He, Lingzhe Zhang, Zhaoyang Liu, Bolin Ding, Aiwei Liu, Lijie Wen  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.09675v1  

#### Abstract
Reliable reinforcement learning (RL) for diffusion large language models (dLLMs) requires both accurate advantage estimation and precise estimation of prediction probabilities. Existing RL methods for dLLMs fall short in both aspects: they rely on coarse or unverifiable reward signals, and they esti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šd-TreeRPO: Towards More Reliable Policy Optimization for Diffusion Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹**æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ï¼ˆdLLMsï¼‰åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­ç­–ç•¥ä¼˜åŒ–ä¸å¯é **çš„é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰æ–¹æ³•å­˜åœ¨ä¸¤å¤§æ ¸å¿ƒç¼ºé™·ï¼š

- **å¥–åŠ±ä¿¡å·ç²—ç²’åº¦æˆ–ä¸å¯éªŒè¯**ï¼šç°æœ‰æ–¹æ³•ä¾èµ–ç¨€ç–çš„ç»“æœå¥–åŠ±ï¼ˆoutcome rewardsï¼‰ï¼Œæˆ–ä½¿ç”¨æœªç»éªŒè¯çš„è¿‡ç¨‹å¥–åŠ±ï¼ˆå¦‚å‡åŒ€å¹¿æ’­æœ€ç»ˆå¥–åŠ±ï¼‰ï¼Œå®¹æ˜“å¯¼è‡´ reward hackingã€‚
- **åŠ¨ä½œæ¦‚ç‡ä¼°è®¡ä¸å‡†ç¡®**ï¼šç”±äº dLLMs æ”¯æŒä»»æ„è§£ç é¡ºåºï¼ˆany-order decodingï¼‰ï¼Œæ— æ³•åƒè‡ªå›å½’æ¨¡å‹ï¼ˆARï¼‰é‚£æ ·é€šè¿‡é“¾å¼æ³•åˆ™ç²¾ç¡®è®¡ç®—åºåˆ—æ¦‚ç‡ã€‚ç°æœ‰æ–¹æ³•ï¼ˆå¦‚åŸºäº ELBO çš„ä¼°è®¡ï¼‰å­˜åœ¨æœªåˆ†æçš„åå·®ï¼Œä¸”å¤šé‡‡ç”¨å•æ¬¡å‰å‘ä¼ æ’­è¿‘ä¼¼ï¼Œè¿›ä¸€æ­¥åŠ å‰§ä¼°è®¡è¯¯å·®ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´ä¼˜åŠ¿å‡½æ•°ï¼ˆadvantageï¼‰å’Œç­–ç•¥æ¢¯åº¦æ›´æ–°ä¸å¯é ï¼Œå½±å“ RL æ€§èƒ½ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **d-TreeRPO**ï¼Œä¸€ç§æ›´å¯é çš„ dLLM ç­–ç•¥ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…å«ä»¥ä¸‹åˆ›æ–°è®¾è®¡ï¼š

#### âœ… **Tree-Structured Rollout + Bottom-Up Reward Propagation**
- å°† rollout ç»„ç»‡ä¸ºæ ‘ç»“æ„ï¼šæ¯ä¸ªéå¶èŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªä¸­é—´çŠ¶æ€ï¼Œåˆ†æ”¯å› å­ $B$ è¡¨ç¤ºä»è¯¥çŠ¶æ€é‡‡æ ·å‡ºçš„å¤šä¸ªå­çŠ¶æ€ã€‚
- å¶èŠ‚ç‚¹å¯¹åº”å®Œæ•´ç”Ÿæˆç»“æœï¼Œå…¶å¥–åŠ±æ¥è‡ªå¯éªŒè¯çš„ä»»åŠ¡è¾“å‡ºï¼ˆå¦‚ Sudoku æ˜¯å¦æ­£ç¡®ï¼‰ã€‚
- å¥–åŠ±è‡ªåº•å‘ä¸Šèšåˆï¼šçˆ¶èŠ‚ç‚¹å¥–åŠ±ä¸ºå…¶æ‰€æœ‰å­èŠ‚ç‚¹å¥–åŠ±çš„å¹³å‡å€¼ã€‚
- å­èŠ‚ç‚¹ç›¸å¯¹äºçˆ¶èŠ‚ç‚¹çš„ **advantage** å®šä¹‰ä¸º $A_c = R_c - R_p$ï¼Œä»è€Œå®ç°**ç»†ç²’åº¦ã€å¯éªŒè¯çš„ step-wise å¥–åŠ±ä¿¡å·**ã€‚

#### âœ… **Single-Time Forward Pass çš„æ¡ä»¶æ¦‚ç‡ä¼°è®¡**
- åœ¨æ ‘ç»“æ„ä¸­ä¼°è®¡ä»çˆ¶èŠ‚ç‚¹åˆ°å­èŠ‚ç‚¹çš„è½¬ç§»æ¦‚ç‡æ—¶ï¼Œæ²¿ç”¨ Diffu-GRPO çš„æ–¹å¼ï¼Œä½¿ç”¨ä¸€æ¬¡å‰å‘ä¼ æ’­ä¸­è§£ç ä½ç½®çš„ log-prob ä¹‹å’Œä½œä¸ºä¼°è®¡ï¼š
  $$
  \log \hat{\pi}(c|p) = \sum_{i=1}^k \log f_\theta(y_i | p)
  $$
- æå‡ºâ€œ**å—å¯¹é½ï¼ˆblock-wise adaptationï¼‰**â€ä»¥è§£å†³ä¸åŒå­èŠ‚ç‚¹è§£ç ä½ç½®ä¸åŒå¯¼è‡´çš„æ¦‚ç‡ä¸å¯æ¯”é—®é¢˜ã€‚

#### âœ… **ç†è®ºåˆ†æï¼šé¢„æµ‹ç½®ä¿¡åº¦ä¸ä¼°è®¡è¯¯å·®çš„å…³ç³»**
- é¦–æ¬¡ç†è®ºè¯æ˜ï¼šå•æ¬¡å‰å‘ä¼ æ’­ä¼°è®¡çš„è½¬ç§»æ¦‚ç‡ $\hat{P}(c|p)$ ä¸çœŸå®æœŸæœ›æ¦‚ç‡ $P(c|p)$ ä¹‹é—´çš„è¯¯å·®éšæ¨¡å‹**é¢„æµ‹ç½®ä¿¡åº¦æå‡è€Œå‡å°**ã€‚
- å®šä¹‰â€œæœ€ä¸ç¡®å®šæ­¥ç½®ä¿¡å·®è·â€ $e = \max(\epsilon_{\text{parent}}, \epsilon_{\text{path}})$ï¼Œå¹¶æ¨å¯¼å‡ºï¼š
  $$
  (1-e)^k \leq \frac{P(c|p)}{\hat{P}(c|p)} \leq \exp\left(\frac{ke}{1-e}\right)
  $$
- å½“ $e \to 0$ï¼Œè¿‘ä¼¼æ¯”è¶‹äº 1ï¼Œè¯´æ˜é«˜ç½®ä¿¡åº¦å¯æ˜¾è‘—é™ä½ä¼°è®¡è¯¯å·®ã€‚

#### âœ… **Time-Scheduled Self-Distillation Loss**
- åŸºäºä¸Šè¿°ç†è®ºï¼Œå¼•å…¥æ—¶é—´è°ƒåº¦çš„è‡ªè’¸é¦æŸå¤±ï¼Œåœ¨è®­ç»ƒåæœŸé€æ­¥å¢å¼ºæ¨¡å‹ç¡®å®šæ€§ï¼Œä»¥æé«˜æ¦‚ç‡ä¼°è®¡ç²¾åº¦ã€‚
- è®¾è®¡ä¼˜åŠ¿åŠ æƒç›®æ ‡åˆ†å¸ƒï¼š
  $$
  w_c = \frac{\exp(A_c / \tau(t))}{\sum_{c'} \exp(A_c' / \tau(t))}
  $$
  å…¶ä¸­æ¸©åº¦ $\tau(t)$ éšè®­ç»ƒæ­¥æ•°é€’å‡ã€‚
- è‡ªè’¸é¦æŸå¤±ä¸ºï¼š
  $$
  \mathcal{L}_{\text{distill}} = \lambda(t) \cdot \text{KL}(P_{\text{target}} \| \pi_\theta)
  $$
  æƒé‡ $\lambda(t)$ éšè®­ç»ƒé€æ­¥å¢å¤§ã€‚

è¿™ä¸€æœºåˆ¶å®ç°äº†**æ—©æœŸé¼“åŠ±æ¢ç´¢ã€åæœŸä¿ƒè¿›æ”¶æ•›**çš„å¹³è¡¡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ç°æœ‰æ–¹æ³• | d-TreeRPO |
|------|--------|----------|
| **å¥–åŠ±è®¾è®¡** | ç¨€ç–ç»“æœå¥–åŠ± æˆ– ä¸å¯éªŒè¯è¿‡ç¨‹å¥–åŠ± | ç»†ç²’åº¦ã€å¯éªŒè¯çš„æ ‘å½¢ bottom-up å¥–åŠ± |
| **ä¼˜åŠ¿ä¼°è®¡** | æ˜“å—å™ªå£°å¹²æ‰°ï¼Œç¼ºä¹ step-wise åˆ¤åˆ«åŠ› | åŸºäºå®é™…é‡‡æ ·ç»“æœçš„ group-relative advantage |
| **æ¦‚ç‡ä¼°è®¡** | ELBO ä¸‹ç•Œåè¯¯å¤§ï¼Œæˆ–å¤šæ­¥ç´¯ç§¯è¯¯å·® | å•æ¬¡å‰å‘ä¼ æ’­ + ç†è®ºæ”¯æŒçš„è¯¯å·®æ§åˆ¶æœºåˆ¶ |
| **è®­ç»ƒç¨³å®šæ€§** | æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜æˆ– reward hacking | è‡ªè’¸é¦å¼•å¯¼å‘é«˜ä¼˜åŠ¿è·¯å¾„æ”¶æ•›ï¼Œæå‡é²æ£’æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **Sudoku**ï¼š4x4 æ•°ç‹¬æ¨ç†ä»»åŠ¡ï¼Œæµ‹è¯•é€»è¾‘å¡«ç©ºèƒ½åŠ›ã€‚
- **Countdown**ï¼šæ•°å­—è¿ç®—è°œé¢˜ï¼Œæµ‹è¯•æ•°å­¦ç»„åˆæ¨ç†ã€‚
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œæ ‡å‡†æ•°å­¦æ¨ç†åŸºå‡†ã€‚
- **Math500**ï¼šé«˜ä¸­æ°´å¹³æ•°å­¦é¢˜é›†åˆï¼Œæ›´å…·æŒ‘æˆ˜æ€§ã€‚

> æ‰€æœ‰ä»»åŠ¡å‡é‡‡ç”¨ zero-shot è®¾ç½®ï¼Œpass@1 ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **åŸºç¡€æ¨¡å‹**ï¼šLLaDA-8B-Instructï¼ˆå·²å®Œæˆ SFTï¼Œæœªè¿›è¡Œ RLï¼‰ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ LoRAï¼ˆrank=128, Î±=64ï¼‰
  - æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼š256 tokensï¼ˆblock length=32ï¼‰ï¼Œ128 denoising steps
  - Tree ç»“æ„ï¼šé«˜åº¦ $H=2$ï¼Œåˆ†æ”¯å› å­ $B=4$
  - è‡ªè’¸é¦å‚æ•°ï¼š$\lambda_{\max}=3\times10^{-3}$, $T_{\max}=2$, $\beta=0.7$
- **è¯„ä¼°è®¾ç½®**ï¼š
  - ä¸¤ç§ç”Ÿæˆé•¿åº¦ï¼š256 å’Œ 512 tokens
  - deterministic samplingï¼ˆtemperature=0.0ï¼‰
  - denoising steps = ç”Ÿæˆé•¿åº¦ / 2

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Diffu-GRPO** | GRPO å˜ä½“ | ä½¿ç”¨ outcome rewardï¼Œå•æ­¥å‰å‘ä¼°è®¡æ¦‚ç‡ |
| **VRPO (LLaDA-1.5)** | Variance-reduced PO | å¤šæ¬¡å‰å‘é™ä½æ–¹å·® |
| **wd1** | Weighted PO | åŠ æƒç­–ç•¥ä¼˜åŒ– |
| **SAPO+** | Step-aware PO | å¼•å…¥è¿‡ç¨‹å¥–åŠ± |
| **d2-stepMerge** | Multi-step merge | åˆ†é˜¶æ®µåˆå¹¶æ­¥éª¤ |
| **TraceRL** | Value-model based | ä½¿ç”¨ value model é¢„æµ‹ä¸­é—´å¥–åŠ± |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ256-token settingï¼‰**

| æ–¹æ³• | Sudoku | Countdown | GSM8K | Math500 |
|------|--------|-----------|-------|---------|
| Base (LLaDA-8B) | 6.7 | 19.5 | 76.7 | 32.4 |
| +Diffu-GRPO | 12.9 | 31.3 | 79.8 | 34.1 |
| +wd1 | 25.2 | 51.2 | 80.8 | 34.4 |
| +d2-stepMerge | 76.1 | 52.4 | 81.1 | 34.4 |
| **+d-TreeRPO (Ours)** | **92.9** | **71.1** | **81.2** | **37.7** |
| **ç›¸å¯¹æå‡** | **+86.2** | **+51.6** | **+4.5** | **+5.3** |

> æ³¨ï¼šæ€§èƒ½å•ä½ä¸ºç™¾åˆ†æ¯”ï¼ˆ%ï¼‰ï¼Œæå‡å¹…åº¦å·¨å¤§ï¼Œå°¤å…¶åœ¨ Sudoku å’Œ Countdown ä¸Šè¡¨ç°çªå‡ºã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šï¼Œ**d-TreeRPO å‡è¾¾åˆ° SOTA æ€§èƒ½**ï¼Œæ˜¾è‘—è¶…è¶Šæ‰€æœ‰åŸºçº¿ã€‚
- åœ¨ Sudoku ä¸Šè¶…è¶Šæœ€å¼ºåŸºçº¿ d2-stepMerge è¶…è¿‡ 16 ä¸ªç™¾åˆ†ç‚¹ã€‚
- åœ¨é•¿ç”Ÿæˆåœºæ™¯ï¼ˆ512 tokensï¼‰ä¸‹ï¼š
  - Sudoku å’Œ Countdown å› è®­ç»ƒé™åˆ¶ï¼ˆä»… 256-tokenï¼‰ç•¥æœ‰ä¸‹é™ï¼›
  - GSM8K å’Œ Math500 å¾—ç›Šäºæ›´é•¿ä¸Šä¸‹æ–‡ç©ºé—´ï¼Œæ€§èƒ½ç»§ç»­æå‡ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ” **ç§»é™¤è‡ªè’¸é¦æŸå¤±çš„å½±å“**

| æ–¹æ³• | Sudoku | Countdown | GSM8K | Math500 |
|------|--------|-----------|-------|---------|
| d-TreeRPO (Full) | 92.9 | 71.1 | 81.2 | 37.7 |
| w/o self-distill loss | 89.8 | 66.4 | 80.9 | 36.1 |
| w/ diversity-promoting loss | 84.2 | 63.4 | 78.5 | 35.2 |

- ç§»é™¤è‡ªè’¸é¦å¯¼è‡´å…¨é¢æ€§èƒ½ä¸‹é™ã€‚
- ä½¿ç”¨â€œå¤šæ ·æ€§ä¿ƒè¿›æŸå¤±â€åè€Œä¸¥é‡æŸå®³æ€§èƒ½ï¼ŒéªŒè¯äº†åæœŸæå‡ç¡®å®šæ€§çš„å¿…è¦æ€§ã€‚

#### ğŸ” **Tree å‚æ•°æ•æ„Ÿæ€§åˆ†æ**

- **Tree Height $H$**ï¼š
  - $H=4$ï¼šåˆæœŸæ”¶æ•›æœ€å¿«ï¼Œä½†è®¡ç®—å¼€é”€è¿‡å¤§ï¼Œéš¾ä»¥å®Œæˆè®­ç»ƒã€‚
  - $H=2$ï¼šå…¼é¡¾æ•ˆç‡ä¸æ€§èƒ½ï¼Œé€‰æ‹©ä¸ºé»˜è®¤è®¾ç½®ã€‚
- **Branch Factor $B$**ï¼š
  - $B=2$ï¼šæ¢ç´¢ä¸è¶³ï¼Œæœ€ç»ˆå¥–åŠ±ä½ï¼ˆ~0.2ï¼‰ã€‚
  - $B=4$ å’Œ $B=6$ï¼šå‡èƒ½æ”¶æ•›è‡³ >0.9ï¼Œ$B=6$ åˆå§‹æ›´å¿«ä½†æˆæœ¬æ›´é«˜ï¼Œæ•…é€‰ $B=4$ã€‚

#### ğŸ” **æ—¶é—´è°ƒåº¦è®¾è®¡çš„æœ‰æ•ˆæ€§**

- å¯¹æ¯”â€œåå‘è°ƒåº¦â€ï¼ˆearly high $\lambda$, late lowï¼‰ï¼š
  - åˆæœŸä¸Šå‡å¿«ï¼Œä½†ä¸­æœŸåæ€§èƒ½ä¸‹é™ï¼ˆreward ä» 0.75 è·Œè½ï¼‰ã€‚
  - è¯´æ˜è¿‡æ—©å›ºåŒ–ç­–ç•¥ä¼šæŠ‘åˆ¶æ³›åŒ–èƒ½åŠ›ã€‚
- æ­£å‘è°ƒåº¦ï¼ˆæœ¬æ–‡è®¾è®¡ï¼‰åœ¨åæœŸæŒç»­æå‡ï¼Œä½“ç°å…¶åˆç†æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **æ ‘å½¢ rollout + bottom-up reward æ˜¯æ„å»ºå¯é  advantage çš„æœ‰æ•ˆèŒƒå¼**ï¼Œè§£å†³äº†ä¼ ç»Ÿ RL ä¸­ reward hacking å’Œç²—ç²’åº¦å¥–åŠ±é—®é¢˜ã€‚
2. âœ… **é¢„æµ‹ç½®ä¿¡åº¦ç›´æ¥å½±å“æ¦‚ç‡ä¼°è®¡è¯¯å·®**ï¼Œè¿™æ˜¯é¦–æ¬¡åœ¨ dLLM ä¸­å»ºç«‹è¯¥ç†è®ºè”ç³»ã€‚
3. âœ… **time-scheduled self-distillation æ˜¯åè°ƒæ¢ç´¢-åˆ©ç”¨æƒè¡¡çš„å…³é”®æœºåˆ¶**ï¼Œåœ¨è®­ç»ƒåæœŸå¢å¼ºç¡®å®šæ€§å¯æ˜¾è‘—æå‡æ”¶æ•›è´¨é‡ã€‚
4. âœ… **d-TreeRPO åœ¨å¤šä¸ªå¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå–å¾—æ˜¾è‘—é¢†å…ˆæ€§èƒ½**ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ä¸é€šç”¨æ€§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼štree rollout éœ€è¦ $O(B^H)$ æ¬¡æ¨ç†ï¼Œé™åˆ¶äº† $H$ å’Œ $B$ çš„æ‰©å±•ã€‚
- **ä¾èµ–å¯éªŒè¯å¥–åŠ±çš„ä»»åŠ¡**ï¼šç›®å‰é€‚ç”¨äº Sudokuã€æ•°å­¦ç­‰æœ‰æ˜ç¡®ç­”æ¡ˆçš„ä»»åŠ¡ï¼Œå¯¹å¼€æ”¾ç”Ÿæˆä»»åŠ¡é€‚ç”¨æ€§å¾…éªŒè¯ã€‚
- **å—å¯¹é½è¦æ±‚**ï¼šéœ€ä¸ block-wise decoding å¯¹é½æ‰èƒ½ä¿è¯æ¦‚ç‡å¯æ¯”æ€§ï¼Œé™åˆ¶äº†çµæ´»æ€§ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ¢ç´¢æ›´é«˜æ•ˆçš„ tree search ç­–ç•¥ï¼ˆå¦‚ MCTS å¯å‘å¼å‰ªæï¼‰ã€‚
- å°† d-TreeRPO æ‰©å±•åˆ°å¤šæ¨¡æ€æˆ–ä»£ç ç”Ÿæˆç­‰å…¶ä»–é¢†åŸŸã€‚
- ç ”ç©¶æ— éœ€å—å¯¹é½çš„é€šç”¨æ¦‚ç‡å½’ä¸€åŒ–æ–¹æ³•ã€‚
- æ¢ç´¢åœ¨å¼€æ”¾åŸŸä»»åŠ¡ä¸­ç»“åˆè¿‡ç¨‹å¥–åŠ±å»ºæ¨¡ï¼ˆProcess Reward Modelingï¼‰çš„å¯èƒ½æ€§ã€‚

---

> **æ€»ç»“**ï¼š  
> d-TreeRPO é€šè¿‡**ç»“æ„åŒ– rollout** å’Œ **ç†è®ºé©±åŠ¨çš„è®­ç»ƒæœºåˆ¶**ï¼Œç³»ç»Ÿæ€§æå‡äº† dLLM çš„ RL å¯é æ€§ã€‚å®ƒä¸ä»…åœ¨æ€§èƒ½ä¸Šå¤§å¹…é¢†å…ˆï¼Œä¹Ÿä¸ºæœªæ¥ diffusion-based RL æä¾›äº†æ–°çš„è®¾è®¡èŒƒå¼ã€‚

</details>

---

### 12. [Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration](https://arxiv.org/abs/2512.09340)

**Authors**: Chethana Prasad Kabgere  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.09340v1  

#### Abstract
Understanding how humans and AI systems interpret ambiguous visual stimuli offers critical insight into the nature of perception, reasoning, and decision-making. This paper examines image labeling performance across human participants and deep neural networks, focusing on low-resolution, perceptuall...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šVisual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³ **äººç±»ä¸AIåœ¨è§†è§‰åˆ†ç±»ä»»åŠ¡ä¸­å¤„ç†æ¨¡ç³Šå›¾åƒæ—¶çš„è®¤çŸ¥æœºåˆ¶å·®å¼‚**ã€‚å…·ä½“è€Œè¨€ï¼Œç ”ç©¶å…³æ³¨ä»¥ä¸‹æ ¸å¿ƒé—®é¢˜ï¼š
> å¦‚ä½•æ¯”è¾ƒäººç±»åœ¨æ ‡æ³¨æ¨¡ç³Šè§†è§‰åˆºæ¿€æ—¶çš„è®¤çŸ¥ç­–ç•¥ä¸AIç³»ç»Ÿçš„ç‰¹å¾é©±åŠ¨åˆ†ç±»è¿‡ç¨‹ï¼Ÿè¿™äº›è®¤çŸ¥å·®å¼‚å¦‚ä½•å¯å‘æ›´ç¬¦åˆäººç±»æ€ç»´æ¨¡å¼çš„ç¥ç»ç¬¦å·ï¼ˆneuro-symbolicï¼‰AIæ¶æ„è®¾è®¡ï¼Ÿ

å½“å‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚CNNï¼‰è™½åœ¨å›¾åƒåˆ†ç±»ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†å…¶å†³ç­–æœºåˆ¶ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œä¸”ä¸äººç±»çš„ç±»æ¯”æ¨ç†ã€ä¸Šä¸‹æ–‡ç†è§£ç­‰é«˜çº§è®¤çŸ¥èƒ½åŠ›å­˜åœ¨æ ¹æœ¬å·®å¼‚ã€‚æœ¬æ–‡é€šè¿‡è·¨å¿ƒæ™ºï¼ˆmindsï¼‰ä¸æ¨¡å‹ï¼ˆmodelsï¼‰çš„å¯¹æ¯”åˆ†æï¼Œæ­ç¤ºäº†è¿™ç§å·®è·ï¼Œå¹¶æå‡ºèåˆè·¯å¾„ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

- **å¤šç»´åº¦äººç±»è¡Œä¸ºæ•°æ®é‡‡é›†æ¡†æ¶**  
  è®¾è®¡äº†ä¸€å¥—ç»“åˆ**æ ‡ç­¾é€‰æ‹©ã€ç½®ä¿¡åº¦è¯„åˆ†ã€ç­–ç•¥æè¿°ã€æ³¨æ„åŠ›ç„¦ç‚¹ã€æƒ…ç»ªååº”ã€ä¿¡ä»»åº¦**ç­‰å¤šç»´è®¤çŸ¥æŒ‡æ ‡çš„å®éªŒèŒƒå¼ï¼Œè¶…è¶Šä¼ ç»Ÿä»…çœ‹å‡†ç¡®ç‡çš„ç ”ç©¶æ–¹å¼ã€‚

- **åŸºäºMarrä¸‰å±‚æ¬¡ç†è®ºçš„è·¨ç³»ç»Ÿæ¯”è¾ƒæ¡†æ¶**  
  åˆ©ç”¨ Marrâ€™s tri-level hypothesisï¼ˆè®¡ç®—å±‚ã€ç®—æ³•å±‚ã€å®ç°å±‚ï¼‰ç³»ç»Ÿæ€§åœ°å¯¹æ¯”äººç±»ä¸ResNet-18æ¨¡å‹åœ¨ï¼š
  - **è®¡ç®—ç›®æ ‡**ï¼ˆå›¾åƒåˆ†ç±»ï¼‰
  - **ç®—æ³•è¿‡ç¨‹**ï¼ˆäººç±»ä½¿ç”¨å½¢çŠ¶/ç±»æ¯” vs AIä½¿ç”¨çº¹ç†/ç‰¹å¾æ¿€æ´»ï¼‰
  - **å®ç°æœºåˆ¶**ï¼ˆå…·èº«è®¤çŸ¥ vs è¿æ¥ä¸»ä¹‰ç½‘ç»œï¼‰

- **æ¨åŠ¨ç¥ç»ç¬¦å·æ•´åˆï¼ˆNeuro-Symbolic Integrationï¼‰çš„è®¾è®¡è“å›¾**  
  æå‡ºå°† Grad-CAM æ³¨æ„åŠ›å›¾è°±ä¸ç¬¦å·è§„åˆ™å¼•æ“ç»“åˆï¼Œåœ¨AIç½®ä¿¡åº¦ä½æ—¶è§¦å‘â€œå½¢çŠ¶éªŒè¯â€ç­‰é€»è¾‘æ£€æŸ¥ï¼Œä»è€Œæå‡é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | æœ¬å·¥ä½œçš„ä¼˜åŠ¿ |
|------|--------------|-------------|
| **åˆ†æç²’åº¦** | ä»…æ¯”è¾ƒå‡†ç¡®ç‡æˆ–æ··æ·†çŸ©é˜µ | å¼•å…¥ä¿¡å¿ƒã€ç­–ç•¥ã€æƒ…æ„Ÿç­‰è®¤çŸ¥ç»´åº¦ï¼Œæ·±å…¥ç†è§£â€œä¸ºä»€ä¹ˆè¿™æ ·åˆ¤æ–­â€ |
| **è§£é‡Šæ€§å»ºæ¨¡** | é»‘ç®±æ¨¡å‹ + åè§£é‡Šå·¥å…·ï¼ˆå¦‚Grad-CAMï¼‰ | å°†Grad-CAMä¸äººç±»æŠ¥å‘Šçš„ç­–ç•¥ç›´æ¥å¯¹é½ï¼Œå»ºç«‹è®¤çŸ¥å¯æ¯”æ€§ |
| **ç†è®ºåŸºç¡€** | å¤šä¸ºå·¥ç¨‹å¯¼å‘ | èåˆè®¤çŸ¥ç§‘å­¦ç»å…¸ç†è®ºï¼ˆBounded Rationality, Analogical Reasoning, Embodied Cognition, Distributed Cognitionï¼‰æŒ‡å¯¼AIè®¾è®¡ |
| **æœªæ¥æ–¹å‘** | å•çº¯ä¼˜åŒ–æ€§èƒ½ | æ˜ç¡®æå‡ºé€šå¾€**è®¤çŸ¥å¯¹é½ï¼ˆcognitively alignedï¼‰AI**çš„è·¯å¾„ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä¸»è¦ä½¿ç”¨ **CIFAR-10** æ•°æ®é›†ä¸­çš„10å¼ ä½åˆ†è¾¨ç‡ï¼ˆ32Ã—32ï¼‰å›¾åƒã€‚
- å›¾åƒè¢«ç‰¹æ„é€‰ä¸ºä»**æ¸…æ™°åˆ°æ¨¡ç³Šä¸ç­‰**ï¼Œä»¥åˆ¶é€ æ„ŸçŸ¥ä¸ç¡®å®šæ€§ï¼Œä¾¿äºè§‚å¯Ÿäººç±»ä¸AIåœ¨è¾¹ç¼˜æ¡ˆä¾‹ä¸Šçš„è¡Œä¸ºå·®å¼‚ã€‚

---

### å®éªŒè®¾ç½®

#### äººç±»å‚ä¸è€…
- **äººæ•°**ï¼š12åå‚ä¸è€…ï¼ˆä¾¿åˆ©æŠ½æ ·ï¼Œæ¥è‡ªè¯¾å ‚åŠåŒäº‹ï¼‰
- **ä»»åŠ¡æµç¨‹**ï¼š
  1. è§‚å¯Ÿä¸€å¼ ä½åˆ†è¾¨ç‡å›¾åƒ
  2. é€‰æ‹©ç±»åˆ«æ ‡ç­¾ï¼ˆ10ç±»ä¹‹ä¸€ï¼‰
  3. æä¾› **confidence rating**ï¼ˆ1â€“5æå…‹ç‰¹é‡è¡¨ï¼‰
  4. æè¿°æ‰€ç”¨**ç­–ç•¥**ï¼ˆå¦‚â€œçœ‹èµ·æ¥åƒç¿…è†€â€ã€â€œç±»ä¼¼åœç€çš„è½¦â€ï¼‰
  5. æŠ¥å‘Š**æ³¨æ„åŠ›ç„¦ç‚¹åŒºåŸŸ**ï¼ˆä¸­å¿ƒ/é¡¶éƒ¨/åº•éƒ¨/è¾¹ç¼˜ï¼‰
  6. å›ç­”**è®¤çŸ¥è´Ÿè·ã€æƒ…ç»ªã€å¯¹AIçš„ä¿¡ä»»ã€ä»»åŠ¡äº«å—åº¦**

#### AIæ¨¡å‹
- ä½¿ç”¨ **ResNet-18** æ¶æ„ï¼Œé’ˆå¯¹CIFAR-10å°ºå¯¸è¿›è¡Œè°ƒæ•´ï¼š
  - ç¬¬ä¸€å±‚å·ç§¯æ ¸ç”±7Ã—7 stride 2æ”¹ä¸º3Ã—3 stride 1ï¼Œé¿å…å°å›¾åƒç©ºé—´ä¿¡æ¯ä¸¢å¤±
  - ä¸ä½¿ç”¨åˆå§‹max pooling
  - æ·»åŠ æ•°æ®å¢å¼ºï¼ˆéšæœºè£å‰ªã€æ°´å¹³ç¿»è½¬ã€å½’ä¸€åŒ–ï¼‰
- è®­ç»ƒé…ç½®ï¼š
  - ä»é›¶å¼€å§‹è®­ç»ƒ
  - 5ä¸ªepoch
  - Adamä¼˜åŒ–å™¨ï¼ˆlr=0.001ï¼‰ï¼Œäº¤å‰ç†µæŸå¤±
  - æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡çº¦ **70.7%**

#### å¯è§†åŒ–ä¸è§£é‡Šå·¥å…·
- ä½¿ç”¨ **Grad-CAM** ç”Ÿæˆæ¯å¼ å›¾åƒçš„çƒ­åŠ›å›¾ï¼Œå¯è§†åŒ–AIå…³æ³¨åŒºåŸŸ
- å¯¹æ¯”äººç±»æŠ¥å‘Šçš„â€œæ³¨æ„åŠ›ç„¦ç‚¹â€ä¸Grad-CAMé«˜äº®åŒºåŸŸçš„ä¸€è‡´æ€§

---

### è¯„ä¼°æŒ‡æ ‡

| ç±»å‹ | æŒ‡æ ‡ |
|------|------|
| **æ€§èƒ½æŒ‡æ ‡** | å‡†ç¡®ç‡ã€softmaxç½®ä¿¡åº¦ |
| **è®¤çŸ¥æŒ‡æ ‡** | äººç±»ç½®ä¿¡åº¦å‡å€¼ä¸æ ‡å‡†å·®ã€è®¤çŸ¥è´Ÿè·ã€ç­–ç•¥ç±»å‹åˆ†å¸ƒ |
| **å¯è§£é‡Šæ€§å¯¹æ¯”** | äººç±»ç­–ç•¥ vs Grad-CAMæ³¨æ„åŠ›åŒºåŸŸåŒ¹é…ç¨‹åº¦ |
| **ç†è®ºæ˜ å°„** | æ˜¯å¦ä½“ç° bounded rationalityã€analogical reasoningã€embodied cognition ç­‰åŸåˆ™ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **äººç±» vs ResNet-18** ä½œä¸ºä¸»è¦å¯¹æ¯”è½´
- æ— å…¶ä»–DLæ¨¡å‹å¯¹æ¯”ï¼ˆéSOTAæ€§èƒ½ç«èµ›ï¼‰ï¼Œé‡ç‚¹åœ¨äº**æœºåˆ¶å·®å¼‚åˆ†æ**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

| æ¨¡å— | ç»“æœ |
|------|------|
| **AIæ¨¡å‹æ•´ä½“å‡†ç¡®ç‡** | ~70.7% ï¼ˆåˆç†åŸºå‡†ï¼Œéæœ€ä¼˜ï¼‰ |
| **äººç±»æ•´ä½“å‡†ç¡®ç‡** | **100%**ï¼ˆæ‰€æœ‰12äººå…¨éƒ¨æ­£ç¡®æ ‡æ³¨10å¼ å›¾ï¼‰ |
| **äººç±»å¹³å‡ç½®ä¿¡åº¦** | é«˜è¾¾ **4.5â€“4.92 / 5**ï¼Œå³ä½¿é¢å¯¹æ¨¡ç³Šå›¾åƒä¹Ÿä¿æŒé«˜åº¦è‡ªä¿¡ |
| **AIç½®ä¿¡åº¦èŒƒå›´** | 0.329 â€“ 0.957ï¼Œéƒ¨åˆ†é”™è¯¯é¢„æµ‹ä»æœ‰ä¸€å®šç½®ä¿¡åº¦ï¼ˆå¦‚ deer_00.png è¢«åˆ¤ä¸º airplaneï¼Œç½®ä¿¡0.37ï¼‰ |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

| ç»´åº¦ | äººç±»è¡¨ç° | AIè¡¨ç° | å·®å¼‚è¯´æ˜ |
|------|--------|-------|---------|
| **åˆ†ç±»å‡†ç¡®æ€§** | å®Œç¾ï¼ˆ100%ï¼‰ | ä¸­ç­‰ï¼ˆ~70.7%ï¼‰ | äººç±»åˆ©ç”¨å…ˆéªŒçŸ¥è¯†è¡¥å¿ä½è´¨é‡è¾“å…¥ |
| **ç½®ä¿¡åº¦æ ¡å‡†** | é«˜å‡†ç¡®+é«˜ç½®ä¿¡ï¼Œæ¨¡ç³Šæ—¶è½»å¾®ä¸‹é™ | æ­£ç¡®é¡¹ç½®ä¿¡è¾ƒé«˜ï¼Œä½†è¯¯åˆ¤ä¹Ÿæœ‰ä¸€å®šç½®ä¿¡ | äººç±»å…·å¤‡æ›´å¼ºçš„å…ƒè®¤çŸ¥ç›‘æ§ï¼ˆmetacognitive monitoringï¼‰ |
| **æ³¨æ„åŠ›æœºåˆ¶** | å…¨å±€å½¢çŠ¶ã€ç»“æ„çº¿ç´¢ï¼ˆå¦‚â€œè€³æœµâ€ã€â€œè§’â€ï¼‰ | å±€éƒ¨çº¹ç†ã€è¾¹ç¼˜ç‰¹å¾ï¼ˆGrad-CAMæ˜¾ç¤ºåˆ†æ•£æˆ–è¯¯å¯¼æ€§æ¿€æ´»ï¼‰ | æ”¯æŒæ–‡çŒ®[16]ï¼šCNNåå‘textureè€Œéshape |
| **æ¨ç†ç­–ç•¥** | å¹¿æ³›ä½¿ç”¨â€œå½¢çŠ¶â€ã€â€œç†Ÿæ‚‰æ„Ÿâ€ã€â€œç±»æ¯”â€ | æ— æ˜¾å¼ç­–ç•¥ï¼Œä¾èµ–éšå¼ç‰¹å¾ç»„åˆ | äººç±»é‡‡ç”¨ symbolic/analogical reasoningï¼›AIä¸º subsymbolic processing |

#### å…¸å‹é”™ä¾‹åˆ†æ
- **deer_00.png**ï¼š
  - AIè¯¯åˆ¤ä¸ºâ€œairplaneâ€ï¼ŒGrad-CAMé«˜äº®é¡¶éƒ¨æ–œçº¿çº¹ç† â†’ è¢«è¯¯è®¤ä¸ºæœºç¿¼
  - äººç±»å¤šæ•°è¯†åˆ«ä¸ºâ€œdeerâ€ï¼Œä¾æ®æ˜¯â€œantler-like shapeâ€ã€â€œforest-like fuzzâ€
  - æ˜¾ç¤ºAIå—è¯¯å¯¼æ€§å‡ ä½•çº¹ç†å½±å“ï¼Œè€Œäººç±»ä¾èµ–è¯­ä¹‰ç»“æ„ä¸æƒ…å¢ƒè”æƒ³

- **bird_01.png**ï¼š
  - AIæ­£ç¡®ä½†ä½ç½®ä¿¡ï¼ˆ0.358ï¼‰ï¼ŒGrad-CAMæ³¨æ„åŠ›å¼¥æ•£
  - äººç±»ä¸­æœ‰äººè¯¯åˆ¤ä¸ºcatï¼Œç†ç”±æ˜¯â€œfur texture seems like catâ€
  - è¡¨æ˜ä¸¤è€…éƒ½å—çº¹ç†å¹²æ‰°ï¼Œä½†äººç±»å¯é€šè¿‡å½¢çŠ¶ä¿®æ­£åˆ¤æ–­

---

### æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
- æœ¬æ–‡æœªè¿›è¡Œä¼ ç»Ÿæ„ä¹‰ä¸Šçš„æ¶ˆèå®éªŒï¼ˆå¦‚ç§»é™¤æŸæ¨¡å—æµ‹æ€§èƒ½å˜åŒ–ï¼‰
- ä½†é€šè¿‡**è·¨è¢«è¯•ç­–ç•¥å¤šæ ·æ€§åˆ†æ**å®ç°äº†ç±»ä¼¼åŠŸèƒ½ï¼š
  - åˆ†æä¸åŒç­–ç•¥ï¼ˆshape vs texture vs guessingï¼‰å¯¹åº”çš„å‡†ç¡®ç‡ä¸è®¤çŸ¥è´Ÿè·
  - å‘ç°ä½¿ç”¨â€œshape + familiarityâ€çš„ç­–ç•¥ç»„å‡†ç¡®ç‡æœ€é«˜ã€è®¤çŸ¥è´Ÿè·æœ€ä½ â†’ æ”¯æŒå…¶æœ‰æ•ˆæ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **äººç±»åœ¨ä½åˆ†è¾¨ç‡å›¾åƒåˆ†ç±»ä¸­è¡¨ç°å‡ºæé«˜çš„é²æ£’æ€§ä¸ä¸€è‡´æ€§**  
   å°½ç®¡å›¾åƒæ¨¡ç³Šï¼Œæ‰€æœ‰äººä»è¾¾åˆ°100%å‡†ç¡®ç‡ï¼Œä¾èµ–çš„æ˜¯**åŸå‹åŒ¹é…ã€ç±»æ¯”æ¨ç†å’Œå…·èº«ç»éªŒ**ã€‚

2. ğŸ” **äººç±»å†³ç­–ä½“ç° bounded rationality å’Œ dual-process theory**  
   - æ¸…æ™°å›¾åƒ â†’ å¿«é€ŸType 1å¤„ç†ï¼ˆç›´è§‰åˆ¤æ–­ï¼‰
   - æ¨¡ç³Šå›¾åƒ â†’ å¯åŠ¨Type 2å¤„ç†ï¼ˆåˆ†ææ€§æ€è€ƒï¼‰ï¼Œä¼´éšæ›´é«˜è®¤çŸ¥è´Ÿè·
   - ç½®ä¿¡åº¦ä¸è®¤çŸ¥è´Ÿè·å‘ˆè´Ÿç›¸å…³ â†’ å­˜åœ¨å…ƒè®¤çŸ¥è°ƒèŠ‚æœºåˆ¶

3. ğŸ§  **äººç±»ä½¿ç”¨ analogical reasoning å’Œ case-based reasoning**  
   å¦‚å°†çŒ«å›¾åƒè¯†åˆ«ä¸ºâ€œæœ‰è€³æœµâ€ã€â€œæœ‰èƒ¡é¡»â€ï¼Œå³è°ƒç”¨é•¿æœŸè®°å¿†ä¸­çš„å¯¹è±¡åŸå‹è¿›è¡Œæ˜ å°„ã€‚

4. ğŸ¤– **AIï¼ˆResNet-18ï¼‰ä¸¥é‡ä¾èµ–å±€éƒ¨çº¹ç†ä¸è¾¹ç¼˜ç‰¹å¾**  
   Grad-CAMæ˜¾ç¤ºå…¶æ³¨æ„åŠ›å¸¸é›†ä¸­åœ¨éè¯­ä¹‰åŒºåŸŸï¼Œå¯¼è‡´åœ¨çº¹ç†è¯¯å¯¼ä¸‹å‘ç”Ÿè¯­ä¹‰è·ç¦»è¾ƒè¿œçš„è¯¯åˆ¤ï¼ˆå¦‚deerâ†’airplaneï¼‰ã€‚

5. âš–ï¸ **AIä¸äººç±»çš„æ³¨æ„åŠ›æ˜¾è‘—ä¸ä¸€è‡´**  
   äººç±»å…³æ³¨æ•´ä½“ç»“æ„ï¼ˆshape-basedï¼‰ï¼ŒAIå…³æ³¨å±€éƒ¨patternï¼ˆtexture-drivenï¼‰ï¼Œè¿™æ˜¯å½“å‰CNNæ¨¡å‹ä¸äººç±»è§†è§‰ç³»ç»Ÿçš„å…³é”®åˆ†æ­§ã€‚

6. ğŸ’¡ **ç¥ç»ç¬¦å·æ•´åˆå…·æœ‰æ˜ç¡®æ½œåŠ›**  
   å½“AIç½®ä¿¡åº¦ä½æˆ–æ³¨æ„åŠ›ä¸å¸¸è§å½¢çŠ¶ä¸ç¬¦æ—¶ï¼Œå¼•å…¥ç¬¦å·è§„åˆ™ï¼ˆå¦‚â€œé£æœºå¿…é¡»æœ‰ç¿…è†€â€ï¼‰å¯ä½œä¸ºfallbackæœºåˆ¶ï¼Œæé«˜å®‰å…¨æ€§ä¸å¯è§£é‡Šæ€§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **æ ·æœ¬é‡å°** | ä»…12åå‚ä¸è€…ï¼Œå¯èƒ½å½±å“ç»Ÿè®¡æ•ˆåŠ› |
| **å›¾åƒæ•°é‡å°‘** | ä»…åˆ†æ10å¼ å›¾åƒï¼Œæ³›åŒ–æ€§æœ‰é™ |
| **æœªæ§åˆ¶å˜é‡** | æœªç³»ç»Ÿæ“æ§å›¾åƒæ¨¡ç³Šåº¦ã€å™ªå£°ç±»å‹ç­‰ç‹¬ç«‹å˜é‡ |
| **AIéSOTA** | ä½¿ç”¨è½»é‡çº§ResNet-18ï¼Œæœªæ¢ç´¢ViTæˆ–å…¶ä»–å…ˆè¿›æ¶æ„çš„è¡Œä¸ºå·®å¼‚ |
| **ä¸»è§‚æŠ¥å‘Šåå·®** | äººç±»ç­–ç•¥æè¿°å¯èƒ½å­˜åœ¨äº‹ååˆç†åŒ–ï¼ˆpost-hoc rationalizationï¼‰ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ„å»ºç¥ç»ç¬¦å·æ··åˆæ¨¡å‹ï¼ˆNeuro-Symbolic Systemï¼‰**
   - ç»“åˆ Grad-CAM ç‰¹å¾æ¿€æ´» ä¸ ç¬¦å·è§„åˆ™å¼•æ“
   - åœ¨ä½ç½®ä¿¡æˆ–å¼‚å¸¸æ³¨æ„åŠ›æ—¶è§¦å‘ symbolic validation rules
   - ç¤ºä¾‹ï¼šè‹¥æ£€æµ‹åˆ°â€œé£è¡Œç‰©â€ä½†æ— â€œå¯¹ç§°ç¿¼ç»“æ„â€ï¼Œåˆ™é™æƒ airplane ç±»åˆ«

2. **æ¢ç´¢ scalable representation alignment**
   - ä½¿ç”¨å›¾åµŒå…¥ï¼ˆgraph-based embeddingsï¼‰ç»Ÿä¸€ç¥ç»ç‰¹å¾ç©ºé—´ä¸ç¬¦å·æ¦‚å¿µç©ºé—´
   - åœ¨ CLEVR æˆ– GQA ç­‰éœ€è¦ç»„åˆæ¨ç†çš„æ•°æ®é›†ä¸ŠéªŒè¯æŠ½è±¡èƒ½åŠ›

3. **å¢å¼ºAIçš„æƒ…å¢ƒæ„ŸçŸ¥ä¸å¤šæ¨¡æ€è¾“å…¥**
   - å¼•å…¥èƒŒæ™¯é¢œè‰²ã€åœºæ™¯ä¸Šä¸‹æ–‡ï¼ˆå¦‚â€œå¤©ç©ºè“â€æš—ç¤ºé£æœºï¼‰ã€ç”šè‡³è§¦è§‰æ¨¡æ‹Ÿ
   - æ¨è¿› towards neuromorphic and context-aware AI

4. **å¼€å±•äºº-AIåä½œå®éªŒ**
   - æµ‹è¯•åŠ å…¥ symbolic trace å’Œ confidence reporting åï¼Œæ˜¯å¦èƒ½æå‡äººç±»å¯¹AIçš„ä¿¡ä»»ä¸åä½œæ•ˆç‡
   - ç‰¹åˆ«æ˜¯åœ¨ ambiguous æˆ– low-fidelity æ¡ä»¶ä¸‹çš„è”åˆå†³ç­–åœºæ™¯

---

## æ€»ç»“

> æœ¬è®ºæ–‡ä¸æ˜¯ä¸€ç¯‡è¿½æ±‚æ€§èƒ½çªç ´çš„æŠ€æœ¯è®ºæ–‡ï¼Œè€Œæ˜¯ä¸€ç¯‡**è¿æ¥è®¤çŸ¥ç§‘å­¦ä¸äººå·¥æ™ºèƒ½çš„æ¡¥æ¢æ€§ç ”ç©¶**ã€‚å®ƒé€šè¿‡ä¸¥è°¨çš„å®éªŒè®¾è®¡ï¼Œæ­ç¤ºäº†äººç±»ä¸AIåœ¨è§†è§‰åˆ†ç±»ä¸­çš„æ·±å±‚æœºåˆ¶å·®å¼‚ï¼Œå¹¶å‘¼åä¸‹ä¸€ä»£AIåº”èµ°å‘ **cognitively grounded, interpretable, and neuro-symbolic** çš„å‘å±•æ–¹å‘ã€‚

å…¶æœ€å¤§ä»·å€¼åœ¨äºï¼š
- æä¾›äº†ä¸€ä¸ª**ç†è®ºé©±åŠ¨çš„åˆ†ææ¡†æ¶**ï¼ˆMarr + Simon + Thagardï¼‰
- å±•ç¤ºäº†å¦‚ä½•å°†**äººç±»è®¤çŸ¥æ•°æ®è½¬åŒ–ä¸ºAIè®¾è®¡å¯ç¤º**
- æ˜ç¡®æŒ‡å‡ºï¼šæœªæ¥çš„æ™ºèƒ½ä¸åº”åªæ˜¯â€œåšå¾—å¯¹â€ï¼Œæ›´è¦â€œæƒ³å¾—åƒâ€â€”â€”å³å…·å¤‡è®¤çŸ¥åˆç†æ€§ä¸å¯æ²Ÿé€šæ€§ã€‚

</details>

---

### 13. [RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning](https://arxiv.org/abs/2512.09829)

**Authors**: Khurram Khalil, Muhammad Mahad Khaliq, Khaza Anuarul Hoque  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.09829v1  

#### Abstract
The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targetin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… è§£å†³çš„é—®é¢˜
ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸“ç”¨ AI åŠ é€Ÿå™¨ï¼ˆå¦‚ GPUã€TPUï¼‰ä¸Šè¿è¡Œæ—¶ï¼Œå…¶å‚æ•°è§„æ¨¡å¯è¾¾æ•°åäº¿ç”šè‡³ä¸Šåƒäº¿ï¼Œå¯¼è‡´ä¼ ç»Ÿæ•…éšœè¯„ä¼°æ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **è®¡ç®—æˆæœ¬æé«˜**ï¼šéšæœºæ•…éšœæ³¨å…¥ï¼ˆRandom Fault Injection, RFIï¼‰éœ€è¦å¤§é‡ä»¿çœŸæ—¶é—´æ‰èƒ½è·å¾—æœ‰é™è¦†ç›–ã€‚
- **éš¾ä»¥å‘ç°é«˜å½±å“æ•…éšœ**ï¼šæœ€å±é™©çš„â€œç¾éš¾æ€§æ•…éšœâ€é€šå¸¸ç”±å°‘æ•°ååŒä½œç”¨çš„æ¯”ç‰¹ç¿»è½¬ï¼ˆbit-flipsï¼‰å¼•èµ·ï¼Œè¿™ç±»ç¨€ç–ä¸”éçº¿æ€§çš„ç»„åˆåœ¨æµ·é‡æœç´¢ç©ºé—´ä¸­æéš¾è¢«éšæœºæ–¹æ³•æ•è·ã€‚
- **ç¼ºä¹å¯æ‰©å±•æ€§**ï¼šå½¢å¼åŒ–éªŒè¯ç­‰ç²¾ç¡®æ–¹æ³•å› çŠ¶æ€çˆ†ç‚¸é—®é¢˜æ— æ³•åº”ç”¨äºå¤§è§„æ¨¡è®¾è®¡ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šRIFT æ¡†æ¶
æœ¬æ–‡æå‡º **RIFT**ï¼ˆReinforcement Learning-guided Intelligent Fault Targetingï¼‰ï¼Œä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–æ•…éšœå®šä½æ¡†æ¶ï¼Œç”¨äºé«˜æ•ˆè¯†åˆ«å¯¹ LLM æ¨ç†é€ æˆæœ€å¤§ç ´åçš„æœ€å°æ¯”ç‰¹ç¿»è½¬é›†åˆã€‚

#### åˆ›æ–°æ€è·¯ï¼š
1. **å°†æ•…éšœæœç´¢å»ºæ¨¡ä¸º MDP é—®é¢˜**  
   å°†å¯»æ‰¾æœ€åæƒ…å†µä¸‹çš„æœ€å°é«˜å½±å“æ•…éšœé›†è½¬åŒ–ä¸ºä¸€ä¸ª**åºåˆ—å†³ç­–è¿‡ç¨‹**ï¼Œç”± RL Agent é€šè¿‡è¯•é”™é€æ­¥æ„å»ºæœ€ä¼˜æ•…éšœç»„åˆã€‚

2. **ä¸‰é˜¶æ®µæ¼æ–—å¼æ¶æ„è®¾è®¡**
   - **Phase I: Vulnerability Profiling**  
     ç»“åˆé™æ€å‚æ•°é‡è¦æ€§ï¼ˆmagnitudeï¼‰ä¸åŠ¨æ€æ¢¯åº¦æ•æ„Ÿåº¦ï¼ˆgradientï¼‰ï¼Œç”Ÿæˆæ··åˆæ•æ„Ÿåº¦è¯„åˆ†ï¼Œå¹¶ç»“åˆå†…å­˜è®¿é—®çƒ­ç‚¹è¿›è¡ŒåŠ æƒï¼Œå½¢æˆå…¨é¢çš„è„†å¼±æ€§æ’åºã€‚
   - **Phase II: Candidate Set Initialization**  
     ä»æ‰€æœ‰å‚æ•°ä¸­ç­›é€‰å‡º top-ranked é«˜æ•æ„Ÿåº¦å­é›† $P_{\text{crit}}$ï¼Œå¤§å¹…ç¼©å° RL æœç´¢ç©ºé—´ã€‚
   - **Phase III: RL-Powered Test Vector Generation**  
     ä½¿ç”¨ Q-learning åœ¨å€™é€‰é›†ä¸­æ¢ç´¢æ·»åŠ /åˆ é™¤æ¯”ç‰¹çš„æ“ä½œï¼Œä»¥æœ€å¤§åŒ–â€œç²¾åº¦ä¸‹é™ + æ•…éšœæ•°é‡æƒ©ç½šâ€çš„å¥–åŠ±å‡½æ•°ï¼Œæœ€ç»ˆè¾“å‡ºæœ€å°é«˜å½±å“æ•…éšœé›† $F_{\text{crit}}$ã€‚

3. **æ”¯æŒ UVM å…¼å®¹æµ‹è¯•å¹³å°è‡ªåŠ¨ç”Ÿæˆ**
   è¾“å‡ºå¯ç›´æ¥é›†æˆåˆ°å·¥ä¸šçº§ RTL éªŒè¯æµç¨‹ä¸­çš„ `UVM-compliant testbench`ï¼Œå®ç°â€œpush-buttonâ€å¼æ•…éšœæ³¨å…¥éªŒè¯ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | RIFT çš„ä¼˜åŠ¿ |
|------|--------|-------------|
| **RFI (Random Fault Injection)** | è¦†ç›–æ•ˆç‡ä½ï¼Œéœ€ç™¾ä¸‡çº§æµ‹è¯•å‘é‡ | >99% å‡å°‘æµ‹è¯•å‘é‡ï¼Œé€Ÿåº¦æå‡ 7.5Ã— |
| **Magnitude/Gradient Heuristics** | å›ºå®šè§„åˆ™ï¼Œæ— è‡ªé€‚åº”èƒ½åŠ› | åŠ¨æ€å­¦ä¹ ç­–ç•¥ï¼Œæ›´ä¼˜æ”¶æ•›è·¯å¾„ |
| **Evolutionary Search (e.g., GenBFA)** | ç¼ºä¹é•¿æœŸè§„åˆ’ï¼Œæ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ | å¼ºåŒ–å­¦ä¹ å…·å¤‡è®°å¿†ä¸å›æº¯èƒ½åŠ›ï¼Œæœç´¢æ›´æ™ºèƒ½ |
| **Formal Methods** | ä¸é€‚ç”¨äº billion-scale è®¾è®¡ | å¯æ‰©å±•æ€§å¼ºï¼Œä»…èšç„¦å…³é”®åŒºåŸŸ |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ä¸ç›®æ ‡æ¨¡å‹
- **ç›®æ ‡æ¨¡å‹ï¼ˆDUTï¼‰**ï¼š
  - GPT-2 Large (~300M å‚æ•°)
  - LLaMA 3.1 8B (8 billion å‚æ•°)
  - DeepSeek-V2 7B (Mixture-of-Experts æ¶æ„)
- æ‰€æœ‰æ¨¡å‹å‡é‡‡ç”¨ **8-bit æ•´æ•°é‡åŒ–**ï¼Œç¬¦åˆå®é™…éƒ¨ç½²åœºæ™¯ã€‚
- **è¯„ä¼°åŸºå‡†**ï¼š
  - MMLUï¼ˆMassive Multitask Language Understandingï¼‰
  - MMLU-Proï¼ˆæ›´å…·æŒ‘æˆ˜æ€§çš„å˜ä½“ï¼‰

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A100 80GB GPUs ç»„æˆçš„é«˜æ€§èƒ½é›†ç¾¤
- **æ•…éšœæ¨¡å‹**ï¼šå•æ¯”ç‰¹ç¿»è½¬ï¼ˆSingle-bit flipï¼‰ï¼Œç‰¹åˆ«å…³æ³¨ MSBï¼ˆMost Significant Bitï¼‰ç¿»è½¬ï¼Œå› å…¶å¯¹æ•°å€¼åå·®å½±å“æœ€å¤§
- **ç¾éš¾æ€§å¤±è´¥å®šä¹‰**ï¼šæ¨¡å‹å‡†ç¡®ç‡ä¸‹é™è¶…è¿‡ 90%
- **è®¡ç®—é¢„ç®—**ï¼šå›ºå®šä¸º 1000 CPU å°æ—¶ï¼Œç”¨äºå…¬å¹³æ¯”è¾ƒä¸åŒæ–¹æ³•çš„æ•ˆç‡

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Coverage (Cov)** | æˆåŠŸè¯†åˆ«çš„å…³é”®æ•…éšœæ¯”ä¾‹ï¼ˆå¯¼è‡´ >90% ç²¾åº¦ä¸‹é™ï¼‰ |
| **Time (hrs)** | è¾¾åˆ°è¯¥è¦†ç›–ç‡æ‰€éœ€æ—¶é—´ï¼ˆCPU hoursï¼‰ |
| **Test Vectors (TV)** | ç”Ÿæˆçš„æ•…éšœæµ‹è¯•ç”¨ä¾‹æ€»æ•° |
| **Efficiency (Eff)** | Coverage per hourï¼Œè¡¡é‡å•ä½æ—¶é—´å†…çš„å‘ç°æ•ˆç‡ |
| **Speedup (SU)** | ç›¸å¯¹äº RFI çš„åŠ é€Ÿæ¯” |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Random Fault Injection (RFI)** â€” å·¥ä¸šç•Œæ ‡å‡†
2. **Magnitude Ranking** â€” åŸºäºå‚æ•°å¤§å°çš„é™æ€åˆ†æï¼ˆç±»ä¼¼ PrisonBreakï¼‰
3. **Gradient Selection** â€” åŸºäºæ¢¯åº¦çš„åŠ¨æ€åˆ†æï¼ˆç±»ä¼¼ DeepHammerï¼‰
4. **GenBFA [17]** â€” å½“å‰æœ€å…ˆè¿›çš„è¿›åŒ–ç®—æ³•ï¼Œç”¨äºå¯¹æŠ—æ€§æ¯”ç‰¹æ”»å‡»

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### ğŸ“ˆ ä¸»è¦æ€§èƒ½å¯¹æ¯”ï¼ˆTable Iï¼‰

| æ–¹æ³• | Cov (%) | Time (hrs) | TV æ•°é‡ | Eff (Cov/hr) | Speedup vs RFI |
|------|---------|------------|----------|---------------|----------------|
| RFI | 65.3Â±4.1 | 1000Â±52 | 1.2Ã—10âµ | 0.065 | 1.0Ã— |
| Magnitude Ranking | 73.8Â±3.7 | 245Â±18 | 8.4Ã—10Â³ | 0.301 | 4.6Ã— |
| Gradient Selection | 79.2Â±2.9 | 198Â±15 | 6.1Ã—10Â³ | 0.400 | 6.2Ã— |
| GenBFA [17] | 84.6Â±3.2 | 388Â±24 | 4.7Ã—10Â³ | 0.218 | 3.4Ã— |
| **RIFT (Ours)** | **91.7Â±2.1** | **187Â±12** | **847Â±73** | **0.490** | **7.5Ã—** |

> âœ… **å…³é”®ç»“è®º**ï¼š
> - RIFT å®ç°äº† **æœ€é«˜è¦†ç›–ç‡ï¼ˆ91.7%ï¼‰**
> - **æ¯” GenBFA å¿« 2.2Ã—**ï¼ˆæ•ˆç‡ 0.490 vs 0.218ï¼‰
> - **æµ‹è¯•å‘é‡å‡å°‘ >99%**ï¼ˆä»…éœ€ ~847 ä¸ª vs RFI çš„ 120,000ï¼‰
> - æ€»è€—æ—¶ä»…ä¸º RFI çš„ 1/5ï¼Œå´å‘ç°äº†æ›´å¤šå…³é”®æ•…éšœ

### ğŸ” å…³é”®æ¼æ´å‘ç°ï¼ˆTable IIï¼‰
| DUT æ¨¡å‹ | åˆå§‹ç²¾åº¦ | è‡´å‘½æ¯”ç‰¹æ•°ï¼ˆå¹³å‡ï¼‰ | æœ€ç»ˆç²¾åº¦ | å‘ç°æ—¶é—´ï¼ˆå°æ—¶ï¼‰ |
|----------|-----------|--------------------|------------|------------------|
| GPT-2 Large | 30.5% | 5.1Â±0.6 | 0.34% | 89Â±8 |
| LLaMA 3.1 8B | 69.9% | 5.3Â±0.7 | 0.18% | 312Â±18 |
| DeepSeek-V2 7B | 71.3% | 5.8Â±1.1 | 0.22% | 156Â±12 |
| **å¹³å‡** | â€” | **5.4Â±0.8** | **0.25%** | **186Â±13** |

> ğŸ’¡ **å‘ç°**ï¼šå¹³å‡åªéœ€ **ç¿»è½¬çº¦ 5 ä¸ªå…³é”®æ¯”ç‰¹** å³å¯ä½¿ LLM åŠŸèƒ½å®Œå…¨å´©æºƒï¼ˆ>99% ç²¾åº¦æŸå¤±ï¼‰ï¼Œè¯´æ˜å­˜åœ¨é«˜åº¦ç¨€ç–ä½†è‡´å‘½çš„è„†å¼±ç‚¹ã€‚

### ğŸ›¡ï¸ å¯é æ€§æ„ŸçŸ¥è®¾è®¡æ´å¯Ÿï¼ˆTable IIIï¼‰
| ä¿æŠ¤ç­–ç•¥ | é¢ç§¯å¼€é”€ (AO%) | æ•…éšœè¦†ç›–ç‡ (FC%) | æˆæœ¬æ•ˆç›Š (CE = FC/AO) |
|----------|----------------|-------------------|------------------------|
| No Protection | 0 | 0 | â€” |
| Parity (Uniform) | 6.3 | 0.1 | 0.0 |
| ECC SECDED (Uniform) | 18.7 | 95.1 | 5.1 |
| ECC ChipKill (Uniform) | 31.4 | 98.7 | 3.1 |
| TMR (Uniform) | 205.0 | 99.2 | 0.5 |
| **RIFT-Guided ECC** | **13.8** | **88.5** | **6.4** |

> âœ… **å…³é”®ä¼˜åŠ¿**ï¼šRIFT æŒ‡å¯¼çš„**é€‰æ‹©æ€§ ECC ä¿æŠ¤æ–¹æ¡ˆ**ï¼Œç›¸æ¯”å…¨èŠ¯ç‰‡ TMRï¼Œåœ¨é¢ç§¯å¼€é”€ä»… **13.8%** çš„æƒ…å†µä¸‹è¾¾åˆ° 88.5% è¦†ç›–ç‡ï¼Œ**æˆæœ¬æ•ˆç›Šæå‡ 12.8Ã—**ï¼ˆ6.4 / 0.5ï¼‰ï¼

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### A. æ··åˆæ•æ„Ÿåº¦æŒ‡æ ‡æœ‰æ•ˆæ€§ï¼ˆFigure 3ï¼‰
- å½“æ··åˆç³»æ•° $\alpha = 0.5$ï¼ˆå¹³è¡¡ magnitude ä¸ gradientï¼‰æ—¶ï¼Œæ‰¾åˆ°çš„æœ€å°æ•…éšœé›†æœ€å°ï¼ˆ5.0Â±0.4ï¼‰ï¼Œæ¯”çº¯ magnitudeï¼ˆ7.1ï¼‰å‡å°‘ **29%**ã€‚
- è¡¨æ˜**é™æ€ä¸åŠ¨æ€ä¿¡æ¯èåˆæ˜¾è‘—æå‡å¼•å¯¼è´¨é‡**ã€‚

#### B. ä¸‰é˜¶æ®µæ¶æ„å¿…è¦æ€§ï¼ˆTable Vï¼‰
| é…ç½® | æ‰¾åˆ°çš„å…³é”®æ•…éšœæ•° | æ”¶æ•›æ‰€éœ€ Episodes |
|------|------------------|---------------------|
| Complete RIFT | 5.0Â±0.4 | 50Â±3 |
| RL-Onlyï¼ˆç›¸åŒé¢„ç®—ï¼‰ | 47.3Â±8.2 | 50ï¼ˆæœªæ”¶æ•›ï¼‰ |
| RL-Onlyï¼ˆè‡³æ”¶æ•›ï¼‰ | 5.2Â±0.6 | 890Â±67 |

> â— **ç»“è®º**ï¼šè‹¥è·³è¿‡ Phase I & II çš„æ•æ„Ÿåº¦é¢„ç­›é€‰ï¼ŒRL éœ€è¦ **17Ã— æ›´å¤šè®­ç»ƒæ­¥æ•°** æ‰èƒ½æ”¶æ•›ï¼Œè¯æ˜å‰æœŸå‰ªæè‡³å…³é‡è¦ã€‚

#### C. RL è¶…å‚æ•°é²æ£’æ€§ï¼ˆFigure 4ï¼‰
- è®­ç»ƒ Episodes â‰¥ 50 åæ€§èƒ½é¥±å’Œ
- æ¢ç´¢ç‡ $\epsilon \in [0.05, 0.3]$ å†…ç»“æœç¨³å®šï¼ˆæ³¢åŠ¨ <5%ï¼‰
> ğŸ‘‰ è¯´æ˜ RIFT å¯¹è¶…å‚ä¸æ•æ„Ÿï¼Œæ˜“äºéƒ¨ç½²ã€‚

#### D. è·¨æ¶æ„æ³›åŒ–èƒ½åŠ›ï¼ˆTable VIï¼‰
| æ¨¡å‹ | æ··åˆæŒ‡æ ‡å¢ç›Š | ä¸‰é˜¶æ®µæ¶æ„å¢ç›Š |
|------|--------------|----------------|
| GPT-2 Large | 24% | 3.8Ã— |
| LLaMA 3.1 8B | 29% | 4.2Ã— |
| DeepSeek-V2 7B | 31% | 4.6Ã— |

> âœ… RIFT çš„ä¼˜åŠ¿åœ¨å¤šç§ LLM æ¶æ„ä¸‹ä¸€è‡´æˆç«‹ï¼Œå…·å¤‡è‰¯å¥½é€šç”¨æ€§ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… ä¸»è¦å‘ç°
1. **LLM å­˜åœ¨æç«¯ç¨€ç–ä½†é«˜å½±å“åŠ›çš„è„†å¼±æ¯”ç‰¹ä½**ï¼Œå¹³å‡ä»…éœ€ **5~6 ä¸ªæ¯”ç‰¹ç¿»è½¬**å³å¯å¯¼è‡´åŠŸèƒ½å´©æºƒã€‚
2. **ä¼ ç»Ÿ RFI æ–¹æ³•æ•ˆç‡ä½ä¸‹**ï¼Œéœ€æµ·é‡æµ‹è¯•å‘é‡ï¼Œè€Œ RIFT å¯å®ç° >99% å‘é‡å‹ç¼©ã€‚
3. **RIFT æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•**ï¼š
   - ç›¸æ¯” GenBFAï¼Œ**é€Ÿåº¦å¿« 2.2Ã—**
   - ç›¸æ¯” RFIï¼Œ**æ•ˆç‡é«˜ 7.5Ã—**
4. **RIFT æ”¯æŒå¯é æ€§æ„ŸçŸ¥è®¾è®¡ä¼˜åŒ–**ï¼š
   - æä¾›å¯æ“ä½œçš„è„†å¼±ä½ç½®æ•°æ®
   - æŒ‡å¯¼çš„é€‰æ‹©æ€§ ECC æ–¹æ¡ˆæ¯” TMR **æˆæœ¬æ•ˆç›Šé«˜ 12.8Ã—**
5. **æ¡†æ¶å…·å¤‡å¼ºä¸€è‡´æ€§ä¸å¯æ‰©å±•æ€§**ï¼š
   - å¤šæ¬¡è¿è¡Œç»“æœç¨³å®šï¼ˆCI çª„ï¼‰
   - æ—¶é—´å¤æ‚åº¦éšå…³é”®å‚æ•°é›†çº¿æ€§å¢é•¿ï¼ˆ$O(k)$ï¼‰ï¼Œå†…å­˜ä¸º $O(k^{1.3})$

### âš ï¸ å±€é™æ€§
- å½“å‰ä»…è€ƒè™‘ **æ°¸ä¹…æ€§å†…å­˜æ¯”ç‰¹ç¿»è½¬**ï¼Œå°šæœªæ¶µç›–ç¬æ€é”™è¯¯ï¼ˆsoft errorsï¼‰ã€é€»è¾‘é—¨æ•…éšœæˆ–æ—¶åºç›¸å…³æ•…éšœã€‚
- å¼ºåŒ–å­¦ä¹ é˜¶æ®µä»ä¾èµ–å¤§é‡ DUT ä»¿çœŸè¯„ä¼°ï¼ˆ$C_{\text{eval}}$ æˆæœ¬é«˜ï¼‰ï¼Œè™½å·²å‰ªæä½†ä»æœ‰ä¸€å®šå¼€é”€ã€‚
- å¯¹éå¸¸è§„é‡åŒ–æ ¼å¼ï¼ˆå¦‚ FP8ã€NF4ï¼‰çš„æ”¯æŒæœ‰å¾…éªŒè¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³å…¶ä»–å¤§æ¨¡å‹æ¶æ„ï¼šVision Transformersã€Diffusion Models
2. æ”¯æŒæ›´å¤æ‚çš„æ•…éšœæ¨¡å‹ï¼štransient faultsã€timing violationsã€cross-layer error propagation
3. é›†æˆè¿›è‡ªåŠ¨åŒ–ç»¼åˆæµç¨‹ï¼ˆreliability-aware synthesisï¼‰ï¼Œå®ç°ç‰©ç†è®¾è®¡å±‚é¢çš„è‡ªåŠ¨åŠ å›º
4. æ¢ç´¢åŸºäº LLM è‡ªèº«åé¦ˆçš„åœ¨çº¿ fault detection æœºåˆ¶

---

## âœ… æ€»ç»“
**RIFT æ˜¯é¦–ä¸ªå°†å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿæ€§åº”ç”¨äº LLM åŠ é€Ÿå™¨æ•…éšœè¯„ä¼°çš„å·¥ä½œ**ï¼Œé€šè¿‡â€œæ•æ„Ÿåº¦åˆ†æ + RL æœç´¢ + UVM è‡ªåŠ¨ç”Ÿæˆâ€çš„ä¸‰é˜¶æ®µæ¡†æ¶ï¼Œå®ç°äº†ï¼š
- **é«˜æ•ˆç²¾å‡†åœ°å‘ç°æœ€å°é«˜å½±å“æ•…éšœé›†**
- **æå¤§é™ä½æµ‹è¯•æˆæœ¬ä¸æ—¶é—´**
- **ä¸ºæ™ºèƒ½ç¡¬ä»¶ä¿æŠ¤æä¾›æ•°æ®é©±åŠ¨ä¾æ®**

å®ƒä¸ä»…æå‡äº† Design Automation åœ¨ AI èŠ¯ç‰‡å¯é æ€§é¢†åŸŸçš„æŠ€æœ¯æ°´å¹³ï¼Œä¹Ÿä¸ºä¸‹ä¸€ä»£å®‰å…¨å…³é”®åº”ç”¨ï¼ˆè‡ªåŠ¨é©¾é©¶ã€åŒ»ç–— AIï¼‰æä¾›äº†åšå®çš„æ•…éšœè¯„ä¼°åŸºç¡€ã€‚

</details>

---

### 14. [SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments](https://arxiv.org/abs/2512.09897)

**Authors**: Haoye Lu, Pavan Seshadri, Kaheer Suleman  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.09897v1  

#### Abstract
Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for gu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å¤æ‚çš„æ–‡æœ¬ç¯å¢ƒï¼ˆtext-based environmentsï¼‰ä¸­è¿›è¡Œé•¿æœŸè§„åˆ’é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å¼€æ”¾çš„åŠ¨ä½œç©ºé—´**ï¼ˆopen-ended action spacesï¼‰
- **æ¨¡ç³Šçš„è§‚æµ‹çŠ¶æ€**ï¼ˆambiguous observationsï¼‰
- **ç¨€ç–çš„åé¦ˆä¿¡å·**ï¼ˆsparse feedbackï¼‰

ç°æœ‰çš„åŸºäº **Large Language Models (LLMs)** çš„åˆ†å±‚è§„åˆ’æ–¹æ³•è™½ç„¶èƒ½åˆ©ç”¨ LLM çš„è¯­ä¹‰çŸ¥è¯†æŒ‡å¯¼é«˜å±‚æ¨ç†ï¼Œä½†é€šå¸¸å­˜åœ¨ä¸¤ä¸ªæ˜¾è‘—ç¼ºé™·ï¼š
1. åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­é¢‘ç¹è°ƒç”¨ LLMï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬é«˜æ˜‚ã€éƒ¨ç½²æ•ˆç‡ä½ï¼›
2. LLM å‚æ•°å›ºå®šï¼ˆfrozenï¼‰ï¼Œæ— æ³•é’ˆå¯¹ç›®æ ‡ä»»åŠ¡è¿›è¡Œé€‚åº”æ€§è°ƒæ•´ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSCOPE
æœ¬æ–‡æå‡º **SCOPE**ï¼ˆSubgoal-COnditioned Pretraining for Efficient planningï¼‰ï¼Œä¸€ç§é«˜æ•ˆçš„**ä¸€æ¬¡æ€§æ•™å¸ˆæ¡†æ¶**ï¼ˆone-time teacher frameworkï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **ä»…åœ¨åˆå§‹åŒ–é˜¶æ®µä½¿ç”¨ä¸€æ¬¡ LLM**ï¼Œä»äººç±»ç¤ºèŒƒè½¨è¿¹ä¸­æå–å­ç›®æ ‡ï¼ˆsubgoalsï¼‰ï¼›
- åˆ©ç”¨è¿™äº›å­ç›®æ ‡å¯¹ä¸€ä¸ªè½»é‡çº§å­¦ç”Ÿæ¨¡å‹ï¼ˆstudent modelï¼‰è¿›è¡Œé¢„è®­ç»ƒï¼›
- åç»­é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¾®è°ƒï¼Œä½¿å­¦ç”Ÿæ¨¡å‹ç‹¬ç«‹å®Œæˆä»»åŠ¡ï¼Œæ— éœ€å†ä¾èµ– LLMã€‚

#### å…³é”®åˆ›æ–°ç‚¹ï¼š
- **One-shot LLM Usage**ï¼šä¸åŒäºä»¥å¾€åå¤æŸ¥è¯¢ LLM ç”ŸæˆåŠ¨æ€å­ç›®æ ‡çš„æ–¹æ³•ï¼ŒSCOPE åªåœ¨å¼€å§‹æ—¶ç”¨ LLM åˆ†æç¤ºèŒƒè½¨è¿¹å¹¶ç”Ÿæˆå›ºå®šçš„å­ç›®æ ‡åºåˆ—ï¼Œä¹‹åå®Œå…¨è„±ç¦» LLMã€‚
- **Subgoal Extraction via Code Generation**ï¼šè®© LLM è¾“å‡ºä¸€ä¸ªå¯æ‰§è¡Œçš„ Python å‡½æ•° `fac(T)` æ¥ç³»ç»ŸåŒ–åœ°åˆ†è§£è½¨è¿¹ä¸ºå­ç›®æ ‡ï¼Œç¡®ä¿ä¸€è‡´æ€§ã€‚
- **Hierarchical RL æ¶æ„**ï¼šé‡‡ç”¨ manager-agentï¼ˆé«˜å±‚ç®¡ç†è€…ï¼‰ä¸ employee-agentï¼ˆåº•å±‚æ‰§è¡Œè€…ï¼‰çš„åŒå±‚æ¶æ„ï¼Œåˆ†åˆ«è´Ÿè´£å­ç›®æ ‡æè®®å’Œå…·ä½“åŠ¨ä½œæ‰§è¡Œã€‚
- **World Model æ”¯æŒ RL å¾®è°ƒ**ï¼šæ„å»ºåŸºäºç¤ºèŒƒæ•°æ®çš„ä¸–ç•Œæ¨¡å‹ï¼ˆworld modelï¼‰ï¼Œç”¨äºåœ¨æ— çœŸå®ç¯å¢ƒäº¤äº’çš„æƒ…å†µä¸‹è¿›è¡Œ RL è®­ç»ƒï¼Œæå‡æ ·æœ¬æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ADaPT (åŸºçº¿) | SCOPE (æœ¬æ–‡) |
|------|-------------|------------|
| LLM è°ƒç”¨é¢‘ç‡ | æ¨ç†æ—¶æŒç»­è°ƒç”¨ | ä»…åˆå§‹åŒ–ä¸€æ¬¡ |
| æ¨¡å‹å¤§å° | 175B (GPT-3.5) | 11.04Mï¼ˆå°å‹ç½‘ç»œï¼‰ |
| æ¨ç†æ—¶é—´ | 164.4 ç§’ | **3.0 ç§’** |
| æˆåŠŸç‡ | 0.52 | **0.56** |
| éƒ¨ç½²æ•ˆç‡ | ä½ï¼ˆéœ€ API è°ƒç”¨ï¼‰ | é«˜ï¼ˆæœ¬åœ° GPU è¿è¡Œï¼‰ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼š**æ›´é«˜æ€§èƒ½ + æ›´ä½æˆæœ¬ + æ›´æ˜“éƒ¨ç½²**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **TextCraft**ï¼šä¸€ä¸ªå— Minecraft å¯å‘çš„çº¯æ–‡æœ¬ç¯å¢ƒï¼Œæµ‹è¯•æ™ºèƒ½ä½“åœ¨åˆæˆç‰©å“ä»»åŠ¡ä¸­çš„ç»„åˆæ¨ç†ä¸é•¿æœŸè§„åˆ’èƒ½åŠ›ã€‚
  - æ™ºèƒ½ä½“éœ€æ ¹æ®ç›®æ ‡ï¼ˆå¦‚â€œåˆ¶ä½œäº‘æ‰å°é˜¶â€ï¼‰å’Œå¯ç”¨é…æ–¹ï¼Œé€æ­¥æ”¶é›†åŸºç¡€ææ–™ã€åˆ¶é€ ä¸­é—´å“ï¼Œæœ€ç»ˆåˆæˆç›®æ ‡ç‰©å“ã€‚
  - çŠ¶æ€ä»¥åº“å­˜å­—å…¸è¡¨ç¤ºï¼ŒåŠ¨ä½œä¸ºè‡ªç„¶è¯­è¨€å‘½ä»¤ï¼ˆå¦‚ `craft 6 spruce slab using 3 spruce planks`ï¼‰ã€‚
- **ç¤ºèŒƒæ•°æ®ç”Ÿæˆ**ï¼š
  - è‡ªåŠ¨ç”Ÿæˆ 50ä¸‡æ¡æ¬¡ä¼˜è½¨è¿¹ï¼ˆsuboptimal trajectoriesï¼‰ï¼Œæ¨¡æ‹Ÿäººç±»ç©å®¶è¡Œä¸ºï¼ˆåŒ…å«çº¦10%éšæœºå™ªå£°ï¼‰ã€‚
  - å…¶ä¸­ 1K ç”¨äºéªŒè¯å’Œæµ‹è¯•ã€‚

### å®éªŒè®¾ç½®
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Success Rate**ï¼šæˆåŠŸå®Œæˆç›®æ ‡ä»»åŠ¡çš„æ¯”ä¾‹ã€‚
  - **Inference Time**ï¼šå•æ¬¡æ¸¸æˆå¹³å‡è€—æ—¶ï¼ˆåœ¨ NVIDIA A10 GPU ä¸Šæµ‹é‡ï¼‰ã€‚
- **æ¨¡å‹æ¶æ„**ï¼š
  - Manager å’Œ Employee Agent å…±äº«ç»Ÿä¸€çš„ **variational sequence-to-sequence æ¶æ„**ï¼ŒåŸºäº LSTM ç¼–ç å™¨-è§£ç å™¨ã€‚
  - æ‰€æœ‰è¾“å…¥è¾“å‡ºå‡è½¬æ¢ä¸ºæ–‡æœ¬å½¢å¼å¤„ç†ã€‚
- **è®­ç»ƒæµç¨‹**ï¼š
  1. **é¢„è®­ç»ƒé˜¶æ®µ**ï¼šä½¿ç”¨ LLM æå–çš„å­ç›®æ ‡å¯¹ manager å’Œ employee è¿›è¡Œæ¨¡ä»¿å­¦ä¹ ï¼ˆimitation learningï¼‰ã€‚
  2. **RL å¾®è°ƒé˜¶æ®µ**ï¼š
     - Employee Agent åœ¨ **Employee World Model (EWM)** ä¸Šä¼˜åŒ–å­ç›®æ ‡è¾¾æˆç‡ï¼›
     - Manager Agent åœ¨ **Manager World Model (MWM)** ä¸Šä¼˜åŒ–æœ€ç»ˆç›®æ ‡æˆåŠŸç‡ã€‚
  3. MWM ç”± EWM å’Œè®­ç»ƒå¥½çš„ employee agent ç»„åˆè€Œæˆï¼Œå®ç°å­ç›®æ ‡çº§åˆ«çš„ rolloutã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ADaPT (Prasad et al., 2024)**ï¼šå½“å‰æœ€å…ˆè¿›çš„ LLM é©±åŠ¨åˆ†å±‚è§„åˆ’å™¨ï¼Œä½¿ç”¨ GPT-3.5 ä½œä¸º plannerï¼Œåœ¨æ¨ç†æ—¶å®æ—¶ç”Ÿæˆå­ç›®æ ‡ã€‚
- **å…¶ä»– LLM åç«¯å¯¹æ¯”**ï¼šåœ¨ Table 4 ä¸­è¿˜æ¯”è¾ƒäº†å¤šç§ LLMï¼ˆå¦‚ GPT-4oã€Mistral Small 3ã€Claude-3 Haiku ç­‰ï¼‰ä½œä¸º ADaPT çš„ backend è¡¨ç°ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰

| æ–¹æ³• | Success Rate | å‚æ•°é‡ |
|------|--------------|--------|
| ADaPT (GPT-3.5) | 0.52 | 175B |
| **SCOPE (ours)** | **0.56** | **11.04M** |
| SCOPE (hand-engineered subgoal) | 0.58 | 11.04M |
| SCOPE (without manager RL-finetuning) | 0.24 | 11.04M |

> ğŸ” **ç»“è®º**ï¼šå³ä½¿ä½¿ç”¨éæœ€ä¼˜çš„ LLM ç”Ÿæˆå­ç›®æ ‡ï¼ŒSCOPE ä»èƒ½è¶…è¶Šä¾èµ–å¤§å‹ LLM å®æ—¶æ¨ç†çš„ ADaPTã€‚

### æ¨ç†æ•ˆç‡å¯¹æ¯”
- **SCOPE**ï¼šå¹³å‡ **3.0 ç§’** å®Œæˆæ¸¸æˆï¼ˆå•å¼  A10 GPUï¼‰
- **ADaPT**ï¼šå¹³å‡ **164.4 ç§’**ï¼ˆé€šè¿‡ OpenAI API è°ƒç”¨ GPT-3.5ï¼Œç†æƒ³ç½‘ç»œæ¡ä»¶ä¸‹ï¼‰

> â±ï¸ **é€Ÿåº¦æå‡è¶…è¿‡ 50 å€**

### å¤šç§ LLM åç«¯ä¸‹çš„ ADaPT æ€§èƒ½ï¼ˆTable 4ï¼‰
| Backend | Success Rate | æ˜¯å¦å¼€æºæƒé‡ |
|--------|---------------|-------------|
| GPT-4o | 0.58 | No |
| Mistral Small 3 | 0.58 | Yes |
| GPT-3.5 | 0.52 | No |
| GPT-4o mini | 0.43 | No |
| DeepSeek-R1-Distill-Qwen-32B | 0.13 | Yes |
| Claude-3 Haiku | 0.00 | No |
| **SCOPE (ours)** | **0.56** | â€”â€” |

> ğŸ“Œ **è§‚å¯Ÿ**ï¼šSCOPE ä»¥æå°æ¨¡å‹ï¼ˆ11Mï¼‰è¾¾åˆ°äº†æ¥è¿‘æœ€å¼ºé—­æºæ¨¡å‹ï¼ˆGPT-4oï¼‰çš„æ€§èƒ½ï¼Œè¿œè¶…å¤šæ•°å¼€æº LLMã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰å­ç›®æ ‡è´¨é‡çš„å½±å“ï¼ˆFig 8aï¼‰
- **Hand-engineered subgoal**ï¼ˆæ‰‹å·¥è®¾è®¡ã€å¯è§£é‡Šæ€§å¼ºï¼‰ï¼šæˆåŠŸç‡ 0.58
- **Standard SCOPE**ï¼ˆLLM è‡ªåŠ¨ç”Ÿæˆï¼‰ï¼š0.56
- **No Quantity Info**ï¼ˆå»æ‰æ•°é‡ä¿¡æ¯ï¼‰ï¼šä¸‹é™è‡³ ~0.50
- **Non-Hierarchical**ï¼ˆæ— å­ç›®æ ‡ï¼Œç›´æ¥è¿½æ±‚ç»ˆæç›®æ ‡ï¼‰ï¼šä»… 0.28

> ğŸ’¡ è¯´æ˜ï¼š**å­ç›®æ ‡çš„å­˜åœ¨è‡³å…³é‡è¦**ï¼Œä¸”**æ•°é‡ç²¾åº¦å½±å“æ˜¾è‘—**ã€‚

#### ï¼ˆ2ï¼‰å­ç›®æ ‡ä¸ç¯å¢ƒå¯¹é½æ€§çš„ç ´åå®éªŒï¼ˆFig 8bï¼‰
- éšæœºæ›¿æ¢å­ç›®æ ‡ä¸­ç‰©å“åç§°çš„æ¯”ä¾‹ $ p \in \{0, 0.25, 0.5, 1.0\} $
- ç»“æœæ˜¾ç¤ºï¼š
  - å½“ $ p=0.25 $ æ—¶ï¼Œæœ€ç»ˆæˆåŠŸç‡é™è‡³ **0.09**
  - å½“ $ p=1.0 $ æ—¶ï¼Œå‡ ä¹å®Œå…¨å¤±è´¥ï¼ˆ0.02ï¼‰
- å³ä½¿å­ç›®æ ‡æ¨¡ç³Šä½†**è¯­ä¹‰æ­£ç¡®**ï¼Œä»æœ‰åŠ©äºè§„åˆ’ï¼›ä¸€æ—¦**è¯­ä¹‰é”™ä½**ï¼Œåè€Œè¯¯å¯¼ agentã€‚

> â— ç»“è®ºï¼š**å­ç›®æ ‡å¿…é¡»ä¸çœŸå®ç¯å¢ƒå› æœå¯¹é½**ï¼Œå¦åˆ™å±å®³å¤§äºæ— ç”¨ã€‚

#### ï¼ˆ3ï¼‰Manager RL å¾®è°ƒçš„é‡è¦æ€§
- ç§»é™¤ manager çš„ RL å¾®è°ƒåï¼ŒæˆåŠŸç‡ä» 0.56 ä¸‹é™åˆ° **0.24**
- å›¾ 6 æ˜¾ç¤º manager åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å­¦ä¼šç»•å¼€ employee çš„å¼±ç‚¹ï¼Œé€‰æ‹©æ›´æ˜“å®ç°çš„æ›¿ä»£è·¯å¾„ã€‚

> âœ… è¯æ˜ï¼š**manager çš„è‡ªé€‚åº”èƒ½åŠ›æ˜¯é²æ£’æ€§çš„å…³é”®æ¥æº**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **LLM ä¸å¿…å…¨ç¨‹å‚ä¸ä¹Ÿèƒ½æœ‰æ•ˆèµ‹èƒ½ RL**ï¼š
   - å³ä½¿ LLM æœªä¸ç¯å¢ƒäº¤äº’ã€ç”Ÿæˆçš„æ˜¯æ¬¡ä¼˜ç”šè‡³ä¸å¯è§£é‡Šçš„å­ç›®æ ‡ï¼Œåªè¦æä¾›åˆç†çš„åˆå§‹åˆ†è§£ç»“æ„ï¼Œå°±èƒ½ä¸ºåˆ†å±‚ RL æä¾›å¼ºå¤§å…ˆéªŒã€‚
   
2. âœ… **One-time teaching æ˜¯é«˜æ•ˆå¯è¡Œçš„èŒƒå¼**ï¼š
   - å°† LLM è§†ä¸ºâ€œä¸€æ¬¡æ€§æ•™å¸ˆâ€ï¼Œä»…ç”¨äºåˆå§‹åŒ–ï¼Œåç»­å®Œå…¨ç”±å°å‹å­¦ç”Ÿæ¨¡å‹è‡ªä¸»è¿è¡Œï¼Œå¤§å¹…é™ä½éƒ¨ç½²æˆæœ¬ã€‚

3. âœ… **å­ç›®æ ‡çš„è´¨é‡å…³é”®åœ¨äºâ€œå¯¹é½æ€§â€è€Œéâ€œç²¾ç¡®æ€§â€**ï¼š
   - å­ç›®æ ‡æ˜¯å¦åæ˜ çœŸå®çš„ç¯å¢ƒä¾èµ–å…³ç³»ï¼ˆcausal groundingï¼‰æ¯”å…¶æ˜¯å¦å¯è§£é‡Šæ›´é‡è¦ã€‚
   - é”™è¯¯å¯¹é½çš„å­ç›®æ ‡ä¼šä¸¥é‡è¯¯å¯¼ agentï¼Œç”šè‡³ä¸å¦‚æ²¡æœ‰å­ç›®æ ‡ã€‚

4. âœ… **Manager å±‚çš„ RL å¾®è°ƒå…·æœ‰è¡¥å¿æœºåˆ¶ä½œç”¨**ï¼š
   - èƒ½ä¸»åŠ¨è§„é¿ employee agent çš„æ‰§è¡Œç¼ºé™·ï¼ŒåŠ¨æ€è°ƒæ•´è®¡åˆ’ï¼Œæé«˜æ•´ä½“é²æ£’æ€§å’ŒæˆåŠŸç‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡ç¤ºèŒƒè½¨è¿¹**ï¼šè‹¥ç¤ºèŒƒæœ¬èº«åå·®è¿‡å¤§æˆ–ç¼ºä¹å¤šæ ·æ€§ï¼ŒLLM æå–çš„å­ç›®æ ‡å¯èƒ½ä¸¥é‡å¤±çœŸã€‚
- **å­ç›®æ ‡ä¸å¯è§£é‡Š**ï¼šç”±äº LLM è¾“å‡ºçš„æ˜¯ç¨‹åºåŒ–å‡½æ•°è€Œéè‡ªç„¶è¯­è¨€è§£é‡Šï¼Œç”Ÿæˆçš„å­ç›®æ ‡å¾€å¾€éš¾ä»¥ç†è§£ã€‚
- **æ³›åŒ–èƒ½åŠ›å¾…éªŒè¯**ï¼šç›®å‰ä»…åœ¨ TextCraft ä¸ŠéªŒè¯ï¼Œå¤æ‚å¼€æ”¾ä¸–ç•Œä¸­çš„è¡¨ç°å°šä¸æ˜ç¡®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å¦‚ä½•ç»“åˆå°‘é‡åœ¨çº¿ LLM æŸ¥è¯¢ä¸ one-time teachingï¼Œè¿›ä¸€æ­¥æå‡å­ç›®æ ‡è´¨é‡ï¼›
- è®¾è®¡æ›´å…·è§£é‡Šæ€§çš„å­ç›®æ ‡æå–æœºåˆ¶ï¼Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å¢å¼ºé€æ˜åº¦ï¼›
- å°† SCOPE æ‰©å±•åˆ°è§†è§‰-è¯­è¨€æˆ–å¤šæ¨¡æ€ç¯å¢ƒä¸­ï¼›
- ç ”ç©¶å¦‚ä½•è‡ªåŠ¨è¯†åˆ«å’Œä¿®æ­£é”™è¯¯å¯¹é½çš„å­ç›®æ ‡ã€‚

---

> ğŸ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **SCOPE æˆåŠŸå±•ç¤ºäº†â€œå¤§æ¨¡å‹æ•™å°æ¨¡å‹ä¸€æ¬¡ï¼Œå°æ¨¡å‹è‡ªå·±å­¦ä¼šé•¿æœŸè§„åˆ’â€çš„å¯è¡Œæ€§ï¼Œåœ¨æ€§èƒ½ä¸Šè¶…è¶Šå®æ—¶è°ƒç”¨ LLM çš„æ–¹æ³•ï¼ŒåŒæ—¶å°†æ¨ç†é€Ÿåº¦æå‡æ•°åå€ï¼Œä¸ºé«˜æ•ˆã€å¯éƒ¨ç½²çš„æ–‡æœ¬ç¯å¢ƒæ™ºèƒ½ä½“æä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 15. [An End-to-end Planning Framework with Agentic LLMs and PDDL](https://arxiv.org/abs/2512.09629)

**Authors**: Emanuele La Malfa, Ping Zhu, Samuele Marro, Sara Bernardini, Michael Wooldridge  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.09629v1  

#### Abstract
We present an end-to-end framework for planning supported by verifiers. An orchestrator receives a human specification written in natural language and converts it into a PDDL (Planning Domain Definition Language) model, where the domain and problem are iteratively refined by sub-modules (agents) to ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAn End-to-end Planning Framework with Agentic LLMs and PDDL

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**è‡ªç„¶è¯­è¨€åˆ°å¯æ‰§è¡Œè®¡åˆ’ä¹‹é—´çš„é¸¿æ²Ÿé—®é¢˜**ã€‚ä¼ ç»Ÿè‡ªåŠ¨åŒ–è§„åˆ’ï¼ˆå¦‚åŸºäº PDDL çš„æ–¹æ³•ï¼‰è™½ç„¶èƒ½ä¿è¯æ­£ç¡®æ€§å’Œæœ€ä¼˜æ€§ï¼Œä½†ä¾èµ–ä¸“å®¶æ‰‹å·¥å»ºæ¨¡é¢†åŸŸçŸ¥è¯†ï¼›è€Œ Large Language Modelsï¼ˆLLMsï¼‰è™½æ“…é•¿ç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œå´åœ¨é•¿è§†é‡ã€å¤šæ­¥é€»è¾‘æ¨ç†ä»»åŠ¡ä¸­å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼ˆhallucinationsï¼‰ã€ä¸ä¸€è‡´æˆ–ä¸å¯è¡Œçš„åŠ¨ä½œåºåˆ—ã€‚

æ­¤å¤–ï¼Œç°æœ‰ LLM+PDDL æ¡†æ¶é€šå¸¸é‡‡ç”¨é™æ€æµæ°´çº¿ç»“æ„ï¼Œç¼ºä¹åŠ¨æ€é€‚åº”èƒ½åŠ›æ¥å¤„ç†æ¨¡ç³Šã€çŸ›ç›¾æˆ–æœªæ˜ç¡®è¯´æ˜çš„éœ€æ±‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**ç«¯åˆ°ç«¯çš„ã€åŸºäºä»£ç†ï¼ˆagenticï¼‰æ¶æ„çš„è§„åˆ’æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **åŠ¨æ€å¤šä»£ç†å·¥ä½œæµç¼–æ’ï¼ˆDynamic Agent Orchestrationï¼‰**  
  å¼•å…¥ä¸€ä¸ªç”± LLM é©±åŠ¨çš„â€œOrchestratorâ€æ¨¡å—ï¼Œèƒ½å¤Ÿæ ¹æ®å½“å‰ PDDL åŸŸ/é—®é¢˜çš„çŠ¶æ€ã€æ±‚è§£å™¨æ—¥å¿—å’ŒéªŒè¯åé¦ˆï¼Œ**åŠ¨æ€é€‰æ‹©å¹¶è°ƒç”¨ä¸åŒçš„ä¸“ç”¨ Agent å­æ¨¡å—**è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œè€Œéå›ºå®šæµç¨‹ã€‚

- **é—­ç¯è¿­ä»£ç²¾ç‚¼æœºåˆ¶ï¼ˆIterative Refinement Loopï¼‰**  
  åˆå§‹ç”± LLM å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸º JSON è¡¨ç¤ºï¼Œå†ç”Ÿæˆåˆæ­¥ PDDL æ¨¡å‹ â†’ è°ƒç”¨å¤–éƒ¨ Plannerï¼ˆå¦‚ Fast Downwardï¼‰å°è¯•æ±‚è§£ â†’ è‹¥å¤±è´¥æˆ–å­˜åœ¨é”™è¯¯ï¼Œåˆ™é€šè¿‡å¤šä¸ª Refiner Agents å¯¹æ¨¡å‹è¿›è¡Œè¯­æ³•ã€è¯­ä¹‰ã€æ—¶é—´ä¸€è‡´æ€§ç­‰æ–¹é¢çš„ä¿®å¤ â†’ å¾ªç¯ç›´è‡³æˆåŠŸã€‚

- **å…¨è‡ªåŠ¨åŒ–ä¸”æ— éœ€äººå·¥å¹²é¢„**  
  æ•´ä¸ªè¿‡ç¨‹ä»è‡ªç„¶è¯­è¨€è¾“å…¥åˆ°æœ€ç»ˆå¯æ‰§è¡Œè®¡åˆ’è¾“å‡ºå®Œå…¨è‡ªåŠ¨å®Œæˆï¼Œ**æ— éœ€ä»»ä½•ä¸­é—´äººç±»ä»‹å…¥**ï¼Œå®ç°äº†çœŸæ­£çš„ end-to-end è§„åˆ’ã€‚

- **è‡ªç„¶è¯­è¨€å›è¯‘å¢å¼ºå¯è§£é‡Šæ€§**  
  æœ€ç»ˆå°† PDDL è®¡åˆ’ç¿»è¯‘å›è‡ªç„¶è¯­è¨€ï¼Œæå‡å¯¹ç”¨æˆ·çš„å¯è¯»æ€§å’Œå®¡è®¡èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒå½¢å¼åŒ–æ­£ç¡®æ€§ã€‚

- **æ”¯æŒä»»æ„ PDDL æ±‚è§£å™¨ä¸éªŒè¯å·¥å…·é›†æˆ**  
  å…¼å®¹ Fast Downwardã€LPGã€POPF ç­‰ä¸»æµ Plannerï¼Œä»¥åŠ VAL/uVAL ç­‰ Validatorï¼Œå…·å¤‡è‰¯å¥½çš„é€šç”¨æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿ LLM ç›´æ¥ç”Ÿæˆ | é™æ€ LLM+PDDL æµæ°´çº¿ | æœ¬æ–‡æ–¹æ³• |
|------|------------------|------------------------|----------|
| æ­£ç¡®æ€§ä¿éšœ | âŒ æ˜“å‡ºç°å¹»è§‰ | âœ… æœ‰ PDDL å½¢å¼åŒ–çº¦æŸ | âœ…âœ… å¤šè½®éªŒè¯+ä¿®æ­£ |
| åŠ¨æ€é€‚åº”æ€§ | âŒ å›ºå®šæµç¨‹ | âŒ å›ºå®šè§’è‰²åˆ†é… | âœ… åŠ¨æ€è°ƒåº¦ Agent |
| å¤„ç†æ¨¡ç³Š/çŸ›ç›¾éœ€æ±‚ | âŒ èƒ½åŠ›å¼± | âš ï¸ æœ‰é™ | âœ… æ˜¾å¼æ¾„æ¸…ä¸ä¿®æ­£ |
| å¯æ‰©å±•æ€§ | ä¸­ç­‰ | ä¸­ç­‰ | âœ… æ”¯æŒçµæ´»æ·»åŠ æ–° Agent |
| ç”¨æˆ·å‹å¥½æ€§ | âœ… è‡ªç„¶è¯­è¨€è¾“å‡º | âš ï¸ è¾“å‡ºå¯èƒ½å¤æ‚ | âœ… åŒå‘è‡ªç„¶è¯­è¨€äº¤äº’ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Google Natural Plan Benchmark**  
  åŒ…å«ä¸‰ç±»ç°å®åœºæ™¯ä»»åŠ¡ï¼š
  - Calendar Schedulingï¼ˆæ—¥ç¨‹å®‰æ’ï¼‰
  - Meeting Planningï¼ˆä¼šè®®è¡Œç¨‹è§„åˆ’ï¼‰
  - Trip Planningï¼ˆæ—…è¡Œè·¯çº¿è§„åˆ’ï¼‰

- **PlanBench**  
  æ ‡å‡†åŒ–è§„åˆ’åŸºå‡†ï¼Œæ¶µç›–ç»å…¸è§„åˆ’åŸŸï¼š
  - Logisticsï¼ˆç‰©æµè¿è¾“ï¼‰
  - Depotsï¼ˆä»“åº“è°ƒåº¦ï¼‰
  - Blocksworldï¼ˆç§¯æœ¨ä¸–ç•Œï¼‰
  - Mystery Blocksworld
  - Obfuscated Deceptive Logisticsï¼ˆæ··æ·†æ¬ºéª—æ€§ç‰©æµï¼‰

- **Blocksworld å’Œ Tower of Hanoi**  
  ç»å…¸ç¬¦å·è§„åˆ’éš¾é¢˜ï¼Œç”¨äºæµ‹è¯• LLM åœ¨ç»“æ„åŒ–æ¨ç†ä¸Šçš„æé™ï¼Œå°¤å…¶æ˜¯éšç€é—®é¢˜è§„æ¨¡å¢é•¿çš„è¡¨ç°ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **åŸºç¡€æ¨¡å‹**ï¼šGPT-5-miniï¼ˆä½œä¸º LLM ä¸»å¹²ï¼‰
- **Planner**ï¼šFast Downwardã€POPFã€LPG ç­‰
- **Validator**ï¼šVAL / uVAL
- **è¯„ä¼°æ–¹å¼**ï¼š
  - **Accuracy**ï¼šLLM-as-a-judge åˆ¤æ–­ç”Ÿæˆè®¡åˆ’æ˜¯å¦ä¸çœŸå®è§£åŒ¹é…ï¼ˆ0/1ï¼‰
  - **Verified Accuracy**ï¼šä»…ç»Ÿè®¡é‚£äº›è¢« PDDL éªŒè¯å™¨æ¥å—çš„æœ‰æ•ˆè®¡åˆ’ä¸­çš„å‡†ç¡®ç‡
  - **Cost Reduction (%)**ï¼šå¯ç”¨ä¼˜åŒ–åå¹³å‡æˆæœ¬ä¸‹é™æ¯”ä¾‹ï¼ˆè¡¡é‡ä¼˜åŒ–æ•ˆæœï¼‰
- **æ¯é¡¹ä»»åŠ¡è¿è¡Œ 30 ä¸ªå®ä¾‹**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Vanilla LLMï¼ˆGPT-5-miniï¼‰**ï¼šç›´æ¥è®© LLM è¾“å‡ºè®¡åˆ’ï¼Œä¸åšä»»ä½•å½¢å¼åŒ–å»ºæ¨¡æˆ–éªŒè¯
- **å…¶ä»– LLM+PDDL æ–¹æ³•ï¼ˆå¦‚ LLM+Pï¼‰**ï¼šä»…å•æ¬¡è½¬æ¢ï¼Œæ— è¿­ä»£ç²¾ç‚¼æœºåˆ¶

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### åœ¨ Google Natural Plan ä¸Šçš„ç»“æœï¼ˆå›¾3ï¼‰
| ä»»åŠ¡ | æœ¬æ–¹æ³• Accuracy | Vanilla LLM Accuracy | æå‡å¹…åº¦ |
|------|------------------|-----------------------|---------|
| Calendar Scheduling | 93% | 80% | +13% |
| Meeting Planning | 93% | 53% | **+40%** |
| Trip Planning | 88% | 24% | **+64%** |

> æ³¨ï¼šæœ¬æ–¹æ³•åœ¨ Meeting Planning ä¸Šè¡¨ç°å°¤ä¸ºçªå‡ºï¼Œæ˜¾ç¤ºå…¶åœ¨æ—¶åºçº¦æŸå¤„ç†ä¸Šçš„ä¼˜åŠ¿ã€‚

#### åœ¨ PlanBench ä¸Šçš„ç»“æœï¼ˆå›¾3ï¼‰
| åŸŸ | æœ¬æ–¹æ³• Accuracy | Vanilla LLM Accuracy | æå‡ |
|----|------------------|------------------------|------|
| Depots | 100% | 90% | +10% |
| Logistics | 100% | 93% | +7% |
| Mystery Blocksworld | 93% | 87% | +6% |
| Blocksworld | 93% | 37% | **+56%** |
| Obfuscated Deceptive Logistics | 90% | 20% | **+70%** |

> å¹³å‡æå‡çº¦ **+15%**ï¼Œåœ¨å…·æœ‰è¯¯å¯¼ä¿¡æ¯çš„ä»»åŠ¡ä¸­ä¼˜åŠ¿æ˜¾è‘—ã€‚

#### Blocksworld ä¸ Tower of Hanoi ç»“æœï¼ˆå›¾4ï¼‰
| ä»»åŠ¡ | éš¾åº¦ | æœ¬æ–¹æ³• Accuracy | Vanilla LLM Accuracy |
|------|------|------------------|------------------------|
| Blocksworld | Easy (2â€“4æ­¥) | 97% | 97% |
| | Medium (6â€“8æ­¥) | 100% | 97% |
| | Hard (10â€“12æ­¥) | **97%** | 80% | â†’ **+17%**
| Tower of Hanoi | 4â€“6 disks | 97%~100% | 73%~90% |
| | 7 disks | **90%** | 73% | â†’ **+17%**

> ç‰¹åˆ«å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ**LLMs é€šå¸¸æ— æ³•è§£å†³è¶…è¿‡ 6 å±‚çš„ Tower of Hanoi**ï¼Œè€Œæœ¬æ–‡æ¡†æ¶åœ¨ 7 å±‚ä»è¾¾åˆ° 90% å‡†ç¡®ç‡ã€‚

#### æˆæœ¬ä¼˜åŒ–æ•ˆæœï¼ˆè¡¨1ï¼‰
| ä»»åŠ¡ | éä¼˜åŒ–å¹³å‡æˆæœ¬ | ä¼˜åŒ–åå¹³å‡æˆæœ¬ | æˆæœ¬é™ä½ |
|------|----------------|----------------|-----------|
| Calendar Scheduling | 1.63 | 1.24 | 23.9% |
| Meeting Planning | 210.46 | 79.00 | **62.5%** |
| Trip Planning | 13.24 | 11.22 | 15.2% |
| **å¹³å‡é™ä½** | â€”â€” | â€”â€” | **45.8%** |

> è¡¨æ˜è¯¥æ¡†æ¶ä¸ä»…èƒ½ç”Ÿæˆå¯è¡Œè®¡åˆ’ï¼Œè¿˜èƒ½æœ‰æ•ˆå®ç°**æˆæœ¬æœ€å°åŒ–**ã€‚

### æ¶ˆèå®éªŒåˆ†æï¼ˆå›¾5 & å›¾6ï¼‰
- **æœ€å¸¸ç”¨ Agent**ï¼š
  - `AgentSyntaxPDDL`ï¼ˆä¿®å¤ PDDL è¯­æ³•é”™è¯¯ï¼‰ä½¿ç”¨é¢‘ç‡æœ€é«˜ï¼ˆ>50%ï¼‰ï¼Œè¯´æ˜ LLM ç”Ÿæˆ PDDL æ—¶å¸¸å‡ºç°è¯­æ³•é—®é¢˜ã€‚
  - `AgentDeepThinkPDDL` å’Œ `TemporalConsistency` åœ¨ Meeting Planning å’Œ Trip Planning ä¸­é¢‘ç¹è°ƒç”¨ï¼Œåæ˜ è¿™äº›ä»»åŠ¡å¯¹æ—¶é—´é€»è¾‘è¦æ±‚é«˜ã€‚
  - `FastDownwardsAdapter` åœ¨å¤šä¸ªä»»åŠ¡ä¸­å æ¯”é«˜ï¼Œè¡¨æ˜ä¸åŒæ±‚è§£å™¨çš„è¯­æ³•å…¼å®¹æ€§æ˜¯å¸¸è§ç“¶é¢ˆã€‚

- å‘ç°ï¼šæ¡†æ¶èƒ½æ ¹æ®ä¸åŒä»»åŠ¡ç‰¹ç‚¹**è‡ªé€‚åº”åœ°é€‰æ‹©æœ€åˆé€‚çš„ Agent**ï¼Œä½“ç°äº†åŠ¨æ€ç¼–æ’çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLMs å•ç‹¬ä¸è¶³ä»¥èƒœä»»å¤æ‚è§„åˆ’ä»»åŠ¡**ï¼Œå°¤å…¶åœ¨æ¶‰åŠæ—¶é—´çº¦æŸã€èµ„æºç«äº‰æˆ–å¤šæ­¥æ¨ç†æ—¶è¡¨ç°è„†å¼±ã€‚
2. **ç»“åˆç¬¦å·æ±‚è§£å™¨ï¼ˆSymbolic Plannerï¼‰å¯å¤§å¹…æå‡å¯é æ€§ä¸å‡†ç¡®æ€§**ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æŠ—å¹»è§‰å’Œè¯­ä¹‰ä¸ä¸€è‡´æ–¹é¢ã€‚
3. **åŠ¨æ€å¤šä»£ç†åä½œä¼˜äºé™æ€æµæ°´çº¿è®¾è®¡**ï¼ŒOrchestrator èƒ½æ ¹æ®ä¸Šä¸‹æ–‡æ™ºèƒ½è°ƒåº¦ Refiner Agentsï¼Œå½¢æˆâ€œè‡ªæˆ‘çº æ­£â€å¾ªç¯ã€‚
4. **å³ä½¿å°è§„æ¨¡ Tower of Hanoi è¿™ç±»ä¼ ç»Ÿ LLM éš¾é¢˜ï¼Œä¹Ÿèƒ½è¢«æœ¬æ¡†æ¶é«˜æ•ˆè§£å†³**ï¼Œè¯æ˜äº†å…¶å¼ºå¤§çš„ç»„åˆæ³›åŒ–èƒ½åŠ›ã€‚
5. **è®¡åˆ’ä¼˜åŒ–ä¸ä»…å¯è¡Œï¼Œè€Œä¸”æ”¶ç›Šæ˜¾è‘—**ï¼Œå¹³å‡é™ä½æˆæœ¬è¿‘ 46%ï¼Œåœ¨å¤æ‚ä»»åŠ¡ä¸­å¯è¾¾ 60% ä»¥ä¸Šã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¯¹ Orchestrator çš„ Prompt è®¾è®¡æ•æ„Ÿ**ï¼šå¾®å°æç¤ºå˜åŒ–å¯èƒ½å¯¼è‡´ Agent è°ƒåº¦ç­–ç•¥å‰§çƒˆæ³¢åŠ¨ï¼Œç³»ç»Ÿè¾ƒâ€œbrittleâ€ã€‚
- **ä¾èµ–é«˜è´¨é‡ LLM**ï¼šè‹¥åº•å±‚ LLM æ¨ç†èƒ½åŠ›ä¸è¶³ï¼ŒOrchestrator å¯èƒ½åšå‡ºé”™è¯¯å†³ç­–ã€‚
- **Benchmark æœ¬èº«å­˜åœ¨é—®é¢˜**ï¼š
  - Google Natural Plan ä¸­éƒ¨åˆ† ground truth é”™è¯¯æˆ–æ­§ä¹‰ï¼ˆä¾‹å¦‚æ—…è¡Œå¤©æ•°è®¡ç®—æ–¹å¼ä¸ç»Ÿä¸€ï¼‰ï¼›
  - PlanBench è¦†ç›–é¢å¹¿ä½†åé‡ç»å…¸é¢†åŸŸï¼Œç¼ºä¹ç°å®å¤æ‚æ€§ã€‚
- **LLM-as-a-judge ä¸å¯é **ï¼šé™¤éè¯„åˆ¤æ¨¡å‹è¿œå¼ºäºè¢«æµ‹æ¨¡å‹ï¼Œå¦åˆ™éš¾ä»¥å‡†ç¡®åˆ¤æ–­è®¡åˆ’æ­£ç¡®æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤§è§„æ¨¡çš„ Agent ç¾¤ä½“ä¸æ›´å¤æ‚çš„ååŒæœºåˆ¶
- æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾åƒã€è¯­éŸ³ç­‰ï¼‰
- æ¢ç´¢åœ¨å…·èº«æ™ºèƒ½ï¼ˆembodied AIï¼‰å’Œæœºå™¨äººç³»ç»Ÿä¸­çš„åº”ç”¨
- å¼€å‘ç†è®ºæ¨¡å‹åˆ†æåŠ¨æ€å·¥ä½œæµçš„æ”¶æ•›æ€§ä¸ç¨³å®šæ€§
- æ„å»ºæ›´ä¸¥è°¨ã€ç»äººå·¥å®¡æ ¸çš„è§„åˆ’è¯„æµ‹åŸºå‡†

---

## æ€»ç»“
æœ¬æ–‡æå‡ºçš„ **Agentic End-to-End Planning Framework** æ˜¯è¿ˆå‘çœŸæ­£è‡ªä¸»æ™ºèƒ½ä½“çš„é‡è¦ä¸€æ­¥ã€‚å®ƒé€šè¿‡**åŠ¨æ€ç¼–æ’ LLM Agents + ç¬¦å·æ±‚è§£å™¨ + è¿­ä»£éªŒè¯æœºåˆ¶**ï¼Œå®ç°äº†ä»æ¨¡ç³Šè‡ªç„¶è¯­è¨€åˆ°å½¢å¼åŒ–å¯æ‰§è¡Œè®¡åˆ’çš„å…¨è‡ªåŠ¨è½¬åŒ–ï¼Œåœ¨å‡†ç¡®æ€§ã€é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨ä¼ ç»Ÿ LLM è¡¨ç°ç³Ÿç³•çš„ä»»åŠ¡ï¼ˆå¦‚ Blocksworldã€Tower of Hanoiï¼‰ä¸Šå–å¾—çªç ´ï¼Œå±•ç¤ºäº† LLM ä¸ Symbolic AI æ·±åº¦èåˆçš„å·¨å¤§æ½œåŠ›ã€‚

</details>

---

### 16. [Targeting Misalignment: A Conflict-Aware Framework for Reward-Model-based LLM Alignment](https://arxiv.org/abs/2512.09212)

**Authors**: Zixuan Liu, Siavash H. Khajavi, Guangkai Jiang, Xinru Liu  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.09212v1  

#### Abstract
Reward-model-based fine-tuning is a central paradigm in aligning Large Language Models with human preferences. However, such approaches critically rely on the assumption that proxy reward models accurately reflect intended supervision, a condition often violated due to annotation noise, bias, or lim...

---

### 17. [WarmServe: Enabling One-for-Many GPU Prewarming for Multi-LLM Serving](https://arxiv.org/abs/2512.09472)

**Authors**: Chiheng Lou, Sheng Qi, Rui Kang, Yong Zhang, Chen Sun, Pengcheng Wang, Bingyang Liu, Xuanzhe Liu, Xin Jin  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.09472v1  

#### Abstract
Deploying multiple models within shared GPU clusters is promising for improving resource efficiency in large language model (LLM) serving. Existing multi-LLM serving systems optimize GPU utilization at the cost of worse inference performance, especially time-to-first-token (TTFT). We identify the ro...

---

### 18. [Luxical: High-Speed Lexical-Dense Text Embeddings](https://arxiv.org/abs/2512.09015)

**Authors**: DatologyAI,  :, Luke Merrick, Alex Fang, Aldo Carranza, Alvin Deng, Amro Abbas, Brett Larsen, Cody Blakeney, Darren Teh, David Schwab, Fan Pan, Haakon Mongstad, Haoli Yin, Jack Urbanek, Jason Lee, Jason Telanoff, Josh Wills, Kaleigh Mentzer, Paul Burstein, Parth Doshi, Paul Burnstein, Pratyush Maini, Ricardo Monti, Rishabh Adiga, Scott Loftin, Siddharth Joshi, Spandan Das, Tony Jiang, Vineeth Dorma, Zhengping Wang, Bogdan Gaza, Ari Morcos, Matthew Leavitt  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.09015v1  

#### Abstract
Frontier language model quality increasingly hinges on our ability to organize web-scale text corpora for training. Today's dominant tools trade off speed and flexibility: lexical classifiers (e.g., FastText) are fast but limited to producing classification output scores, while the vector-valued out...

---

### 19. [Spectral Embedding via Chebyshev Bases for Robust DeepONet Approximation](https://arxiv.org/abs/2512.09165)

**Authors**: Muhammad Abid, Omer San  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.09165v1  

#### Abstract
Deep Operator Networks (DeepONets) have become a central tool in data-driven operator learning, providing flexible surrogates for nonlinear mappings arising in partial differential equations (PDEs). However, the standard trunk design based on fully connected layers acting on raw spatial or spatiotem...

---

### 20. [Latent-Autoregressive GP-VAE Language Model](https://arxiv.org/abs/2512.09535)

**Authors**: Yves Ruffenach  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.09535v1  

#### Abstract
We investigate a fully Latent AutoRegressive scheme based on a Gaussian Process (GP) integrated into a Variational Autoencoder (VAE). In this setting, sequential dynamics are transferred from the observation space to a continuous latent space, while linguistic generation remains parallel through a n...

---

### 21. [Physics-Aware Heterogeneous GNN Architecture for Real-Time BESS Optimization in Unbalanced Distribution Systems](https://arxiv.org/abs/2512.09780)

**Authors**: Aoxiang Ma, Salah Ghamizi, Jun Cao, Pedro Rodriguez  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.09780v1  

#### Abstract
Battery energy storage systems (BESS) have become increasingly vital in three-phase unbalanced distribution grids for maintaining voltage stability and enabling optimal dispatch. However, existing deep learning approaches often lack explicit three-phase representation, making it difficult to accurat...

---

### 22. [SDialog: A Python Toolkit for End-to-End Agent Building, User Simulation, Dialog Generation, and Evaluation](https://arxiv.org/abs/2512.09142)

**Authors**: Sergio Burdisso, S\'everin Baroudi, Yanis Labrak, David Grunert, Pawel Cyrta, Yiyang Chen, Srikanth Madikeri, Esa\'u Villatoro-Tello, Thomas Schaaf, Ricard Marxer, Petr Motlicek  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09142v1  

#### Abstract
We present SDialog, an MIT-licensed open-source Python toolkit that unifies dialog generation, evaluation and mechanistic interpretability into a single end-to-end framework for building and analyzing LLM-based conversational agents. Built around a standardized \texttt{Dialog} representation, SDialo...

---

### 23. [Advancing Text Classification with Large Language Models and Neural Attention Mechanisms](https://arxiv.org/abs/2512.09444)

**Authors**: Ning Lyu, Yuxi Wang, Feng Chen, Qingyuan Zhang  
**Category**: cs.CL  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09444v1  

#### Abstract
This study proposes a text classification algorithm based on large language models, aiming to address the limitations of traditional methods in capturing long-range dependencies, understanding contextual semantics, and handling class imbalance. The framework includes text encoding, contextual repres...

---

### 24. [A Distributed Framework for Privacy-Enhanced Vision Transformers on the Edge](https://arxiv.org/abs/2512.09309)

**Authors**: Zihao Ding, Mufeng Zhu, Zhongze Tang, Sheng Wei, Yao Liu  
**Category**: cs.DC  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09309v1  

#### Abstract
Nowadays, visual intelligence tools have become ubiquitous, offering all kinds of convenience and possibilities. However, these tools have high computational requirements that exceed the capabilities of resource-constrained mobile and wearable devices. While offloading visual data to the cloud is a ...

---

### 25. [Contrast transfer functions help quantify neural network out-of-distribution generalization in HRTEM](https://arxiv.org/abs/2512.09067)

**Authors**: Luis Rangel DaCosta, Mary C. Scott  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09067v1  

#### Abstract
Neural networks, while effective for tackling many challenging scientific tasks, are not known to perform well out-of-distribution (OOD), i.e., within domains which differ from their training data. Understanding neural network OOD generalization is paramount to their successful deployment in experim...

---

### 26. [Improved Physics-Driven Neural Network to Solve Inverse Scattering Problems](https://arxiv.org/abs/2512.09333)

**Authors**: Yutong Du, Zicheng Liu, Bo Wu, Jingwei Kou, Hang Li, Changyou Li, Yali Zong, Bo Qi  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09333v1  

#### Abstract
This paper presents an improved physics-driven neural network (IPDNN) framework for solving electromagnetic inverse scattering problems (ISPs). A new Gaussian-localized oscillation-suppressing window (GLOW) activation function is introduced to stabilize convergence and enable a lightweight yet accur...

---

### 27. [Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning](https://arxiv.org/abs/2512.09706)

**Authors**: Kaichen He, Zihao Wang, Muyao Li, Anji Liu, Yitao Liang  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09706v1  

#### Abstract
The paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces--such as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dy...

---

### 28. [Closing the Train-Test Gap in World Models for Gradient-Based Planning](https://arxiv.org/abs/2512.09929)

**Authors**: Arjun Parthasarathy, Nimit Kalra, Rohun Agrawal, Yann LeCun, Oumayma Bounou, Pavel Izmailov, Micah Goldblum  
**Category**: cs.LG  
**Published**: 2025-12-11  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.09929v1  

#### Abstract
World models paired with model predictive control (MPC) can be trained offline on large-scale datasets of expert trajectories and enable generalization to a wide range of planning tasks at inference time. Compared to traditional MPC procedures, which rely on slow search algorithms or on iteratively ...

---

### 29. [Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search](https://arxiv.org/abs/2512.09566)

**Authors**: Junkai Ji, Zhangfan Yang, Dong Xu, Ruibin Bai, Jianqiang Li, Tingjun Hou, Zexuan Zhu  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.09566v1  

#### Abstract
Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, diffusion, and flow-based approaches, have enabled ...

---

### 30. [Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions](https://arxiv.org/abs/2512.09727)

**Authors**: Junlin Xiao, Victor-Alexandru Darvariu, Bruno Lacerda, Nick Hawes  
**Category**: cs.AI  
**Published**: 2025-12-11  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.09727v1  

#### Abstract
Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
