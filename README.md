# arXiv Papers Bot ü§ñ

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## üìä Statistics

- **Last Updated**: 2025-12-29 05:56:00 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## üìö Recent Papers

### 1. [Accelerate Speculative Decoding with Sparse Computation in Verification](https://arxiv.org/abs/2512.21911)

**Authors**: Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 14.5  
**Type**: new  
**ArXiv ID**: 2512.21911v1  

#### Abstract
Speculative decoding accelerates autoregressive language model inference by verifying multiple draft tokens in parallel. However, the verification stage often becomes the dominant computational bottleneck, especially for long-context inputs and mixture-of-experts (MoE) models. Existing sparsificatio...

---

### 2. [LIME:Accelerating Collaborative Lossless LLM Inference on Memory-Constrained Edge Devices](https://arxiv.org/abs/2512.21835)

**Authors**: Mingyu Sun, Xiao Zhang, Shen Qu, Yan Li, Mengbai Xiao, Yuan Yuan, Dongxiao Yu  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2512.21835v1  

#### Abstract
Large language models (LLMs) have emerged as a powerful foundation for intelligent reasoning and decision-making, demonstrating substantial impact across a wide range of domains and applications. However, their massive parameter scales and substantial resource demands pose critical challenges for ef...

---

### 3. [FUSCO: High-Performance Distributed Data Shuffling via Transformation-Communication Fusion](https://arxiv.org/abs/2512.22036)

**Authors**: Zhuoran Zhu, Chunyang Zhu, Hao Lin, Xu Fu, Yiming Zhou, Quanlu Zhang, Zhenhua Li, Feng Qian, Chao Yu, Boxun Li, Guohao Dai, Yu Wang  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.22036v1  

#### Abstract
Large-scale Mixture-of-Experts (MoE) models rely on \emph{expert parallelism} for efficient training and inference, which splits experts across devices and necessitates distributed data shuffling to route each token to its assigned experts. However, existing communication libraries handle this shuff...

---

### 4. [A Reinforcement Learning Approach to Synthetic Data Generation](https://arxiv.org/abs/2512.21395)

**Authors**: Natalia Espinosa-Dice, Nicholas J. Jackson, Chao Yan, Aaron Lee, Bradley A. Malin  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2512.21395v1  

#### Abstract
Synthetic data generation (SDG) is a promising approach for enabling data sharing in biomedical studies while preserving patient privacy. Yet, state-of-the-art generative models often require large datasets and complex training procedures, limiting their applicability in small-sample settings. In th...

---

### 5. [MAD-NG: Meta-Auto-Decoder Neural Galerkin Method for Solving Parametric Partial Differential Equations](https://arxiv.org/abs/2512.21633)

**Authors**: Qiuqi Li, Yiting Liu, Jin Zhao, Wencan Zhu  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.21633v1  

#### Abstract
Parametric partial differential equations (PDEs) are fundamental for modeling a wide range of physical and engineering systems influenced by uncertain or varying parameters. Traditional neural network-based solvers, such as Physics-Informed Neural Networks (PINNs) and Deep Galerkin Methods, often fa...

---

### 6. [TimeBill: Time-Budgeted Inference for Large Language Models](https://arxiv.org/abs/2512.21859)

**Authors**: Qi Fan, An Zou, Yehan Ma  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.21859v1  

#### Abstract
Large Language Models (LLMs) are increasingly deployed in time-critical systems, such as robotics, autonomous driving, embodied intelligence, and industrial automation, where generating accurate responses within a given time budget is crucial for decision-making, control, or safety-critical tasks. H...

---

### 7. [nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures](https://arxiv.org/abs/2512.21571)

**Authors**: Hui Guo, Qihang Zheng, Chenghai Huo, Dongliang Guo, Haoqi Yang, Yang Zhang  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.21571v1  

#### Abstract
The efficient deployment of large language models (LLMs) is hindered by memory architecture heterogeneity, where traditional compilers suffer from fragmented workflows and high adaptation costs. We present nncase, an open-source, end-to-end compilation framework designed to unify optimization across...

---

### 8. [Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model](https://arxiv.org/abs/2512.21540)

**Authors**: Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo  
**Category**: cs.AI  
**Published**: 2025-12-29  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.21540v1  

#### Abstract
Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challenge, we propose Leash (adaptive LEngth penAlty and...

---

### 9. [BLEST: Blazingly Efficient BFS using Tensor Cores](https://arxiv.org/abs/2512.21967)

**Authors**: Deniz Elbek, Kamer Kaya  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.21967v1  

#### Abstract
Breadth-First Search (BFS) is a fundamental graph kernel that underpins a wide range of applications. While modern GPUs provide specialised Matrix-Multiply-Accumulate (MMA) units, e.g., Tensor Cores (TC), with extremely high throughput, they target dense operations, making it non-trivial to exploit ...

---

### 10. [RLLaVA: An RL-central Framework for Language and Vision Assistants](https://arxiv.org/abs/2512.21450)

**Authors**: Lei Zhao, Zihao Ma, Boyu Lin, Yuhe Liu, Wenjun Wu, Lei Huang  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.21450v1  

#### Abstract
We present an RL-central framework for Language and Vision Assistants (RLLaVA) with its formulation of Markov decision process (MDP). RLLaVA decouples RL algorithmic logic from model architecture and distributed execution, supporting researchers in implementing new RL algorithms with minimal code, a...

---

### 11. [Knowledge Reasoning of Large Language Models Integrating Graph-Structured Information for Pest and Disease Control in Tobacco](https://arxiv.org/abs/2512.21837)

**Authors**: Siyu Li, Chenwei Song, Wan Zhou, Xinyi Liu  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.21837v1  

#### Abstract
This paper proposes a large language model (LLM) approach that integrates graph-structured information for knowledge reasoning in tobacco pest and disease control. Built upon the GraphRAG framework, the proposed method enhances knowledge retrieval and reasoning by explicitly incorporating structured...

---

### 12. [Demystifying ARM SME to Optimize General Matrix Multiplications](https://arxiv.org/abs/2512.21473)

**Authors**: Chencheng Deng, Weiling Yang, Jianbin Fang, Dezun Dong  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.21473v1  

#### Abstract
General Matrix Multiplication (GEMM) is a critical kernel in high-performance computing and deep learning. While modern architectures like ARM's Scalable Matrix Extension (SME) introduce dedicated hardware for matrix operations, existing linear algebra libraries fail to fully exploit its potential, ...

---

### 13. [Rethinking Output Alignment For 1-bit Post-Training Quantization of Large Language Models](https://arxiv.org/abs/2512.21651)

**Authors**: Dung Anh Hoang, Cuong Pham, Cuong Nguyen, Trung le, Jianfei Cai, Thanh-Toan Do  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.21651v1  

#### Abstract
Large Language Models (LLMs) deliver strong performance across a wide range of NLP tasks, but their massive sizes hinder deployment on resource-constrained devices. To reduce their computational and memory burden, various compression techniques have been proposed, including quantization, pruning, an...

---

### 14. [DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction](https://arxiv.org/abs/2512.22007)

**Authors**: Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj, Nour El Yakine Guendouz, Manel Kara Laouar  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.22007v1  

#### Abstract
Predicting the binding affinity between antigens and antibodies is fundamental to drug discovery and vaccine development. Traditional computational approaches often rely on experimentally determined 3D structures, which are scarce and computationally expensive to obtain. This paper introduces DuaDee...

---

### 15. [Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View](https://arxiv.org/abs/2512.22035)

**Authors**: Yanmeng Wang, Zhiwen Dai, Shuai Wang, Jian Zhou, Fu Xiao, Tony Q. S. Quek, Tsung-Hui Chang  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.22035v1  

#### Abstract
Federated Fine-Tuning (FFT) has attracted growing interest as it leverages both server- and client-side data to enhance global model generalization while preserving privacy, and significantly reduces the computational burden on edge devices by avoiding training from scratch. Despite these advantages...

---

### 16. [Synthetic Financial Data Generation for Enhanced Financial Modelling](https://arxiv.org/abs/2512.21791)

**Authors**: Christophe D. Hounwanou, Yae Ulrich Gaba, Pierre Ntakirutimana  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.21791v1  

#### Abstract
Data scarcity and confidentiality in finance often impede model development and robust testing. This paper presents a unified multi-criteria evaluation framework for synthetic financial data and applies it to three representative generative paradigms: the statistical ARIMA-GARCH baseline, Variationa...

---

### 17. [HWL-HIN: A Hypergraph-Level Hypergraph Isomorphism Network as Powerful as the Hypergraph Weisfeiler-Lehman Test with Application to Higher-Order Network Robustness](https://arxiv.org/abs/2512.22014)

**Authors**: Chengyu Tian, Wenbin Pei  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.22014v1  

#### Abstract
Robustness in complex systems is of significant engineering and economic importance. However, conventional attack-based a posteriori robustness assessments incur prohibitive computational overhead. Recently, deep learning methods, such as Convolutional Neural Networks (CNNs) and Graph Neural Network...

---

### 18. [Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2512.21625)

**Authors**: Xinyu Tang, Yuliang Zhan, Zhixun Li, Wayne Xin Zhao, Zhenduo Zhang, Zujie Wen, Zhiqiang Zhang, Jun Zhou  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21625v1  

#### Abstract
Large reasoning models (LRMs) are typically trained using reinforcement learning with verifiable reward (RLVR) to enhance their reasoning abilities. In this paradigm, policies are updated using both positive and negative self-generated rollouts, which correspond to distinct sample polarities. In thi...

---

### 19. [Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments](https://arxiv.org/abs/2512.21817)

**Authors**: Hong Su  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21817v1  

#### Abstract
Intelligent IoT systems increasingly rely on large language models (LLMs) to generate task-execution methods for dynamic environments. However, existing approaches lack the ability to systematically produce new methods when facing previously unseen situations, and they often depend on fixed, device-...

---

### 20. [SWE-RM: Execution-free Feedback For Software Engineering Agents](https://arxiv.org/abs/2512.21919)

**Authors**: KaShun Shum, Binyuan Hui, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, Junxian He  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21919v1  

#### Abstract
Execution-based feedback like unit testing is widely used in the development of coding agents through test-time scaling (TTS) and reinforcement learning (RL). This paradigm requires scalable and reliable collection of unit test cases to provide accurate feedback, and the resulting feedback is often ...

---

### 21. [Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess Mortality in the US](https://arxiv.org/abs/2512.21456)

**Authors**: Sukanya Krishna, Marie-Laure Charpignon, Maimuna Majumder  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21456v1  

#### Abstract
Substance overdose mortality in the United States claimed over 80,000 lives in 2023, with the COVID-19 pandemic exacerbating existing trends through healthcare disruptions and behavioral changes. Estimating excess mortality, defined as deaths beyond expected levels based on pre-pandemic patterns, is...

---

### 22. [AnchorGK: Anchor-based Incremental and Stratified Graph Learning Framework for Inductive Spatio-Temporal Kriging](https://arxiv.org/abs/2512.21569)

**Authors**: Xiaobin Ren, Kaiqi Zhao, Katerina Ta\v{s}kova, Patricia Riddle  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21569v1  

#### Abstract
Spatio-temporal kriging is a fundamental problem in sensor networks, driven by the sparsity of deployed sensors and the resulting missing observations. Although recent approaches model spatial and temporal correlations, they often under-exploit two practical characteristics of real deployments: the ...

---

### 23. [Robustness and Scalability Of Machine Learning for Imbalanced Clinical Data in Emergency and Critical Care](https://arxiv.org/abs/2512.21602)

**Authors**: Yusuf Brima, Marcellin Atemkeng  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21602v1  

#### Abstract
Emergency and intensive care environments require predictive models that are both accurate and computationally efficient, yet clinical data in these settings are often severely imbalanced. Such skewness undermines model reliability, particularly for rare but clinically crucial outcomes, making robus...

---

### 24. [Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations](https://arxiv.org/abs/2512.21635)

**Authors**: Chengxu Yang, Jingling Yuan, Siqi Cai, Jiawei Jiang, Chuang Hu  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.21635v1  

#### Abstract
Hallucinations in large language models (LLMs) are commonly regarded as errors to be minimized. However, recent perspectives suggest that some hallucinations may encode creative or epistemically valuable content, a dimension that remains underquantified in current literature. Existing hallucination ...

---

### 25. [MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles](https://arxiv.org/abs/2512.21708)

**Authors**: Jing Han, Binwei Yan, Tianyu Guo, Zheyuan Bai, Mengyu Zheng, Hanting Chen, Ying Nie  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.21708v1  

#### Abstract
Despite recent advancements of fine-tuning large language models (LLMs) to facilitate agent tasks, parameter-efficient fine-tuning (PEFT) methodologies for agent remain largely unexplored. In this paper, we introduce three key strategies for PEFT in agent tasks: 1) Inspired by the increasingly domin...

---

### 26. [Dictionary-Transform Generative Adversarial Networks](https://arxiv.org/abs/2512.21677)

**Authors**: Angshul Majumdar  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.21677v1  

#### Abstract
Generative adversarial networks (GANs) are widely used for distribution learning, yet their classical formulations remain theoretically fragile, with ill-posed objectives, unstable training dynamics, and limited interpretability. In this work, we introduce \emph{Dictionary-Transform Generative Adver...

---

### 27. [Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs](https://arxiv.org/abs/2512.21915)

**Authors**: Yafeng Tang, Xiaoou Ding, Jianzhuo Du, Zishuo Yan, Zhuang Ma, Zheng Liang, Zekai Qian, Hongzhi Wang  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.21915v1  

#### Abstract
Tabular data generation has become increasingly essential for enabling robust machine learning applications, which require large-scale, high-quality data. Existing solutions leverage generative models to learn original data distributions. However, real-world data are naturally heterogeneous with div...

---

### 28. [NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent](https://arxiv.org/abs/2512.21578)

**Authors**: Ali Sahami, Sudhanshu Garg, Andrew Wang, Chaitanya Kulkarni, Farhad Farahani, Sean Yun-Shiuan Chuang, Jian Wan, Srinivasan Manoharan, Uma Kona, Nitin Sharma, Linsey Pang, Prakhar Mehrotra, Jessica Clark, Mark Moyou  
**Category**: cs.AI  
**Published**: 2025-12-29  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.21578v1  

#### Abstract
We present the development and optimization of PayPal's Commerce Agent, powered by NEMO-4-PAYPAL, a multi-agent system designed to revolutionize agentic commerce on the PayPal platform. Through our strategic partnership with NVIDIA, we leveraged the NeMo Framework for LLM model fine-tuning to enhanc...

---

### 29. [Generative Actor Critic](https://arxiv.org/abs/2512.21527)

**Authors**: Aoyang Qin, Deqian Kong, Wei Wang, Ying Nian Wu, Song-Chun Zhu, Sirui Xie  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.21527v1  

#### Abstract
Conventional Reinforcement Learning (RL) algorithms, typically focused on estimating or maximizing expected returns, face challenges when refining offline pretrained models with online experiences. This paper introduces Generative Actor Critic (GAC), a novel framework that decouples sequential decis...

---

### 30. [RefineBridge: Generative Bridge Models Improve Financial Forecasting by Foundation Models](https://arxiv.org/abs/2512.21572)

**Authors**: Anthony Bolton, Wuyang Zhou, Zehua Chen, Giorgos Iacovides, Danilo Mandic  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.21572v1  

#### Abstract
Financial time series forecasting is particularly challenging for transformer-based time series foundation models (TSFMs) due to non-stationarity, heavy-tailed distributions, and high-frequency noise present in data. Low-rank adaptation (LoRA) has become a popular parameter-efficient method for adap...

---

## üîß Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Linear, LLM, RL, RLHF, Reinforcement learning, Reinforcement Learning, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Parallelism, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## üìÖ Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## üöÄ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## üìù Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## üîç Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
