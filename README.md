# arXiv Papers Bot ü§ñ

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## üìä Statistics

- **Last Updated**: 2025-12-31 05:53:25 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## üìö Recent Papers

### 1. [AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis](https://arxiv.org/abs/2512.23424)

**Authors**: Jinye Du, Quan Yuan, Zuyao Zhang, Yanzhi Yi, Jiahui Hu, Wangyi Chen, Yiyang Zhu, Qishui Zheng, Wenxiang Zou, Xiangyu Chang, Zuohe Zheng, Zichun Ye, Chao Liu, Shanni Li, Renwei Zhang, Yiping Deng, Xinwei Hu, Xuefeng Jin, Jie Zhao  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.23424v1  

#### Abstract
Modern AI models demand high-performance computation kernels. The growing complexity of LLMs, multimodal architectures, and recommendation systems, combined with techniques like sparsity and quantization, creates significant computational challenges. Moreover, frequent hardware updates and diverse c...

---

### 2. [Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following](https://arxiv.org/abs/2512.23457)

**Authors**: Kongcheng Zhang, Qi Yao, Shunyu Liu, Wenjian Zhang, Min Cen, Yang Zhou, Wenkai Fang, Yiru Zhao, Baisheng Lai, Mingli Song  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.23457v1  

#### Abstract
Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to gen...

---

### 3. [SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning](https://arxiv.org/abs/2512.22895)

**Authors**: Xiaotian Ren, Nuerxiati Abudurexiti, Zhengyong Jiang, Angelos Stefanidis, Hongbin Liu, Jionglong Su  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.22895v1  

#### Abstract
Portfolio optimization in non-stationary markets is challenging due to regime shifts, dynamic correlations, and the limited interpretability of deep reinforcement learning (DRL) policies. We propose a Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierar...

---

### 4. [SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search](https://arxiv.org/abs/2512.23167)

**Authors**: Yifan Zhang, Giridhar Ganapavarapu, Srideepika Jayaraman, Bhavna Agrawal, Dhaval Patel, Achille Fokoue  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.23167v1  

#### Abstract
Large Language Models (LLMs) often falter at complex planning tasks that require exploration and self-correction, as their linear reasoning process struggles to recover from early mistakes. While search algorithms like Monte Carlo Tree Search (MCTS) can explore alternatives, they are often ineffecti...

---

### 5. [Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent Feedback](https://arxiv.org/abs/2512.22336)

**Authors**: Mengkang Hu, Bowei Xia, Yuran Wu, Ailing Yu, Yude Zou, Qiguang Chen, Shijian Wang, Jiarui Jin, Kexin Li, Wenxiang Jiao, Yuan Lu, Ping Luo  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.22336v1  

#### Abstract
Symbolic world models (e.g., PDDL domains or executable simulators) are central to model-based planning, but training LLMs to generate such world models is limited by the lack of large-scale verifiable supervision. Current approaches rely primarily on static validation methods that fail to catch beh...

---

### 6. [DICE: Discrete Interpretable Comparative Evaluation with Probabilistic Scoring for Retrieval-Augmented Generation](https://arxiv.org/abs/2512.22629)

**Authors**: Shiyan Liu, Jian Ma, Rui Qu  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.22629v1  

#### Abstract
As Retrieval-Augmented Generation (RAG) systems evolve toward more sophisticated architectures, ensuring their trustworthiness through explainable and robust evaluation becomes critical. Existing scalar metrics suffer from limited interpretability, inadequate uncertainty quantification, and computat...

---

### 7. [Physics-Informed Neural Networks for Device and Circuit Modeling: A Case Study of NeuroSPICE](https://arxiv.org/abs/2512.23624)

**Authors**: Chien-Ting Tung, Chenming Hu  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.23624v1  

#### Abstract
We present NeuroSPICE, a physics-informed neural network (PINN) framework for device and circuit simulation. Unlike conventional SPICE, which relies on time-discretized numerical solvers, NeuroSPICE leverages PINNs to solve circuit differential-algebraic equations (DAEs) by minimizing the residual o...

---

### 8. [SANet: A Semantic-aware Agentic AI Networking Framework for Cross-layer Optimization in 6G](https://arxiv.org/abs/2512.22579)

**Authors**: Yong Xiao, Xubo Li, Haoran Zhou, Yingyu Li, Yayu Gao, Guangming Shi, Ping Zhang, Marwan Krunz  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.22579v1  

#### Abstract
Agentic AI networking (AgentNet) is a novel AI-native networking paradigm in which a large number of specialized AI agents collaborate to perform autonomous decision-making, dynamic environmental adaptation, and complex missions. It has the potential to facilitate real-time network management and op...

---

### 9. [InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization](https://arxiv.org/abs/2512.23126)

**Authors**: Yu Li, Tian Lan, Zhengling Qi  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.23126v1  

#### Abstract
Direct Preference Optimization (DPO) and its variants have become standard for aligning Large Language Models due to their simplicity and offline stability. However, we identify two fundamental limitations. First, the optimal policy depends on arbitrary modeling choices (scalarization function, refe...

---

### 10. [HalluMat: Detecting Hallucinations in LLM-Generated Materials Science Content Through Multi-Stage Verification](https://arxiv.org/abs/2512.22396)

**Authors**: Bhanu Prakash Vangala, Sajid Mahmud, Pawan Neupane, Joel Selvaraj, Jianlin Cheng  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.22396v1  

#### Abstract
Artificial Intelligence (AI), particularly Large Language Models (LLMs), is transforming scientific discovery, enabling rapid knowledge generation and hypothesis formulation. However, a critical challenge is hallucination, where LLMs generate factually incorrect or misleading information, compromisi...

---

### 11. [Problems With Large Language Models for Learner Modelling: Why LLMs Alone Fall Short for Responsible Tutoring in K--12 Education](https://arxiv.org/abs/2512.23036)

**Authors**: Danial Hooshyar, Yeongwook Yang, Gustav \v{S}\'i\v{r}, Tommi K\"arkk\"ainen, Raija H\"am\"al\"ainen, Mutlu Cukurova, Roger Azevedo  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.23036v1  

#### Abstract
The rapid rise of large language model (LLM)-based tutors in K--12 education has fostered a misconception that generative models can replace traditional learner modelling for adaptive instruction. This is especially problematic in K--12 settings, which the EU AI Act classifies as high-risk domain re...

---

### 12. [The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis](https://arxiv.org/abs/2512.23419)

**Authors**: Alex Lewandowski, Adtiya A. Ramesh, Edan Meyer, Dale Schuurmans, Marlos C. Machado  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.23419v1  

#### Abstract
Continual learning is often motivated by the idea, known as the big world hypothesis, that "the world is bigger" than the agent. Recent problem formulations capture this idea by explicitly constraining an agent relative to the environment. These constraints lead to solutions in which the agent conti...

---

### 13. [Divergent-Convergent Thinking in Large Language Models for Creative Problem Generation](https://arxiv.org/abs/2512.23601)

**Authors**: Manh Hung Nguyen, Adish Singla  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.23601v1  

#### Abstract
Large language models (LLMs) have significant potential for generating educational questions and problems, enabling educators to create large-scale learning materials. However, LLMs are fundamentally limited by the ``Artificial Hivemind'' effect, where they generate similar responses within the same...

---

### 14. [Web World Models](https://arxiv.org/abs/2512.23676)

**Authors**: Jichen Feng, Yifan Zhang, Chenggong Zhang, Yifu Lu, Shilong Liu, Mengdi Wang  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.23676v1  

#### Abstract
Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the e...

---

### 15. [Monadic Context Engineering](https://arxiv.org/abs/2512.22431)

**Authors**: Yifan Zhang, Mengdi Wang  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.22431v1  

#### Abstract
The proliferation of Large Language Models (LLMs) has catalyzed a shift towards autonomous agents capable of complex reasoning and tool use. However, current agent architectures are frequently constructed using imperative, ad hoc patterns. This results in brittle systems plagued by difficulties in s...

---

### 16. [Multi-AI Agent Framework Reveals the "Oxide Gatekeeper" in Aluminum Nanoparticle Oxidation](https://arxiv.org/abs/2512.22529)

**Authors**: Yiming Lu, Tingyu Lu, Di Zhang, Lili Ye, Hao Li  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.22529v1  

#### Abstract
Aluminum nanoparticles (ANPs) are among the most energy-dense solid fuels, yet the atomic mechanisms governing their transition from passivated particles to explosive reactants remain elusive. This stems from a fundamental computational bottleneck: ab initio methods offer quantum accuracy but are re...

---

### 17. [Multimodal Fact-Checking: An Agent-based Approach](https://arxiv.org/abs/2512.22933)

**Authors**: Danni Xu, Shaojing Fan, Xuanang Cheng, Mohan Kankanhalli  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.22933v1  

#### Abstract
The rapid spread of multimodal misinformation poses a growing challenge for automated fact-checking systems. Existing approaches, including large vision language models (LVLMs) and deep multimodal fusion methods, often fall short due to limited reasoning and shallow evidence utilization. A key bottl...

---

### 18. [Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients](https://arxiv.org/abs/2512.23090)

**Authors**: Armin Berger, Manuela Bergau, Helen Schneider, Saad Ahmad, Tom Anglim Lagones, Gianluca Brugnara, Martha Foltyn-Dumitru, Kai Schlamp, Philipp Vollmuth, Rafet Sifa  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.23090v1  

#### Abstract
Recent Reinforcement Learning (RL) advances for Large Language Models (LLMs) have improved reasoning tasks, yet their resource-constrained application to medical imaging remains underexplored. We introduce ChexReason, a vision-language model trained via R1-style methodology (SFT followed by GRPO) us...

---

### 19. [TCEval: Using Thermal Comfort to Assess Cognitive and Perceptual Abilities of AI](https://arxiv.org/abs/2512.23217)

**Authors**: Jingming Li  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.23217v1  

#### Abstract
A critical gap exists in LLM task-specific benchmarks. Thermal comfort, a sophisticated interplay of environmental factors and personal perceptions involving sensory integration and adaptive decision-making, serves as an ideal paradigm for evaluating real-world cognitive capabilities of AI systems. ...

---

### 20. [With Great Capabilities Come Great Responsibilities: Introducing the Agentic Risk & Capability Framework for Governing Agentic AI Systems](https://arxiv.org/abs/2512.22211)

**Authors**: Shaun Khoo, Jessica Foo, Roy Ka-Wei Lee  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.22211v1  

#### Abstract
Agentic AI systems present both significant opportunities and novel risks due to their capacity for autonomous action, encompassing tasks such as code execution, internet interaction, and file modification. This poses considerable challenges for effective organizational governance, particularly in c...

---

### 21. [Lightweight Inference-Time Personalization for Frozen Knowledge Graph Embeddings](https://arxiv.org/abs/2512.22398)

**Authors**: Ozan Oguztuzun, Cerag Oguztuzun  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.22398v1  

#### Abstract
Foundation models for knowledge graphs (KGs) achieve strong cohort-level performance in link prediction, yet fail to capture individual user preferences; a key disconnect between general relational reasoning and personalized ranking. We propose GatedBias, a lightweight inference-time personalization...

---

### 22. [DarkPatterns-LLM: A Multi-Layer Benchmark for Detecting Manipulative and Harmful AI Behavior](https://arxiv.org/abs/2512.22470)

**Authors**: Sadia Asif, Israel Antonio Rosales Laguan, Haris Khan, Shumaila Asif, Muneeb Asif  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.22470v1  

#### Abstract
The proliferation of Large Language Models (LLMs) has intensified concerns about manipulative or deceptive behaviors that can undermine user autonomy, trust, and well-being. Existing safety benchmarks predominantly rely on coarse binary labels and fail to capture the nuanced psychological and social...

---

### 23. [The Gaining Paths to Investment Success: Information-Driven LLM Graph Reasoning for Venture Capital Prediction](https://arxiv.org/abs/2512.23489)

**Authors**: Haoyu Pei, Zhongyang Liu, Xiangyi Xiao, Xiaocong Du, Haipeng Zhang, Kunpeng Zhang, Suting Hong  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.23489v1  

#### Abstract
Most venture capital (VC) investments fail, while a few deliver outsized returns. Accurately predicting startup success requires synthesizing complex relational evidence, including company disclosures, investor track records, and investment network structures, through explicit reasoning to form cohe...

---

### 24. [Logic Sketch Prompting (LSP): A Deterministic and Interpretable Prompting Method](https://arxiv.org/abs/2512.22258)

**Authors**: Satvik Tripathi  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.22258v1  

#### Abstract
Large language models (LLMs) excel at natural language reasoning but remain unreliable on tasks requiring strict rule adherence, determinism, and auditability. Logic Sketch Prompting (LSP) is a lightweight prompting framework that introduces typed variables, deterministic condition evaluators, and a...

---

### 25. [Memento-II: Learning by Stateful Reflective Memory](https://arxiv.org/abs/2512.22716)

**Authors**: Jun Wang  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.22716v1  

#### Abstract
We propose a theoretical framework for continual and experiential learning in large language model agents that integrates episodic memory with reinforcement learning. The framework identifies reflection as the key mechanism that enables agents to adapt through interaction without back propagation or...

---

### 26. [The Reward Model Selection Crisis in Personalized Alignment](https://arxiv.org/abs/2512.23067)

**Authors**: Fady Rezk, Yuangang Pan, Chuan-Sheng Foo, Xun Xu, Nancy Chen, Henry Gouk, Timothy Hospedales  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.23067v1  

#### Abstract
Personalized alignment from preference data has focused primarily on improving reward model (RM) accuracy, with the implicit assumption that better preference ranking translates to better personalized behavior. However, in deployment, computational constraints necessitate inference-time adaptation v...

---

### 27. [MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning](https://arxiv.org/abs/2512.23412)

**Authors**: Jiawei Chen, Xintian Shen, Lihao Zheng, Zhenwei Shao, Hongyuan Zhang, Pengfei Yu, Xudong Rao, Ning Mao, Xiaobo Liu, Lian Wen, Chaoqun Du, Feng Gu, Wei He, Qizhen Li, Shanshan Li, Zide Liu, Jing Luo, Lifu Mu, Xuhao Pan, Chang Ren, Haoyi Sun, Qian Wang, Wei Wang, Hongfu Yang, Jiqing Zhan, Chunpeng Zhou, Zheng Zhou, Hao Ma, Tao Wei, Pan Zhou, Wei Chen  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.23412v1  

#### Abstract
Traditional workflow-based agents exhibit limited intelligence when addressing real-world problems requiring tool invocation. Tool-integrated reasoning (TIR) agents capable of autonomous reasoning and tool invocation are rapidly emerging as a powerful approach for complex decision-making tasks invol...

---

### 28. [LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation](https://arxiv.org/abs/2512.22608)

**Authors**: Zhongyang Liu, Haoyu Pei, Xiangyi Xiao, Xiaocong Du, Yihui Li, Suting Hong, Kunpeng Zhang, Haipeng Zhang  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.22608v1  

#### Abstract
Due to the high value and high failure rate of startups, predicting their success has become a critical challenge across interdisciplinary research. Existing approaches typically model success prediction from the perspective of a single decision-maker, overlooking the collective dynamics of investor...

---

### 29. [From Model Choice to Model Belief: Establishing a New Measure for LLM-Based Research](https://arxiv.org/abs/2512.23184)

**Authors**: Hongshen Sun, Juanjuan Zhang  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 4.5  
**Type**: new  
**ArXiv ID**: 2512.23184v1  

#### Abstract
Large language models (LLMs) are increasingly used to simulate human behavior, but common practices to use LLM-generated data are inefficient. Treating an LLM's output ("model choice") as a single data point underutilizes the information inherent to the probabilistic nature of LLMs. This paper intro...

---

### 30. [Toward Equitable Recovery: A Fairness-Aware AI Framework for Prioritizing Post-Flood Aid in Bangladesh](https://arxiv.org/abs/2512.22210)

**Authors**: Farjana Yesmin, Romana Akter  
**Category**: cs.AI  
**Published**: 2025-12-31  
**Score**: 4.0  
**Type**: new  
**ArXiv ID**: 2512.22210v1  

#### Abstract
Post-disaster aid allocation in developing nations often suffers from systematic biases that disadvantage vulnerable regions, perpetuating historical inequities. This paper presents a fairness-aware artificial intelligence framework for prioritizing post-flood aid distribution in Bangladesh, a count...

---

## üîß Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Linear, LLM, RL, RLHF, Reinforcement learning, Reinforcement Learning, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Parallelism, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## üìÖ Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## üöÄ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## üìù Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## üîç Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
